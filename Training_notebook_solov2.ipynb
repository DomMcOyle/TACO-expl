{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "id": "7pzTIxbXnL6S",
        "outputId": "26910210-a43e-46bf-acdb-a985ffcfebef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2023 NVIDIA Corporation\n",
            "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
            "Cuda compilation tools, release 12.2, V12.2.140\n",
            "Build cuda_12.2.r12.2/compiler.33191640_0\n",
            "Fri May 10 05:34:12 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   52C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.2.1+cu121'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "!nvcc --version\n",
        "!nvidia-smi\n",
        "import torch\n",
        "torch.__version__"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install 'git+https://github.com/facebookresearch/detectron2.git@5aeb252b194b93dc2879b4ac34bc51a31b5aee13'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "WGL4szW1o_UM",
        "outputId": "6f464d68-4e8e-444f-abd8-5c15266cc95c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/facebookresearch/detectron2.git@5aeb252b194b93dc2879b4ac34bc51a31b5aee13\n",
            "  Cloning https://github.com/facebookresearch/detectron2.git (to revision 5aeb252b194b93dc2879b4ac34bc51a31b5aee13) to /tmp/pip-req-build-6o3we4ro\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/detectron2.git /tmp/pip-req-build-6o3we4ro\n",
            "  Running command git rev-parse -q --verify 'sha^5aeb252b194b93dc2879b4ac34bc51a31b5aee13'\n",
            "  Running command git fetch -q https://github.com/facebookresearch/detectron2.git 5aeb252b194b93dc2879b4ac34bc51a31b5aee13\n",
            "  Running command git checkout -q 5aeb252b194b93dc2879b4ac34bc51a31b5aee13\n",
            "  Resolved https://github.com/facebookresearch/detectron2.git to commit 5aeb252b194b93dc2879b4ac34bc51a31b5aee13\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: Pillow>=7.1 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (9.4.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (3.7.1)\n",
            "Requirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (2.0.7)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (2.4.0)\n",
            "Collecting yacs>=0.1.8 (from detectron2==0.6)\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (0.9.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (2.2.1)\n",
            "Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (4.66.4)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (2.15.2)\n",
            "Collecting fvcore<0.1.6,>=0.1.5 (from detectron2==0.6)\n",
            "  Downloading fvcore-0.1.5.post20221221.tar.gz (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting iopath<0.1.10,>=0.1.7 (from detectron2==0.6)\n",
            "  Downloading iopath-0.1.9-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (0.18.3)\n",
            "Requirement already satisfied: pydot in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (1.4.2)\n",
            "Collecting omegaconf>=2.1 (from detectron2==0.6)\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting hydra-core>=1.1 (from detectron2==0.6)\n",
            "  Downloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting black==22.3.0 (from detectron2==0.6)\n",
            "  Downloading black-22.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting timm (from detectron2==0.6)\n",
            "  Downloading timm-0.9.16-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fairscale (from detectron2==0.6)\n",
            "  Downloading fairscale-0.4.13.tar.gz (266 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m266.3/266.3 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (24.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from black==22.3.0->detectron2==0.6) (8.1.7)\n",
            "Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.10/dist-packages (from black==22.3.0->detectron2==0.6) (4.2.1)\n",
            "Collecting pathspec>=0.9.0 (from black==22.3.0->detectron2==0.6)\n",
            "  Downloading pathspec-0.12.1-py3-none-any.whl (31 kB)\n",
            "Collecting mypy-extensions>=0.4.3 (from black==22.3.0->detectron2==0.6)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from black==22.3.0->detectron2==0.6) (2.0.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (1.25.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (6.0.1)\n",
            "Collecting antlr4-python3-runtime==4.9.* (from hydra-core>=1.1->detectron2==0.6)\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting portalocker (from iopath<0.1.10,>=0.1.7->detectron2==0.6)\n",
            "  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (2.8.2)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from fairscale->detectron2==0.6) (2.2.1+cu121)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (1.63.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (3.6)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (2.31.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (67.7.2)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (3.0.3)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm->detectron2==0.6) (0.17.1+cu121)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (from timm->detectron2==0.6) (0.20.3)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm->detectron2==0.6) (0.4.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard->detectron2==0.6) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (2024.2.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->fairscale->detectron2==0.6) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->fairscale->detectron2==0.6) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->fairscale->detectron2==0.6) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->fairscale->detectron2==0.6) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->fairscale->detectron2==0.6) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->fairscale->detectron2==0.6) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.8.0->fairscale->detectron2==0.6)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.8.0->fairscale->detectron2==0.6)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.8.0->fairscale->detectron2==0.6)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.8.0->fairscale->detectron2==0.6)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.8.0->fairscale->detectron2==0.6)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.8.0->fairscale->detectron2==0.6)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.8.0->fairscale->detectron2==0.6)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.8.0->fairscale->detectron2==0.6)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.8.0->fairscale->detectron2==0.6)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch>=1.8.0->fairscale->detectron2==0.6)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.8.0->fairscale->detectron2==0.6)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->fairscale->detectron2==0.6) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.0->fairscale->detectron2==0.6)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard->detectron2==0.6) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard->detectron2==0.6) (3.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->fairscale->detectron2==0.6) (1.3.0)\n",
            "Building wheels for collected packages: detectron2, fvcore, antlr4-python3-runtime, fairscale\n",
            "  Building wheel for detectron2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for detectron2: filename=detectron2-0.6-cp310-cp310-linux_x86_64.whl size=6172654 sha256=62441c37433b87ae3e3b65b2023e99be98dd12cf6d191c5a56c9d209ee111218\n",
            "  Stored in directory: /root/.cache/pip/wheels/93/68/da/76b0102912a9ea75cda929a4556a3eb0e5377b1d1ce0a79940\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fvcore: filename=fvcore-0.1.5.post20221221-py3-none-any.whl size=61400 sha256=7b91abf12c626b4b6028bb9433244b7333c8968fa9303b2199cc9a87867e75e4\n",
            "  Stored in directory: /root/.cache/pip/wheels/01/c0/af/77c1cf53a1be9e42a52b48e5af2169d40ec2e89f7362489dd0\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=a98d04d31f608844ba818b35b724ce681948cabd470d5ec1a2ada9ff72528c47\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n",
            "  Building wheel for fairscale (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fairscale: filename=fairscale-0.4.13-py3-none-any.whl size=332108 sha256=b2ce93736f776b72b151a710f9919e07f792647a7a8ea34957f04d1bf1088a4e\n",
            "  Stored in directory: /root/.cache/pip/wheels/78/a4/c0/fb0a7ef03cff161611c3fa40c6cf898f76e58ec421b88e8cb3\n",
            "Successfully built detectron2 fvcore antlr4-python3-runtime fairscale\n",
            "Installing collected packages: antlr4-python3-runtime, yacs, portalocker, pathspec, omegaconf, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, mypy-extensions, nvidia-cusparse-cu12, nvidia-cudnn-cu12, iopath, hydra-core, black, nvidia-cusolver-cu12, fvcore, fairscale, timm, detectron2\n",
            "Successfully installed antlr4-python3-runtime-4.9.3 black-22.3.0 detectron2-0.6 fairscale-0.4.13 fvcore-0.1.5.post20221221 hydra-core-1.3.2 iopath-0.1.9 mypy-extensions-1.0.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 omegaconf-2.3.0 pathspec-0.12.1 portalocker-2.8.2 timm-0.9.16 yacs-0.1.8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pydevd_plugins"
                ]
              },
              "id": "034a03af7dd6480697d03b797c9a9324"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/\n",
        "!git clone https://github.com/DomMcOyle/TACO-expl.git\n",
        "%cd /content/TACO-expl\n",
        "!git checkout solov2\n",
        "!git pull origin solov2\n",
        "%cd /content/TACO-expl/AdelaiDet/\n",
        "!python setup.py build develop"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X9P0HDTGnRDI",
        "outputId": "1d507e2d-5d2e-4616-9ee9-449230ac40a4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'TACO-expl'...\n",
            "remote: Enumerating objects: 2308, done.\u001b[K\n",
            "remote: Counting objects: 100% (2308/2308), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1105/1105), done.\u001b[K\n",
            "remote: Total 2308 (delta 1207), reused 2237 (delta 1164), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (2308/2308), 130.39 MiB | 20.09 MiB/s, done.\n",
            "Resolving deltas: 100% (1207/1207), done.\n",
            "/content/TACO-expl\n",
            "Branch 'solov2' set up to track remote branch 'solov2' from 'origin'.\n",
            "Switched to a new branch 'solov2'\n",
            "From https://github.com/DomMcOyle/TACO-expl\n",
            " * branch            solov2     -> FETCH_HEAD\n",
            "Already up to date.\n",
            "/content/TACO-expl/AdelaiDet\n",
            "running build\n",
            "running build_py\n",
            "creating build\n",
            "creating build/lib.linux-x86_64-cpython-310\n",
            "creating build/lib.linux-x86_64-cpython-310/adet\n",
            "copying adet/__init__.py -> build/lib.linux-x86_64-cpython-310/adet\n",
            "creating build/lib.linux-x86_64-cpython-310/adet/data\n",
            "copying adet/data/__init__.py -> build/lib.linux-x86_64-cpython-310/adet/data\n",
            "copying adet/data/dataset_mapper.py -> build/lib.linux-x86_64-cpython-310/adet/data\n",
            "copying adet/data/fcpose_dataset_mapper.py -> build/lib.linux-x86_64-cpython-310/adet/data\n",
            "copying adet/data/builtin.py -> build/lib.linux-x86_64-cpython-310/adet/data\n",
            "copying adet/data/augmentation.py -> build/lib.linux-x86_64-cpython-310/adet/data\n",
            "copying adet/data/detection_utils.py -> build/lib.linux-x86_64-cpython-310/adet/data\n",
            "creating build/lib.linux-x86_64-cpython-310/adet/structures\n",
            "copying adet/structures/__init__.py -> build/lib.linux-x86_64-cpython-310/adet/structures\n",
            "copying adet/structures/beziers.py -> build/lib.linux-x86_64-cpython-310/adet/structures\n",
            "creating build/lib.linux-x86_64-cpython-310/adet/utils\n",
            "copying adet/utils/comm.py -> build/lib.linux-x86_64-cpython-310/adet/utils\n",
            "copying adet/utils/__init__.py -> build/lib.linux-x86_64-cpython-310/adet/utils\n",
            "copying adet/utils/visualizer.py -> build/lib.linux-x86_64-cpython-310/adet/utils\n",
            "copying adet/utils/measures.py -> build/lib.linux-x86_64-cpython-310/adet/utils\n",
            "creating build/lib.linux-x86_64-cpython-310/adet/modeling\n",
            "copying adet/modeling/__init__.py -> build/lib.linux-x86_64-cpython-310/adet/modeling\n",
            "copying adet/modeling/one_stage_detector.py -> build/lib.linux-x86_64-cpython-310/adet/modeling\n",
            "copying adet/modeling/poolers.py -> build/lib.linux-x86_64-cpython-310/adet/modeling\n",
            "creating build/lib.linux-x86_64-cpython-310/adet/config\n",
            "copying adet/config/__init__.py -> build/lib.linux-x86_64-cpython-310/adet/config\n",
            "copying adet/config/defaults.py -> build/lib.linux-x86_64-cpython-310/adet/config\n",
            "copying adet/config/config.py -> build/lib.linux-x86_64-cpython-310/adet/config\n",
            "creating build/lib.linux-x86_64-cpython-310/adet/evaluation\n",
            "copying adet/evaluation/text_eval_script.py -> build/lib.linux-x86_64-cpython-310/adet/evaluation\n",
            "copying adet/evaluation/__init__.py -> build/lib.linux-x86_64-cpython-310/adet/evaluation\n",
            "copying adet/evaluation/text_eval_script_ic15.py -> build/lib.linux-x86_64-cpython-310/adet/evaluation\n",
            "copying adet/evaluation/rrc_evaluation_funcs.py -> build/lib.linux-x86_64-cpython-310/adet/evaluation\n",
            "copying adet/evaluation/text_evaluation_all.py -> build/lib.linux-x86_64-cpython-310/adet/evaluation\n",
            "copying adet/evaluation/rrc_evaluation_funcs_ic15.py -> build/lib.linux-x86_64-cpython-310/adet/evaluation\n",
            "creating build/lib.linux-x86_64-cpython-310/adet/checkpoint\n",
            "copying adet/checkpoint/__init__.py -> build/lib.linux-x86_64-cpython-310/adet/checkpoint\n",
            "copying adet/checkpoint/adet_checkpoint.py -> build/lib.linux-x86_64-cpython-310/adet/checkpoint\n",
            "creating build/lib.linux-x86_64-cpython-310/adet/layers\n",
            "copying adet/layers/__init__.py -> build/lib.linux-x86_64-cpython-310/adet/layers\n",
            "copying adet/layers/ml_nms.py -> build/lib.linux-x86_64-cpython-310/adet/layers\n",
            "copying adet/layers/def_roi_align.py -> build/lib.linux-x86_64-cpython-310/adet/layers\n",
            "copying adet/layers/iou_loss.py -> build/lib.linux-x86_64-cpython-310/adet/layers\n",
            "copying adet/layers/deform_conv.py -> build/lib.linux-x86_64-cpython-310/adet/layers\n",
            "copying adet/layers/naive_group_norm.py -> build/lib.linux-x86_64-cpython-310/adet/layers\n",
            "copying adet/layers/gcn.py -> build/lib.linux-x86_64-cpython-310/adet/layers\n",
            "copying adet/layers/conv_with_kaiming_uniform.py -> build/lib.linux-x86_64-cpython-310/adet/layers\n",
            "copying adet/layers/bezier_align.py -> build/lib.linux-x86_64-cpython-310/adet/layers\n",
            "creating build/lib.linux-x86_64-cpython-310/adet/modeling/batext\n",
            "copying adet/modeling/batext/__init__.py -> build/lib.linux-x86_64-cpython-310/adet/modeling/batext\n",
            "copying adet/modeling/batext/batext_outputs.py -> build/lib.linux-x86_64-cpython-310/adet/modeling/batext\n",
            "copying adet/modeling/batext/batext.py -> build/lib.linux-x86_64-cpython-310/adet/modeling/batext\n",
            "creating build/lib.linux-x86_64-cpython-310/adet/modeling/blendmask\n",
            "copying adet/modeling/blendmask/__init__.py -> build/lib.linux-x86_64-cpython-310/adet/modeling/blendmask\n",
            "copying adet/modeling/blendmask/blender.py -> build/lib.linux-x86_64-cpython-310/adet/modeling/blendmask\n",
            "copying adet/modeling/blendmask/basis_module.py -> build/lib.linux-x86_64-cpython-310/adet/modeling/blendmask\n",
            "copying adet/modeling/blendmask/blendmask.py -> build/lib.linux-x86_64-cpython-310/adet/modeling/blendmask\n",
            "creating build/lib.linux-x86_64-cpython-310/adet/modeling/MEInst\n",
            "copying adet/modeling/MEInst/MEInst_outputs.py -> build/lib.linux-x86_64-cpython-310/adet/modeling/MEInst\n",
            "copying adet/modeling/MEInst/MaskEncoding.py -> build/lib.linux-x86_64-cpython-310/adet/modeling/MEInst\n",
            "copying adet/modeling/MEInst/__init__.py -> build/lib.linux-x86_64-cpython-310/adet/modeling/MEInst\n",
            "copying adet/modeling/MEInst/MEInst.py -> build/lib.linux-x86_64-cpython-310/adet/modeling/MEInst\n",
            "creating build/lib.linux-x86_64-cpython-310/adet/modeling/fcos\n",
            "copying adet/modeling/fcos/__init__.py -> build/lib.linux-x86_64-cpython-310/adet/modeling/fcos\n",
            "copying adet/modeling/fcos/fcos_outputs.py -> build/lib.linux-x86_64-cpython-310/adet/modeling/fcos\n",
            "copying adet/modeling/fcos/fcos.py -> build/lib.linux-x86_64-cpython-310/adet/modeling/fcos\n",
            "creating build/lib.linux-x86_64-cpython-310/adet/modeling/backbone\n",
            "copying adet/modeling/backbone/fpn.py -> build/lib.linux-x86_64-cpython-310/adet/modeling/backbone\n",
            "copying adet/modeling/backbone/__init__.py -> build/lib.linux-x86_64-cpython-310/adet/modeling/backbone\n",
            "copying adet/modeling/backbone/mobilenet.py -> build/lib.linux-x86_64-cpython-310/adet/modeling/backbone\n",
            "copying adet/modeling/backbone/resnet_interval.py -> build/lib.linux-x86_64-cpython-310/adet/modeling/backbone\n",
            "copying adet/modeling/backbone/bifpn.py -> build/lib.linux-x86_64-cpython-310/adet/modeling/backbone\n",
            "copying adet/modeling/backbone/vovnet.py -> build/lib.linux-x86_64-cpython-310/adet/modeling/backbone\n",
            "copying adet/modeling/backbone/lpf.py -> build/lib.linux-x86_64-cpython-310/adet/modeling/backbone\n",
            "copying adet/modeling/backbone/dla.py -> build/lib.linux-x86_64-cpython-310/adet/modeling/backbone\n",
            "copying adet/modeling/backbone/resnet_lpf.py -> build/lib.linux-x86_64-cpython-310/adet/modeling/backbone\n",
            "creating build/lib.linux-x86_64-cpython-310/adet/modeling/fcpose\n",
            "copying adet/modeling/fcpose/fcpose_head.py -> build/lib.linux-x86_64-cpython-310/adet/modeling/fcpose\n",
            "copying adet/modeling/fcpose/__init__.py -> build/lib.linux-x86_64-cpython-310/adet/modeling/fcpose\n",
            "copying adet/modeling/fcpose/utils.py -> build/lib.linux-x86_64-cpython-310/adet/modeling/fcpose\n",
            "copying adet/modeling/fcpose/basis_module.py -> build/lib.linux-x86_64-cpython-310/adet/modeling/fcpose\n",
            "copying adet/modeling/fcpose/fcpose_framework.py -> build/lib.linux-x86_64-cpython-310/adet/modeling/fcpose\n",
            "creating build/lib.linux-x86_64-cpython-310/adet/modeling/roi_heads\n",
            "copying adet/modeling/roi_heads/__init__.py -> build/lib.linux-x86_64-cpython-310/adet/modeling/roi_heads\n",
            "copying adet/modeling/roi_heads/attn_predictor.py -> build/lib.linux-x86_64-cpython-310/adet/modeling/roi_heads\n",
            "copying adet/modeling/roi_heads/text_head.py -> build/lib.linux-x86_64-cpython-310/adet/modeling/roi_heads\n",
            "creating build/lib.linux-x86_64-cpython-310/adet/modeling/condinst\n",
            "copying adet/modeling/condinst/dynamic_mask_head.py -> build/lib.linux-x86_64-cpython-310/adet/modeling/condinst\n",
            "copying adet/modeling/condinst/__init__.py -> build/lib.linux-x86_64-cpython-310/adet/modeling/condinst\n",
            "copying adet/modeling/condinst/mask_branch.py -> build/lib.linux-x86_64-cpython-310/adet/modeling/condinst\n",
            "copying adet/modeling/condinst/condinst.py -> build/lib.linux-x86_64-cpython-310/adet/modeling/condinst\n",
            "creating build/lib.linux-x86_64-cpython-310/adet/modeling/solov2\n",
            "copying adet/modeling/solov2/__init__.py -> build/lib.linux-x86_64-cpython-310/adet/modeling/solov2\n",
            "copying adet/modeling/solov2/utils.py -> build/lib.linux-x86_64-cpython-310/adet/modeling/solov2\n",
            "copying adet/modeling/solov2/solov2.py -> build/lib.linux-x86_64-cpython-310/adet/modeling/solov2\n",
            "copying adet/modeling/solov2/loss.py -> build/lib.linux-x86_64-cpython-310/adet/modeling/solov2\n",
            "creating build/lib.linux-x86_64-cpython-310/adet/modeling/MEInst/LME\n",
            "copying adet/modeling/MEInst/LME/__init__.py -> build/lib.linux-x86_64-cpython-310/adet/modeling/MEInst/LME\n",
            "copying adet/modeling/MEInst/LME/mask_generation.py -> build/lib.linux-x86_64-cpython-310/adet/modeling/MEInst/LME\n",
            "copying adet/modeling/MEInst/LME/utils.py -> build/lib.linux-x86_64-cpython-310/adet/modeling/MEInst/LME\n",
            "copying adet/modeling/MEInst/LME/mask_evaluation.py -> build/lib.linux-x86_64-cpython-310/adet/modeling/MEInst/LME\n",
            "copying adet/modeling/MEInst/LME/MaskLoader.py -> build/lib.linux-x86_64-cpython-310/adet/modeling/MEInst/LME\n",
            "running build_ext\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py:500: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n",
            "  warnings.warn(msg.format('we could not find ninja.'))\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py:415: UserWarning: The detected CUDA version (12.2) has a minor version mismatch with the version that was used to compile PyTorch (12.1). Most likely this shouldn't be a problem.\n",
            "  warnings.warn(CUDA_MISMATCH_WARN.format(cuda_str_version, torch.version.cuda))\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py:425: UserWarning: There are no x86_64-linux-gnu-g++ version bounds defined for CUDA version 12.2\n",
            "  warnings.warn(f'There are no {compiler_name} version bounds defined for CUDA version {cuda_str_version}')\n",
            "building 'adet._C' extension\n",
            "creating build/temp.linux-x86_64-cpython-310\n",
            "creating build/temp.linux-x86_64-cpython-310/content\n",
            "creating build/temp.linux-x86_64-cpython-310/content/TACO-expl\n",
            "creating build/temp.linux-x86_64-cpython-310/content/TACO-expl/AdelaiDet\n",
            "creating build/temp.linux-x86_64-cpython-310/content/TACO-expl/AdelaiDet/adet\n",
            "creating build/temp.linux-x86_64-cpython-310/content/TACO-expl/AdelaiDet/adet/layers\n",
            "creating build/temp.linux-x86_64-cpython-310/content/TACO-expl/AdelaiDet/adet/layers/csrc\n",
            "creating build/temp.linux-x86_64-cpython-310/content/TACO-expl/AdelaiDet/adet/layers/csrc/BezierAlign\n",
            "creating build/temp.linux-x86_64-cpython-310/content/TACO-expl/AdelaiDet/adet/layers/csrc/DefROIAlign\n",
            "creating build/temp.linux-x86_64-cpython-310/content/TACO-expl/AdelaiDet/adet/layers/csrc/ml_nms\n",
            "x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -DWITH_CUDA -I/content/TACO-expl/AdelaiDet/adet/layers/csrc -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.10 -c /content/TACO-expl/AdelaiDet/adet/layers/csrc/BezierAlign/BezierAlign_cpu.cpp -o build/temp.linux-x86_64-cpython-310/content/TACO-expl/AdelaiDet/adet/layers/csrc/BezierAlign/BezierAlign_cpu.o -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
            "In file included from \u001b[01m\u001b[K/content/TACO-expl/AdelaiDet/adet/layers/csrc/BezierAlign/BezierAlign_cpu.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/content/TACO-expl/AdelaiDet/adet/layers/csrc/BezierAlign/BezierAlign.h:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kat::Tensor adet::BezierAlign_forward(const at::Tensor&, const at::Tensor&, float, int, int, int, bool)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K/content/TACO-expl/AdelaiDet/adet/layers/csrc/BezierAlign/BezierAlign.h:62:17:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   62 |   if (\u001b[01;35m\u001b[Kinput.type()\u001b[m\u001b[K.is_cuda()) {\n",
            "      |       \u001b[01;35m\u001b[K~~~~~~~~~~^~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/TensorUtils.h:5\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/TACO-expl/AdelaiDet/adet/layers/csrc/BezierAlign/BezierAlign_cpu.cpp:2\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:225:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  225 |   DeprecatedTypeProperties & \u001b[01;36m\u001b[Ktype\u001b[m\u001b[K() const {\n",
            "      |                              \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/content/TACO-expl/AdelaiDet/adet/layers/csrc/BezierAlign/BezierAlign_cpu.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/content/TACO-expl/AdelaiDet/adet/layers/csrc/BezierAlign/BezierAlign.h:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kat::Tensor adet::BezierAlign_backward(const at::Tensor&, const at::Tensor&, float, int, int, int, int, int, int, int, bool)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K/content/TACO-expl/AdelaiDet/adet/layers/csrc/BezierAlign/BezierAlign.h:98:16:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   98 |   if (\u001b[01;35m\u001b[Kgrad.type()\u001b[m\u001b[K.is_cuda()) {\n",
            "      |       \u001b[01;35m\u001b[K~~~~~~~~~^~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/TensorUtils.h:5\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/TACO-expl/AdelaiDet/adet/layers/csrc/BezierAlign/BezierAlign_cpu.cpp:2\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:225:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  225 |   DeprecatedTypeProperties & \u001b[01;36m\u001b[Ktype\u001b[m\u001b[K() const {\n",
            "      |                              \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/ATen.h:11\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/TACO-expl/AdelaiDet/adet/layers/csrc/BezierAlign/BezierAlign.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/TACO-expl/AdelaiDet/adet/layers/csrc/BezierAlign/BezierAlign_cpu.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/content/TACO-expl/AdelaiDet/adet/layers/csrc/BezierAlign/BezierAlign_cpu.cpp:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[K/content/TACO-expl/AdelaiDet/adet/layers/csrc/BezierAlign/BezierAlign_cpu.cpp:493:49:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  493 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\u001b[01;35m\u001b[Kinput.type()\u001b[m\u001b[K, \"BezierAlign_forward\", [&] {\n",
            "      |                                       \u001b[01;35m\u001b[K~~~~~~~~~~^~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:215:28:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro ‘\u001b[01m\u001b[KAT_DISPATCH_SWITCH\u001b[m\u001b[K’\n",
            "  215 |     const auto& the_type = \u001b[01;36m\u001b[KTYPE\u001b[m\u001b[K;                                            \\\n",
            "      |                            \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/TACO-expl/AdelaiDet/adet/layers/csrc/BezierAlign/BezierAlign_cpu.cpp:493:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_DISPATCH_FLOATING_TYPES_AND_HALF\u001b[m\u001b[K’\n",
            "  493 |   \u001b[01;36m\u001b[KAT_DISPATCH_FLOATING_TYPES_AND_HALF\u001b[m\u001b[K(input.type(), \"BezierAlign_forward\", [&] {\n",
            "      |   \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/TensorUtils.h:5\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/TACO-expl/AdelaiDet/adet/layers/csrc/BezierAlign/BezierAlign_cpu.cpp:2\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:225:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  225 |   DeprecatedTypeProperties & \u001b[01;36m\u001b[Ktype\u001b[m\u001b[K() const {\n",
            "      |                              \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/ATen.h:11\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/TACO-expl/AdelaiDet/adet/layers/csrc/BezierAlign/BezierAlign.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/TACO-expl/AdelaiDet/adet/layers/csrc/BezierAlign/BezierAlign_cpu.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:218:47:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kc10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)\u001b[m\u001b[K’ is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  218 |     at::ScalarType _st = \u001b[01;35m\u001b[K::detail::scalar_type(the_type)\u001b[m\u001b[K;                   \\\n",
            "      |                          \u001b[01;35m\u001b[K~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:245:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_DISPATCH_SWITCH\u001b[m\u001b[K’\n",
            "  245 |   \u001b[01;36m\u001b[KAT_DISPATCH_SWITCH\u001b[m\u001b[K(                                        \\\n",
            "      |   \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/TACO-expl/AdelaiDet/adet/layers/csrc/BezierAlign/BezierAlign_cpu.cpp:493:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_DISPATCH_FLOATING_TYPES_AND_HALF\u001b[m\u001b[K’\n",
            "  493 |   \u001b[01;36m\u001b[KAT_DISPATCH_FLOATING_TYPES_AND_HALF\u001b[m\u001b[K(input.type(), \"BezierAlign_forward\", [&] {\n",
            "      |   \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:109:23:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  109 | inline at::ScalarType \u001b[01;36m\u001b[Kscalar_type\u001b[m\u001b[K(const at::DeprecatedTypeProperties& t) {\n",
            "      |                       \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/TACO-expl/AdelaiDet/adet/layers/csrc/BezierAlign/BezierAlign_cpu.cpp:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[K/content/TACO-expl/AdelaiDet/adet/layers/csrc/BezierAlign/BezierAlign_cpu.cpp:545:48:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  545 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\u001b[01;35m\u001b[Kgrad.type()\u001b[m\u001b[K, \"BezierAlign_forward\", [&] {\n",
            "      |                                       \u001b[01;35m\u001b[K~~~~~~~~~^~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:215:28:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro ‘\u001b[01m\u001b[KAT_DISPATCH_SWITCH\u001b[m\u001b[K’\n",
            "  215 |     const auto& the_type = \u001b[01;36m\u001b[KTYPE\u001b[m\u001b[K;                                            \\\n",
            "      |                            \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/TACO-expl/AdelaiDet/adet/layers/csrc/BezierAlign/BezierAlign_cpu.cpp:545:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_DISPATCH_FLOATING_TYPES_AND_HALF\u001b[m\u001b[K’\n",
            "  545 |   \u001b[01;36m\u001b[KAT_DISPATCH_FLOATING_TYPES_AND_HALF\u001b[m\u001b[K(grad.type(), \"BezierAlign_forward\", [&] {\n",
            "      |   \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/TensorUtils.h:5\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/TACO-expl/AdelaiDet/adet/layers/csrc/BezierAlign/BezierAlign_cpu.cpp:2\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:225:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  225 |   DeprecatedTypeProperties & \u001b[01;36m\u001b[Ktype\u001b[m\u001b[K() const {\n",
            "      |                              \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/ATen.h:11\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/TACO-expl/AdelaiDet/adet/layers/csrc/BezierAlign/BezierAlign.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/TACO-expl/AdelaiDet/adet/layers/csrc/BezierAlign/BezierAlign_cpu.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:218:47:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kc10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)\u001b[m\u001b[K’ is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  218 |     at::ScalarType _st = \u001b[01;35m\u001b[K::detail::scalar_type(the_type)\u001b[m\u001b[K;                   \\\n",
            "      |                          \u001b[01;35m\u001b[K~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:245:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_DISPATCH_SWITCH\u001b[m\u001b[K’\n",
            "  245 |   \u001b[01;36m\u001b[KAT_DISPATCH_SWITCH\u001b[m\u001b[K(                                        \\\n",
            "      |   \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/TACO-expl/AdelaiDet/adet/layers/csrc/BezierAlign/BezierAlign_cpu.cpp:545:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_DISPATCH_FLOATING_TYPES_AND_HALF\u001b[m\u001b[K’\n",
            "  545 |   \u001b[01;36m\u001b[KAT_DISPATCH_FLOATING_TYPES_AND_HALF\u001b[m\u001b[K(grad.type(), \"BezierAlign_forward\", [&] {\n",
            "      |   \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:109:23:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  109 | inline at::ScalarType \u001b[01;36m\u001b[Kscalar_type\u001b[m\u001b[K(const at::DeprecatedTypeProperties& t) {\n",
            "      |                       \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
            "/content/TACO-expl/AdelaiDet/adet/layers/csrc/BezierAlign/BezierAlign_cpu.cpp: In instantiation of ‘\u001b[01m\u001b[Kvoid {anonymous}::BezierAlignForward(int, const T*, const T&, int, int, int, int, int, int, const T*, T*, bool) [with T = double]\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K/content/TACO-expl/AdelaiDet/adet/layers/csrc/BezierAlign/BezierAlign_cpu.cpp:493:3:\u001b[m\u001b[K   required from here\n",
            "\u001b[01m\u001b[K/content/TACO-expl/AdelaiDet/adet/layers/csrc/BezierAlign/BezierAlign_cpu.cpp:168:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Koffset\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wunused-variable\u0007-Wunused-variable\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  168 |     T \u001b[01;35m\u001b[Koffset\u001b[m\u001b[K = aligned ? (T)0.5 : (T)0.0;\n",
            "      |       \u001b[01;35m\u001b[K^~~~~~\u001b[m\u001b[K\n",
            "/content/TACO-expl/AdelaiDet/adet/layers/csrc/BezierAlign/BezierAlign_cpu.cpp: In instantiation of ‘\u001b[01m\u001b[Kvoid {anonymous}::BezierAlignForward(int, const T*, const T&, int, int, int, int, int, int, const T*, T*, bool) [with T = float]\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K/content/TACO-expl/AdelaiDet/adet/layers/csrc/BezierAlign/BezierAlign_cpu.cpp:493:3:\u001b[m\u001b[K   required from here\n",
            "\u001b[01m\u001b[K/content/TACO-expl/AdelaiDet/adet/layers/csrc/BezierAlign/BezierAlign_cpu.cpp:168:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Koffset\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wunused-variable\u0007-Wunused-variable\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "/content/TACO-expl/AdelaiDet/adet/layers/csrc/BezierAlign/BezierAlign_cpu.cpp: In instantiation of ‘\u001b[01m\u001b[Kvoid {anonymous}::BezierAlignForward(int, const T*, const T&, int, int, int, int, int, int, const T*, T*, bool) [with T = c10::Half]\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K/content/TACO-expl/AdelaiDet/adet/layers/csrc/BezierAlign/BezierAlign_cpu.cpp:493:3:\u001b[m\u001b[K   required from here\n",
            "\u001b[01m\u001b[K/content/TACO-expl/AdelaiDet/adet/layers/csrc/BezierAlign/BezierAlign_cpu.cpp:168:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kvariable ‘\u001b[01m\u001b[Koffset\u001b[m\u001b[K’ set but not used [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wunused-but-set-variable\u0007-Wunused-but-set-variable\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "/usr/local/cuda/bin/nvcc -DWITH_CUDA -I/content/TACO-expl/AdelaiDet/adet/layers/csrc -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.10 -c /content/TACO-expl/AdelaiDet/adet/layers/csrc/BezierAlign/BezierAlign_cuda.cu -o build/temp.linux-x86_64-cpython-310/content/TACO-expl/AdelaiDet/adet/layers/csrc/BezierAlign/BezierAlign_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -DCUDA_HAS_FP16=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++17\n",
            "/usr/local/cuda/bin/nvcc -DWITH_CUDA -I/content/TACO-expl/AdelaiDet/adet/layers/csrc -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.10 -c /content/TACO-expl/AdelaiDet/adet/layers/csrc/DefROIAlign/DefROIAlign_cuda.cu -o build/temp.linux-x86_64-cpython-310/content/TACO-expl/AdelaiDet/adet/layers/csrc/DefROIAlign/DefROIAlign_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -DCUDA_HAS_FP16=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++17\n",
            "/usr/local/cuda/bin/nvcc -DWITH_CUDA -I/content/TACO-expl/AdelaiDet/adet/layers/csrc -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.10 -c /content/TACO-expl/AdelaiDet/adet/layers/csrc/cuda_version.cu -o build/temp.linux-x86_64-cpython-310/content/TACO-expl/AdelaiDet/adet/layers/csrc/cuda_version.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -DCUDA_HAS_FP16=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++17\n",
            "/usr/local/cuda/bin/nvcc -DWITH_CUDA -I/content/TACO-expl/AdelaiDet/adet/layers/csrc -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.10 -c /content/TACO-expl/AdelaiDet/adet/layers/csrc/ml_nms/ml_nms.cu -o build/temp.linux-x86_64-cpython-310/content/TACO-expl/AdelaiDet/adet/layers/csrc/ml_nms/ml_nms.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -DCUDA_HAS_FP16=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++17\n",
            "\u001b[01m\u001b[K/content/TACO-expl/AdelaiDet/adet/layers/csrc/ml_nms/ml_nms.cu:4:10:\u001b[m\u001b[K \u001b[01;31m\u001b[Kfatal error: \u001b[m\u001b[KTHC/THC.h: No such file or directory\n",
            "    4 | #include \u001b[01;31m\u001b[K<THC/THC.h>\u001b[m\u001b[K\n",
            "      |          \u001b[01;31m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
            "compilation terminated.\n",
            "error: command '/usr/local/cuda/bin/nvcc' failed with exit code 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rapidfuzz==2.15.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v1kqCskPxLoY",
        "outputId": "c9771401-cc0d-495f-fefa-9fd799cd4227"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rapidfuzz==2.15.1\n",
            "  Downloading rapidfuzz-2.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rapidfuzz\n",
            "Successfully installed rapidfuzz-2.15.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/MyDrive/\", force_remount = True)"
      ],
      "metadata": {
        "id": "yKG8tycQnkyb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d71bbb3-692c-459c-d8c1-37b691781a35"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/MyDrive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, detectron2\n",
        "!nvcc --version\n",
        "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
        "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
        "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
        "print(\"detectron2:\", detectron2.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJ444LmfnVe7",
        "outputId": "8be842fe-0115-49f9-9330-214b2f8d8771"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2023 NVIDIA Corporation\n",
            "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
            "Cuda compilation tools, release 12.2, V12.2.140\n",
            "Build cuda_12.2.r12.2/compiler.33191640_0\n",
            "torch:  2.2 ; cuda:  cu121\n",
            "detectron2: 0.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/\n",
        "# Some basic setup:\n",
        "# Setup detectron2 logger\n",
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "\n",
        "# import some common libraries\n",
        "import numpy as np\n",
        "import os, json, cv2, random\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# import some common detectron2 utilities\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
        "\n",
        "from detectron2.modeling import build_model\n",
        "%cd /content/TACO-expl/AdelaiDet/adet/modeling/solov2/\n",
        "from solov2 import SOLOv2"
      ],
      "metadata": {
        "id": "LfdhgozHnZpe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d302372-2ddf-491b-e24a-38e6df4ae779"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "/content/TACO-expl/AdelaiDet/adet/modeling/solov2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "#sys.path.append(\"/content/TACO-expl/MaskDINO\")\n",
        "#!cd /content/TACO-expl/MaskDINO/\n",
        "#cfg_biggest_path = '/content/TACO-expl/MaskDINO/configs/coco/instance-segmentation/swin/maskdino_R50_bs16_50ep_4s_dowsample1_2048.yaml'\n",
        "#model_biggest_weights_url = 'https://github.com/IDEA-Research/detrex-storage/releases/download/maskdino-v0.1.0/maskdino_swinl_50ep_300q_hid2048_3sd1_instance_maskenhanced_mask52.3ap_box59.0ap.pth'\n",
        "\n",
        "#cfg_smallest_path = '/content/TACO-expl/MaskDINO/configs/coco/instance-segmentation/maskdino_R50_bs16_50ep_3s.yaml'\n",
        "#model_smallest_weight_url = 'https://github.com/IDEA-Research/detrex-storage/releases/download/maskdino-v0.1.0/maskdino_r50_50ep_300q_hid1024_3sd1_instance_maskenhanced_mask46.1ap_box51.5ap.pth'\n",
        "\n",
        "cfg_solo_base_path = '/content/TACO-expl/AdelaiDet/configs/SOLOv2/Base-SOLOv2.yaml'\n",
        "cfg_solo_r50_path = '/content/TACO-expl/AdelaiDet/configs/SOLOv2/R50_3x.yaml'"
      ],
      "metadata": {
        "id": "tAagzHqSncrP"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sys.path.append('/content/TACO-expl/AdelaiDet/adet/config')\n",
        "from defaults import _C\n",
        "\n",
        "def setup_cfg(cfg_base, cfg_backbone):\n",
        "  cfg = _C\n",
        "  cfg.merge_from_file(cfg_base)\n",
        "  cfg.merge_from_file(cfg_backbone)\n",
        "  return cfg\n",
        "\n",
        "cfg_solov2 = setup_cfg(cfg_solo_base_path, cfg_solo_r50_path)\n",
        "print(cfg_solov2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xFqN2ogZngcc",
        "outputId": "7ad63011-f7f5-4402-d1ed-fed30380036c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDNN_BENCHMARK: False\n",
            "DATALOADER:\n",
            "  ASPECT_RATIO_GROUPING: True\n",
            "  FILTER_EMPTY_ANNOTATIONS: True\n",
            "  NUM_WORKERS: 4\n",
            "  REPEAT_THRESHOLD: 0.0\n",
            "  SAMPLER_TRAIN: TrainingSampler\n",
            "DATASETS:\n",
            "  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000\n",
            "  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000\n",
            "  PROPOSAL_FILES_TEST: ()\n",
            "  PROPOSAL_FILES_TRAIN: ()\n",
            "  TEST: ('coco_2017_val',)\n",
            "  TRAIN: ('coco_2017_train',)\n",
            "GLOBAL:\n",
            "  HACK: 1.0\n",
            "INPUT:\n",
            "  CROP:\n",
            "    CROP_INSTANCE: True\n",
            "    ENABLED: False\n",
            "    SIZE: [0.9, 0.9]\n",
            "    TYPE: relative_range\n",
            "  FORMAT: BGR\n",
            "  HFLIP_TRAIN: True\n",
            "  IS_ROTATE: False\n",
            "  MASK_FORMAT: bitmask\n",
            "  MAX_SIZE_TEST: 1333\n",
            "  MAX_SIZE_TRAIN: 1333\n",
            "  MIN_SIZE_TEST: 800\n",
            "  MIN_SIZE_TRAIN: (640, 672, 704, 736, 768, 800)\n",
            "  MIN_SIZE_TRAIN_SAMPLING: choice\n",
            "  RANDOM_FLIP: horizontal\n",
            "MODEL:\n",
            "  ANCHOR_GENERATOR:\n",
            "    ANGLES: [[-90, 0, 90]]\n",
            "    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]\n",
            "    NAME: DefaultAnchorGenerator\n",
            "    OFFSET: 0.0\n",
            "    SIZES: [[32, 64, 128, 256, 512]]\n",
            "  BACKBONE:\n",
            "    ANTI_ALIAS: False\n",
            "    FREEZE_AT: 2\n",
            "    NAME: build_resnet_fpn_backbone\n",
            "  BASIS_MODULE:\n",
            "    ANN_SET: coco\n",
            "    COMMON_STRIDE: 8\n",
            "    CONVS_DIM: 128\n",
            "    IN_FEATURES: ['p3', 'p4', 'p5']\n",
            "    LOSS_ON: False\n",
            "    LOSS_WEIGHT: 0.3\n",
            "    NAME: ProtoNet\n",
            "    NORM: SyncBN\n",
            "    NUM_BASES: 4\n",
            "    NUM_CLASSES: 80\n",
            "    NUM_CONVS: 3\n",
            "  BATEXT:\n",
            "    CANONICAL_SIZE: 96\n",
            "    CONV_DIM: 256\n",
            "    CUSTOM_DICT: \n",
            "    EVAL_TYPE: 3\n",
            "    IN_FEATURES: ['p2', 'p3', 'p4']\n",
            "    NUM_CHARS: 25\n",
            "    NUM_CONV: 2\n",
            "    POOLER_RESOLUTION: (8, 32)\n",
            "    POOLER_SCALES: (0.25, 0.125, 0.0625)\n",
            "    RECOGNITION_LOSS: ctc\n",
            "    RECOGNIZER: attn\n",
            "    SAMPLING_RATIO: 1\n",
            "    USE_AET: False\n",
            "    USE_COORDCONV: False\n",
            "    VOC_SIZE: 96\n",
            "  BLENDMASK:\n",
            "    ATTN_SIZE: 14\n",
            "    BOTTOM_RESOLUTION: 56\n",
            "    INSTANCE_LOSS_WEIGHT: 1.0\n",
            "    POOLER_SAMPLING_RATIO: 1\n",
            "    POOLER_SCALES: (0.25,)\n",
            "    POOLER_TYPE: ROIAlignV2\n",
            "    TOP_INTERP: bilinear\n",
            "    VISUALIZE: False\n",
            "  BOXINST:\n",
            "    BOTTOM_PIXELS_REMOVED: 10\n",
            "    ENABLED: False\n",
            "    PAIRWISE:\n",
            "      COLOR_THRESH: 0.3\n",
            "      DILATION: 2\n",
            "      SIZE: 3\n",
            "      WARMUP_ITERS: 10000\n",
            "  BiFPN:\n",
            "    IN_FEATURES: ['res2', 'res3', 'res4', 'res5']\n",
            "    NORM: \n",
            "    NUM_REPEATS: 6\n",
            "    OUT_CHANNELS: 160\n",
            "  CONDINST:\n",
            "    BOTTOM_PIXELS_REMOVED: -1\n",
            "    MASK_BRANCH:\n",
            "      CHANNELS: 128\n",
            "      IN_FEATURES: ['p3', 'p4', 'p5']\n",
            "      NORM: BN\n",
            "      NUM_CONVS: 4\n",
            "      OUT_CHANNELS: 8\n",
            "      SEMANTIC_LOSS_ON: False\n",
            "    MASK_HEAD:\n",
            "      CHANNELS: 8\n",
            "      DISABLE_REL_COORDS: False\n",
            "      NUM_LAYERS: 3\n",
            "      USE_FP16: False\n",
            "    MASK_OUT_STRIDE: 4\n",
            "    MAX_PROPOSALS: -1\n",
            "    TOPK_PROPOSALS_PER_IM: -1\n",
            "  DEVICE: cuda\n",
            "  DLA:\n",
            "    CONV_BODY: DLA34\n",
            "    NORM: FrozenBN\n",
            "    OUT_FEATURES: ['stage2', 'stage3', 'stage4', 'stage5']\n",
            "  FCOS:\n",
            "    BOX_QUALITY: ctrness\n",
            "    CENTER_SAMPLE: True\n",
            "    FPN_STRIDES: [8, 16, 32, 64, 128]\n",
            "    INFERENCE_TH_TEST: 0.05\n",
            "    INFERENCE_TH_TRAIN: 0.05\n",
            "    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']\n",
            "    LOC_LOSS_TYPE: giou\n",
            "    LOSS_ALPHA: 0.25\n",
            "    LOSS_GAMMA: 2.0\n",
            "    LOSS_NORMALIZER_CLS: fg\n",
            "    LOSS_WEIGHT_CLS: 1.0\n",
            "    NMS_TH: 0.6\n",
            "    NORM: GN\n",
            "    NUM_BOX_CONVS: 4\n",
            "    NUM_CLASSES: 80\n",
            "    NUM_CLS_CONVS: 4\n",
            "    NUM_SHARE_CONVS: 0\n",
            "    POST_NMS_TOPK_TEST: 100\n",
            "    POST_NMS_TOPK_TRAIN: 100\n",
            "    POS_RADIUS: 1.5\n",
            "    PRE_NMS_TOPK_TEST: 1000\n",
            "    PRE_NMS_TOPK_TRAIN: 1000\n",
            "    PRIOR_PROB: 0.01\n",
            "    SIZES_OF_INTEREST: [64, 128, 256, 512]\n",
            "    THRESH_WITH_CTR: False\n",
            "    TOP_LEVELS: 2\n",
            "    USE_DEFORMABLE: False\n",
            "    USE_RELU: True\n",
            "    USE_SCALE: True\n",
            "    YIELD_BOX_FEATURES: False\n",
            "    YIELD_PROPOSAL: False\n",
            "  FCPOSE:\n",
            "    ATTN_LEN: 2737\n",
            "    BASIS_MODULE:\n",
            "      BN_TYPE: SyncBN\n",
            "      COMMON_STRIDE: 8\n",
            "      CONVS_DIM: 128\n",
            "      LOSS_WEIGHT: 0.2\n",
            "      NUM_BASES: 32\n",
            "      NUM_CLASSES: 17\n",
            "    DISTANCE_NORM: 12.0\n",
            "    DYNAMIC_CHANNELS: 32\n",
            "    FOCAL_LOSS_ALPHA: 0.25\n",
            "    FOCAL_LOSS_GAMMA: 2.0\n",
            "    GT_HEATMAP_STRIDE: 2\n",
            "    HEAD_HEATMAP_SIGMA: 0.01\n",
            "    HEATMAP_SIGMA: 1.8\n",
            "    LOSS_WEIGHT_DIRECTION: 9.0\n",
            "    LOSS_WEIGHT_KEYPOINT: 2.5\n",
            "    MAX_PROPOSALS: 70\n",
            "    PROPOSALS_PER_INST: 70\n",
            "    SIGMA: 1\n",
            "  FCPOSE_ON: False\n",
            "  FPN:\n",
            "    FUSE_TYPE: sum\n",
            "    IN_FEATURES: ['res2', 'res3', 'res4', 'res5']\n",
            "    NORM: \n",
            "    OUT_CHANNELS: 256\n",
            "  KEYPOINT_ON: False\n",
            "  LOAD_PROPOSALS: False\n",
            "  MASK_ON: True\n",
            "  MEInst:\n",
            "    AGNOSTIC: True\n",
            "    CENTER_SAMPLE: True\n",
            "    DIM_MASK: 60\n",
            "    FLAG_PARAMETERS: False\n",
            "    FPN_STRIDES: [8, 16, 32, 64, 128]\n",
            "    GCN_KERNEL_SIZE: 9\n",
            "    INFERENCE_TH_TEST: 0.05\n",
            "    INFERENCE_TH_TRAIN: 0.05\n",
            "    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']\n",
            "    IOU_LABELS: [0, 1]\n",
            "    IOU_THRESHOLDS: [0.5]\n",
            "    LAST_DEFORMABLE: False\n",
            "    LOC_LOSS_TYPE: giou\n",
            "    LOSS_ALPHA: 0.25\n",
            "    LOSS_GAMMA: 2.0\n",
            "    LOSS_ON_MASK: False\n",
            "    MASK_LOSS_TYPE: mse\n",
            "    MASK_ON: True\n",
            "    MASK_SIZE: 28\n",
            "    NMS_TH: 0.6\n",
            "    NORM: GN\n",
            "    NUM_BOX_CONVS: 4\n",
            "    NUM_CLASSES: 80\n",
            "    NUM_CLS_CONVS: 4\n",
            "    NUM_MASK_CONVS: 4\n",
            "    NUM_SHARE_CONVS: 0\n",
            "    PATH_COMPONENTS: datasets/coco/components/coco_2017_train_class_agnosticTrue_whitenTrue_sigmoidTrue_60.npz\n",
            "    POST_NMS_TOPK_TEST: 100\n",
            "    POST_NMS_TOPK_TRAIN: 100\n",
            "    POS_RADIUS: 1.5\n",
            "    PRE_NMS_TOPK_TEST: 1000\n",
            "    PRE_NMS_TOPK_TRAIN: 1000\n",
            "    PRIOR_PROB: 0.01\n",
            "    SIGMOID: True\n",
            "    SIZES_OF_INTEREST: [64, 128, 256, 512]\n",
            "    THRESH_WITH_CTR: False\n",
            "    TOP_LEVELS: 2\n",
            "    TYPE_DEFORMABLE: DCNv1\n",
            "    USE_DEFORMABLE: False\n",
            "    USE_GCN_IN_MASK: False\n",
            "    USE_RELU: True\n",
            "    USE_SCALE: True\n",
            "    WHITEN: True\n",
            "  META_ARCHITECTURE: SOLOv2\n",
            "  MOBILENET: False\n",
            "  PANOPTIC_FPN:\n",
            "    COMBINE:\n",
            "      ENABLED: True\n",
            "      INSTANCES_CONFIDENCE_THRESH: 0.5\n",
            "      OVERLAP_THRESH: 0.5\n",
            "      STUFF_AREA_LIMIT: 4096\n",
            "    INSTANCE_LOSS_WEIGHT: 1.0\n",
            "  PIXEL_MEAN: [103.53, 116.28, 123.675]\n",
            "  PIXEL_STD: [1.0, 1.0, 1.0]\n",
            "  PROPOSAL_GENERATOR:\n",
            "    MIN_SIZE: 0\n",
            "    NAME: RPN\n",
            "  RESNETS:\n",
            "    DEFORM_INTERVAL: 1\n",
            "    DEFORM_MODULATED: False\n",
            "    DEFORM_NUM_GROUPS: 1\n",
            "    DEFORM_ON_PER_STAGE: [False, False, False, False]\n",
            "    DEPTH: 50\n",
            "    NORM: FrozenBN\n",
            "    NUM_GROUPS: 1\n",
            "    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']\n",
            "    RES2_OUT_CHANNELS: 256\n",
            "    RES5_DILATION: 1\n",
            "    STEM_OUT_CHANNELS: 64\n",
            "    STRIDE_IN_1X1: True\n",
            "    WIDTH_PER_GROUP: 64\n",
            "  RETINANET:\n",
            "    BBOX_REG_LOSS_TYPE: smooth_l1\n",
            "    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)\n",
            "    FOCAL_LOSS_ALPHA: 0.25\n",
            "    FOCAL_LOSS_GAMMA: 2.0\n",
            "    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']\n",
            "    IOU_LABELS: [0, -1, 1]\n",
            "    IOU_THRESHOLDS: [0.4, 0.5]\n",
            "    NMS_THRESH_TEST: 0.5\n",
            "    NORM: \n",
            "    NUM_CLASSES: 80\n",
            "    NUM_CONVS: 4\n",
            "    PRIOR_PROB: 0.01\n",
            "    SCORE_THRESH_TEST: 0.05\n",
            "    SMOOTH_L1_LOSS_BETA: 0.1\n",
            "    TOPK_CANDIDATES_TEST: 1000\n",
            "  ROI_BOX_CASCADE_HEAD:\n",
            "    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))\n",
            "    IOUS: (0.5, 0.6, 0.7)\n",
            "  ROI_BOX_HEAD:\n",
            "    BBOX_REG_LOSS_TYPE: smooth_l1\n",
            "    BBOX_REG_LOSS_WEIGHT: 1.0\n",
            "    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)\n",
            "    CLS_AGNOSTIC_BBOX_REG: False\n",
            "    CONV_DIM: 256\n",
            "    FC_DIM: 1024\n",
            "    FED_LOSS_FREQ_WEIGHT_POWER: 0.5\n",
            "    FED_LOSS_NUM_CLASSES: 50\n",
            "    NAME: \n",
            "    NORM: \n",
            "    NUM_CONV: 0\n",
            "    NUM_FC: 0\n",
            "    POOLER_RESOLUTION: 14\n",
            "    POOLER_SAMPLING_RATIO: 0\n",
            "    POOLER_TYPE: ROIAlignV2\n",
            "    SMOOTH_L1_BETA: 0.0\n",
            "    TRAIN_ON_PRED_BOXES: False\n",
            "    USE_FED_LOSS: False\n",
            "    USE_SIGMOID_CE: False\n",
            "  ROI_HEADS:\n",
            "    BATCH_SIZE_PER_IMAGE: 512\n",
            "    IN_FEATURES: ['res4']\n",
            "    IOU_LABELS: [0, 1]\n",
            "    IOU_THRESHOLDS: [0.5]\n",
            "    NAME: Res5ROIHeads\n",
            "    NMS_THRESH_TEST: 0.5\n",
            "    NUM_CLASSES: 80\n",
            "    POSITIVE_FRACTION: 0.25\n",
            "    PROPOSAL_APPEND_GT: True\n",
            "    SCORE_THRESH_TEST: 0.05\n",
            "  ROI_KEYPOINT_HEAD:\n",
            "    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)\n",
            "    LOSS_WEIGHT: 1.0\n",
            "    MIN_KEYPOINTS_PER_IMAGE: 1\n",
            "    NAME: KRCNNConvDeconvUpsampleHead\n",
            "    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True\n",
            "    NUM_KEYPOINTS: 17\n",
            "    POOLER_RESOLUTION: 14\n",
            "    POOLER_SAMPLING_RATIO: 0\n",
            "    POOLER_TYPE: ROIAlignV2\n",
            "  ROI_MASK_HEAD:\n",
            "    CLS_AGNOSTIC_MASK: False\n",
            "    CONV_DIM: 256\n",
            "    NAME: MaskRCNNConvUpsampleHead\n",
            "    NORM: \n",
            "    NUM_CONV: 0\n",
            "    POOLER_RESOLUTION: 14\n",
            "    POOLER_SAMPLING_RATIO: 0\n",
            "    POOLER_TYPE: ROIAlignV2\n",
            "  RPN:\n",
            "    BATCH_SIZE_PER_IMAGE: 256\n",
            "    BBOX_REG_LOSS_TYPE: smooth_l1\n",
            "    BBOX_REG_LOSS_WEIGHT: 1.0\n",
            "    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)\n",
            "    BOUNDARY_THRESH: -1\n",
            "    CONV_DIMS: [-1]\n",
            "    HEAD_NAME: StandardRPNHead\n",
            "    IN_FEATURES: ['res4']\n",
            "    IOU_LABELS: [0, -1, 1]\n",
            "    IOU_THRESHOLDS: [0.3, 0.7]\n",
            "    LOSS_WEIGHT: 1.0\n",
            "    NMS_THRESH: 0.7\n",
            "    POSITIVE_FRACTION: 0.5\n",
            "    POST_NMS_TOPK_TEST: 1000\n",
            "    POST_NMS_TOPK_TRAIN: 2000\n",
            "    PRE_NMS_TOPK_TEST: 6000\n",
            "    PRE_NMS_TOPK_TRAIN: 12000\n",
            "    SMOOTH_L1_BETA: 0.0\n",
            "  SEM_SEG_HEAD:\n",
            "    COMMON_STRIDE: 4\n",
            "    CONVS_DIM: 128\n",
            "    IGNORE_VALUE: 255\n",
            "    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']\n",
            "    LOSS_WEIGHT: 1.0\n",
            "    NAME: SemSegFPNHead\n",
            "    NORM: GN\n",
            "    NUM_CLASSES: 54\n",
            "  SOLOV2:\n",
            "    FPN_INSTANCE_STRIDES: [8, 8, 16, 32, 32]\n",
            "    FPN_SCALE_RANGES: ((1, 96), (48, 192), (96, 384), (192, 768), (384, 2048))\n",
            "    INSTANCE_CHANNELS: 512\n",
            "    INSTANCE_IN_CHANNELS: 256\n",
            "    INSTANCE_IN_FEATURES: ['p2', 'p3', 'p4', 'p5', 'p6']\n",
            "    LOSS:\n",
            "      DICE_WEIGHT: 3.0\n",
            "      FOCAL_ALPHA: 0.25\n",
            "      FOCAL_GAMMA: 2.0\n",
            "      FOCAL_USE_SIGMOID: True\n",
            "      FOCAL_WEIGHT: 1.0\n",
            "    MASK_CHANNELS: 128\n",
            "    MASK_IN_CHANNELS: 256\n",
            "    MASK_IN_FEATURES: ['p2', 'p3', 'p4', 'p5']\n",
            "    MASK_THR: 0.5\n",
            "    MAX_PER_IMG: 100\n",
            "    NMS_KERNEL: gaussian\n",
            "    NMS_PRE: 500\n",
            "    NMS_SIGMA: 2\n",
            "    NMS_TYPE: matrix\n",
            "    NORM: GN\n",
            "    NUM_CLASSES: 80\n",
            "    NUM_GRIDS: [40, 36, 24, 16, 12]\n",
            "    NUM_INSTANCE_CONVS: 4\n",
            "    NUM_KERNELS: 256\n",
            "    NUM_MASKS: 256\n",
            "    PRIOR_PROB: 0.01\n",
            "    SCORE_THR: 0.1\n",
            "    SIGMA: 0.2\n",
            "    TYPE_DCN: DCN\n",
            "    UPDATE_THR: 0.05\n",
            "    USE_COORD_CONV: True\n",
            "    USE_DCN_IN_INSTANCE: False\n",
            "  TOP_MODULE:\n",
            "    DIM: 16\n",
            "    NAME: conv\n",
            "  VOVNET:\n",
            "    BACKBONE_OUT_CHANNELS: 256\n",
            "    CONV_BODY: V-39-eSE\n",
            "    NORM: FrozenBN\n",
            "    OUT_CHANNELS: 256\n",
            "    OUT_FEATURES: ['stage2', 'stage3', 'stage4', 'stage5']\n",
            "  WEIGHTS: detectron2://ImageNetPretrained/MSRA/R-50.pkl\n",
            "OUTPUT_DIR: ./output\n",
            "SEED: -1\n",
            "SOLVER:\n",
            "  AMP:\n",
            "    ENABLED: False\n",
            "  BASE_LR: 0.01\n",
            "  BASE_LR_END: 0.0\n",
            "  BIAS_LR_FACTOR: 1.0\n",
            "  CHECKPOINT_PERIOD: 5000\n",
            "  CLIP_GRADIENTS:\n",
            "    CLIP_TYPE: value\n",
            "    CLIP_VALUE: 1.0\n",
            "    ENABLED: False\n",
            "    NORM_TYPE: 2.0\n",
            "  GAMMA: 0.1\n",
            "  IMS_PER_BATCH: 16\n",
            "  LR_SCHEDULER_NAME: WarmupMultiStepLR\n",
            "  MAX_ITER: 270000\n",
            "  MOMENTUM: 0.9\n",
            "  NESTEROV: False\n",
            "  REFERENCE_WORLD_SIZE: 0\n",
            "  STEPS: (210000, 250000)\n",
            "  WARMUP_FACTOR: 0.01\n",
            "  WARMUP_ITERS: 1000\n",
            "  WARMUP_METHOD: linear\n",
            "  WEIGHT_DECAY: 0.0001\n",
            "  WEIGHT_DECAY_BIAS: None\n",
            "  WEIGHT_DECAY_NORM: 0.0\n",
            "TEST:\n",
            "  AUG:\n",
            "    ENABLED: False\n",
            "    FLIP: True\n",
            "    MAX_SIZE: 4000\n",
            "    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)\n",
            "  DETECTIONS_PER_IMAGE: 100\n",
            "  EVAL_PERIOD: 0\n",
            "  EXPECTED_RESULTS: []\n",
            "  KEYPOINT_OKS_SIGMAS: []\n",
            "  PRECISE_BN:\n",
            "    ENABLED: False\n",
            "    NUM_ITER: 200\n",
            "VERSION: 2\n",
            "VIS_PERIOD: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_model(cfg_solov2)\n",
        "num_trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(num_trainable_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WU8b_0sjT80T",
        "outputId": "27b507d1-806b-457a-e5d7-6dd3f1ef6bd3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "46317392\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/TACO-expl\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "import os.path\n",
        "import json\n",
        "import argparse\n",
        "import numpy as np\n",
        "import random\n",
        "import datetime as dt\n",
        "import copy\n",
        "import torch.nn as nn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from pathlib import Path\n",
        "\n",
        "import torch\n",
        "import math\n",
        "import torch.utils.data\n",
        "from torch.utils.data import DataLoader\n",
        "from pycocotools import mask as coco_mask\n",
        "\n",
        "\n",
        "from torchvision.ops import RoIAlign\n",
        "from HDDETR.datasets.torchvision_datasets.coco import CocoDetection as TvCocoDetection # from torchvision.datasets import CocoDetection as TvCocoDetection\n",
        "                                                                                       # the right above import import does not work bc of attribute definitions\n",
        "import HDDETR.datasets.transforms as T #from torchvision import transforms as T # this import does not contain the randomselect method\n",
        "import HDDETR.util.misc as mutils"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oEpIySaFnprv",
        "outputId": "0983a973-837a-49d7-e09d-a3ccb1351c03"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/TACO-expl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DEFAULT_RANDOM_SEED = 42\n",
        "# basic random seed\n",
        "def seedBasic(seed=DEFAULT_RANDOM_SEED):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "# torch random seed\n",
        "def seedTorch(seed=DEFAULT_RANDOM_SEED):\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "# combine\n",
        "def seedEverything(seed=DEFAULT_RANDOM_SEED):\n",
        "    seedBasic(seed)\n",
        "    seedTorch(seed)\n",
        "\n",
        "seedEverything()"
      ],
      "metadata": {
        "id": "gHfxVrm3nrzg"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keep_categories = [\"Bottle\", \"Bottle cap\", \"Can\", \"Cigarette\", \"Cup\",\n",
        "                   \"Lid\", \"Plastic bag & wrapper\", \"Pop tab\", \"Straw\"]\n",
        "\n",
        "def create_map(original, keep_supercategories):\n",
        "  class_map = {}\n",
        "  for cat in original:\n",
        "    if cat[\"supercategory\"] in keep_supercategories:\n",
        "      class_map[cat[\"name\"]] = cat[\"supercategory\"]\n",
        "    else:\n",
        "      class_map[cat[\"name\"]] = \"Other\"\n",
        "  return class_map\n",
        "\n",
        "def replace_dataset_classes(dataset, class_map):\n",
        "      \"\"\" Replaces classes of dataset based on a dictionary\"\"\"\n",
        "      class_new_names = list(set(class_map.values()))\n",
        "      class_new_names.sort()\n",
        "      class_originals = copy.deepcopy(dataset['categories'])\n",
        "      dataset['categories'] = []\n",
        "      class_ids_map = {}  # map from old id to new id\n",
        "\n",
        "      # Assign background id 0\n",
        "      has_background = False\n",
        "      if 'Background' in class_new_names:\n",
        "          if class_new_names.index('Background') != 0:\n",
        "              class_new_names.remove('Background')\n",
        "              class_new_names.insert(0, 'Background')\n",
        "          has_background = True\n",
        "\n",
        "      # Replace categories\n",
        "      for id_new, class_new_name in enumerate(class_new_names):\n",
        "          # Make sure id:0 is reserved for background\n",
        "          id_rectified = id_new\n",
        "          if not has_background:\n",
        "              id_rectified += 1\n",
        "\n",
        "          category = {\n",
        "              'supercategory': '',\n",
        "              'id': id_rectified,  # Background has id=0\n",
        "              'name': class_new_name,\n",
        "          }\n",
        "          dataset['categories'].append(category)\n",
        "          # Map class names\n",
        "          for class_original in class_originals:\n",
        "              if class_map[class_original['name']] == class_new_name:\n",
        "                  class_ids_map[class_original['id']] = id_rectified\n",
        "\n",
        "      # Update annotations category id tag\n",
        "      for ann in dataset['annotations']:\n",
        "          ann['category_id'] = class_ids_map[ann['category_id']]"
      ],
      "metadata": {
        "id": "ZCws_VTInwr5"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/TACO-expl/data/annotations.json\", \"r\") as f: #\"/content/TACO/data/annotations.json\"\n",
        "    dataset = json.loads(f.read())\n",
        "\n",
        "class_map = create_map(dataset[\"categories\"], keep_categories)\n",
        "replace_dataset_classes(dataset, class_map)\n",
        "dataset[\"categories\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9QJNgK7anxnv",
        "outputId": "1579abd0-bd95-4314-dbf3-8053ac6a7116"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'supercategory': '', 'id': 1, 'name': 'Bottle'},\n",
              " {'supercategory': '', 'id': 2, 'name': 'Bottle cap'},\n",
              " {'supercategory': '', 'id': 3, 'name': 'Can'},\n",
              " {'supercategory': '', 'id': 4, 'name': 'Cigarette'},\n",
              " {'supercategory': '', 'id': 5, 'name': 'Cup'},\n",
              " {'supercategory': '', 'id': 6, 'name': 'Lid'},\n",
              " {'supercategory': '', 'id': 7, 'name': 'Other'},\n",
              " {'supercategory': '', 'id': 8, 'name': 'Plastic bag & wrapper'},\n",
              " {'supercategory': '', 'id': 9, 'name': 'Pop tab'},\n",
              " {'supercategory': '', 'id': 10, 'name': 'Straw'}]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classes = [elem[\"name\"] for elem in dataset[\"categories\"]]\n",
        "print(classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mz77Fd0Any8W",
        "outputId": "11e4d55e-cb52-4e8d-fd51-ede4380ece8e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Bottle', 'Bottle cap', 'Can', 'Cigarette', 'Cup', 'Lid', 'Other', 'Plastic bag & wrapper', 'Pop tab', 'Straw']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!mkdir /content/official/\n",
        "!cp -r /content/MyDrive/MyDrive/official/ /content/\n",
        "!mkdir /content/output/\n",
        "!cp -r /content/MyDrive/MyDrive/solo_models/chkpt/ /content/output/"
      ],
      "metadata": {
        "id": "abjM4Yf0jP7s"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from detectron2.data.datasets import register_coco_instances\n",
        "from detectron2.data import MetadataCatalog\n",
        "\n",
        "train_annotation_file = '/content/TACO-expl/data/annotations_off_0_train.json'\n",
        "val_annotation_file = '/content/TACO-expl/data/annotations_off_0_val.json'\n",
        "\n",
        "img_dir = '/content/official/'\n",
        "\n",
        "#register_coco_instances(\"TACO_train\", {}, train_dataset.annotation_file, train_dataset.image_dir)\n",
        "#MetadataCatalog.get(\"TACO_train\").set(thing_classes=train_dataset.classes)\n",
        "#dataset_dicts_train = DatasetCatalog.get(\"TACO_train\")\n",
        "\n",
        "#register_coco_instances(\"TACO_val\", {}, val_dataset.annotation_file, val_dataset.image_dir)\n",
        "#MetadataCatalog.get(\"TACO_val\").set(thing_classes=val_dataset.classes)\n",
        "#dataset_dicts_val = DatasetCatalog.get(\"TACO_val\")\n",
        "\n",
        "register_coco_instances(\"TACO_train\", {}, train_annotation_file, img_dir)\n",
        "MetadataCatalog.get(\"TACO_train\").set(thing_classes = classes)\n",
        "dataset_dicts_train = DatasetCatalog.get(\"TACO_train\")\n",
        "\n",
        "register_coco_instances(\"TACO_val\", {}, val_annotation_file, img_dir)\n",
        "MetadataCatalog.get(\"TACO_val\").set(thing_classes = classes)\n",
        "dataset_dicts_val = DatasetCatalog.get(\"TACO_val\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LmR4YkANn3eG",
        "outputId": "448cefe6-eb7c-41e0-8f33-b6dd162d960f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05/10 06:07:46 d2.data.datasets.coco]: Loaded 1200 images in COCO format from /content/TACO-expl/data/annotations_off_0_train.json\n",
            "[05/10 06:07:46 d2.data.datasets.coco]: Loaded 150 images in COCO format from /content/TACO-expl/data/annotations_off_0_val.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset_dicts_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pUaBOZRUlx1V",
        "outputId": "a9b643ef-2cd6-4f3b-fdf3-46f94ff99ccc"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'file_name': '/content/official/batch_1/000058.jpg', 'height': 2049, 'width': 1537, 'image_id': 15, 'annotations': [{'iscrowd': 0, 'bbox': [150.0, 328.0, 568.0, 1304.0], 'category_id': 0, 'segmentation': [[249.0, 1458.0, 236.0, 1360.0, 222.0, 1247.0, 150.0, 784.0, 150.0, 747.0, 157.0, 712.0, 172.0, 675.0, 184.0, 656.0, 205.0, 632.0, 238.0, 603.0, 263.0, 589.0, 299.0, 575.0, 312.0, 570.0, 322.0, 568.0, 324.0, 567.0, 323.0, 538.0, 319.0, 497.0, 314.0, 432.0, 307.0, 362.0, 307.0, 354.0, 313.0, 346.0, 317.0, 343.0, 328.0, 338.0, 345.0, 333.0, 355.0, 330.0, 363.0, 328.0, 371.0, 334.0, 386.0, 332.0, 404.0, 330.0, 421.0, 330.0, 450.0, 332.0, 476.0, 335.0, 486.0, 338.0, 489.0, 337.0, 493.0, 335.0, 501.0, 337.0, 509.0, 341.0, 518.0, 346.0, 527.0, 351.0, 531.0, 359.0, 531.0, 369.0, 532.0, 400.0, 533.0, 429.0, 538.0, 526.0, 541.0, 566.0, 545.0, 568.0, 582.0, 580.0, 626.0, 604.0, 655.0, 627.0, 688.0, 667.0, 707.0, 704.0, 717.0, 753.0, 718.0, 806.0, 712.0, 952.0, 706.0, 1090.0, 698.0, 1222.0, 693.0, 1386.0, 688.0, 1433.0, 685.0, 1454.0, 671.0, 1493.0, 644.0, 1539.0, 603.0, 1582.0, 552.0, 1614.0, 498.0, 1630.0, 445.0, 1632.0, 381.0, 1617.0, 329.0, 1589.0, 285.0, 1544.0, 265.0, 1505.0, 256.0, 1482.0, 249.0, 1458.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [802.0, 405.0, 547.0, 1404.0], 'category_id': 0, 'segmentation': [[802.0, 1576.0, 804.0, 1525.0, 805.0, 1507.0, 807.0, 1503.0, 815.0, 1492.0, 818.0, 1419.0, 830.0, 1054.0, 843.0, 753.0, 847.0, 680.0, 857.0, 660.0, 876.0, 644.0, 910.0, 626.0, 949.0, 609.0, 986.0, 598.0, 992.0, 587.0, 976.0, 574.0, 969.0, 558.0, 971.0, 546.0, 982.0, 453.0, 985.0, 441.0, 998.0, 429.0, 1022.0, 418.0, 1054.0, 411.0, 1088.0, 405.0, 1136.0, 405.0, 1183.0, 412.0, 1216.0, 426.0, 1235.0, 434.0, 1254.0, 445.0, 1267.0, 461.0, 1265.0, 489.0, 1260.0, 514.0, 1257.0, 541.0, 1253.0, 550.0, 1251.0, 559.0, 1250.0, 573.0, 1255.0, 579.0, 1246.0, 591.0, 1230.0, 600.0, 1220.0, 604.0, 1222.0, 610.0, 1187.0, 658.0, 1249.0, 617.0, 1289.0, 651.0, 1322.0, 704.0, 1339.0, 743.0, 1349.0, 767.0, 1348.0, 800.0, 1342.0, 828.0, 1331.0, 881.0, 1266.0, 1149.0, 1170.0, 1541.0, 1159.0, 1589.0, 1159.0, 1598.0, 1165.0, 1642.0, 1163.0, 1651.0, 1155.0, 1696.0, 1145.0, 1721.0, 1140.0, 1728.0, 1120.0, 1744.0, 1079.0, 1771.0, 1032.0, 1796.0, 1001.0, 1809.0, 987.0, 1808.0, 968.0, 1801.0, 932.0, 1765.0, 888.0, 1716.0, 845.0, 1659.0, 811.0, 1604.0, 804.0, 1591.0, 802.0, 1576.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [971.0, 405.0, 296.0, 191.0], 'category_id': 1, 'segmentation': [[971.0, 543.0, 981.0, 557.0, 995.0, 565.0, 1028.0, 579.0, 1067.0, 588.0, 1098.0, 592.0, 1132.0, 596.0, 1170.0, 596.0, 1201.0, 592.0, 1226.0, 588.0, 1241.0, 580.0, 1250.0, 573.0, 1251.0, 558.0, 1252.0, 552.0, 1257.0, 542.0, 1260.0, 515.0, 1267.0, 462.0, 1254.0, 445.0, 1235.0, 435.0, 1183.0, 413.0, 1136.0, 405.0, 1089.0, 405.0, 1024.0, 417.0, 1000.0, 428.0, 984.0, 441.0, 971.0, 543.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_1/000027.jpg', 'height': 2049, 'width': 1537, 'image_id': 29, 'annotations': [{'iscrowd': 0, 'bbox': [668.0, 717.0, 455.0, 655.0], 'category_id': 2, 'segmentation': [[729.0, 1322.0, 806.0, 1354.0, 861.0, 1372.0, 937.0, 1251.0, 1006.0, 1101.0, 1123.0, 845.0, 1118.0, 821.0, 1104.0, 807.0, 1097.0, 791.0, 1031.0, 748.0, 962.0, 725.0, 932.0, 717.0, 911.0, 726.0, 885.0, 727.0, 872.0, 746.0, 802.0, 905.0, 711.0, 1104.0, 668.0, 1212.0, 673.0, 1285.0, 688.0, 1300.0, 729.0, 1322.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_1/000035.jpg', 'height': 2049, 'width': 1537, 'image_id': 43, 'annotations': [{'iscrowd': 0, 'bbox': [33.0, 230.0, 602.0, 1316.0], 'category_id': 0, 'segmentation': [[210.0, 1503.0, 180.0, 1463.0, 168.0, 1444.0, 169.0, 1426.0, 152.0, 1406.0, 117.0, 1294.0, 65.0, 1125.0, 49.0, 988.0, 56.0, 888.0, 64.0, 808.0, 52.0, 763.0, 33.0, 700.0, 38.0, 637.0, 64.0, 586.0, 103.0, 526.0, 123.0, 496.0, 143.0, 477.0, 129.0, 459.0, 114.0, 447.0, 92.0, 352.0, 98.0, 335.0, 116.0, 320.0, 138.0, 307.0, 129.0, 257.0, 143.0, 243.0, 253.0, 230.0, 281.0, 233.0, 294.0, 239.0, 290.0, 252.0, 290.0, 269.0, 299.0, 294.0, 327.0, 305.0, 350.0, 317.0, 358.0, 334.0, 371.0, 420.0, 360.0, 441.0, 352.0, 455.0, 361.0, 461.0, 390.0, 477.0, 439.0, 517.0, 472.0, 548.0, 500.0, 577.0, 515.0, 608.0, 522.0, 636.0, 523.0, 663.0, 520.0, 695.0, 521.0, 710.0, 529.0, 729.0, 542.0, 761.0, 567.0, 806.0, 587.0, 854.0, 610.0, 927.0, 614.0, 971.0, 625.0, 1029.0, 630.0, 1086.0, 633.0, 1151.0, 635.0, 1204.0, 631.0, 1235.0, 625.0, 1257.0, 625.0, 1280.0, 630.0, 1296.0, 626.0, 1341.0, 618.0, 1376.0, 595.0, 1405.0, 551.0, 1441.0, 498.0, 1477.0, 426.0, 1512.0, 345.0, 1537.0, 273.0, 1546.0, 241.0, 1535.0, 210.0, 1503.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [807.0, 103.0, 710.0, 1613.0], 'category_id': 0, 'segmentation': [[1043.0, 1687.0, 1132.0, 1712.0, 1181.0, 1716.0, 1219.0, 1709.0, 1256.0, 1692.0, 1283.0, 1676.0, 1304.0, 1656.0, 1324.0, 1610.0, 1354.0, 1558.0, 1402.0, 1450.0, 1433.0, 1368.0, 1468.0, 1270.0, 1491.0, 1192.0, 1507.0, 1118.0, 1516.0, 1044.0, 1517.0, 975.0, 1509.0, 915.0, 1501.0, 835.0, 1484.0, 733.0, 1478.0, 667.0, 1452.0, 553.0, 1435.0, 492.0, 1427.0, 465.0, 1413.0, 453.0, 1425.0, 432.0, 1428.0, 404.0, 1433.0, 357.0, 1441.0, 334.0, 1453.0, 287.0, 1477.0, 222.0, 1473.0, 184.0, 1430.0, 162.0, 1426.0, 142.0, 1401.0, 127.0, 1329.0, 109.0, 1271.0, 103.0, 1228.0, 103.0, 1213.0, 117.0, 1214.0, 131.0, 1224.0, 145.0, 1232.0, 154.0, 1229.0, 178.0, 1232.0, 201.0, 1220.0, 228.0, 1198.0, 239.0, 1166.0, 250.0, 1148.0, 262.0, 1138.0, 308.0, 1125.0, 379.0, 1116.0, 394.0, 1121.0, 421.0, 1105.0, 431.0, 1076.0, 468.0, 1037.0, 540.0, 969.0, 652.0, 926.0, 728.0, 897.0, 784.0, 867.0, 853.0, 839.0, 936.0, 823.0, 1008.0, 813.0, 1088.0, 810.0, 1146.0, 807.0, 1208.0, 809.0, 1313.0, 811.0, 1387.0, 815.0, 1476.0, 819.0, 1505.0, 824.0, 1535.0, 838.0, 1574.0, 860.0, 1606.0, 891.0, 1633.0, 917.0, 1648.0, 944.0, 1663.0, 1043.0, 1687.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [886.0, 522.0, 314.0, 432.0], 'category_id': 4, 'segmentation': [[889.0, 762.0, 893.0, 564.0, 921.0, 545.0, 975.0, 526.0, 1012.0, 522.0, 1042.0, 522.0, 1121.0, 535.0, 1185.0, 577.0, 1200.0, 613.0, 1184.0, 732.0, 1155.0, 897.0, 1123.0, 932.0, 1054.0, 954.0, 964.0, 948.0, 907.0, 927.0, 886.0, 878.0, 889.0, 762.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_1/000037.jpg', 'height': 1537, 'width': 2049, 'image_id': 44, 'annotations': [{'iscrowd': 0, 'bbox': [929.0, 557.0, 379.0, 500.0], 'category_id': 2, 'segmentation': [[1059.0, 1048.0, 1087.0, 1055.0, 1120.0, 1057.0, 1157.0, 1053.0, 1185.0, 1046.0, 1215.0, 1024.0, 1231.0, 999.0, 1243.0, 969.0, 1277.0, 814.0, 1298.0, 721.0, 1308.0, 698.0, 1308.0, 663.0, 1297.0, 634.0, 1273.0, 606.0, 1239.0, 580.0, 1197.0, 561.0, 1137.0, 557.0, 1088.0, 566.0, 1060.0, 587.0, 1043.0, 612.0, 1036.0, 627.0, 974.0, 783.0, 929.0, 890.0, 929.0, 936.0, 948.0, 977.0, 990.0, 1014.0, 1030.0, 1036.0, 1059.0, 1048.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [494.0, 531.0, 372.0, 533.0], 'category_id': 2, 'segmentation': [[688.0, 1064.0, 723.0, 1064.0, 759.0, 1056.0, 795.0, 1042.0, 820.0, 1025.0, 843.0, 1003.0, 856.0, 982.0, 862.0, 958.0, 866.0, 933.0, 861.0, 873.0, 856.0, 788.0, 851.0, 679.0, 848.0, 615.0, 841.0, 597.0, 824.0, 575.0, 806.0, 563.0, 780.0, 547.0, 744.0, 536.0, 708.0, 531.0, 666.0, 532.0, 630.0, 538.0, 594.0, 548.0, 567.0, 561.0, 544.0, 576.0, 525.0, 592.0, 508.0, 614.0, 496.0, 639.0, 494.0, 659.0, 501.0, 684.0, 508.0, 703.0, 519.0, 748.0, 540.0, 835.0, 557.0, 912.0, 570.0, 980.0, 579.0, 997.0, 592.0, 1013.0, 606.0, 1028.0, 624.0, 1041.0, 643.0, 1052.0, 666.0, 1059.0, 688.0, 1064.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [709.0, 271.0, 296.0, 482.0], 'category_id': 2, 'segmentation': [[912.0, 752.0, 936.0, 746.0, 960.0, 730.0, 978.0, 711.0, 993.0, 689.0, 996.0, 663.0, 999.0, 584.0, 999.0, 467.0, 1005.0, 362.0, 1005.0, 339.0, 989.0, 313.0, 958.0, 290.0, 920.0, 279.0, 866.0, 271.0, 810.0, 277.0, 775.0, 285.0, 738.0, 304.0, 717.0, 329.0, 709.0, 352.0, 715.0, 372.0, 720.0, 413.0, 728.0, 484.0, 734.0, 532.0, 774.0, 544.0, 793.0, 553.0, 811.0, 563.0, 820.0, 571.0, 833.0, 585.0, 844.0, 604.0, 849.0, 624.0, 850.0, 643.0, 857.0, 753.0, 879.0, 753.0, 893.0, 753.0, 912.0, 752.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [658.0, 639.0, 137.0, 90.0], 'category_id': 8, 'segmentation': [[739.0, 727.0, 721.0, 720.0, 702.0, 711.0, 681.0, 702.0, 667.0, 692.0, 658.0, 680.0, 661.0, 667.0, 672.0, 658.0, 693.0, 646.0, 706.0, 640.0, 726.0, 639.0, 745.0, 645.0, 760.0, 654.0, 774.0, 671.0, 790.0, 688.0, 795.0, 702.0, 789.0, 713.0, 778.0, 723.0, 762.0, 728.0, 751.0, 729.0, 739.0, 727.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [781.0, 293.0, 101.0, 76.0], 'category_id': 8, 'segmentation': [[800.0, 358.0, 817.0, 367.0, 838.0, 369.0, 861.0, 366.0, 879.0, 353.0, 882.0, 341.0, 879.0, 329.0, 862.0, 321.0, 843.0, 311.0, 825.0, 299.0, 811.0, 293.0, 798.0, 298.0, 783.0, 307.0, 781.0, 323.0, 789.0, 344.0, 800.0, 358.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_1/000074.JPG', 'height': 3264, 'width': 2448, 'image_id': 56, 'annotations': [{'iscrowd': 0, 'bbox': [1205.0, 1905.0, 211.0, 271.0], 'category_id': 4, 'segmentation': [[1345.0, 1906.0, 1362.0, 1905.0, 1381.0, 1916.0, 1399.0, 1931.0, 1411.0, 1950.0, 1416.0, 1970.0, 1405.0, 1992.0, 1380.0, 2052.0, 1366.0, 2083.0, 1362.0, 2087.0, 1362.0, 2095.0, 1353.0, 2094.0, 1348.0, 2093.0, 1342.0, 2092.0, 1343.0, 2083.0, 1347.0, 2075.0, 1346.0, 2071.0, 1344.0, 2071.0, 1342.0, 2075.0, 1341.0, 2066.0, 1338.0, 2065.0, 1337.0, 2070.0, 1333.0, 2067.0, 1329.0, 2069.0, 1329.0, 2075.0, 1333.0, 2080.0, 1338.0, 2092.0, 1335.0, 2095.0, 1340.0, 2099.0, 1343.0, 2118.0, 1337.0, 2116.0, 1329.0, 2113.0, 1331.0, 2124.0, 1326.0, 2127.0, 1321.0, 2120.0, 1318.0, 2124.0, 1313.0, 2121.0, 1312.0, 2109.0, 1310.0, 2116.0, 1304.0, 2109.0, 1299.0, 2113.0, 1307.0, 2120.0, 1308.0, 2124.0, 1302.0, 2126.0, 1303.0, 2130.0, 1312.0, 2128.0, 1314.0, 2133.0, 1309.0, 2137.0, 1313.0, 2139.0, 1318.0, 2143.0, 1321.0, 2147.0, 1313.0, 2145.0, 1311.0, 2148.0, 1308.0, 2149.0, 1303.0, 2144.0, 1302.0, 2151.0, 1298.0, 2147.0, 1297.0, 2150.0, 1294.0, 2149.0, 1293.0, 2154.0, 1292.0, 2157.0, 1290.0, 2152.0, 1285.0, 2147.0, 1282.0, 2153.0, 1285.0, 2156.0, 1286.0, 2159.0, 1282.0, 2155.0, 1280.0, 2149.0, 1277.0, 2147.0, 1277.0, 2152.0, 1268.0, 2152.0, 1271.0, 2157.0, 1277.0, 2160.0, 1286.0, 2161.0, 1293.0, 2164.0, 1297.0, 2163.0, 1299.0, 2166.0, 1297.0, 2168.0, 1296.0, 2171.0, 1302.0, 2169.0, 1305.0, 2172.0, 1299.0, 2176.0, 1286.0, 2176.0, 1266.0, 2172.0, 1245.0, 2162.0, 1226.0, 2148.0, 1213.0, 2131.0, 1207.0, 2118.0, 1205.0, 2101.0, 1207.0, 2085.0, 1220.0, 2071.0, 1232.0, 2061.0, 1253.0, 2030.0, 1271.0, 2003.0, 1333.0, 1916.0, 1338.0, 1909.0, 1345.0, 1906.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [1776.0, 1222.0, 38.0, 10.0], 'category_id': 3, 'segmentation': [[1806.0, 1232.0, 1780.0, 1230.0, 1776.0, 1224.0, 1814.0, 1222.0, 1814.0, 1228.0, 1806.0, 1232.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_1/000079.JPG', 'height': 3264, 'width': 2448, 'image_id': 59, 'annotations': [{'iscrowd': 0, 'bbox': [257.0, 1089.0, 1712.0, 1781.0], 'category_id': 6, 'segmentation': [[1167.0, 1176.0, 1285.0, 1180.0, 1407.0, 1231.0, 1490.0, 1180.0, 1564.0, 1110.0, 1597.0, 1089.0, 1633.0, 1134.0, 1692.0, 1241.0, 1732.0, 1331.0, 1776.0, 1465.0, 1860.0, 1534.0, 1866.0, 1563.0, 1901.0, 1607.0, 1947.0, 1761.0, 1940.0, 1776.0, 1969.0, 1840.0, 1963.0, 1876.0, 1941.0, 1896.0, 1953.0, 1984.0, 1936.0, 2115.0, 1927.0, 2193.0, 1912.0, 2275.0, 1905.0, 2332.0, 1769.0, 2362.0, 1722.0, 2358.0, 1703.0, 2345.0, 1668.0, 2254.0, 1606.0, 2254.0, 1563.0, 2230.0, 1520.0, 2248.0, 1491.0, 2272.0, 1495.0, 2298.0, 1487.0, 2326.0, 1473.0, 2426.0, 1455.0, 2469.0, 1434.0, 2508.0, 1401.0, 2558.0, 1373.0, 2604.0, 1337.0, 2618.0, 1298.0, 2609.0, 1197.0, 2586.0, 1110.0, 2581.0, 1082.0, 2578.0, 1033.0, 2554.0, 1017.0, 2551.0, 1009.0, 2571.0, 952.0, 2592.0, 941.0, 2593.0, 936.0, 2658.0, 913.0, 2678.0, 774.0, 2765.0, 674.0, 2832.0, 577.0, 2870.0, 434.0, 2865.0, 386.0, 2842.0, 342.0, 2842.0, 302.0, 2836.0, 290.0, 2836.0, 285.0, 2800.0, 257.0, 2775.0, 273.0, 2726.0, 261.0, 2699.0, 302.0, 2629.0, 302.0, 2599.0, 315.0, 2571.0, 317.0, 2500.0, 338.0, 2457.0, 342.0, 2380.0, 377.0, 2129.0, 454.0, 1804.0, 482.0, 1770.0, 497.0, 1748.0, 592.0, 1586.0, 670.0, 1482.0, 724.0, 1456.0, 727.0, 1441.0, 817.0, 1355.0, 936.0, 1336.0, 950.0, 1339.0, 963.0, 1327.0, 965.0, 1297.0, 977.0, 1287.0, 1120.0, 1204.0, 1167.0, 1176.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_1/000086.JPG', 'height': 3264, 'width': 2448, 'image_id': 65, 'annotations': [{'iscrowd': 0, 'bbox': [1246.0, 1052.0, 407.0, 563.0], 'category_id': 6, 'segmentation': [[1302.0, 1052.0, 1350.0, 1129.0, 1441.0, 1278.0, 1513.0, 1392.0, 1527.0, 1408.0, 1541.0, 1416.0, 1565.0, 1421.0, 1585.0, 1429.0, 1603.0, 1449.0, 1619.0, 1474.0, 1634.0, 1506.0, 1646.0, 1533.0, 1653.0, 1560.0, 1650.0, 1579.0, 1642.0, 1594.0, 1620.0, 1610.0, 1601.0, 1615.0, 1581.0, 1611.0, 1563.0, 1598.0, 1532.0, 1569.0, 1492.0, 1522.0, 1483.0, 1500.0, 1480.0, 1478.0, 1483.0, 1454.0, 1481.0, 1432.0, 1465.0, 1408.0, 1417.0, 1340.0, 1357.0, 1251.0, 1246.0, 1083.0, 1302.0, 1052.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [740.0, 540.0, 122.0, 62.0], 'category_id': 3, 'segmentation': [[862.0, 570.0, 756.0, 602.0, 740.0, 568.0, 764.0, 562.0, 794.0, 566.0, 840.0, 540.0, 862.0, 570.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [1396.0, 1630.0, 124.0, 86.0], 'category_id': 3, 'segmentation': [[1494.0, 1716.0, 1396.0, 1652.0, 1410.0, 1630.0, 1520.0, 1702.0, 1494.0, 1716.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_1/000092.JPG', 'height': 3264, 'width': 2448, 'image_id': 70, 'annotations': [{'iscrowd': 0, 'bbox': [277.0, 686.0, 1133.0, 1198.0], 'category_id': 6, 'segmentation': [[1347.0, 1241.0, 1271.0, 1281.0, 1187.0, 1326.0, 1148.0, 1350.0, 1133.0, 1362.0, 1122.0, 1374.0, 1109.0, 1390.0, 1095.0, 1410.0, 1069.0, 1450.0, 1042.0, 1493.0, 992.0, 1571.0, 945.0, 1649.0, 885.0, 1752.0, 822.0, 1874.0, 816.0, 1883.0, 812.0, 1884.0, 801.0, 1877.0, 760.0, 1848.0, 722.0, 1826.0, 674.0, 1792.0, 577.0, 1720.0, 476.0, 1649.0, 401.0, 1597.0, 336.0, 1552.0, 277.0, 1510.0, 277.0, 1457.0, 281.0, 1400.0, 286.0, 1367.0, 293.0, 1337.0, 302.0, 1309.0, 318.0, 1278.0, 332.0, 1257.0, 346.0, 1241.0, 361.0, 1222.0, 371.0, 1203.0, 373.0, 1191.0, 376.0, 1184.0, 367.0, 1173.0, 340.0, 1134.0, 332.0, 1113.0, 325.0, 1094.0, 326.0, 1076.0, 329.0, 1054.0, 337.0, 1037.0, 344.0, 1021.0, 352.0, 1006.0, 365.0, 981.0, 377.0, 962.0, 382.0, 956.0, 401.0, 936.0, 427.0, 913.0, 451.0, 895.0, 457.0, 889.0, 449.0, 885.0, 459.0, 876.0, 466.0, 881.0, 491.0, 866.0, 460.0, 874.0, 510.0, 841.0, 552.0, 814.0, 565.0, 806.0, 595.0, 784.0, 616.0, 770.0, 664.0, 741.0, 705.0, 716.0, 734.0, 699.0, 761.0, 691.0, 774.0, 689.0, 789.0, 688.0, 809.0, 691.0, 827.0, 694.0, 846.0, 699.0, 859.0, 703.0, 873.0, 709.0, 885.0, 707.0, 894.0, 705.0, 899.0, 696.0, 903.0, 689.0, 908.0, 686.0, 912.0, 688.0, 952.0, 711.0, 998.0, 736.0, 1054.0, 765.0, 1063.0, 770.0, 1075.0, 772.0, 1079.0, 783.0, 1114.0, 802.0, 1147.0, 820.0, 1211.0, 854.0, 1217.0, 853.0, 1221.0, 856.0, 1220.0, 859.0, 1243.0, 872.0, 1300.0, 903.0, 1355.0, 936.0, 1384.0, 953.0, 1398.0, 962.0, 1406.0, 971.0, 1408.0, 978.0, 1410.0, 1010.0, 1410.0, 1030.0, 1408.0, 1064.0, 1405.0, 1088.0, 1400.0, 1113.0, 1392.0, 1143.0, 1385.0, 1167.0, 1378.0, 1186.0, 1371.0, 1202.0, 1365.0, 1215.0, 1356.0, 1231.0, 1347.0, 1241.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [1533.0, 926.0, 618.0, 656.0], 'category_id': 6, 'segmentation': [[2151.0, 1049.0, 2126.0, 1199.0, 2108.0, 1324.0, 2103.0, 1367.0, 2093.0, 1434.0, 2088.0, 1442.0, 2075.0, 1456.0, 2061.0, 1466.0, 2044.0, 1472.0, 2029.0, 1474.0, 2025.0, 1471.0, 1984.0, 1464.0, 1972.0, 1483.0, 1959.0, 1502.0, 1941.0, 1518.0, 1914.0, 1537.0, 1882.0, 1554.0, 1853.0, 1566.0, 1816.0, 1578.0, 1791.0, 1582.0, 1761.0, 1582.0, 1735.0, 1573.0, 1708.0, 1556.0, 1683.0, 1535.0, 1663.0, 1513.0, 1643.0, 1492.0, 1622.0, 1460.0, 1615.0, 1439.0, 1605.0, 1401.0, 1604.0, 1390.0, 1579.0, 1387.0, 1575.0, 1389.0, 1566.0, 1387.0, 1551.0, 1375.0, 1538.0, 1360.0, 1533.0, 1340.0, 1538.0, 1320.0, 1543.0, 1297.0, 1539.0, 1290.0, 1533.0, 1279.0, 1537.0, 1262.0, 1545.0, 1233.0, 1556.0, 1194.0, 1585.0, 1095.0, 1605.0, 1033.0, 1623.0, 962.0, 1637.0, 940.0, 1661.0, 926.0, 1683.0, 926.0, 1702.0, 928.0, 1721.0, 934.0, 1738.0, 938.0, 1753.0, 942.0, 1783.0, 951.0, 1794.0, 955.0, 1814.0, 957.0, 1834.0, 961.0, 1870.0, 967.0, 1896.0, 972.0, 1922.0, 975.0, 1968.0, 980.0, 2037.0, 988.0, 2104.0, 998.0, 2106.0, 1000.0, 2111.0, 1001.0, 2121.0, 1007.0, 2127.0, 1013.0, 2134.0, 1021.0, 2139.0, 1028.0, 2141.0, 1034.0, 2143.0, 1040.0, 2143.0, 1044.0, 2146.0, 1046.0, 2151.0, 1046.0, 2151.0, 1049.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [1535.0, 926.0, 614.0, 525.0], 'category_id': 7, 'segmentation': [[1580.0, 1315.0, 1646.0, 1337.0, 1680.0, 1353.0, 1695.0, 1361.0, 1712.0, 1368.0, 1741.0, 1382.0, 1781.0, 1399.0, 1800.0, 1405.0, 1818.0, 1408.0, 1874.0, 1422.0, 1898.0, 1426.0, 1924.0, 1429.0, 1944.0, 1436.0, 2019.0, 1451.0, 2033.0, 1451.0, 2041.0, 1445.0, 2052.0, 1435.0, 2064.0, 1430.0, 2071.0, 1427.0, 2073.0, 1423.0, 2079.0, 1412.0, 2085.0, 1390.0, 2107.0, 1268.0, 2117.0, 1221.0, 2138.0, 1114.0, 2149.0, 1053.0, 2147.0, 1049.0, 2144.0, 1046.0, 2142.0, 1043.0, 2142.0, 1039.0, 2141.0, 1034.0, 2139.0, 1030.0, 2135.0, 1022.0, 2130.0, 1016.0, 2126.0, 1012.0, 2114.0, 1003.0, 2112.0, 1001.0, 2110.0, 1001.0, 2107.0, 1001.0, 2105.0, 1000.0, 2103.0, 998.0, 2099.0, 997.0, 2092.0, 996.0, 2082.0, 995.0, 2049.0, 990.0, 1891.0, 972.0, 1863.0, 966.0, 1839.0, 962.0, 1809.0, 956.0, 1797.0, 955.0, 1790.0, 954.0, 1785.0, 951.0, 1775.0, 948.0, 1760.0, 944.0, 1741.0, 939.0, 1733.0, 937.0, 1724.0, 935.0, 1715.0, 933.0, 1705.0, 929.0, 1696.0, 927.0, 1686.0, 926.0, 1665.0, 926.0, 1657.0, 928.0, 1646.0, 932.0, 1641.0, 936.0, 1637.0, 941.0, 1633.0, 947.0, 1625.0, 958.0, 1620.0, 968.0, 1617.0, 985.0, 1608.0, 1021.0, 1598.0, 1054.0, 1589.0, 1080.0, 1579.0, 1120.0, 1573.0, 1138.0, 1564.0, 1170.0, 1553.0, 1205.0, 1548.0, 1228.0, 1544.0, 1242.0, 1539.0, 1255.0, 1536.0, 1271.0, 1535.0, 1283.0, 1541.0, 1293.0, 1549.0, 1297.0, 1568.0, 1308.0, 1580.0, 1315.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_1/000098.JPG', 'height': 3264, 'width': 2448, 'image_id': 76, 'annotations': [{'iscrowd': 0, 'bbox': [571.0, 985.0, 447.0, 814.0], 'category_id': 0, 'segmentation': [[929.0, 1203.0, 947.0, 1240.0, 959.0, 1266.0, 976.0, 1300.0, 985.0, 1321.0, 993.0, 1338.0, 1001.0, 1356.0, 1006.0, 1365.0, 1008.0, 1371.0, 1009.0, 1385.0, 1012.0, 1400.0, 1018.0, 1423.0, 1012.0, 1440.0, 1006.0, 1461.0, 993.0, 1511.0, 987.0, 1536.0, 978.0, 1566.0, 979.0, 1567.0, 975.0, 1573.0, 971.0, 1592.0, 970.0, 1603.0, 968.0, 1609.0, 965.0, 1621.0, 961.0, 1629.0, 964.0, 1636.0, 959.0, 1645.0, 948.0, 1667.0, 943.0, 1683.0, 933.0, 1704.0, 919.0, 1730.0, 908.0, 1746.0, 895.0, 1761.0, 880.0, 1774.0, 865.0, 1780.0, 855.0, 1779.0, 846.0, 1775.0, 836.0, 1771.0, 827.0, 1765.0, 821.0, 1761.0, 813.0, 1763.0, 805.0, 1770.0, 787.0, 1786.0, 772.0, 1795.0, 762.0, 1796.0, 751.0, 1796.0, 740.0, 1799.0, 730.0, 1792.0, 721.0, 1788.0, 710.0, 1782.0, 703.0, 1772.0, 696.0, 1765.0, 689.0, 1753.0, 680.0, 1744.0, 669.0, 1741.0, 653.0, 1744.0, 637.0, 1741.0, 626.0, 1730.0, 613.0, 1708.0, 608.0, 1683.0, 600.0, 1650.0, 598.0, 1622.0, 596.0, 1610.0, 598.0, 1591.0, 595.0, 1571.0, 590.0, 1555.0, 584.0, 1538.0, 578.0, 1522.0, 574.0, 1509.0, 571.0, 1505.0, 572.0, 1501.0, 575.0, 1489.0, 581.0, 1477.0, 582.0, 1470.0, 584.0, 1461.0, 587.0, 1442.0, 593.0, 1419.0, 598.0, 1399.0, 601.0, 1383.0, 602.0, 1380.0, 606.0, 1380.0, 616.0, 1383.0, 627.0, 1388.0, 645.0, 1396.0, 661.0, 1403.0, 669.0, 1407.0, 675.0, 1413.0, 678.0, 1416.0, 674.0, 1419.0, 677.0, 1421.0, 681.0, 1420.0, 694.0, 1413.0, 705.0, 1407.0, 716.0, 1400.0, 724.0, 1394.0, 733.0, 1386.0, 738.0, 1383.0, 755.0, 1375.0, 773.0, 1366.0, 789.0, 1353.0, 801.0, 1342.0, 807.0, 1334.0, 812.0, 1325.0, 815.0, 1320.0, 813.0, 1315.0, 805.0, 1308.0, 798.0, 1306.0, 786.0, 1300.0, 774.0, 1295.0, 767.0, 1290.0, 761.0, 1287.0, 759.0, 1287.0, 761.0, 1291.0, 760.0, 1294.0, 755.0, 1296.0, 743.0, 1295.0, 731.0, 1295.0, 719.0, 1294.0, 705.0, 1293.0, 699.0, 1292.0, 693.0, 1291.0, 693.0, 1293.0, 697.0, 1295.0, 698.0, 1299.0, 694.0, 1303.0, 683.0, 1311.0, 669.0, 1316.0, 657.0, 1321.0, 645.0, 1327.0, 637.0, 1329.0, 632.0, 1330.0, 635.0, 1323.0, 642.0, 1314.0, 649.0, 1305.0, 660.0, 1293.0, 669.0, 1281.0, 679.0, 1267.0, 698.0, 1245.0, 715.0, 1220.0, 736.0, 1193.0, 753.0, 1164.0, 770.0, 1130.0, 784.0, 1101.0, 793.0, 1077.0, 794.0, 1070.0, 795.0, 1048.0, 796.0, 1039.0, 797.0, 1024.0, 801.0, 1012.0, 805.0, 1003.0, 821.0, 989.0, 836.0, 985.0, 857.0, 986.0, 868.0, 990.0, 881.0, 1001.0, 888.0, 1012.0, 892.0, 1025.0, 892.0, 1033.0, 892.0, 1046.0, 893.0, 1052.0, 895.0, 1063.0, 895.0, 1072.0, 891.0, 1082.0, 888.0, 1089.0, 896.0, 1108.0, 907.0, 1143.0, 917.0, 1170.0, 929.0, 1203.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [1751.0, 2342.0, 174.0, 90.0], 'category_id': 7, 'segmentation': [[1762.0, 2342.0, 1790.0, 2347.0, 1819.0, 2355.0, 1840.0, 2363.0, 1861.0, 2367.0, 1885.0, 2372.0, 1916.0, 2380.0, 1925.0, 2382.0, 1917.0, 2403.0, 1909.0, 2421.0, 1901.0, 2431.0, 1887.0, 2432.0, 1871.0, 2426.0, 1860.0, 2428.0, 1838.0, 2423.0, 1813.0, 2411.0, 1798.0, 2398.0, 1776.0, 2389.0, 1769.0, 2385.0, 1761.0, 2374.0, 1757.0, 2364.0, 1751.0, 2357.0, 1762.0, 2342.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [1998.0, 1730.0, 85.0, 67.0], 'category_id': 1, 'segmentation': [[2012.0, 1746.0, 2018.0, 1736.0, 2029.0, 1730.0, 2047.0, 1731.0, 2061.0, 1739.0, 2073.0, 1750.0, 2080.0, 1764.0, 2083.0, 1776.0, 2080.0, 1788.0, 2071.0, 1794.0, 2057.0, 1796.0, 2037.0, 1797.0, 2027.0, 1792.0, 2018.0, 1791.0, 2014.0, 1782.0, 2004.0, 1777.0, 2003.0, 1771.0, 1998.0, 1771.0, 2000.0, 1753.0, 2012.0, 1746.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [797.0, 985.0, 96.0, 53.0], 'category_id': 1, 'segmentation': [[797.0, 1028.0, 809.0, 1018.0, 823.0, 1011.0, 840.0, 1007.0, 855.0, 1010.0, 870.0, 1015.0, 881.0, 1025.0, 890.0, 1038.0, 893.0, 1038.0, 892.0, 1025.0, 889.0, 1013.0, 882.0, 1001.0, 870.0, 992.0, 856.0, 985.0, 846.0, 985.0, 831.0, 985.0, 818.0, 991.0, 810.0, 999.0, 803.0, 1008.0, 798.0, 1020.0, 797.0, 1028.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [1913.0, 2526.0, 125.0, 95.0], 'category_id': 8, 'segmentation': [[1947.0, 2529.0, 1959.0, 2533.0, 1961.0, 2535.0, 1960.0, 2538.0, 1961.0, 2539.0, 1963.0, 2539.0, 1963.0, 2537.0, 1963.0, 2534.0, 1969.0, 2537.0, 1977.0, 2542.0, 1985.0, 2547.0, 1990.0, 2549.0, 2003.0, 2554.0, 2016.0, 2557.0, 2025.0, 2561.0, 2030.0, 2567.0, 2035.0, 2580.0, 2037.0, 2585.0, 2038.0, 2587.0, 2036.0, 2591.0, 2033.0, 2607.0, 2030.0, 2609.0, 2018.0, 2620.0, 2012.0, 2621.0, 2000.0, 2618.0, 1979.0, 2611.0, 1971.0, 2609.0, 1958.0, 2609.0, 1941.0, 2604.0, 1924.0, 2596.0, 1920.0, 2593.0, 1922.0, 2590.0, 1930.0, 2593.0, 1930.0, 2589.0, 1925.0, 2586.0, 1917.0, 2584.0, 1913.0, 2582.0, 1913.0, 2569.0, 1914.0, 2560.0, 1918.0, 2550.0, 1923.0, 2540.0, 1927.0, 2536.0, 1933.0, 2547.0, 1930.0, 2550.0, 1928.0, 2556.0, 1926.0, 2566.0, 1926.0, 2573.0, 1929.0, 2581.0, 1934.0, 2587.0, 1942.0, 2590.0, 1951.0, 2590.0, 1959.0, 2587.0, 1962.0, 2578.0, 1965.0, 2570.0, 1966.0, 2561.0, 1963.0, 2555.0, 1975.0, 2563.0, 1974.0, 2567.0, 1973.0, 2573.0, 1972.0, 2582.0, 1971.0, 2588.0, 1972.0, 2591.0, 1975.0, 2594.0, 1981.0, 2596.0, 1989.0, 2598.0, 1997.0, 2600.0, 2001.0, 2602.0, 2004.0, 2604.0, 2006.0, 2597.0, 2007.0, 2587.0, 2010.0, 2579.0, 2011.0, 2573.0, 2002.0, 2570.0, 1997.0, 2568.0, 1989.0, 2566.0, 1983.0, 2564.0, 1978.0, 2563.0, 1976.0, 2563.0, 1975.0, 2563.0, 1963.0, 2554.0, 1961.0, 2551.0, 1958.0, 2548.0, 1952.0, 2546.0, 1949.0, 2544.0, 1944.0, 2543.0, 1941.0, 2544.0, 1937.0, 2544.0, 1935.0, 2545.0, 1934.0, 2547.0, 1933.0, 2547.0, 1927.0, 2536.0, 1929.0, 2534.0, 1930.0, 2532.0, 1932.0, 2530.0, 1932.0, 2528.0, 1934.0, 2526.0, 1940.0, 2527.0, 1942.0, 2527.0, 1943.0, 2528.0, 1945.0, 2529.0, 1947.0, 2529.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_1/000064.JPG', 'height': 3264, 'width': 2448, 'image_id': 78, 'annotations': [{'iscrowd': 0, 'bbox': [913.0, 1077.0, 606.0, 591.0], 'category_id': 4, 'segmentation': [[1470.0, 1260.0, 1488.0, 1308.0, 1510.0, 1380.0, 1519.0, 1463.0, 1505.0, 1534.0, 1487.0, 1566.0, 1451.0, 1587.0, 1422.0, 1600.0, 1398.0, 1606.0, 1379.0, 1602.0, 1355.0, 1600.0, 1335.0, 1611.0, 1316.0, 1610.0, 1283.0, 1613.0, 1258.0, 1621.0, 1230.0, 1635.0, 1152.0, 1655.0, 1107.0, 1666.0, 1078.0, 1668.0, 1029.0, 1636.0, 981.0, 1569.0, 939.0, 1485.0, 913.0, 1383.0, 916.0, 1321.0, 937.0, 1294.0, 1011.0, 1244.0, 1123.0, 1168.0, 1155.0, 1147.0, 1174.0, 1119.0, 1212.0, 1097.0, 1251.0, 1082.0, 1284.0, 1077.0, 1342.0, 1100.0, 1384.0, 1133.0, 1425.0, 1181.0, 1451.0, 1223.0, 1470.0, 1260.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_1/000128.JPG', 'height': 3264, 'width': 2448, 'image_id': 99, 'annotations': [{'iscrowd': 0, 'bbox': [0.0, 0.0, 1528.0, 1687.0], 'category_id': 6, 'segmentation': [[324.0, 1643.0, 313.0, 1650.0, 301.0, 1658.0, 282.0, 1661.0, 263.0, 1655.0, 242.0, 1667.0, 209.0, 1668.0, 113.0, 1681.0, 90.0, 1675.0, 74.0, 1687.0, 0.0, 1622.0, 9.0, 1055.0, 298.0, 806.0, 629.0, 476.0, 712.0, 393.0, 797.0, 312.0, 966.0, 150.0, 972.0, 115.0, 995.0, 63.0, 1030.0, 35.0, 1076.0, 0.0, 1313.0, 2.0, 1447.0, 238.0, 1521.0, 367.0, 1479.0, 410.0, 1528.0, 633.0, 1394.0, 790.0, 1353.0, 840.0, 1113.0, 1081.0, 828.0, 1371.0, 692.0, 1489.0, 526.0, 1644.0, 391.0, 1653.0, 333.0, 1653.0, 324.0, 1643.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [52.0, 71.0, 758.0, 654.0], 'category_id': 6, 'segmentation': [[54.0, 349.0, 71.0, 513.0, 63.0, 562.0, 64.0, 571.0, 66.0, 662.0, 73.0, 693.0, 86.0, 694.0, 194.0, 709.0, 246.0, 714.0, 382.0, 725.0, 810.0, 294.0, 807.0, 296.0, 755.0, 291.0, 706.0, 286.0, 636.0, 275.0, 577.0, 259.0, 532.0, 246.0, 456.0, 214.0, 371.0, 178.0, 283.0, 143.0, 152.0, 92.0, 92.0, 71.0, 83.0, 72.0, 81.0, 97.0, 74.0, 131.0, 63.0, 177.0, 58.0, 202.0, 55.0, 251.0, 52.0, 296.0, 52.0, 326.0, 54.0, 349.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [0.0, 1093.0, 1936.0, 1756.0], 'category_id': 6, 'segmentation': [[1.0, 2452.0, 15.0, 2457.0, 35.0, 2475.0, 62.0, 2487.0, 105.0, 2490.0, 122.0, 2486.0, 123.0, 2505.0, 137.0, 2505.0, 150.0, 2514.0, 156.0, 2537.0, 163.0, 2556.0, 120.0, 2606.0, 66.0, 2663.0, 74.0, 2679.0, 103.0, 2715.0, 125.0, 2735.0, 148.0, 2766.0, 171.0, 2780.0, 188.0, 2787.0, 206.0, 2796.0, 235.0, 2809.0, 257.0, 2821.0, 277.0, 2815.0, 299.0, 2818.0, 333.0, 2807.0, 376.0, 2849.0, 412.0, 2840.0, 457.0, 2819.0, 496.0, 2799.0, 589.0, 2747.0, 832.0, 2587.0, 1089.0, 2420.0, 1341.0, 2257.0, 1363.0, 2243.0, 1374.0, 2227.0, 1387.0, 2209.0, 1402.0, 2192.0, 1426.0, 2163.0, 1462.0, 2131.0, 1500.0, 2099.0, 1581.0, 2034.0, 1784.0, 1866.0, 1860.0, 1800.0, 1934.0, 1739.0, 1936.0, 1734.0, 1930.0, 1700.0, 1924.0, 1645.0, 1918.0, 1642.0, 1904.0, 1644.0, 1898.0, 1644.0, 1892.0, 1608.0, 1889.0, 1580.0, 1881.0, 1520.0, 1875.0, 1475.0, 1870.0, 1441.0, 1863.0, 1420.0, 1855.0, 1393.0, 1846.0, 1373.0, 1840.0, 1358.0, 1836.0, 1352.0, 1826.0, 1352.0, 1817.0, 1341.0, 1810.0, 1333.0, 1818.0, 1319.0, 1801.0, 1295.0, 1779.0, 1267.0, 1754.0, 1237.0, 1713.0, 1190.0, 1686.0, 1158.0, 1676.0, 1158.0, 1674.0, 1164.0, 1669.0, 1173.0, 1665.0, 1181.0, 1660.0, 1188.0, 1645.0, 1193.0, 1640.0, 1197.0, 1630.0, 1200.0, 1562.0, 1189.0, 1502.0, 1179.0, 1381.0, 1159.0, 1200.0, 1125.0, 1178.0, 1117.0, 1156.0, 1115.0, 1144.0, 1113.0, 1135.0, 1107.0, 1102.0, 1093.0, 981.0, 1216.0, 869.0, 1330.0, 574.0, 1601.0, 526.0, 1644.0, 422.0, 1653.0, 336.0, 1654.0, 306.0, 1689.0, 299.0, 1692.0, 293.0, 1686.0, 265.0, 1688.0, 252.0, 1702.0, 236.0, 1692.0, 210.0, 1668.0, 113.0, 1682.0, 104.0, 1679.0, 93.0, 1677.0, 91.0, 1675.0, 75.0, 1687.0, 0.0, 1622.0, 1.0, 2452.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [1102.0, 861.0, 611.0, 339.0], 'category_id': 2, 'segmentation': [[1102.0, 1093.0, 1133.0, 1106.0, 1145.0, 1114.0, 1156.0, 1114.0, 1178.0, 1117.0, 1200.0, 1125.0, 1235.0, 1132.0, 1281.0, 1141.0, 1364.0, 1156.0, 1474.0, 1173.0, 1569.0, 1190.0, 1630.0, 1200.0, 1639.0, 1197.0, 1645.0, 1192.0, 1660.0, 1187.0, 1666.0, 1180.0, 1675.0, 1162.0, 1692.0, 1106.0, 1697.0, 1083.0, 1705.0, 1045.0, 1711.0, 1001.0, 1713.0, 959.0, 1710.0, 926.0, 1704.0, 904.0, 1694.0, 887.0, 1687.0, 880.0, 1681.0, 876.0, 1674.0, 870.0, 1665.0, 867.0, 1636.0, 869.0, 1554.0, 875.0, 1499.0, 878.0, 1421.0, 884.0, 1398.0, 886.0, 1391.0, 884.0, 1363.0, 873.0, 1333.0, 861.0, 1270.0, 923.0, 1164.0, 1030.0, 1102.0, 1093.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [1505.0, 401.0, 543.0, 567.0], 'category_id': 2, 'segmentation': [[1539.0, 599.0, 1548.0, 568.0, 1566.0, 529.0, 1598.0, 487.0, 1625.0, 457.0, 1653.0, 438.0, 1686.0, 422.0, 1726.0, 409.0, 1759.0, 402.0, 1801.0, 401.0, 1839.0, 406.0, 1886.0, 421.0, 1929.0, 443.0, 1976.0, 481.0, 2012.0, 529.0, 2034.0, 582.0, 2046.0, 624.0, 2048.0, 676.0, 2041.0, 730.0, 2025.0, 773.0, 1998.0, 821.0, 1961.0, 862.0, 1929.0, 889.0, 1896.0, 910.0, 1855.0, 939.0, 1811.0, 953.0, 1758.0, 966.0, 1724.0, 968.0, 1714.0, 965.0, 1712.0, 947.0, 1710.0, 926.0, 1706.0, 911.0, 1701.0, 899.0, 1694.0, 889.0, 1688.0, 880.0, 1682.0, 877.0, 1676.0, 871.0, 1666.0, 867.0, 1632.0, 869.0, 1556.0, 875.0, 1544.0, 858.0, 1533.0, 838.0, 1521.0, 813.0, 1512.0, 781.0, 1505.0, 745.0, 1507.0, 708.0, 1512.0, 671.0, 1516.0, 652.0, 1521.0, 644.0, 1528.0, 633.0, 1528.0, 619.0, 1539.0, 599.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [1850.0, 1007.0, 598.0, 531.0], 'category_id': 2, 'segmentation': [[1889.0, 1457.0, 1909.0, 1481.0, 1932.0, 1500.0, 1958.0, 1514.0, 1980.0, 1527.0, 2013.0, 1536.0, 2042.0, 1537.0, 2111.0, 1538.0, 2276.0, 1533.0, 2302.0, 1537.0, 2330.0, 1537.0, 2362.0, 1533.0, 2397.0, 1525.0, 2426.0, 1515.0, 2447.0, 1501.0, 2448.0, 1040.0, 2427.0, 1028.0, 2398.0, 1018.0, 2374.0, 1012.0, 2349.0, 1008.0, 2320.0, 1007.0, 2296.0, 1009.0, 2273.0, 1013.0, 2242.0, 1022.0, 2212.0, 1035.0, 2185.0, 1052.0, 2159.0, 1070.0, 2142.0, 1070.0, 2112.0, 1085.0, 2041.0, 1115.0, 1980.0, 1142.0, 1962.0, 1152.0, 1946.0, 1162.0, 1936.0, 1170.0, 1918.0, 1180.0, 1907.0, 1190.0, 1893.0, 1204.0, 1885.0, 1211.0, 1880.0, 1223.0, 1866.0, 1253.0, 1860.0, 1269.0, 1851.0, 1301.0, 1850.0, 1318.0, 1851.0, 1340.0, 1850.0, 1354.0, 1855.0, 1386.0, 1862.0, 1404.0, 1866.0, 1418.0, 1873.0, 1434.0, 1882.0, 1448.0, 1889.0, 1457.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [1694.0, 727.0, 602.0, 538.0], 'category_id': 6, 'segmentation': [[2194.0, 736.0, 2204.0, 742.0, 2218.0, 750.0, 2228.0, 757.0, 2235.0, 761.0, 2247.0, 774.0, 2259.0, 792.0, 2267.0, 806.0, 2278.0, 832.0, 2286.0, 854.0, 2291.0, 871.0, 2296.0, 893.0, 2295.0, 905.0, 2295.0, 917.0, 2292.0, 923.0, 2268.0, 938.0, 2215.0, 974.0, 2116.0, 1048.0, 2053.0, 1091.0, 1997.0, 1128.0, 1938.0, 1164.0, 1869.0, 1208.0, 1779.0, 1265.0, 1775.0, 1261.0, 1766.0, 1250.0, 1744.0, 1225.0, 1730.0, 1207.0, 1720.0, 1186.0, 1712.0, 1166.0, 1703.0, 1146.0, 1697.0, 1123.0, 1694.0, 1100.0, 1699.0, 1070.0, 1706.0, 1058.0, 1707.0, 1051.0, 1716.0, 1047.0, 1732.0, 1040.0, 1757.0, 1027.0, 1773.0, 1015.0, 1802.0, 999.0, 1845.0, 966.0, 1927.0, 908.0, 1968.0, 878.0, 2031.0, 830.0, 2092.0, 781.0, 2155.0, 727.0, 2166.0, 728.0, 2178.0, 731.0, 2194.0, 736.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [2294.0, 1152.0, 154.0, 161.0], 'category_id': 8, 'segmentation': [[2304.0, 1276.0, 2311.0, 1285.0, 2327.0, 1293.0, 2354.0, 1301.0, 2374.0, 1307.0, 2406.0, 1308.0, 2446.0, 1313.0, 2448.0, 1174.0, 2434.0, 1167.0, 2420.0, 1162.0, 2401.0, 1157.0, 2371.0, 1152.0, 2347.0, 1156.0, 2337.0, 1157.0, 2328.0, 1165.0, 2313.0, 1178.0, 2302.0, 1209.0, 2295.0, 1224.0, 2294.0, 1245.0, 2297.0, 1260.0, 2301.0, 1269.0, 2315.0, 1257.0, 2312.0, 1239.0, 2316.0, 1221.0, 2323.0, 1199.0, 2330.0, 1185.0, 2352.0, 1168.0, 2365.0, 1164.0, 2383.0, 1167.0, 2403.0, 1171.0, 2420.0, 1179.0, 2430.0, 1188.0, 2437.0, 1211.0, 2436.0, 1230.0, 2432.0, 1253.0, 2425.0, 1267.0, 2413.0, 1281.0, 2395.0, 1290.0, 2378.0, 1291.0, 2354.0, 1286.0, 2337.0, 1281.0, 2327.0, 1274.0, 2319.0, 1263.0, 2316.0, 1257.0, 2301.0, 1270.0, 2304.0, 1276.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [954.0, 1582.0, 1492.0, 1290.0], 'category_id': 0, 'segmentation': [[1633.0, 1993.0, 1797.0, 1856.0, 1922.0, 1751.0, 2044.0, 1657.0, 2078.0, 1628.0, 2108.0, 1611.0, 2165.0, 1592.0, 2218.0, 1582.0, 2255.0, 1584.0, 2294.0, 1592.0, 2331.0, 1617.0, 2384.0, 1657.0, 2419.0, 1698.0, 2446.0, 1735.0, 2444.0, 1966.0, 2394.0, 2015.0, 2339.0, 2058.0, 2271.0, 2115.0, 2131.0, 2217.0, 2003.0, 2316.0, 1914.0, 2384.0, 1763.0, 2493.0, 1697.0, 2540.0, 1662.0, 2556.0, 1626.0, 2574.0, 1584.0, 2586.0, 1545.0, 2590.0, 1506.0, 2591.0, 1464.0, 2593.0, 1429.0, 2599.0, 1388.0, 2625.0, 1327.0, 2667.0, 1256.0, 2713.0, 1213.0, 2744.0, 1195.0, 2753.0, 1181.0, 2763.0, 1174.0, 2772.0, 1181.0, 2789.0, 1179.0, 2799.0, 1076.0, 2872.0, 1056.0, 2871.0, 1035.0, 2855.0, 1005.0, 2816.0, 976.0, 2772.0, 960.0, 2740.0, 954.0, 2712.0, 957.0, 2698.0, 965.0, 2690.0, 1047.0, 2623.0, 1047.0, 2616.0, 1054.0, 2611.0, 1063.0, 2611.0, 1074.0, 2614.0, 1079.0, 2619.0, 1103.0, 2598.0, 1273.0, 2439.0, 1294.0, 2420.0, 1306.0, 2394.0, 1315.0, 2371.0, 1326.0, 2336.0, 1335.0, 2300.0, 1347.0, 2272.0, 1363.0, 2243.0, 1386.0, 2209.0, 1426.0, 2163.0, 1480.0, 2115.0, 1633.0, 1993.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [953.0, 2663.0, 173.0, 211.0], 'category_id': 1, 'segmentation': [[1044.0, 2755.0, 1066.0, 2785.0, 1083.0, 2809.0, 1108.0, 2830.0, 1126.0, 2836.0, 1097.0, 2856.0, 1071.0, 2874.0, 1062.0, 2872.0, 1050.0, 2868.0, 1034.0, 2853.0, 1015.0, 2832.0, 995.0, 2805.0, 981.0, 2781.0, 974.0, 2768.0, 967.0, 2756.0, 958.0, 2736.0, 953.0, 2716.0, 954.0, 2705.0, 959.0, 2695.0, 991.0, 2670.0, 997.0, 2665.0, 1000.0, 2663.0, 1006.0, 2688.0, 1012.0, 2700.0, 1027.0, 2727.0, 1035.0, 2744.0, 1044.0, 2755.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [0.0, 2601.0, 868.0, 617.0], 'category_id': 7, 'segmentation': [[1.0, 3109.0, 34.0, 3108.0, 62.0, 3120.0, 117.0, 3115.0, 156.0, 3112.0, 195.0, 3130.0, 232.0, 3146.0, 256.0, 3156.0, 296.0, 3156.0, 314.0, 3154.0, 471.0, 3177.0, 505.0, 3179.0, 538.0, 3184.0, 568.0, 3189.0, 596.0, 3203.0, 622.0, 3218.0, 632.0, 3199.0, 654.0, 3166.0, 658.0, 3154.0, 678.0, 3119.0, 728.0, 3036.0, 770.0, 2976.0, 813.0, 2922.0, 833.0, 2896.0, 855.0, 2875.0, 863.0, 2868.0, 868.0, 2853.0, 867.0, 2839.0, 851.0, 2797.0, 846.0, 2784.0, 847.0, 2778.0, 846.0, 2768.0, 840.0, 2757.0, 839.0, 2748.0, 840.0, 2731.0, 837.0, 2703.0, 833.0, 2680.0, 834.0, 2667.0, 831.0, 2660.0, 826.0, 2640.0, 812.0, 2602.0, 811.0, 2601.0, 729.0, 2654.0, 626.0, 2722.0, 586.0, 2749.0, 531.0, 2780.0, 488.0, 2805.0, 464.0, 2818.0, 421.0, 2836.0, 412.0, 2840.0, 377.0, 2848.0, 342.0, 2816.0, 337.0, 2815.0, 332.0, 2808.0, 331.0, 2807.0, 299.0, 2818.0, 295.0, 2819.0, 280.0, 2819.0, 278.0, 2815.0, 263.0, 2818.0, 255.0, 2820.0, 242.0, 2815.0, 226.0, 2806.0, 202.0, 2796.0, 188.0, 2787.0, 172.0, 2782.0, 159.0, 2777.0, 148.0, 2768.0, 132.0, 2745.0, 117.0, 2728.0, 110.0, 2724.0, 108.0, 2715.0, 99.0, 2708.0, 93.0, 2701.0, 79.0, 2688.0, 59.0, 2689.0, 0.0, 2691.0, 1.0, 3109.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [739.0, 2488.0, 704.0, 570.0], 'category_id': 6, 'segmentation': [[966.0, 2501.0, 1009.0, 2500.0, 1015.0, 2497.0, 1038.0, 2491.0, 1057.0, 2488.0, 1082.0, 2491.0, 1116.0, 2491.0, 1138.0, 2493.0, 1165.0, 2497.0, 1186.0, 2500.0, 1206.0, 2501.0, 1123.0, 2579.0, 1079.0, 2619.0, 1076.0, 2614.0, 1064.0, 2611.0, 1054.0, 2611.0, 1047.0, 2616.0, 1047.0, 2623.0, 964.0, 2690.0, 959.0, 2695.0, 955.0, 2702.0, 954.0, 2707.0, 953.0, 2714.0, 957.0, 2732.0, 960.0, 2741.0, 966.0, 2752.0, 974.0, 2769.0, 981.0, 2782.0, 986.0, 2791.0, 994.0, 2803.0, 1001.0, 2814.0, 1010.0, 2825.0, 1015.0, 2832.0, 1023.0, 2841.0, 1030.0, 2849.0, 1038.0, 2858.0, 1046.0, 2864.0, 1052.0, 2870.0, 1058.0, 2872.0, 1067.0, 2873.0, 1073.0, 2873.0, 1082.0, 2867.0, 1099.0, 2855.0, 1127.0, 2836.0, 1180.0, 2799.0, 1181.0, 2789.0, 1184.0, 2775.0, 1183.0, 2762.0, 1213.0, 2743.0, 1238.0, 2726.0, 1274.0, 2701.0, 1335.0, 2662.0, 1373.0, 2635.0, 1412.0, 2610.0, 1429.0, 2599.0, 1437.0, 2602.0, 1440.0, 2622.0, 1443.0, 2642.0, 1438.0, 2667.0, 1427.0, 2707.0, 1428.0, 2716.0, 1429.0, 2728.0, 1433.0, 2742.0, 1430.0, 2763.0, 1421.0, 2789.0, 1420.0, 2805.0, 1401.0, 2835.0, 1386.0, 2858.0, 1369.0, 2887.0, 1353.0, 2910.0, 1344.0, 2925.0, 1336.0, 2942.0, 1331.0, 2954.0, 1323.0, 2984.0, 1320.0, 3008.0, 1316.0, 3025.0, 1307.0, 3041.0, 1303.0, 3051.0, 1286.0, 3052.0, 1262.0, 3048.0, 1238.0, 3041.0, 1228.0, 3039.0, 1224.0, 3035.0, 1204.0, 3037.0, 1202.0, 3047.0, 1194.0, 3051.0, 1193.0, 3057.0, 1181.0, 3058.0, 1172.0, 3056.0, 1171.0, 3050.0, 1163.0, 3044.0, 1155.0, 3039.0, 1136.0, 3035.0, 1132.0, 3031.0, 1135.0, 3022.0, 1137.0, 3017.0, 1136.0, 3010.0, 1141.0, 2999.0, 1134.0, 3012.0, 1115.0, 3012.0, 1101.0, 3015.0, 1095.0, 3012.0, 1067.0, 3012.0, 1036.0, 3015.0, 1019.0, 3016.0, 1004.0, 3018.0, 993.0, 3023.0, 979.0, 3025.0, 972.0, 3023.0, 967.0, 3024.0, 957.0, 3026.0, 943.0, 3027.0, 937.0, 3030.0, 931.0, 3026.0, 917.0, 3025.0, 908.0, 3025.0, 905.0, 3024.0, 898.0, 3022.0, 879.0, 3024.0, 858.0, 3017.0, 844.0, 3013.0, 823.0, 3019.0, 807.0, 3022.0, 789.0, 3015.0, 773.0, 3015.0, 743.0, 3020.0, 739.0, 3020.0, 769.0, 2977.0, 788.0, 2953.0, 812.0, 2923.0, 832.0, 2897.0, 844.0, 2886.0, 863.0, 2868.0, 868.0, 2853.0, 867.0, 2839.0, 847.0, 2784.0, 848.0, 2778.0, 846.0, 2768.0, 840.0, 2756.0, 839.0, 2749.0, 839.0, 2729.0, 837.0, 2706.0, 834.0, 2683.0, 833.0, 2680.0, 834.0, 2666.0, 831.0, 2660.0, 826.0, 2638.0, 811.0, 2601.0, 966.0, 2501.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [1447.0, 2388.0, 1001.0, 876.0], 'category_id': 6, 'segmentation': [[1459.0, 2736.0, 1476.0, 2765.0, 1480.0, 2776.0, 1485.0, 2787.0, 1485.0, 2796.0, 1490.0, 2809.0, 1496.0, 2817.0, 1506.0, 2823.0, 1506.0, 2837.0, 1502.0, 2851.0, 1507.0, 2863.0, 1514.0, 2866.0, 1571.0, 2914.0, 1611.0, 2950.0, 1629.0, 2968.0, 1649.0, 2971.0, 1686.0, 2977.0, 1690.0, 2985.0, 1766.0, 3089.0, 1809.0, 3158.0, 1810.0, 3176.0, 1811.0, 3184.0, 1817.0, 3196.0, 1815.0, 3204.0, 1824.0, 3216.0, 1834.0, 3223.0, 1835.0, 3229.0, 1842.0, 3237.0, 1850.0, 3236.0, 1859.0, 3243.0, 1867.0, 3248.0, 1877.0, 3249.0, 1883.0, 3253.0, 1892.0, 3264.0, 2106.0, 3264.0, 2181.0, 3240.0, 2229.0, 3226.0, 2259.0, 3216.0, 2317.0, 3194.0, 2360.0, 3175.0, 2383.0, 3163.0, 2406.0, 3155.0, 2437.0, 3145.0, 2448.0, 3140.0, 2447.0, 2730.0, 2444.0, 2680.0, 2441.0, 2640.0, 2434.0, 2619.0, 2417.0, 2559.0, 2409.0, 2536.0, 2393.0, 2497.0, 2382.0, 2461.0, 2382.0, 2457.0, 2378.0, 2453.0, 2370.0, 2450.0, 2359.0, 2451.0, 2306.0, 2449.0, 2259.0, 2445.0, 2198.0, 2441.0, 2170.0, 2446.0, 2138.0, 2451.0, 2104.0, 2456.0, 2089.0, 2455.0, 2070.0, 2450.0, 2064.0, 2414.0, 2064.0, 2401.0, 2055.0, 2400.0, 2040.0, 2396.0, 2021.0, 2393.0, 2013.0, 2388.0, 2006.0, 2391.0, 1993.0, 2393.0, 1977.0, 2389.0, 1965.0, 2392.0, 1957.0, 2393.0, 1949.0, 2397.0, 1942.0, 2402.0, 1939.0, 2406.0, 1913.0, 2404.0, 1888.0, 2404.0, 1886.0, 2404.0, 1697.0, 2540.0, 1651.0, 2562.0, 1626.0, 2575.0, 1597.0, 2583.0, 1584.0, 2587.0, 1544.0, 2590.0, 1515.0, 2592.0, 1493.0, 2612.0, 1485.0, 2618.0, 1479.0, 2628.0, 1466.0, 2644.0, 1458.0, 2662.0, 1448.0, 2672.0, 1449.0, 2685.0, 1454.0, 2692.0, 1454.0, 2711.0, 1453.0, 2718.0, 1449.0, 2721.0, 1447.0, 2727.0, 1450.0, 2730.0, 1453.0, 2735.0, 1456.0, 2738.0, 1459.0, 2736.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_10/000027.jpg', 'height': 4000, 'width': 1824, 'image_id': 128, 'annotations': [{'iscrowd': 0, 'bbox': [864.0000000000001, 1569.0, 107.99999999999989, 139.00000000000023], 'category_id': 6, 'segmentation': [[871, 1704, 864, 1645, 874, 1569, 969, 1584, 967, 1649, 966, 1695, 972, 1708]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [949.0000000000001, 1697.0, 10.999999999999886, 22.000000000000227], 'category_id': 9, 'segmentation': [[949, 1699, 950, 1719, 960, 1719, 960, 1697]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [1597.0, 1986.0, 53.0, 22.000000000000227], 'category_id': 3, 'segmentation': [[1599, 2008, 1650, 2004, 1636, 1986, 1597, 1989]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [1352.0, 1847.0, 65.0, 76.0], 'category_id': 6, 'segmentation': [[1352, 1923, 1365, 1906, 1377, 1904, 1408, 1875, 1417, 1847, 1415, 1881, 1394, 1900, 1374, 1919]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_10/000097.jpg', 'height': 4000, 'width': 1824, 'image_id': 198, 'annotations': [{'iscrowd': 0, 'bbox': [800.0, 2520.0, 396.0, 151.0], 'category_id': 0, 'segmentation': [[820, 2671, 967, 2651, 981, 2634, 1004, 2642, 1100, 2632, 1136, 2616, 1159, 2597, 1195, 2591, 1196, 2558, 1188, 2531, 1157, 2535, 1111, 2520, 1073, 2523, 990, 2528, 970, 2543, 949, 2540, 800, 2562, 810, 2662]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [1176.0, 2532.0, 20.0, 61.0], 'category_id': 1, 'segmentation': [[1176, 2534, 1181, 2555, 1183, 2591, 1195, 2593, 1196, 2562, 1193, 2543, 1190, 2532]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_11/000007.jpg', 'height': 4000, 'width': 1824, 'image_id': 208, 'annotations': [{'iscrowd': 0, 'bbox': [1180.0, 2191.0, 504.9999999999998, 806.0], 'category_id': 6, 'segmentation': [[1222, 2996, 1655, 2997, 1677, 2992, 1685, 2970, 1683, 2837, 1648, 2333, 1634, 2307, 1633, 2239, 1620, 2200, 1601, 2191, 1346, 2191, 1342, 2201, 1330, 2202, 1316, 2204, 1193, 2209, 1180, 2225, 1185, 2235, 1186, 2249, 1190, 2264, 1182, 2288, 1183, 2314, 1181, 2334, 1184, 2355, 1200, 2362, 1206, 2377, 1220, 2852, 1216, 2941, 1215, 2973]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_11/000019.jpg', 'height': 4000, 'width': 6000, 'image_id': 220, 'annotations': [{'iscrowd': 0, 'bbox': [2689.0, 1780.58, 462.0, 280.0487000000003], 'category_id': 0, 'segmentation': [[2838, 1831, 2981, 1791, 3052, 1781, 3090, 1788, 3113, 1825, 3136, 1888, 3151, 1947, 3147, 1974, 3122, 1996, 3061, 2030, 3041, 2031, 3017, 2040, 2984, 2034, 2953, 2061, 2939, 2060, 2930, 2050, 2880, 2057, 2858, 2047, 2826, 2023, 2807, 2009, 2778, 2029, 2790, 2042, 2774, 2045, 2689, 1967, 2694, 1942, 2733, 1920, 2746, 1890]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [2687.0, 1925.1539, 65.0, 100.08960000000002], 'category_id': 1, 'segmentation': [[2691, 1939, 2731, 1925, 2737, 1968, 2752, 2025, 2687, 1967]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [1467.0, 1934.1725, 406.0, 88.55210000000011], 'category_id': 6, 'segmentation': [[1467, 2018, 1491, 1969, 1529, 1934, 1555, 1935, 1676, 1951, 1730, 1945, 1779, 1954, 1824, 1953, 1866, 1975, 1868, 1996, 1873, 2016, 1824, 2007, 1800, 2021, 1758, 2023, 1659, 2015, 1619, 2019, 1596, 2005, 1583, 2013, 1529, 2000, 1483, 2006]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [2079.0, 1934.1725, 278.0, 174.0854999999999], 'category_id': 6, 'segmentation': [[2080, 2049, 2159, 1994, 2236, 1949, 2285, 1934, 2332, 1961, 2357, 1982, 2319, 1993, 2304, 2026, 2293, 2078, 2265, 2095, 2196, 2108, 2172, 2092, 2178, 2065, 2162, 2061, 2140, 2081, 2101, 2068, 2079, 2063]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_11/000032.jpg', 'height': 4128, 'width': 2322, 'image_id': 233, 'annotations': [{'iscrowd': 0, 'bbox': [1058.0, 1104.0, 477.0, 705.0], 'category_id': 7, 'segmentation': [[1335.0, 1249.0, 1393.0, 1292.0, 1535.0, 1486.0, 1491.0, 1527.0, 1471.0, 1550.0, 1437.0, 1558.0, 1393.0, 1616.0, 1404.0, 1655.0, 1417.0, 1692.0, 1436.0, 1711.0, 1443.0, 1737.0, 1443.0, 1755.0, 1446.0, 1768.0, 1452.0, 1798.0, 1445.0, 1809.0, 1427.0, 1796.0, 1385.0, 1801.0, 1346.0, 1786.0, 1352.0, 1762.0, 1346.0, 1735.0, 1333.0, 1735.0, 1341.0, 1772.0, 1311.0, 1797.0, 1291.0, 1793.0, 1300.0, 1712.0, 1259.0, 1712.0, 1207.0, 1681.0, 1188.0, 1653.0, 1135.0, 1550.0, 1116.0, 1501.0, 1115.0, 1450.0, 1095.0, 1414.0, 1090.0, 1377.0, 1074.0, 1331.0, 1062.0, 1290.0, 1058.0, 1234.0, 1072.0, 1223.0, 1079.0, 1205.0, 1098.0, 1187.0, 1117.0, 1169.0, 1110.0, 1158.0, 1110.0, 1131.0, 1123.0, 1113.0, 1155.0, 1112.0, 1160.0, 1135.0, 1193.0, 1144.0, 1238.0, 1104.0, 1240.0, 1162.0, 1255.0, 1186.0, 1283.0, 1213.0, 1303.0, 1230.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_11/000035.jpg', 'height': 2448, 'width': 3264, 'image_id': 236, 'annotations': [{'iscrowd': 0, 'bbox': [847.0, 636.0, 1674.0, 1386.0], 'category_id': 6, 'segmentation': [[858, 1508, 1012, 788, 1040, 737, 1145, 708, 1214, 699, 1446, 718, 1602, 636, 1965, 654, 2007, 677, 2033, 756, 2165, 827, 2365, 859, 2418, 896, 2466, 1148, 2485, 1202, 2521, 1241, 2521, 1299, 2490, 1370, 2388, 1477, 2267, 1633, 2246, 1691, 2191, 1771, 2180, 1805, 2025, 1977, 1923, 2006, 1844, 2022, 1753, 2013, 1719, 1989, 1687, 1943, 1810, 1909, 1806, 1868, 1766, 1831, 1723, 1812, 1602, 1791, 1165, 1760, 863, 1677, 847, 1633]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_11/000043.jpg', 'height': 4160, 'width': 3120, 'image_id': 244, 'annotations': [{'iscrowd': 0, 'bbox': [1490.0, 2290.0, 357.0, 361.0], 'category_id': 7, 'segmentation': [[1518, 2295, 1490, 2597, 1613, 2619, 1805, 2651, 1813, 2613, 1847, 2339, 1749, 2321, 1600, 2290, 1595, 2310, 1587, 2351, 1568, 2382, 1576, 2298]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_11/000046.jpg', 'height': 4608, 'width': 3456, 'image_id': 247, 'annotations': [{'iscrowd': 0, 'bbox': [283.0, 3130.0, 495.0, 490.0], 'category_id': 4, 'segmentation': [[289, 3413, 377, 3479, 397, 3501, 477, 3553, 482, 3566, 564, 3620, 624, 3606, 663, 3595, 709, 3536, 750, 3477, 778, 3411, 743, 3365, 582, 3213, 510, 3143, 502, 3130, 450, 3156, 389, 3209, 358, 3245, 317, 3302, 293, 3363, 283, 3397]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [1736.0, 1128.0, 237.0, 346.0], 'category_id': 7, 'segmentation': [[1807, 1474, 1878, 1458, 1961, 1415, 1973, 1365, 1973, 1268, 1961, 1227, 1911, 1150, 1881, 1149, 1853, 1128, 1817, 1148, 1778, 1178, 1744, 1213, 1736, 1265, 1763, 1313, 1780, 1310, 1808, 1277, 1839, 1249, 1854, 1254, 1859, 1292, 1872, 1358, 1804, 1368, 1783, 1387, 1796, 1399, 1796, 1428, 1773, 1461, 1782, 1468]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_11/000060.jpg', 'height': 4032, 'width': 3024, 'image_id': 261, 'annotations': [{'iscrowd': 0, 'bbox': [972.0, 2321.0, 1217.0, 1277.0], 'category_id': 7, 'segmentation': [[1249, 3598, 1144, 3486, 1064, 3419, 986, 3265, 978, 3192, 997, 3138, 1042, 3048, 1039, 2976, 1003, 2955, 996, 2908, 1008, 2887, 993, 2858, 972, 2787, 984, 2763, 1026, 2719, 1061, 2699, 1107, 2673, 1155, 2652, 1188, 2618, 1233, 2577, 1287, 2533, 1358, 2510, 1430, 2469, 1486, 2443, 1557, 2422, 1615, 2411, 1637, 2403, 1673, 2424, 1700, 2423, 1799, 2433, 1867, 2454, 1994, 2419, 2070, 2390, 2102, 2378, 2094, 2366, 2042, 2343, 2034, 2331, 2053, 2327, 2101, 2321, 2140, 2325, 2189, 2338, 2183, 2430, 2169, 2475, 2138, 2504, 2131, 2550, 2120, 2619, 2105, 2643, 2055, 2643, 2032, 2639, 2012, 2767, 1885, 3107, 1729, 3352, 1587, 3474, 1439, 3581]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [1752.0, 1037.0, 111.0, 69.0], 'category_id': 6, 'segmentation': [[1752, 1096, 1809, 1106, 1863, 1104, 1847, 1037, 1756, 1078]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_11/000069.jpg', 'height': 4032, 'width': 3024, 'image_id': 270, 'annotations': [{'iscrowd': 0, 'bbox': [532.0, 1120.0, 934.0, 455.0], 'category_id': 7, 'segmentation': [[744, 1414, 861, 1419, 904, 1418, 875, 1437, 800, 1468, 792, 1515, 784, 1536, 793, 1575, 822, 1564, 867, 1527, 920, 1523, 973, 1522, 1120, 1512, 1156, 1507, 1161, 1487, 1148, 1405, 1229, 1421, 1268, 1428, 1341, 1414, 1407, 1423, 1445, 1424, 1458, 1350, 1466, 1295, 1442, 1220, 1422, 1182, 1453, 1141, 1437, 1120, 1358, 1128, 1335, 1146, 1202, 1179, 1094, 1219, 1032, 1225, 939, 1164, 896, 1164, 783, 1188, 695, 1169, 732, 1221, 685, 1264, 587, 1295, 532, 1332, 548, 1361, 651, 1333, 698, 1319, 682, 1368, 698, 1405]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [1419.0, 2199.0, 853.0, 646.0], 'category_id': 6, 'segmentation': [[1427, 2323, 1419, 2351, 1421, 2409, 1420, 2446, 1423, 2473, 1484, 2523, 1503, 2523, 1546, 2527, 1564, 2543, 1596, 2557, 1628, 2573, 1695, 2609, 1716, 2621, 1778, 2659, 1823, 2676, 1840, 2685, 1891, 2706, 1901, 2719, 1943, 2736, 1971, 2755, 1988, 2756, 2020, 2782, 2065, 2800, 2100, 2804, 2113, 2821, 2159, 2845, 2190, 2836, 2209, 2816, 2221, 2787, 2272, 2730, 2265, 2700, 2214, 2594, 2185, 2526, 2154, 2486, 2124, 2507, 2076, 2595, 2028, 2709, 2011, 2770, 1986, 2749, 2036, 2619, 2063, 2556, 2089, 2498, 2132, 2438, 2130, 2414, 2083, 2410, 2033, 2387, 1967, 2346, 1935, 2347, 1851, 2303, 1788, 2273, 1670, 2228, 1573, 2199, 1527, 2232, 1496, 2265, 1467, 2297]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_11/000070.jpg', 'height': 4032, 'width': 3024, 'image_id': 271, 'annotations': [{'iscrowd': 0, 'bbox': [967.0, 1882.0, 1149.0, 353.0], 'category_id': 0, 'segmentation': [[1205, 1911, 1439, 1886, 1726, 1882, 1794, 1894, 1870, 1931, 1929, 1969, 2005, 1995, 2039, 1993, 2044, 1979, 2104, 1988, 2116, 2015, 2111, 2083, 2053, 2084, 2043, 2088, 2034, 2077, 1980, 2090, 1913, 2121, 1841, 2173, 1783, 2199, 1731, 2210, 1464, 2216, 1434, 2220, 1244, 2207, 1199, 2213, 1157, 2230, 1096, 2235, 1030, 2221, 987, 2196, 982, 2171, 986, 2149, 970, 2137, 969, 2090, 982, 2075, 987, 2030, 967, 1998, 971, 1961, 1014, 1930, 1086, 1899, 1122, 1891, 1145, 1894]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [2068.0, 1985.0, 50.0, 100.0], 'category_id': 1, 'segmentation': [[2068, 1985, 2080, 2020, 2075, 2077, 2109, 2085, 2115, 2052, 2118, 2017, 2105, 1989]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_12/000002.jpg', 'height': 5312, 'width': 2988, 'image_id': 303, 'annotations': [{'iscrowd': 0, 'bbox': [1000.0, 1740.0, 718.0, 734.0], 'category_id': 1, 'segmentation': [[1302.0, 1740.0, 1218.0, 1759.0, 1146.0, 1804.0, 1060.0, 1892.0, 1022.0, 1992.0, 1000.0, 2091.0, 1004.0, 2168.0, 1028.0, 2259.0, 1061.0, 2336.0, 1103.0, 2375.0, 1151.0, 2422.0, 1218.0, 2456.0, 1310.0, 2474.0, 1453.0, 2460.0, 1528.0, 2431.0, 1600.0, 2385.0, 1651.0, 2325.0, 1692.0, 2249.0, 1715.0, 2164.0, 1718.0, 2093.0, 1709.0, 2005.0, 1700.0, 1984.0, 1662.0, 1905.0, 1635.0, 1860.0, 1559.0, 1796.0, 1493.0, 1759.0, 1419.0, 1746.0, 1364.0, 1742.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_12/000005.jpg', 'height': 2340, 'width': 4160, 'image_id': 306, 'annotations': [{'iscrowd': 0, 'bbox': [857.0, 565.0, 2291.0, 1457.0], 'category_id': 7, 'segmentation': [[857, 1394, 926, 1494, 955, 1537, 1031, 1636, 1061, 1694, 1166, 1841, 1255, 1965, 1274, 1932, 1320, 1915, 1358, 1929, 1382, 1979, 1387, 2022, 1403, 2010, 1419, 1974, 1391, 1938, 1368, 1884, 1396, 1810, 1409, 1788, 1459, 1770, 1526, 1758, 1560, 1734, 1590, 1731, 1616, 1742, 1634, 1727, 1672, 1731, 1695, 1747, 1722, 1782, 1758, 1790, 1781, 1823, 1809, 1829, 1826, 1859, 1831, 1886, 1862, 1889, 1910, 1880, 1929, 1881, 1932, 1823, 1955, 1794, 1999, 1773, 2026, 1772, 2041, 1782, 2060, 1770, 2089, 1777, 2113, 1800, 2131, 1813, 2156, 1860, 2170, 1852, 2154, 1820, 2149, 1787, 2149, 1758, 2153, 1743, 2172, 1732, 2202, 1726, 2222, 1743, 2245, 1736, 2265, 1744, 2295, 1778, 2262, 1841, 2293, 1848, 2306, 1828, 2301, 1810, 2335, 1802, 2324, 1777, 2303, 1721, 2314, 1706, 2334, 1694, 2371, 1698, 2396, 1712, 2416, 1732, 2420, 1765, 2392, 1838, 2404, 1837, 2460, 1805, 2493, 1792, 2488, 1775, 2499, 1748, 2519, 1747, 2550, 1767, 2573, 1823, 2598, 1819, 2547, 1674, 2578, 1667, 2625, 1678, 2630, 1655, 2652, 1634, 2679, 1636, 2704, 1725, 2764, 1688, 2785, 1684, 2784, 1667, 2791, 1654, 2807, 1654, 2825, 1646, 2835, 1618, 2860, 1622, 2881, 1619, 2906, 1632, 2918, 1641, 2937, 1663, 2949, 1669, 2937, 1730, 2951, 1728, 2988, 1690, 3023, 1679, 3063, 1693, 3091, 1670, 3121, 1659, 3148, 1637, 3137, 1598, 3098, 1540, 3081, 1505, 3062, 1477, 3060, 1438, 3026, 1352, 2997, 1312, 2969, 1328, 2940, 1315, 2928, 1278, 2927, 1244, 2941, 1200, 2931, 1178, 2917, 1169, 2908, 1085, 2895, 1041, 2846, 936, 2780, 974, 2714, 910, 2615, 789, 2504, 658, 2465, 622, 2429, 565, 2332, 613, 2365, 630, 2338, 650, 2305, 656, 2190, 709, 2072, 760, 1908, 746, 1794, 822, 1627, 936, 1471, 1050, 1342, 1185, 1326, 1195]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_12/000008.jpg', 'height': 5312, 'width': 2988, 'image_id': 309, 'annotations': [{'iscrowd': 0, 'bbox': [1007.0, 1210.0, 1383.0, 2289.0], 'category_id': 2, 'segmentation': [[1070.0, 1470.0, 1097.0, 1540.0, 1112.0, 1588.0, 1033.0, 1704.0, 1007.0, 1788.0, 1127.0, 2797.0, 1193.0, 3373.0, 1221.0, 3399.0, 1318.0, 3442.0, 1344.0, 3457.0, 1390.0, 3493.0, 1520.0, 3499.0, 1846.0, 3472.0, 2117.0, 3427.0, 2237.0, 3390.0, 2265.0, 3350.0, 2316.0, 3298.0, 2381.0, 3254.0, 2390.0, 3214.0, 2249.0, 2222.0, 2151.0, 1563.0, 2021.0, 1408.0, 2019.0, 1330.0, 1984.0, 1271.0, 1861.0, 1221.0, 1743.0, 1210.0, 1605.0, 1210.0, 1498.0, 1226.0, 1368.0, 1257.0, 1242.0, 1306.0, 1163.0, 1349.0, 1093.0, 1420.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_12/000015.jpg', 'height': 2340, 'width': 4160, 'image_id': 316, 'annotations': [{'iscrowd': 0, 'bbox': [1261.0, 1011.0, 333.0, 178.0], 'category_id': 3, 'segmentation': [[1269, 1062, 1537, 1185, 1569, 1189, 1594, 1178, 1552, 1146, 1518, 1115, 1287, 1011, 1270, 1024, 1261, 1041]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [1804.0, 1225.0, 231.0, 217.0], 'category_id': 1, 'segmentation': [[1968, 1433, 1993, 1420, 2014, 1394, 2030, 1371, 2035, 1340, 2028, 1298, 2013, 1266, 1980, 1240, 1947, 1225, 1897, 1226, 1846, 1247, 1818, 1279, 1806, 1333, 1804, 1359, 1823, 1403, 1866, 1429, 1900, 1442, 1940, 1441]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [2133.0, 646.0, 260.0, 132.0], 'category_id': 6, 'segmentation': [[2159, 688, 2369, 778, 2393, 775, 2373, 752, 2173, 664, 2154, 646, 2141, 669, 2133, 695]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_12/000038.jpg', 'height': 4128, 'width': 3096, 'image_id': 339, 'annotations': [{'iscrowd': 0, 'bbox': [482.3332999999998, 2051.2856, 296.0, 128.0], 'category_id': 7, 'segmentation': [[484.0, 2143.0, 524.0, 2164.0, 579.0, 2166.0, 654.0, 2170.0, 705.0, 2179.0, 753.0, 2170.0, 759.0, 2147.0, 778.0, 2130.0, 773.0, 2102.0, 748.0, 2098.0, 743.0, 2086.0, 707.0, 2080.0, 652.0, 2057.0, 628.0, 2051.0, 613.0, 2058.0, 604.0, 2089.0, 605.0, 2114.0, 592.0, 2120.0, 553.0, 2097.0, 531.0, 2089.0, 508.0, 2098.0, 482.0, 2113.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [1234.1428, 2224.3333, 327.0, 241.0], 'category_id': 7, 'segmentation': [[1247.0, 2364.0, 1284.0, 2413.0, 1314.0, 2465.0, 1421.0, 2461.0, 1502.0, 2447.0, 1521.0, 2422.0, 1561.0, 2401.0, 1558.0, 2361.0, 1539.0, 2308.0, 1499.0, 2269.0, 1521.0, 2263.0, 1541.0, 2269.0, 1561.0, 2249.0, 1534.0, 2224.0, 1496.0, 2230.0, 1469.0, 2249.0, 1413.0, 2261.0, 1351.0, 2240.0, 1308.0, 2242.0, 1268.0, 2245.0, 1234.0, 2264.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [696.1428000000001, 1824.9048, 194.0, 123.0], 'category_id': 7, 'segmentation': [[709.0, 1843.0, 747.0, 1825.0, 792.0, 1833.0, 826.0, 1850.0, 862.0, 1850.0, 890.0, 1935.0, 829.0, 1945.0, 786.0, 1948.0, 708.0, 1929.0, 696.0, 1908.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [2288.9048000000003, 3128.5713, 379.99994999999996, 156.0], 'category_id': 0, 'segmentation': [[2351.0, 3262.0, 2411.0, 3285.0, 2465.0, 3264.0, 2484.0, 3253.0, 2547.0, 3238.0, 2627.0, 3213.0, 2645.0, 3194.0, 2669.0, 3175.0, 2648.0, 3152.0, 2594.0, 3140.0, 2560.0, 3138.0, 2465.0, 3129.0, 2406.0, 3143.0, 2325.0, 3157.0, 2292.0, 3178.0, 2289.0, 3197.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [1616.5238, 2275.524, 62.0, 29.0], 'category_id': 6, 'segmentation': [[1624.0, 2283.0, 1653.0, 2276.0, 1679.0, 2282.0, 1662.0, 2305.0, 1617.0, 2302.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [109.95240000000013, 2187.1904, 68.0, 45.0], 'category_id': 6, 'segmentation': [[110.0, 2216.0, 147.0, 2232.0, 178.0, 2215.0, 153.0, 2187.0, 138.0, 2192.0, 147.0, 2204.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_12/000043.jpg', 'height': 3120, 'width': 4160, 'image_id': 344, 'annotations': [{'iscrowd': 0, 'bbox': [746.0, 2233.0, 268.0, 214.0], 'category_id': 2, 'segmentation': [[753, 2355, 951, 2233, 972, 2233, 995, 2251, 1014, 2287, 1003, 2311, 970, 2338, 798, 2447, 777, 2435, 753, 2405, 746, 2378]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [1404.0, 1963.0, 185.0, 165.0], 'category_id': 2, 'segmentation': [[1406, 2054, 1539, 1963, 1573, 1976, 1589, 1999, 1579, 2037, 1456, 2125, 1427, 2128, 1404, 2097]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [2336.0, 1337.0, 140.0, 156.0], 'category_id': 2, 'segmentation': [[2336, 1438, 2398, 1350, 2421, 1337, 2443, 1340, 2468, 1360, 2476, 1377, 2460, 1423, 2401, 1493, 2367, 1488, 2340, 1466]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [1646.0, 1920.0, 171.0, 154.0], 'category_id': 7, 'segmentation': [[1649, 2019, 1659, 1990, 1679, 1984, 1680, 1965, 1697, 1945, 1714, 1928, 1736, 1929, 1756, 1920, 1771, 1925, 1792, 1938, 1785, 1960, 1769, 1971, 1692, 1990], [1738, 2019, 1773, 1999, 1795, 1981, 1817, 1994, 1767, 2053, 1740, 2074, 1700, 2074, 1669, 2058, 1646, 2037, 1705, 2024, 1728, 2032]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [2016.0, 2157.0, 382.0, 206.0], 'category_id': 7, 'segmentation': [[2185, 2175, 2217, 2176, 2238, 2157, 2265, 2166, 2285, 2165, 2327, 2181, 2334, 2200, 2322, 2225, 2333, 2234, 2359, 2232, 2381, 2234, 2382, 2251, 2394, 2261, 2398, 2298, 2392, 2344, 2366, 2327, 2289, 2339, 2259, 2313, 2234, 2313, 2139, 2287, 2159, 2240], [2049, 2245, 2052, 2224, 2082, 2221, 2106, 2222, 2128, 2202, 2146, 2221, 2120, 2265, 2096, 2268], [2016, 2286, 2080, 2290, 2100, 2300, 2029, 2349], [2047, 2353, 2083, 2328, 2059, 2363], [2104, 2345, 2125, 2307, 2166, 2327, 2203, 2336, 2243, 2336, 2232, 2351, 2177, 2362]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [2074.0, 2548.0, 57.0, 113.0], 'category_id': 6, 'segmentation': [[2074, 2653, 2087, 2548, 2131, 2554, 2121, 2661]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [2552.0, 1486.0, 243.0, 263.0], 'category_id': 0, 'segmentation': [[2552, 1530, 2577, 1512, 2607, 1486, 2632, 1497, 2655, 1533, 2680, 1569, 2722, 1610, 2756, 1641, 2768, 1697, 2779, 1716, 2795, 1732, 2772, 1749, 2747, 1739, 2735, 1727, 2683, 1704, 2649, 1662, 2626, 1624, 2630, 1604, 2631, 1567, 2618, 1558, 2569, 1563]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [2750.0, 1715.0, 46.0, 36.0], 'category_id': 1, 'segmentation': [[2750, 1741, 2766, 1729, 2779, 1715, 2796, 1732, 2776, 1751]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_12/000050.jpg', 'height': 3968, 'width': 2976, 'image_id': 351, 'annotations': [{'iscrowd': 0, 'bbox': [1050.0, 35.0, 60.0, 48.0], 'category_id': 3, 'segmentation': [[1050, 66, 1092, 35, 1110, 51, 1064, 83, 1052, 79]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [1208.0, 107.0, 19.0, 45.0], 'category_id': 3, 'segmentation': [[1211, 150, 1208, 109, 1220, 107, 1227, 152]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [1302.0, 330.0, 74.0, 73.0], 'category_id': 3, 'segmentation': [[1302, 345, 1362, 403, 1376, 381, 1316, 330]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [1872.0, 139.0, 32.0, 68.0], 'category_id': 3, 'segmentation': [[1883, 204, 1873, 158, 1872, 139, 1894, 146, 1904, 207]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [1492.0, 442.0, 81.0, 31.0], 'category_id': 3, 'segmentation': [[1492, 453, 1522, 446, 1567, 442, 1573, 464, 1522, 468, 1502, 473]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [2769.0, 497.0, 104.0, 67.0], 'category_id': 3, 'segmentation': [[2769, 522, 2860, 564, 2873, 535, 2777, 497]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [2231.0, 601.0, 26.0, 34.0], 'category_id': 3, 'segmentation': [[2231, 607, 2232, 635, 2250, 634, 2257, 601]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [943.0, 2528.0, 88.0, 71.0], 'category_id': 3, 'segmentation': [[943, 2555, 1014, 2599, 1031, 2577, 957, 2528]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [364.0, 1951.0, 1101.0, 487.0], 'category_id': 6, 'segmentation': [[401, 2242, 416, 2261, 456, 2255, 602, 2222, 690, 2184, 773, 2173, 883, 2165, 987, 2127, 1116, 2067, 1183, 2041, 1226, 2031, 1257, 2060, 1304, 2087, 1366, 2101, 1411, 2132, 1435, 2162, 1428, 2186, 1372, 2253, 1319, 2311, 1293, 2327, 1262, 2333, 1185, 2385, 1166, 2403, 1142, 2398, 1155, 2438, 1175, 2418, 1199, 2421, 1262, 2412, 1324, 2389, 1380, 2356, 1429, 2308, 1460, 2268, 1465, 2230, 1460, 2189, 1463, 2113, 1453, 2057, 1407, 2026, 1354, 2007, 1309, 1999, 1252, 1988, 1172, 1986, 1152, 1979, 1106, 1951, 1055, 1951, 961, 1973, 865, 2002, 804, 2036, 754, 2064, 708, 2072, 586, 2070, 388, 2077, 364, 2069, 385, 2109, 389, 2154, 388, 2205]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [1145.0, 2484.0, 78.0, 82.0], 'category_id': 1, 'segmentation': [[1156, 2501, 1145, 2528, 1150, 2557, 1168, 2566, 1196, 2565, 1214, 2548, 1223, 2512, 1210, 2494, 1191, 2484, 1168, 2488]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [1551.0, 2099.0, 37.0, 48.0], 'category_id': 6, 'segmentation': [[1559, 2100, 1551, 2128, 1553, 2143, 1563, 2147, 1581, 2132, 1588, 2099]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [1670.0, 2471.0, 62.0, 65.0], 'category_id': 6, 'segmentation': [[1670, 2481, 1695, 2516, 1686, 2531, 1700, 2536, 1728, 2532, 1732, 2514, 1716, 2496, 1722, 2510, 1717, 2527, 1706, 2522, 1693, 2471]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [479.0, 2405.0, 53.0, 20.0], 'category_id': 6, 'segmentation': [[485, 2405, 479, 2422, 498, 2425, 527, 2421, 532, 2408]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [787.0, 2296.0, 54.0, 102.0], 'category_id': 6, 'segmentation': [[787, 2307, 820, 2398, 841, 2392, 809, 2296]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [847.0, 1498.0, 62.0, 57.0], 'category_id': 6, 'segmentation': [[848, 1505, 847, 1537, 865, 1555, 888, 1539, 909, 1547, 895, 1526, 878, 1498]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [751.0, 852.0, 83.0, 63.0], 'category_id': 3, 'segmentation': [[751, 875, 760, 852, 834, 897, 827, 915]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_12/000052.jpg', 'height': 5312, 'width': 2988, 'image_id': 353, 'annotations': [{'iscrowd': 0, 'bbox': [1011.0, 1589.0, 824.0, 782.0], 'category_id': 4, 'segmentation': [[1050.0, 1972.0, 1074.0, 2061.0, 1094.0, 2186.0, 1106.0, 2245.0, 1132.0, 2296.0, 1170.0, 2319.0, 1238.0, 2325.0, 1322.0, 2371.0, 1459.0, 2327.0, 1631.0, 2270.0, 1762.0, 2230.0, 1790.0, 2201.0, 1835.0, 2090.0, 1835.0, 2030.0, 1822.0, 1965.0, 1803.0, 1875.0, 1774.0, 1800.0, 1728.0, 1739.0, 1490.0, 1589.0, 1194.0, 1609.0, 1148.0, 1647.0, 1113.0, 1671.0, 1071.0, 1686.0, 1040.0, 1715.0, 1016.0, 1786.0, 1011.0, 1840.0, 1020.0, 1872.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_12/000057.jpg', 'height': 4160, 'width': 3120, 'image_id': 358, 'annotations': [{'iscrowd': 0, 'bbox': [1468.0, 2181.0, 508.0, 437.0], 'category_id': 7, 'segmentation': [[1468, 2545, 1487, 2474, 1500, 2375, 1496, 2223, 1515, 2181, 1547, 2208, 1569, 2208, 1598, 2229, 1627, 2227, 1663, 2230, 1728, 2223, 1818, 2227, 1896, 2253, 1976, 2291, 1938, 2450, 1898, 2591, 1806, 2618, 1661, 2568, 1598, 2508]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [2254.0, 1217.0, 249.0, 173.0], 'category_id': 7, 'segmentation': [[2254, 1248, 2488, 1390, 2503, 1360, 2302, 1220, 2293, 1227, 2280, 1217]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [2331.0, 791.0, 229.0, 204.0], 'category_id': 6, 'segmentation': [[2390, 905, 2415, 966, 2486, 995, 2538, 960, 2560, 935, 2505, 880, 2524, 844, 2518, 807, 2456, 830, 2431, 819, 2417, 827, 2379, 791, 2331, 849, 2396, 888]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [2744.0, 3150.0, 247.0, 211.0], 'category_id': 6, 'segmentation': [[2820, 3287, 2763, 3243, 2744, 3260, 2785, 3339, 2831, 3361, 2925, 3361, 2955, 3338, 2991, 3287, 2926, 3268, 2951, 3233, 2878, 3201, 2835, 3161, 2800, 3150, 2792, 3168, 2803, 3195, 2822, 3265]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [1277.0, 311.0, 473.0, 185.0], 'category_id': 0, 'segmentation': [[1277, 387, 1366, 373, 1395, 344, 1435, 318, 1482, 326, 1738, 311, 1750, 430, 1713, 442, 1654, 437, 1626, 454, 1588, 431, 1581, 468, 1490, 490, 1435, 496, 1390, 474, 1369, 453, 1287, 460, 1279, 440]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [353.0, 951.0, 85.0, 49.0], 'category_id': 6, 'segmentation': [[367, 965, 353, 988, 357, 1000, 438, 982, 436, 951, 396, 952]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [848.0, 3785.0, 257.0, 183.0], 'category_id': 7, 'segmentation': [[898, 3892, 917, 3920, 1069, 3968, 1105, 3906, 1092, 3874, 1015, 3820, 972, 3785, 898, 3787, 867, 3822, 848, 3870, 854, 3908, 868, 3911, 880, 3909]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [2747.0, 154.0, 33.0, 50.0], 'category_id': 3, 'segmentation': [[2754, 197, 2747, 154, 2769, 159, 2780, 204, 2768, 204]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [1343.0, 3815.0, 89.0, 121.0], 'category_id': 7, 'segmentation': [[1343, 3850, 1408, 3936, 1410, 3911, 1432, 3889, 1361, 3815]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_12/000079.jpg', 'height': 4160, 'width': 3120, 'image_id': 380, 'annotations': [{'iscrowd': 0, 'bbox': [748.0, 865.0, 934.0, 2841.0], 'category_id': 0, 'segmentation': [[771, 1447, 804, 1369, 843, 1304, 906, 1237, 925, 1215, 926, 1198, 901, 1189, 879, 1162, 882, 1124, 895, 1109, 881, 939, 909, 906, 962, 880, 1025, 866, 1087, 865, 1166, 876, 1208, 894, 1232, 921, 1244, 955, 1265, 1098, 1283, 1127, 1276, 1162, 1249, 1184, 1249, 1201, 1294, 1234, 1350, 1280, 1397, 1337, 1453, 1432, 1478, 1481, 1523, 1646, 1544, 1778, 1557, 1875, 1587, 2041, 1619, 2249, 1632, 2458, 1653, 2702, 1647, 2759, 1671, 2992, 1682, 3170, 1682, 3333, 1678, 3413, 1663, 3471, 1647, 3509, 1616, 3531, 1575, 3536, 1555, 3597, 1534, 3633, 1504, 3651, 1429, 3676, 1388, 3669, 1331, 3601, 1313, 3581, 1288, 3585, 1261, 3600, 1188, 3679, 1159, 3700, 1125, 3706, 1090, 3698, 1050, 3677, 1031, 3660, 991, 3583, 949, 3461, 909, 3330, 898, 3247, 876, 3065, 869, 3006, 877, 2956, 850, 2748, 810, 2376, 792, 2083, 786, 1922, 765, 1823, 751, 1715, 748, 1642, 756, 1518]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [878.0, 863.0, 380.0, 200.0], 'category_id': 1, 'segmentation': [[892, 1063, 922, 1042, 981, 1021, 1072, 1007, 1145, 1013, 1228, 1028, 1258, 1044, 1245, 953, 1232, 917, 1208, 893, 1168, 878, 1087, 863, 1019, 866, 954, 880, 900, 910, 878, 943]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_12/000080.jpg', 'height': 3120, 'width': 4160, 'image_id': 381, 'annotations': [{'iscrowd': 0, 'bbox': [1582.75, 1241.5, 1982.5, 1085.5], 'category_id': 6, 'segmentation': [[1609, 1976, 1960, 2067, 2382, 2132, 3494, 2327, 3526, 2074, 3494, 1852, 3507, 1696, 3565, 1502, 3559, 1358, 3013, 1242, 1615, 1443, 1583, 1690]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_12/000093.jpg', 'height': 3120, 'width': 4160, 'image_id': 394, 'annotations': [{'iscrowd': 0, 'bbox': [1082.0, 2255.0, 2036.0, 738.0], 'category_id': 0, 'segmentation': [[1137, 2597, 1111, 2648, 1110, 2680, 1163, 2727, 1243, 2765, 1494, 2819, 1722, 2864, 2293, 2953, 2400, 2978, 2522, 2991, 2634, 2993, 2711, 2983, 2779, 2960, 2846, 2923, 2922, 2856, 2953, 2835, 2980, 2834, 2987, 2862, 3102, 2875, 3112, 2865, 3118, 2788, 3114, 2671, 3100, 2662, 3009, 2647, 2993, 2640, 2982, 2658, 2952, 2656, 2898, 2586, 2814, 2505, 2684, 2430, 2534, 2394, 2247, 2369, 1790, 2321, 1734, 2321, 1677, 2297, 1546, 2277, 1400, 2258, 1307, 2255, 1256, 2263, 1211, 2277, 1176, 2310, 1177, 2349, 1184, 2405, 1146, 2423, 1106, 2445, 1083, 2488, 1082, 2527, 1119, 2567, 1138, 2582]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [2867.0, 2835.0, 225.0, 284.0], 'category_id': 6, 'segmentation': [[2878, 2998, 2902, 3068, 2926, 3103, 2955, 3119, 2974, 3098, 2984, 3066, 2975, 3034, 2955, 3007, 2948, 2992, 2939, 2984, 2942, 2969, 2952, 2963, 2946, 2906, 2933, 2853, 2869, 2908, 2867, 2951], [2937, 2848, 2955, 2836, 2978, 2835, 2986, 2861, 3006, 2861, 3026, 2880, 3056, 2929, 3078, 2973, 3092, 3022, 3092, 3051, 3069, 3113, 3029, 3119, 2958, 3118, 2971, 3100, 2982, 3105, 2992, 3095, 3006, 3083, 3020, 3090, 3030, 3077, 3042, 3111, 3058, 3107, 3044, 3062, 3047, 3032, 3031, 3006, 3023, 2988, 2995, 2905, 2991, 2921, 2960, 2905, 2947, 2902]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [674.0, 2706.0, 942.0, 350.0], 'category_id': 7, 'segmentation': [[674, 2953, 766, 2924, 840, 2903, 887, 2889, 927, 2859, 976, 2824, 981, 2913, 995, 2951, 986, 2962, 940, 2967, 874, 2932, 839, 2947, 859, 2967, 764, 2954], [1012, 2945, 1017, 2909, 1001, 2798, 1137, 2706, 1161, 2726, 1244, 2764, 1497, 2823, 1518, 2828, 1512, 2841, 1340, 2878, 1451, 2879, 1427, 2893, 1305, 2923, 1256, 2907, 1182, 2914, 1134, 2907, 1056, 2926], [1376, 2951, 1398, 2981, 1453, 3000, 1484, 2919], [1544, 2912, 1508, 3021, 1568, 3056, 1571, 3037, 1603, 2989, 1616, 2896]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [2903.0, 1815.0, 465.0, 332.0], 'category_id': 6, 'segmentation': [[2903, 1906, 2941, 1869, 3006, 1824, 3022, 1815, 3047, 1857, 3105, 1902, 3158, 1928, 3274, 1955, 3311, 1967, 3368, 2016, 3350, 2076, 3326, 2111, 3307, 2122, 3206, 2134, 3133, 2147, 3033, 2101, 2978, 2119, 2952, 2106, 2956, 2050, 2985, 1998, 2959, 1962, 2929, 1940]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [3732.0, 2112.0, 165.0, 99.0], 'category_id': 6, 'segmentation': [[3732, 2131, 3753, 2115, 3794, 2112, 3835, 2117, 3897, 2156, 3871, 2161, 3800, 2155], [3735, 2147, 3737, 2157, 3758, 2157, 3750, 2147], [3770, 2195, 3776, 2211, 3831, 2205, 3796, 2194]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_13/000004.jpg', 'height': 4160, 'width': 3120, 'image_id': 405, 'annotations': [{'iscrowd': 0, 'bbox': [725.381, 1849.619, 1070.0, 894.0001], 'category_id': 4, 'segmentation': [[869, 2730, 829, 2692, 787, 2635, 758, 2580, 738, 2522, 725, 2458, 806, 2417, 903, 2286, 958, 2229, 1013, 2194, 1046, 2191, 1047, 2171, 1229, 2058, 1359, 1983, 1371, 1963, 1477, 1896, 1476, 1857, 1492, 1850, 1518, 1874, 1556, 1936, 1617, 2044, 1668, 2154, 1718, 2268, 1751, 2344, 1776, 2400, 1795, 2479, 1780, 2496, 1752, 2473, 1726, 2472, 1628, 2510, 1610, 2509, 1426, 2575, 1138, 2675, 1030, 2711, 1010, 2712, 945, 2730, 917, 2744, 893, 2742]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [1655.4762, 1923.8572, 735.3334, 328.0], 'category_id': 9, 'segmentation': [[1655, 2171, 2356, 1924, 2391, 2017, 2357, 2021, 1709, 2243, 1686, 2252]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [1669.381, 2518.0476, 356.0, 246.0], 'category_id': 7, 'segmentation': [[1669, 2518, 1670, 2555, 1692, 2683, 1705, 2728, 1721, 2754, 1802, 2752, 1860, 2754, 1853, 2724, 1876, 2714, 1898, 2696, 1948, 2753, 2025, 2764, 1974, 2730, 1959, 2715, 1964, 2656, 1821, 2591, 1807, 2531, 1738, 2529]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_13/000012.jpg', 'height': 3120, 'width': 4160, 'image_id': 413, 'annotations': [{'iscrowd': 0, 'bbox': [1925.5, 1307.0, 748.0, 764.0], 'category_id': 1, 'segmentation': [[2042, 1396, 2092, 1361, 2174, 1322, 2266, 1307, 2352, 1312, 2436, 1335, 2512, 1375, 2556, 1414, 2608, 1475, 2648, 1550, 2666, 1615, 2674, 1680, 2664, 1752, 2644, 1814, 2616, 1863, 2570, 1921, 2500, 1994, 2406, 2047, 2292, 2071, 2190, 2059, 2118, 2030, 2100, 1982, 2078, 1974, 2048, 1958, 2032, 1922, 2022, 1897, 2006, 1905, 1950, 1826, 1928, 1748, 1926, 1641, 1936, 1563, 1958, 1507, 1984, 1460, 2014, 1422]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_13/000014.jpg', 'height': 4208, 'width': 2368, 'image_id': 415, 'annotations': [{'iscrowd': 0, 'bbox': [1175.4886, 2111.0, 584.7405000000001, 603.0], 'category_id': 4, 'segmentation': [[1175, 2376, 1192, 2393, 1218, 2474, 1249, 2508, 1301, 2563, 1376, 2610, 1472, 2699, 1497, 2711, 1591, 2714, 1649, 2693, 1690, 2666, 1720, 2634, 1740, 2600, 1760, 2465, 1704, 2390, 1603, 2257, 1487, 2115, 1453, 2134, 1418, 2126, 1415, 2111, 1387, 2127, 1360, 2176, 1315, 2228, 1260, 2264, 1197, 2323, 1180, 2345]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [908.7674, 1.0, 470.3972000000001, 307.0], 'category_id': 6, 'segmentation': [[978, 162, 1036, 136, 1066, 92, 1137, 86, 1227, 1, 1293, 4, 1304, 25, 1350, 43, 1379, 85, 1278, 215, 1244, 261, 1176, 308, 1124, 275, 1086, 255, 1045, 259, 993, 203, 925, 219, 909, 194]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [1326.1198, 1.0, 189.15970000000016, 56.0], 'category_id': 6, 'segmentation': [[1326, 19, 1335, 1, 1515, 1, 1466, 49, 1387, 57, 1357, 46]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [1391.1747, 1053.0, 136.115, 142.0], 'category_id': 7, 'segmentation': [[1391, 1195, 1395, 1133, 1434, 1064, 1484, 1053, 1494, 1060, 1483, 1109, 1527, 1182, 1456, 1192]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [2179.8406, 3733.0, 180.15239999999994, 202.0], 'category_id': 6, 'segmentation': [[2243, 3814, 2254, 3804, 2238, 3746, 2249, 3733, 2293, 3735, 2330, 3755, 2347, 3789, 2360, 3816, 2355, 3847, 2300, 3841, 2286, 3850, 2285, 3885, 2267, 3921, 2236, 3935, 2204, 3927, 2180, 3891, 2181, 3861, 2202, 3834, 2225, 3818]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [616.5206, 3902.0, 273.2307400000001, 304.0], 'category_id': 6, 'segmentation': [[827, 4154, 866, 4109, 890, 4050, 886, 3987, 863, 3944, 819, 3912, 766, 3902, 719, 3934, 652, 4015, 633, 4054, 617, 4125, 618, 4167, 636, 4192, 657, 4206, 743, 4206, 779, 4187, 805, 4169]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [1932.0, 1951.0, 108.0, 77.0], 'category_id': 6, 'segmentation': [[1940, 2019, 1932, 1951, 1961, 1985, 2012, 1985, 2024, 1980, 2040, 2028, 2004, 2020, 1966, 2002]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_13/000015.jpg', 'height': 4160, 'width': 3120, 'image_id': 416, 'annotations': [{'iscrowd': 0, 'bbox': [1.0, 1199.0, 840.0, 1380.0], 'category_id': 9, 'segmentation': [[1, 1202, 92, 1199, 806, 2519, 841, 2579, 656, 2487, 254, 1813, 4, 1384]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [1088.0, 1782.0, 115.0, 675.0], 'category_id': 6, 'segmentation': [[1088, 1790, 1135, 2415, 1173, 2457, 1203, 2422, 1129, 1797, 1108, 1782]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [494.0, 1962.0, 1267.0, 1574.0], 'category_id': 4, 'segmentation': [[597, 2132, 698, 2059, 812, 2015, 962, 1979, 1100, 1962, 1348, 1981, 1493, 2023, 1622, 2081, 1706, 2151, 1750, 2223, 1761, 2277, 1753, 2344, 1724, 2410, 1683, 2457, 1639, 2563, 1613, 2643, 1504, 3160, 1412, 3414, 1326, 3487, 1227, 3529, 1121, 3536, 1022, 3518, 922, 3464, 855, 3363, 841, 3333, 793, 3202, 705, 2843, 663, 2660, 637, 2618, 617, 2555, 587, 2497, 533, 2431, 497, 2359, 494, 2291, 506, 2244]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [1023.0, 1392.0, 145.0, 83.0], 'category_id': 7, 'segmentation': [[1037, 1423, 1023, 1441, 1063, 1468, 1086, 1455, 1137, 1475, 1151, 1453, 1168, 1400, 1135, 1392, 1087, 1399, 1069, 1415]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [139.0, 2187.0, 370.0, 304.0], 'category_id': 6, 'segmentation': [[193, 2309, 443, 2187, 482, 2194, 509, 2242, 495, 2290, 495, 2357, 472, 2378, 335, 2472, 297, 2491, 268, 2485, 139, 2417, 145, 2393]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_13/000019.jpg', 'height': 4160, 'width': 3120, 'image_id': 420, 'annotations': [{'iscrowd': 0, 'bbox': [1167.0, 802.0, 1313.0, 696.0], 'category_id': 9, 'segmentation': [[1167, 842, 1831, 1055, 2204, 1164, 2436, 1495, 2457, 1498, 2480, 1479, 2328, 1268, 2257, 1156, 2227, 1132, 2147, 1106, 1182, 802, 1169, 822]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [2718.0, 1893.0, 357.0, 356.0], 'category_id': 6, 'segmentation': [[2744, 2244, 2797, 2249, 2949, 2244, 3000, 2238, 3047, 2224, 3075, 2202, 3061, 2151, 3042, 2110, 3035, 2096, 3036, 2074, 3018, 2056, 3019, 2018, 3004, 1987, 3004, 1953, 3008, 1927, 2986, 1893, 2956, 1898, 2924, 1910, 2896, 1913, 2863, 1935, 2852, 1959, 2807, 1980, 2765, 2004, 2751, 2029, 2760, 2048, 2760, 2086, 2741, 2100, 2740, 2150, 2720, 2194, 2718, 2224]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [205.0, 2726.0, 1248.0, 758.0], 'category_id': 6, 'segmentation': [[211, 3136, 356, 2982, 431, 2941, 443, 2947, 1089, 2778, 1288, 2726, 1453, 3098, 1367, 3309, 1345, 3322, 946, 3405, 516, 3476, 397, 3484, 320, 3379, 205, 3165, 206, 3148]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [345.0, 3061.0, 773.0, 417.0], 'category_id': 9, 'segmentation': [[377, 3377, 1102, 3061, 1118, 3080, 1116, 3110, 397, 3411, 403, 3428, 434, 3431, 726, 3306, 763, 3334, 428, 3478, 368, 3466, 345, 3438, 353, 3401]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [321.0, 3007.0, 899.0, 501.0], 'category_id': 7, 'segmentation': [[675, 3420, 1005, 3298, 1220, 3205, 1173, 3094, 1159, 3007, 680, 3205, 321, 3357, 336, 3407, 412, 3508, 460, 3496]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [1168.0, 1686.0, 948.0, 1070.0], 'category_id': 9, 'segmentation': [[1176, 2721, 2079, 1699, 2101, 1686, 2114, 1734, 2116, 1791, 1908, 2032, 1504, 2497, 1295, 2732, 1287, 2722, 1168, 2756, 1207, 2723]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [359.0, 1566.0, 1368.0, 728.0], 'category_id': 7, 'segmentation': [[744, 1647, 768, 1656, 849, 1669, 907, 1673, 962, 1698, 1046, 1748, 1051, 1768, 1230, 1797, 1500, 1833, 1579, 1855, 1625, 1874, 1694, 1898, 1727, 1954, 1718, 2036, 1712, 2073, 1670, 2083, 1615, 2122, 1599, 2145, 1565, 2174, 1507, 2183, 1483, 2180, 1448, 2173, 1368, 2161, 1337, 2171, 1375, 2192, 1345, 2195, 1303, 2235, 1231, 2261, 1187, 2241, 1172, 2259, 1120, 2275, 1134, 2202, 1140, 2166, 1106, 2170, 1051, 2064, 1013, 2010, 1009, 2030, 1026, 2058, 1016, 2066, 1091, 2194, 1041, 2169, 1036, 2149, 998, 2199, 966, 2285, 946, 2285, 934, 2227, 929, 2279, 877, 2268, 783, 2294, 690, 2286, 652, 2278, 629, 2250, 619, 2251, 606, 2222, 615, 2145, 642, 2016, 579, 2120, 587, 2083, 542, 2043, 490, 1919, 480, 1874, 478, 1856, 489, 1797, 458, 1820, 426, 1772, 394, 1703, 373, 1634, 359, 1587, 412, 1566, 535, 1652, 601, 1700, 628, 1696, 612, 1675], [582, 1642, 607, 1657, 678, 1643, 618, 1638]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [102.0, 1306.0, 428.0, 252.0], 'category_id': 7, 'segmentation': [[254, 1558, 179, 1520, 161, 1507, 193, 1454, 223, 1506, 262, 1446, 283, 1462, 282, 1496, 298, 1471, 330, 1487], [105, 1426, 102, 1383, 124, 1334, 179, 1309, 198, 1306, 180, 1342, 198, 1342, 170, 1383, 149, 1380, 145, 1411], [416, 1387, 482, 1423, 530, 1442, 430, 1438, 411, 1407], [452, 1488, 486, 1512, 529, 1544, 526, 1477]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_13/000022.jpg', 'height': 3120, 'width': 4160, 'image_id': 423, 'annotations': [{'iscrowd': 0, 'bbox': [1652.0, 1762.0, 912.0, 503.0], 'category_id': 9, 'segmentation': [[1652, 1818, 2546, 2265, 2564, 2194, 1699, 1762, 1658, 1791]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [2336.0, 938.0, 708.0, 438.0], 'category_id': 9, 'segmentation': [[2336, 968, 3035, 1376, 3044, 1343, 2363, 938]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [1776.0, 831.0, 93.0, 49.0], 'category_id': 9, 'segmentation': [[1786, 849, 1862, 831, 1869, 848, 1841, 869, 1797, 880, 1776, 867]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [516.0, 781.0, 657.0, 962.0], 'category_id': 4, 'segmentation': [[530, 1559, 730, 1199, 852, 1028, 927, 899, 919, 846, 953, 803, 1022, 781, 1131, 801, 1173, 826, 986, 1290, 988, 1349, 1030, 1415, 837, 1721, 826, 1740, 775, 1743, 687, 1723, 605, 1682, 548, 1640, 516, 1603]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [882.0, 378.0, 2971.0, 1637.0], 'category_id': 7, 'segmentation': [[1007, 1980, 973, 1934, 973, 1904, 907, 1769, 882, 1651, 1030, 1412, 988, 1351, 985, 1288, 1195, 779, 1267, 653, 1309, 653, 1461, 639, 1583, 672, 1669, 711, 1708, 751, 1767, 867, 1839, 992, 1876, 973, 1876, 865, 1846, 813, 1830, 725, 1814, 605, 1831, 558, 1912, 383, 1943, 394, 2114, 378, 2218, 406, 2334, 479, 2367, 507, 2538, 662, 2567, 708, 2616, 801, 2618, 826, 2640, 787, 2678, 747, 2807, 762, 2861, 785, 2848, 854, 2864, 911, 2875, 986, 2885, 1063, 2944, 1087, 3179, 976, 3380, 853, 3532, 796, 3666, 806, 3688, 892, 3785, 840, 3853, 980, 3743, 1117, 3771, 1149, 3814, 1197, 3824, 1244, 3814, 1309, 3680, 1317, 3629, 1326, 3533, 1371, 3436, 1472, 3198, 1612, 3105, 1729, 3012, 1734, 2973, 1624, 2902, 1570, 2860, 1488, 2821, 1382, 2771, 1410, 2743, 1451, 2688, 1433, 2529, 1483, 2473, 1513, 2443, 1626, 2430, 1688, 2392, 1757, 2382, 1808, 2360, 1978, 2226, 2015, 2052, 1928, 2024, 1855, 1931, 1876, 1779, 1911, 1638, 1885, 1392, 1848, 1358, 1803, 1251, 1747, 1238, 1685, 1179, 1623, 1176, 1682, 1124, 1750, 1137, 1822, 1087, 1931]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [2425.0, 1899.0, 408.0, 492.0], 'category_id': 5, 'segmentation': [[2451, 2130, 2502, 2035, 2579, 1949, 2660, 1904, 2727, 1899, 2776, 1952, 2816, 2016, 2833, 2094, 2810, 2208, 2735, 2318, 2642, 2390, 2560, 2391, 2481, 2381, 2429, 2336, 2425, 2221]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [869.0, 2890.0, 604.0, 227.0], 'category_id': 6, 'segmentation': [[869, 3117, 1083, 2935, 1219, 2890, 1303, 2927, 1397, 3012, 1473, 3105]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [2492.0, 2658.0, 614.0, 457.0], 'category_id': 6, 'segmentation': [[2555, 3111, 2492, 3016, 2507, 2801, 2607, 2682, 2710, 2658, 2828, 2669, 2932, 2711, 3042, 2832, 3106, 2946, 3102, 3115]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_13/000038.jpg', 'height': 4160, 'width': 3120, 'image_id': 439, 'annotations': [{'iscrowd': 0, 'bbox': [955.0, 1402.0, 1023.0, 2100.0], 'category_id': 7, 'segmentation': [[1092, 3502, 1065, 3404, 1077, 3390, 1064, 3313, 1035, 3067, 1023, 2948, 980, 2672, 985, 2602, 984, 2519, 955, 2363, 955, 2292, 971, 2157, 1005, 2043, 1056, 1968, 1053, 1924, 1038, 1859, 1049, 1802, 1055, 1776, 1072, 1766, 1097, 1778, 1127, 1727, 1158, 1653, 1228, 1542, 1320, 1415, 1331, 1402, 1369, 1419, 1432, 1461, 1493, 1490, 1519, 1510, 1613, 1620, 1638, 1651, 1681, 1749, 1706, 1817, 1714, 1862, 1706, 1895, 1754, 1945, 1778, 1964, 1813, 1960, 1879, 2001, 1955, 2045, 1968, 2152, 1978, 2241, 1967, 2436, 1959, 2579, 1904, 2681, 1890, 2721, 1844, 2785, 1743, 2836, 1750, 2858, 1851, 2961, 1765, 3037, 1732, 3071, 1713, 3140, 1685, 3240, 1649, 3315, 1614, 3355, 1565, 3399, 1489, 3436, 1412, 3447]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_13/000050.jpg', 'height': 3120, 'width': 4160, 'image_id': 451, 'annotations': [{'iscrowd': 0, 'bbox': [2010.0, 1415.0, 1490.0, 642.0], 'category_id': 6, 'segmentation': [[2010, 1755, 2040, 1476, 2056, 1433, 2069, 1415, 2109, 1416, 3190, 1598, 3228, 1619, 3226, 1650, 3246, 1674, 3269, 1714, 3312, 1734, 3351, 1762, 3437, 1726, 3484, 1761, 3500, 1991, 3454, 2057, 3293, 2032, 3217, 2029, 2067, 1822, 2022, 1805, 2014, 1786]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [2.0, 557.0, 397.0, 569.0], 'category_id': 3, 'segmentation': [[2, 1039, 99, 799, 167, 644, 248, 557, 333, 616, 399, 658, 169, 1126, 44, 1088, 4, 1065]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_13/000070.jpg', 'height': 4160, 'width': 3120, 'image_id': 471, 'annotations': [{'iscrowd': 0, 'bbox': [1467.1702, 1496.3195, 695.0, 996.3332999999998], 'category_id': 8, 'segmentation': [[1493, 2008, 1527, 1786, 1548, 1684, 1590, 1611, 1643, 1559, 1701, 1519, 1766, 1498, 1814, 1497, 1833, 1512, 1896, 1512, 1940, 1496, 1992, 1518, 2046, 1552, 2105, 1619, 2135, 1673, 2159, 1747, 2162, 1866, 2148, 1967, 2119, 2176, 2103, 2264, 2077, 2342, 2035, 2407, 1976, 2455, 1893, 2488, 1845, 2493, 1722, 2482, 1734, 2362, 1799, 2370, 1889, 2360, 1960, 2331, 1993, 2294, 2012, 2242, 2012, 2188, 1983, 2144, 1933, 2123, 1786, 2094, 1688, 2087, 1670, 2072, 1666, 2053, 1666, 1983, 1680, 1970, 1746, 1993, 1780, 2008, 1848, 2015, 1888, 2006, 1956, 1977, 2012, 1920, 2029, 1844, 2040, 1796, 2030, 1763, 1997, 1751, 1966, 1764, 1697, 1708, 1674, 1708, 1655, 1726, 1644, 1751, 1653, 1895, 1665, 1920, 1645, 1942, 1662, 1978, 1662, 2041, 1655, 2071, 1644, 2084, 1615, 2112, 1580, 2153, 1570, 2214, 1593, 2268, 1639, 2313, 1688, 2350, 1729, 2362, 1718, 2487, 1636, 2462, 1588, 2428, 1529, 2376, 1488, 2303, 1468, 2231, 1467, 2167]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_13/000078.jpg', 'height': 4160, 'width': 3120, 'image_id': 479, 'annotations': [{'iscrowd': 0, 'bbox': [312.0, 790.0, 2326.0, 2304.0], 'category_id': 6, 'segmentation': [[728, 1372, 598, 1540, 312, 2294, 494, 2574, 1670, 3062, 1800, 3094, 1832, 3049, 1947, 2908, 2185, 2503, 2348, 2225, 2512, 1904, 2532, 1919, 2498, 2071, 2533, 2069, 2597, 2003, 2596, 1859, 2588, 1806, 2596, 1698, 2638, 1613, 2633, 1575, 2582, 1575, 2627, 1467, 2638, 1371, 2601, 1334, 2441, 1290, 2379, 1384, 2359, 1386, 2392, 1287, 2348, 1274, 2357, 1240, 2318, 1230, 2294, 1175, 2045, 1093, 1822, 1020, 1709, 1081, 1692, 1116, 1350, 920, 1249, 878, 1261, 821, 1217, 790, 1147, 790, 1055, 820, 1021, 794, 1019, 847, 934, 930, 912, 1113, 932, 1138]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [289.0, 1349.0, 2057.0, 1832.0], 'category_id': 7, 'segmentation': [[677, 1349, 852, 1423, 1737, 1830, 1870, 1914, 1954, 1953, 2065, 1967, 2134, 2007, 2127, 2024, 2070, 2052, 2066, 2098, 2107, 2145, 2200, 2189, 2346, 2228, 1947, 2909, 1791, 3100, 1721, 3146, 1673, 3153, 1616, 3181, 1413, 3108, 997, 2954, 947, 2924, 878, 2874, 660, 2754, 351, 2595, 339, 2536, 320, 2448, 300, 2344, 289, 2314]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_13/000080.jpg', 'height': 4160, 'width': 3120, 'image_id': 481, 'annotations': [{'iscrowd': 0, 'bbox': [48.0, 1096.0, 3068.0, 2494.0], 'category_id': 7, 'segmentation': [[105, 1731, 117, 1690, 207, 1558, 313, 1393, 401, 1268, 472, 1176, 501, 1117, 534, 1106, 602, 1096, 670, 1104, 781, 1116, 872, 1137, 1025, 1117, 1102, 1122, 1189, 1127, 1234, 1148, 1702, 1159, 2021, 1187, 2514, 1255, 2821, 1312, 2849, 1333, 2878, 1350, 2949, 1434, 2987, 1546, 3051, 1736, 3060, 1765, 3048, 1802, 2960, 1958, 3079, 2105, 3116, 2158, 3116, 2497, 2995, 2658, 2984, 2695, 2894, 2776, 2827, 2823, 2764, 2861, 2671, 2912, 2531, 3012, 2391, 3064, 2175, 3181, 2024, 3289, 1911, 3342, 1845, 3361, 1787, 3414, 1686, 3481, 1593, 3525, 1489, 3556, 1357, 3578, 1228, 3590, 1174, 3587, 1131, 3566, 1093, 3554, 1071, 3533, 1045, 3528, 988, 3489, 936, 3481, 847, 3441, 783, 3375, 743, 3332, 710, 3279, 659, 3223, 619, 3174, 585, 3109, 552, 3067, 499, 3022, 425, 2957, 408, 2942, 402, 2911, 413, 2877, 429, 2865, 412, 2828, 411, 2803, 424, 2790, 431, 2721, 438, 2689, 465, 2641, 502, 2573, 539, 2466, 565, 2397, 560, 2374, 560, 2361, 501, 2321, 418, 2282, 341, 2231, 282, 2192, 258, 2176, 187, 2117, 160, 2091, 193, 2060, 216, 2063, 238, 2082, 306, 2104, 366, 2123, 424, 2135, 468, 2146, 519, 2138, 551, 2110, 555, 2053, 544, 1938, 541, 1847, 539, 1721, 536, 1689, 540, 1654, 464, 1648, 426, 1647, 326, 1630, 273, 1655, 250, 1664, 197, 1717, 147, 1757, 146, 1792, 150, 1835, 157, 1865, 172, 1873, 175, 1902, 170, 1967, 170, 1998, 183, 2027, 178, 2044, 190, 2060, 156, 2087, 124, 2056, 85, 1990, 58, 1922, 48, 1866, 61, 1871, 63, 1841, 67, 1817, 79, 1774, 88, 1749]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [2945.0, 0.0, 170.0, 240.0], 'category_id': 6, 'segmentation': [[2945, 184, 2970, 144, 2991, 144, 2981, 127, 3013, 96, 3035, 89, 3067, 0, 3115, 1, 3115, 197, 3044, 240, 2967, 212]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_13/000085.jpg', 'height': 4160, 'width': 3120, 'image_id': 486, 'annotations': [{'iscrowd': 0, 'bbox': [706.0, 1378.0, 1708.0, 1179.0], 'category_id': 7, 'segmentation': [[706, 1869, 1058, 2529, 1115, 2510, 1232, 2469, 1302, 2449, 1291, 2512, 1299, 2557, 2104, 2522, 2104, 2245, 2109, 2203, 2363, 2128, 2414, 2119, 2392, 2032, 2326, 1848, 2256, 1643, 2180, 1419, 2172, 1402, 1934, 1475, 1813, 1502, 1671, 1540, 1499, 1476, 1364, 1419, 1316, 1602, 1262, 2015, 1257, 1984, 1277, 1673, 1304, 1399, 1264, 1378, 1169, 1393, 964, 1608, 838, 1738, 769, 1831]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_13/000092.jpg', 'height': 4160, 'width': 3120, 'image_id': 493, 'annotations': [{'iscrowd': 0, 'bbox': [975.5, 367.0, 1063.0, 3586.0], 'category_id': 0, 'segmentation': [[1160, 1007, 1222, 917, 1274, 875, 1356, 807, 1358, 771, 1318, 755, 1304, 712, 1316, 679, 1328, 657, 1336, 515, 1346, 468, 1388, 409, 1428, 387, 1542, 367, 1632, 376, 1698, 396, 1738, 423, 1774, 461, 1780, 503, 1784, 635, 1782, 678, 1798, 710, 1796, 745, 1774, 777, 1744, 791, 1740, 815, 1796, 869, 1860, 925, 1940, 1038, 1998, 1158, 2028, 1220, 2038, 1328, 2028, 1427, 2022, 1781, 2008, 2194, 2004, 2349, 2006, 2426, 2004, 2498, 1978, 2580, 1972, 2636, 1974, 2721, 1978, 3029, 1980, 3297, 1976, 3565, 1960, 3647, 1926, 3722, 1880, 3798, 1834, 3837, 1814, 3833, 1790, 3867, 1740, 3908, 1660, 3936, 1620, 3935, 1586, 3910, 1562, 3912, 1536, 3937, 1498, 3953, 1424, 3950, 1344, 3935, 1296, 3895, 1246, 3907, 1122, 3854, 1092, 3806, 1028, 3723, 982, 3645, 976, 3588, 976, 3530, 982, 3321, 1002, 2975, 1022, 2704, 1034, 2608, 1032, 2574, 1014, 2503, 1002, 2449, 1004, 2370, 1010, 2311, 1016, 2204, 1016, 2042, 1024, 1674, 1032, 1448, 1030, 1296, 1046, 1199, 1104, 1087]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [1330.0, 370.0, 455.0, 263.0], 'category_id': 1, 'segmentation': [[1330, 610, 1367, 585, 1455, 555, 1533, 551, 1633, 557, 1703, 578, 1760, 610, 1785, 633, 1783, 503, 1774, 456, 1730, 417, 1678, 391, 1633, 376, 1559, 370, 1500, 374, 1434, 387, 1388, 400, 1352, 440, 1335, 496]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_13/000093.jpg', 'height': 3120, 'width': 4160, 'image_id': 494, 'annotations': [{'iscrowd': 0, 'bbox': [40.0, 450.0, 3688.0, 1498.0], 'category_id': 0, 'segmentation': [[413, 598, 583, 543, 716, 511, 793, 480, 988, 456, 1137, 450, 1343, 500, 1523, 495, 1570, 516, 1630, 502, 1672, 506, 1688, 518, 1811, 478, 2024, 463, 2645, 547, 2944, 684, 3225, 863, 3313, 940, 3467, 1065, 3505, 1058, 3513, 1045, 3545, 1037, 3597, 1063, 3693, 1081, 3718, 1118, 3728, 1261, 3722, 1357, 3700, 1457, 3657, 1561, 3603, 1571, 3558, 1571, 3522, 1585, 3490, 1590, 3422, 1562, 3319, 1619, 3063, 1787, 2852, 1898, 2720, 1936, 2573, 1948, 1789, 1906, 1152, 1852, 682, 1852, 458, 1813, 249, 1730, 215, 1700, 182, 1636, 126, 1596, 89, 1535, 80, 1465, 44, 1412, 40, 1358, 54, 1188, 54, 1135, 107, 950, 150, 822, 194, 743, 239, 706, 323, 650]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_14/000031.jpg', 'height': 4032, 'width': 3024, 'image_id': 532, 'annotations': [{'iscrowd': 0, 'bbox': [1137.0, 2010.0, 1883.0, 1484.0], 'category_id': 4, 'segmentation': [[1248.0, 2386.0, 1172.0, 2689.0, 1152.0, 2812.0, 1138.0, 2907.0, 1137.0, 2973.0, 1149.0, 3081.0, 1165.0, 3121.0, 1191.0, 3139.0, 1237.0, 3132.0, 1252.0, 3116.0, 1478.0, 3172.0, 1865.0, 3279.0, 2792.0, 3494.0, 3018.0, 3343.0, 3020.0, 2383.0, 2783.0, 2329.0, 2339.0, 2234.0, 1905.0, 2135.0, 1521.0, 2050.0, 1515.0, 2029.0, 1483.0, 2010.0, 1452.0, 2011.0, 1432.0, 2029.0, 1373.0, 2100.0, 1324.0, 2190.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_14/000042.jpg', 'height': 4032, 'width': 3024, 'image_id': 543, 'annotations': [{'iscrowd': 0, 'bbox': [795.0, 1791.0, 718.0, 849.0], 'category_id': 0, 'segmentation': [[1513.0, 2514.0, 1476.0, 2451.0, 1464.0, 2450.0, 1447.0, 2426.0, 1450.0, 2397.0, 1460.0, 2374.0, 1452.0, 2312.0, 1443.0, 2286.0, 1420.0, 2246.0, 1387.0, 2214.0, 1339.0, 2150.0, 1154.0, 1903.0, 1131.0, 1866.0, 1105.0, 1827.0, 1082.0, 1803.0, 1059.0, 1791.0, 1035.0, 1791.0, 983.0, 1821.0, 903.0, 1878.0, 812.0, 1942.0, 795.0, 1961.0, 795.0, 1981.0, 805.0, 2008.0, 834.0, 2049.0, 877.0, 2097.0, 1084.0, 2394.0, 1105.0, 2432.0, 1131.0, 2467.0, 1166.0, 2503.0, 1193.0, 2523.0, 1219.0, 2533.0, 1263.0, 2539.0, 1288.0, 2548.0, 1305.0, 2560.0, 1300.0, 2576.0, 1310.0, 2586.0, 1320.0, 2603.0, 1362.0, 2640.0, 1425.0, 2602.0, 1468.0, 2570.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [1421.0, 2606.0, 197.0, 204.0], 'category_id': 1, 'segmentation': [[1615.0, 2683.0, 1605.0, 2648.0, 1587.0, 2625.0, 1556.0, 2611.0, 1525.0, 2606.0, 1494.0, 2608.0, 1466.0, 2625.0, 1437.0, 2658.0, 1421.0, 2691.0, 1421.0, 2724.0, 1428.0, 2760.0, 1450.0, 2790.0, 1487.0, 2806.0, 1529.0, 2810.0, 1569.0, 2795.0, 1594.0, 2772.0, 1607.0, 2749.0, 1617.0, 2724.0, 1618.0, 2700.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_14/000053.jpg', 'height': 3024, 'width': 4032, 'image_id': 554, 'annotations': [{'iscrowd': 0, 'bbox': [1837.0, 2158.0, 1702.0, 661.0], 'category_id': 6, 'segmentation': [[2881, 2819, 3146, 2812, 3261, 2816, 3439, 2789, 3539, 2759, 3513, 2680, 3442, 2682, 3433, 2709, 3408, 2717, 3332, 2658, 3272, 2560, 3227, 2539, 3173, 2538, 3103, 2491, 3084, 2450, 3106, 2423, 3140, 2421, 3125, 2354, 3044, 2292, 3036, 2261, 2971, 2231, 2877, 2237, 2794, 2236, 2734, 2202, 2657, 2187, 2602, 2199, 2543, 2201, 2502, 2185, 2445, 2184, 2430, 2169, 2368, 2166, 2337, 2192, 2269, 2182, 2217, 2160, 2172, 2158, 2111, 2169, 2012, 2171, 1950, 2191, 1927, 2168, 1855, 2162, 1837, 2178, 1855, 2202, 1920, 2216, 1927, 2262, 1998, 2325, 2072, 2362, 2072, 2390, 2059, 2434, 2077, 2475, 2107, 2502, 2196, 2534, 2230, 2516, 2244, 2456, 2293, 2399, 2337, 2360, 2381, 2349, 2427, 2348, 2462, 2360, 2487, 2387, 2541, 2445, 2617, 2545, 2723, 2634, 2709, 2671, 2772, 2753]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_14/000059.jpg', 'height': 4032, 'width': 3024, 'image_id': 560, 'annotations': [{'iscrowd': 0, 'bbox': [1168.0, 1620.0, 440.0, 547.0], 'category_id': 6, 'segmentation': [[1168.0, 2024.0, 1184.0, 1940.0, 1177.0, 1902.0, 1197.0, 1809.0, 1219.0, 1749.0, 1248.0, 1708.0, 1310.0, 1693.0, 1327.0, 1666.0, 1327.0, 1646.0, 1359.0, 1620.0, 1377.0, 1623.0, 1384.0, 1691.0, 1384.0, 1723.0, 1365.0, 1756.0, 1365.0, 1791.0, 1357.0, 1845.0, 1373.0, 1848.0, 1380.0, 1815.0, 1413.0, 1791.0, 1458.0, 1758.0, 1480.0, 1779.0, 1492.0, 1803.0, 1499.0, 1828.0, 1484.0, 1849.0, 1477.0, 1881.0, 1514.0, 1875.0, 1526.0, 1909.0, 1537.0, 1938.0, 1541.0, 1976.0, 1544.0, 1990.0, 1531.0, 2009.0, 1536.0, 2034.0, 1563.0, 2020.0, 1592.0, 2024.0, 1608.0, 2057.0, 1564.0, 2103.0, 1533.0, 2132.0, 1507.0, 2167.0, 1449.0, 2136.0, 1452.0, 2103.0, 1421.0, 2121.0, 1421.0, 2099.0, 1397.0, 2023.0, 1359.0, 2027.0, 1333.0, 2035.0, 1351.0, 2047.0, 1376.0, 2041.0, 1367.0, 2068.0, 1380.0, 2104.0, 1346.0, 2096.0, 1242.0, 2059.0, 1225.0, 2059.0, 1194.0, 2038.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_14/000069.jpg', 'height': 4032, 'width': 3024, 'image_id': 570, 'annotations': [{'iscrowd': 0, 'bbox': [25.0, 1561.0, 2315.0, 1374.0], 'category_id': 2, 'segmentation': [[32.0, 1969.0, 151.0, 1962.0, 326.0, 1955.0, 374.0, 1935.0, 378.0, 1952.0, 388.0, 1986.0, 417.0, 1977.0, 517.0, 1947.0, 555.0, 1946.0, 591.0, 1941.0, 631.0, 1937.0, 673.0, 1911.0, 720.0, 1897.0, 792.0, 1898.0, 831.0, 1898.0, 860.0, 1912.0, 873.0, 1960.0, 860.0, 1989.0, 860.0, 2013.0, 845.0, 2052.0, 847.0, 2090.0, 842.0, 2107.0, 866.0, 2215.0, 874.0, 2247.0, 901.0, 2277.0, 934.0, 2366.0, 963.0, 2488.0, 963.0, 2516.0, 985.0, 2545.0, 978.0, 2562.0, 982.0, 2602.0, 994.0, 2650.0, 1024.0, 2660.0, 1049.0, 2652.0, 1055.0, 2637.0, 1085.0, 2604.0, 1111.0, 2570.0, 1120.0, 2501.0, 1138.0, 2501.0, 1144.0, 2520.0, 1159.0, 2534.0, 1160.0, 2547.0, 1179.0, 2580.0, 1197.0, 2585.0, 1220.0, 2573.0, 1245.0, 2573.0, 1257.0, 2604.0, 1300.0, 2607.0, 1304.0, 2617.0, 1288.0, 2671.0, 1276.0, 2655.0, 1245.0, 2644.0, 1159.0, 2679.0, 1124.0, 2687.0, 1132.0, 2716.0, 1133.0, 2747.0, 1145.0, 2772.0, 1410.0, 2935.0, 1440.0, 2898.0, 1459.0, 2811.0, 1483.0, 2798.0, 1554.0, 2717.0, 1597.0, 2704.0, 1656.0, 2701.0, 1722.0, 2687.0, 1789.0, 2682.0, 1927.0, 2695.0, 1973.0, 2693.0, 2040.0, 2663.0, 2078.0, 2644.0, 2107.0, 2621.0, 2153.0, 2569.0, 2175.0, 2558.0, 2191.0, 2533.0, 2194.0, 2465.0, 2194.0, 2409.0, 2265.0, 2433.0, 2302.0, 2407.0, 2329.0, 2381.0, 2340.0, 2337.0, 2328.0, 2303.0, 2306.0, 2289.0, 2292.0, 2294.0, 2293.0, 2261.0, 2269.0, 2257.0, 2237.0, 2267.0, 2224.0, 2278.0, 2202.0, 2275.0, 2193.0, 2265.0, 2161.0, 2267.0, 2139.0, 2265.0, 2114.0, 2269.0, 2093.0, 2269.0, 2109.0, 2342.0, 2118.0, 2390.0, 2128.0, 2411.0, 2104.0, 2419.0, 2076.0, 2409.0, 2093.0, 2390.0, 2091.0, 2341.0, 2079.0, 2326.0, 2048.0, 2320.0, 2053.0, 2303.0, 2070.0, 2300.0, 2078.0, 2254.0, 2024.0, 2101.0, 2005.0, 2064.0, 2001.0, 2047.0, 1983.0, 2044.0, 1965.0, 2015.0, 1965.0, 2038.0, 1978.0, 2093.0, 1978.0, 2113.0, 1963.0, 2145.0, 1942.0, 2171.0, 1913.0, 2200.0, 1878.0, 2219.0, 1859.0, 2228.0, 1846.0, 2242.0, 1820.0, 2239.0, 1855.0, 2147.0, 1896.0, 2002.0, 1894.0, 1942.0, 1862.0, 1896.0, 1827.0, 1874.0, 1756.0, 1856.0, 1704.0, 1844.0, 1672.0, 1855.0, 1633.0, 1870.0, 1615.0, 1902.0, 1598.0, 1940.0, 1675.0, 1961.0, 1702.0, 1943.0, 1735.0, 1943.0, 1770.0, 1955.0, 1802.0, 1972.0, 1813.0, 2015.0, 1797.0, 2036.0, 1775.0, 2078.0, 1789.0, 2105.0, 1776.0, 2165.0, 1758.0, 2201.0, 1743.0, 2193.0, 1757.0, 2133.0, 1735.0, 2116.0, 1650.0, 2094.0, 1632.0, 2110.0, 1613.0, 2110.0, 1623.0, 2078.0, 1639.0, 2054.0, 1663.0, 2047.0, 1709.0, 2058.0, 1752.0, 2072.0, 1770.0, 2076.0, 1794.0, 2036.0, 1778.0, 2037.0, 1678.0, 2009.0, 1667.0, 1993.0, 1673.0, 1966.0, 1596.0, 1942.0, 1568.0, 2017.0, 1561.0, 1999.0, 1537.0, 1993.0, 1519.0, 1984.0, 1493.0, 1990.0, 1436.0, 2001.0, 1403.0, 1994.0, 1363.0, 2004.0, 1332.0, 1997.0, 1302.0, 1944.0, 1242.0, 1892.0, 1179.0, 1802.0, 1095.0, 1700.0, 1061.0, 1682.0, 999.0, 1684.0, 945.0, 1648.0, 924.0, 1656.0, 905.0, 1651.0, 862.0, 1621.0, 826.0, 1590.0, 778.0, 1568.0, 746.0, 1561.0, 701.0, 1569.0, 657.0, 1596.0, 637.0, 1611.0, 621.0, 1637.0, 524.0, 1687.0, 456.0, 1709.0, 431.0, 1729.0, 396.0, 1769.0, 354.0, 1812.0, 340.0, 1825.0, 300.0, 1840.0, 245.0, 1845.0, 151.0, 1849.0, 99.0, 1856.0, 54.0, 1901.0, 31.0, 1938.0, 25.0, 1959.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [1536.0, 1844.0, 364.0, 472.0], 'category_id': 8, 'segmentation': [[1629.0, 1872.0, 1609.0, 1905.0, 1538.0, 2105.0, 1536.0, 2156.0, 1540.0, 2202.0, 1558.0, 2236.0, 1599.0, 2276.0, 1646.0, 2309.0, 1684.0, 2316.0, 1724.0, 2316.0, 1764.0, 2303.0, 1811.0, 2258.0, 1828.0, 2223.0, 1900.0, 2002.0, 1896.0, 1936.0, 1865.0, 1898.0, 1823.0, 1869.0, 1758.0, 1856.0, 1706.0, 1844.0, 1671.0, 1854.0, 1642.0, 1867.0, 1691.0, 1948.0, 1720.0, 1943.0, 1751.0, 1945.0, 1799.0, 1968.0, 1812.0, 1995.0, 1809.0, 2016.0, 1801.0, 2035.0, 1780.0, 2078.0, 1790.0, 2112.0, 1778.0, 2166.0, 1760.0, 2200.0, 1743.0, 2192.0, 1755.0, 2133.0, 1739.0, 2117.0, 1651.0, 2091.0, 1635.0, 2098.0, 1628.0, 2113.0, 1613.0, 2110.0, 1621.0, 2080.0, 1635.0, 2054.0, 1666.0, 2046.0, 1706.0, 2055.0, 1751.0, 2072.0, 1770.0, 2077.0, 1794.0, 2034.0, 1780.0, 2035.0, 1680.0, 2010.0, 1668.0, 1992.0, 1672.0, 1967.0, 1685.0, 1951.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_14/000070.jpg', 'height': 4032, 'width': 3024, 'image_id': 571, 'annotations': [{'iscrowd': 0, 'bbox': [1060.0, 2167.0, 940.0, 135.0], 'category_id': 6, 'segmentation': [[1091.0, 2301.0, 1361.0, 2285.0, 1571.0, 2276.0, 1720.0, 2274.0, 1977.0, 2262.0, 2000.0, 2229.0, 1999.0, 2192.0, 1971.0, 2167.0, 1717.0, 2174.0, 1619.0, 2180.0, 1060.0, 2204.0, 1064.0, 2302.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_14/000077.jpg', 'height': 4032, 'width': 3024, 'image_id': 578, 'annotations': [{'iscrowd': 0, 'bbox': [1131.0, 2248.0, 1273.0, 806.0], 'category_id': 0, 'segmentation': [[1438.0, 2611.0, 1385.0, 2681.0, 1320.0, 2738.0, 1196.0, 2792.0, 1131.0, 2827.0, 1199.0, 2993.0, 1219.0, 3054.0, 1269.0, 3041.0, 1328.0, 3015.0, 1417.0, 2987.0, 1485.0, 2978.0, 1556.0, 2978.0, 1659.0, 3000.0, 1746.0, 3016.0, 1812.0, 3008.0, 1867.0, 2981.0, 2033.0, 2913.0, 2229.0, 2831.0, 2271.0, 2774.0, 2321.0, 2737.0, 2375.0, 2721.0, 2404.0, 2649.0, 2385.0, 2550.0, 2236.0, 2261.0, 2189.0, 2248.0, 2098.0, 2272.0, 2039.0, 2284.0, 1990.0, 2285.0, 1878.0, 2327.0, 1704.0, 2396.0, 1591.0, 2447.0, 1528.0, 2479.0, 1502.0, 2512.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [991.0, 2828.5, 227.0, 288.0], 'category_id': 1, 'segmentation': [[1129.0, 2828.0, 991.0, 2890.0, 1083.0, 3116.0, 1218.0, 3052.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_14/000087.jpg', 'height': 4032, 'width': 3024, 'image_id': 588, 'annotations': [{'iscrowd': 0, 'bbox': [1262.0, 1886.0, 509.0, 579.0], 'category_id': 7, 'segmentation': [[1734.0, 2074.0, 1684.0, 2103.0, 1680.0, 2149.0, 1700.0, 2189.0, 1708.0, 2244.0, 1717.0, 2275.0, 1697.0, 2369.0, 1714.0, 2431.0, 1684.0, 2450.0, 1661.0, 2444.0, 1661.0, 2459.0, 1594.0, 2465.0, 1527.0, 2462.0, 1500.0, 2457.0, 1447.0, 2419.0, 1433.0, 2403.0, 1403.0, 2386.0, 1286.0, 2336.0, 1262.0, 2294.0, 1284.0, 2276.0, 1363.0, 2228.0, 1414.0, 2210.0, 1441.0, 2183.0, 1494.0, 2152.0, 1525.0, 2154.0, 1499.0, 2085.0, 1540.0, 2059.0, 1519.0, 2027.0, 1525.0, 1965.0, 1545.0, 1933.0, 1593.0, 1898.0, 1639.0, 1886.0, 1703.0, 1893.0, 1745.0, 1921.0, 1767.0, 1956.0, 1771.0, 2014.0, 1752.0, 2055.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [3.0, 2343.0, 638.0, 406.0], 'category_id': 9, 'segmentation': [[3.0, 2678.0, 423.0, 2433.0, 625.0, 2343.0, 641.0, 2384.0, 475.0, 2480.0, 99.0, 2696.0, 3.0, 2749.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_14/000096.jpg', 'height': 4032, 'width': 3024, 'image_id': 597, 'annotations': [{'iscrowd': 0, 'bbox': [934.0, 3067.0, 906.0, 587.0], 'category_id': 0, 'segmentation': [[981.0, 3067.0, 1098.0, 3113.0, 1283.0, 3195.0, 1410.0, 3202.0, 1476.0, 3230.0, 1734.0, 3354.0, 1840.0, 3420.0, 1819.0, 3476.0, 1807.0, 3532.0, 1743.0, 3654.0, 1708.0, 3644.0, 1297.0, 3430.0, 1250.0, 3354.0, 1235.0, 3335.0, 1173.0, 3303.0, 1141.0, 3281.0, 940.0, 3167.0, 934.0, 3134.0, 956.0, 3092.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_15/000004.jpg', 'height': 4032, 'width': 3024, 'image_id': 605, 'annotations': [{'iscrowd': 0, 'bbox': [1435.0, 1924.0, 550.0, 322.0], 'category_id': 0, 'segmentation': [[1544.0, 1938.0, 1797.0, 2048.0, 1818.0, 2074.0, 1824.0, 2093.0, 1931.0, 2150.0, 1985.0, 2176.0, 1981.0, 2212.0, 1960.0, 2246.0, 1904.0, 2232.0, 1796.0, 2193.0, 1763.0, 2199.0, 1730.0, 2209.0, 1435.0, 2081.0, 1435.0, 2023.0, 1473.0, 1951.0, 1506.0, 1924.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [100.0, 988.0, 222.0, 110.0], 'category_id': 6, 'segmentation': [[211.0, 1007.0, 100.0, 1058.0, 125.0, 1091.0, 216.0, 1064.0, 264.0, 1091.0, 322.0, 1098.0, 303.0, 988.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_15/000017.jpg', 'height': 3264, 'width': 2448, 'image_id': 618, 'annotations': [{'iscrowd': 0, 'bbox': [1206.0, 1590.0, 233.0, 684.0], 'category_id': 0, 'segmentation': [[1327.0, 1590.0, 1367.0, 1598.0, 1395.0, 1609.0, 1417.0, 1654.0, 1439.0, 2090.0, 1432.0, 2120.0, 1405.0, 2169.0, 1377.0, 2201.0, 1374.0, 2225.0, 1380.0, 2233.0, 1380.0, 2267.0, 1357.0, 2273.0, 1328.0, 2274.0, 1295.0, 2272.0, 1280.0, 2269.0, 1282.0, 2226.0, 1287.0, 2209.0, 1253.0, 2181.0, 1221.0, 2124.0, 1209.0, 2084.0, 1215.0, 2046.0, 1206.0, 1649.0, 1228.0, 1610.0, 1251.0, 1602.0, 1283.0, 1593.0, 1309.0, 1590.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [1279.0, 2232.0, 101.0, 43.0], 'category_id': 1, 'segmentation': [[1282.0, 2238.0, 1323.0, 2232.0, 1380.0, 2238.0, 1380.0, 2268.0, 1349.0, 2275.0, 1321.0, 2274.0, 1285.0, 2272.0, 1279.0, 2259.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [460.0, 1733.0, 224.0, 321.0], 'category_id': 9, 'segmentation': [[476.0, 1733.0, 537.0, 1817.0, 628.0, 1951.0, 684.0, 2039.0, 672.0, 2054.0, 662.0, 2036.0, 565.0, 1886.0, 547.0, 1861.0, 460.0, 1744.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [433.0, 678.0, 56.0, 29.0], 'category_id': 3, 'segmentation': [[441.0, 678.0, 489.0, 697.0, 473.0, 707.0, 433.0, 691.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_15/000019.jpg', 'height': 1536, 'width': 2048, 'image_id': 620, 'annotations': [{'iscrowd': 0, 'bbox': [365.0, 233.0, 108.0, 44.0], 'category_id': 6, 'segmentation': [[366, 261, 470, 233, 473, 268, 410, 277, 387, 269, 365, 275]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [1111.0, 317.0, 65.0, 40.0], 'category_id': 4, 'segmentation': [[1117, 329, 1162, 317, 1173, 323, 1176, 346, 1169, 357, 1113, 356, 1111, 343]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [588.0, 770.0, 194.0, 82.0], 'category_id': 0, 'segmentation': [[609, 770, 646, 778, 669, 783, 712, 788, 742, 791, 771, 812, 782, 818, 777, 835, 763, 835, 730, 852, 647, 837, 591, 832, 588, 815, 588, 793]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [92.0, 160.0, 49.0, 58.0], 'category_id': 6, 'segmentation': [[101, 184, 92, 165, 113, 160, 130, 184, 141, 194, 103, 218]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [798.0, 662.0, 92.0, 73.0], 'category_id': 0, 'segmentation': [[798, 714, 806, 680, 842, 669, 858, 665, 874, 662, 888, 667, 886, 692, 890, 717, 852, 735, 817, 733]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [756.0, 664.0, 80.0, 70.0], 'category_id': 4, 'segmentation': [[756, 710, 796, 674, 821, 664, 836, 671, 806, 682, 798, 713, 819, 734, 797, 733]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [1122.0, 936.0, 67.0, 61.0], 'category_id': 6, 'segmentation': [[1129, 997, 1122, 944, 1185, 936, 1189, 964]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [1845.0, 892.0, 202.0, 117.0], 'category_id': 0, 'segmentation': [[1874, 892, 1901, 903, 1897, 977, 1869, 977, 1845, 947, 1846, 923, 1860, 896], [1931, 910, 1984, 922, 2034, 923, 2047, 952, 2045, 999, 2015, 1009, 1936, 995, 1914, 996, 1925, 942]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [831.0, 858.0, 132.0, 18.0], 'category_id': 6, 'segmentation': [[831, 858, 879, 864, 883, 874, 857, 876], [902, 863, 963, 861, 960, 874, 908, 874]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [968.0, 150.0, 97.0, 22.0], 'category_id': 6, 'segmentation': [[968, 156, 1065, 150, 1018, 168, 968, 172]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [1693.0, 436.0, 96.0, 46.0], 'category_id': 6, 'segmentation': [[1693, 445, 1748, 436, 1761, 444, 1789, 460, 1785, 476, 1732, 482, 1715, 469]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_15/000020.jpg', 'height': 1536, 'width': 2048, 'image_id': 621, 'annotations': [{'iscrowd': 0, 'bbox': [980.0, 734.0, 262.0, 333.0], 'category_id': 2, 'segmentation': [[1139, 1067, 1172, 1060, 1193, 1044, 1242, 995, 1240, 959, 1231, 920, 1240, 888, 1240, 842, 1203, 786, 1142, 837, 1106, 864, 1068, 907, 1011, 979, 1004, 993, 1029, 1018, 1052, 1037, 1072, 1053, 1102, 1066], [980, 928, 988, 859, 1049, 786, 1091, 739, 1123, 734, 1160, 740, 1153, 757, 1091, 838, 1069, 861]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [1091.0, 967.0, 52.0, 80.0], 'category_id': 8, 'segmentation': [[1093, 999, 1098, 979, 1111, 967, 1126, 967, 1138, 977, 1143, 987, 1138, 1030, 1131, 1045, 1112, 1047, 1093, 1040, 1102, 1033, 1116, 1040, 1128, 1035, 1127, 1022, 1113, 1016, 1103, 1019, 1102, 1031, 1091, 1034, 1092, 1015]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [39.0, 433.0, 203.0, 91.0], 'category_id': 6, 'segmentation': [[84, 437, 100, 433, 233, 449, 242, 461, 230, 473], [39, 494, 54, 475, 181, 514, 169, 524]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_15/000073.jpg', 'height': 2048, 'width': 1536, 'image_id': 674, 'annotations': [{'iscrowd': 0, 'bbox': [670.0, 915.0, 298.0, 307.0], 'category_id': 4, 'segmentation': [[670, 1085, 679, 1013, 725, 945, 796, 915, 858, 919, 922, 958, 968, 1010, 966, 1033, 945, 1037, 921, 1027, 880, 1015, 862, 1019, 875, 1062, 899, 1087, 896, 1121, 920, 1122, 907, 1152, 924, 1185, 909, 1196, 889, 1186, 866, 1216, 824, 1222, 831, 1184, 826, 1133, 812, 1103, 805, 1149, 782, 1187, 764, 1187, 749, 1168, 725, 1132]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [0.0, 1.0, 533.0, 604.0], 'category_id': 7, 'segmentation': [[1, 169, 0, 1, 153, 3, 151, 26, 155, 49], [2, 233, 173, 98, 212, 137, 232, 176, 230, 287, 165, 328, 142, 357, 151, 376, 179, 388, 233, 383, 225, 432, 194, 437, 142, 393, 69, 347, 35, 336, 42, 362, 86, 434, 109, 452, 40, 466, 29, 457, 58, 440, 70, 418, 24, 418, 20, 405, 29, 379, 4, 362], [461, 136, 462, 183, 453, 213, 486, 272, 533, 224, 505, 98, 497, 69], [66, 483, 60, 509, 85, 547, 115, 557, 160, 605, 180, 593, 144, 576, 102, 534, 133, 526, 176, 530, 194, 538, 206, 528, 193, 511, 140, 482, 122, 470]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [0.0, 1154.0, 301.0, 352.0], 'category_id': 7, 'segmentation': [[77, 1181, 105, 1227, 86, 1277, 49, 1313, 31, 1319, 8, 1267, 0, 1257, 2, 1481, 58, 1461, 79, 1462, 69, 1496, 123, 1506, 158, 1505, 157, 1491, 161, 1474, 164, 1451, 184, 1459, 204, 1428, 211, 1410, 193, 1310, 163, 1154, 118, 1174], [219, 1331, 240, 1439, 270, 1437, 281, 1423, 301, 1380, 275, 1341, 237, 1302, 257, 1299, 235, 1281], [195, 1247, 206, 1308, 220, 1273, 209, 1262]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_2/000032.JPG', 'height': 3264, 'width': 2448, 'image_id': 712, 'annotations': [{'iscrowd': 0, 'bbox': [616.0, 1355.0, 988.0, 1211.0], 'category_id': 6, 'segmentation': [[1220.0, 1365.0, 1310.0, 1392.0, 1317.0, 1390.0, 1326.0, 1385.0, 1331.0, 1374.0, 1340.0, 1365.0, 1347.0, 1358.0, 1360.0, 1355.0, 1370.0, 1358.0, 1431.0, 1382.0, 1434.0, 1389.0, 1438.0, 1397.0, 1435.0, 1406.0, 1432.0, 1420.0, 1438.0, 1432.0, 1451.0, 1440.0, 1509.0, 1458.0, 1540.0, 1471.0, 1559.0, 1484.0, 1576.0, 1498.0, 1589.0, 1519.0, 1597.0, 1538.0, 1602.0, 1558.0, 1604.0, 1578.0, 1602.0, 1600.0, 1581.0, 1661.0, 1526.0, 1816.0, 1504.0, 1883.0, 1485.0, 1938.0, 1468.0, 1987.0, 1450.0, 2015.0, 1436.0, 2033.0, 1422.0, 2059.0, 1412.0, 2080.0, 1407.0, 2102.0, 1408.0, 2138.0, 1405.0, 2154.0, 1402.0, 2178.0, 1388.0, 2201.0, 1329.0, 2304.0, 1247.0, 2458.0, 1227.0, 2496.0, 1206.0, 2518.0, 1181.0, 2537.0, 1148.0, 2555.0, 1128.0, 2562.0, 1099.0, 2566.0, 1074.0, 2566.0, 1057.0, 2564.0, 1029.0, 2556.0, 1010.0, 2547.0, 991.0, 2547.0, 971.0, 2554.0, 948.0, 2557.0, 922.0, 2551.0, 903.0, 2546.0, 856.0, 2521.0, 728.0, 2459.0, 713.0, 2448.0, 699.0, 2429.0, 693.0, 2411.0, 692.0, 2402.0, 689.0, 2394.0, 676.0, 2385.0, 661.0, 2376.0, 640.0, 2356.0, 625.0, 2334.0, 617.0, 2305.0, 616.0, 2294.0, 719.0, 2107.0, 746.0, 2076.0, 792.0, 2015.0, 852.0, 1949.0, 884.0, 1925.0, 907.0, 1912.0, 934.0, 1897.0, 942.0, 1884.0, 950.0, 1871.0, 956.0, 1849.0, 958.0, 1818.0, 968.0, 1775.0, 988.0, 1723.0, 1023.0, 1627.0, 1072.0, 1482.0, 1098.0, 1420.0, 1126.0, 1389.0, 1156.0, 1372.0, 1197.0, 1364.0, 1220.0, 1365.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [579.0, 1947.0, 835.0, 584.0], 'category_id': 6, 'segmentation': [[579.0, 2253.0, 592.0, 2236.0, 607.0, 2222.0, 611.0, 2216.0, 618.0, 2206.0, 627.0, 2194.0, 639.0, 2183.0, 653.0, 2172.0, 661.0, 2164.0, 669.0, 2154.0, 679.0, 2146.0, 688.0, 2140.0, 698.0, 2129.0, 703.0, 2123.0, 712.0, 2114.0, 732.0, 2106.0, 759.0, 2102.0, 775.0, 2104.0, 791.0, 2108.0, 801.0, 2112.0, 813.0, 2122.0, 818.0, 2120.0, 865.0, 2105.0, 910.0, 2093.0, 982.0, 2078.0, 987.0, 2067.0, 974.0, 2050.0, 966.0, 2042.0, 958.0, 2034.0, 1005.0, 1996.0, 1009.0, 1991.0, 1007.0, 1983.0, 1023.0, 1970.0, 1038.0, 1969.0, 1058.0, 1963.0, 1099.0, 1956.0, 1119.0, 1955.0, 1149.0, 1957.0, 1189.0, 1954.0, 1202.0, 1956.0, 1218.0, 1948.0, 1244.0, 1947.0, 1264.0, 1951.0, 1283.0, 1956.0, 1291.0, 1964.0, 1305.0, 1963.0, 1317.0, 1969.0, 1321.0, 1972.0, 1327.0, 1981.0, 1340.0, 1987.0, 1358.0, 1985.0, 1371.0, 1992.0, 1384.0, 2005.0, 1405.0, 2025.0, 1409.0, 2031.0, 1409.0, 2037.0, 1408.0, 2039.0, 1404.0, 2035.0, 1401.0, 2037.0, 1402.0, 2042.0, 1405.0, 2051.0, 1406.0, 2059.0, 1411.0, 2070.0, 1414.0, 2076.0, 1407.0, 2076.0, 1405.0, 2083.0, 1405.0, 2090.0, 1406.0, 2101.0, 1407.0, 2111.0, 1401.0, 2120.0, 1401.0, 2130.0, 1400.0, 2138.0, 1394.0, 2145.0, 1393.0, 2151.0, 1387.0, 2158.0, 1385.0, 2162.0, 1379.0, 2167.0, 1379.0, 2175.0, 1374.0, 2182.0, 1369.0, 2190.0, 1367.0, 2201.0, 1365.0, 2210.0, 1362.0, 2218.0, 1339.0, 2253.0, 1315.0, 2299.0, 1305.0, 2315.0, 1294.0, 2331.0, 1289.0, 2343.0, 1278.0, 2352.0, 1271.0, 2371.0, 1264.0, 2387.0, 1249.0, 2397.0, 1240.0, 2393.0, 1233.0, 2397.0, 1226.0, 2403.0, 1209.0, 2425.0, 1200.0, 2431.0, 1190.0, 2437.0, 1181.0, 2448.0, 1172.0, 2457.0, 1158.0, 2466.0, 1150.0, 2473.0, 1144.0, 2483.0, 1140.0, 2493.0, 1142.0, 2506.0, 1134.0, 2516.0, 1126.0, 2526.0, 1121.0, 2531.0, 1101.0, 2531.0, 1084.0, 2531.0, 1063.0, 2528.0, 1042.0, 2524.0, 1028.0, 2520.0, 998.0, 2506.0, 964.0, 2493.0, 937.0, 2479.0, 873.0, 2451.0, 830.0, 2435.0, 789.0, 2412.0, 694.0, 2351.0, 584.0, 2267.0, 590.0, 2260.0, 579.0, 2253.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_2/000058.JPG', 'height': 3264, 'width': 2448, 'image_id': 736, 'annotations': [{'iscrowd': 0, 'bbox': [1076.0, 1168.0, 287.0, 332.0], 'category_id': 7, 'segmentation': [[1076.0, 1384.0, 1080.0, 1376.0, 1087.0, 1368.0, 1096.0, 1362.0, 1105.0, 1355.0, 1115.0, 1351.0, 1119.0, 1348.0, 1129.0, 1330.0, 1131.0, 1324.0, 1137.0, 1310.0, 1150.0, 1285.0, 1171.0, 1244.0, 1184.0, 1219.0, 1187.0, 1212.0, 1190.0, 1196.0, 1193.0, 1179.0, 1196.0, 1176.0, 1198.0, 1174.0, 1214.0, 1174.0, 1235.0, 1172.0, 1266.0, 1170.0, 1281.0, 1168.0, 1286.0, 1170.0, 1286.0, 1173.0, 1302.0, 1174.0, 1319.0, 1184.0, 1344.0, 1195.0, 1355.0, 1201.0, 1363.0, 1205.0, 1359.0, 1217.0, 1348.0, 1250.0, 1340.0, 1272.0, 1322.0, 1316.0, 1307.0, 1355.0, 1304.0, 1364.0, 1313.0, 1485.0, 1310.0, 1491.0, 1300.0, 1494.0, 1284.0, 1497.0, 1268.0, 1500.0, 1253.0, 1500.0, 1247.0, 1499.0, 1245.0, 1493.0, 1247.0, 1482.0, 1246.0, 1466.0, 1246.0, 1455.0, 1244.0, 1445.0, 1249.0, 1428.0, 1250.0, 1409.0, 1233.0, 1417.0, 1212.0, 1425.0, 1201.0, 1434.0, 1197.0, 1435.0, 1191.0, 1441.0, 1180.0, 1452.0, 1170.0, 1457.0, 1165.0, 1456.0, 1156.0, 1446.0, 1148.0, 1443.0, 1137.0, 1435.0, 1134.0, 1432.0, 1122.0, 1423.0, 1104.0, 1409.0, 1076.0, 1384.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_2/000065.JPG', 'height': 3264, 'width': 2448, 'image_id': 743, 'annotations': [{'iscrowd': 0, 'bbox': [664.0, 1616.0, 587.0, 268.0], 'category_id': 7, 'segmentation': [[681.0, 1616.0, 871.0, 1680.0, 940.0, 1717.0, 1072.0, 1781.0, 1251.0, 1858.0, 1240.0, 1884.0, 1134.0, 1830.0, 1042.0, 1793.0, 948.0, 1745.0, 847.0, 1708.0, 664.0, 1638.0, 681.0, 1616.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [1172.0, 692.0, 38.0, 40.0], 'category_id': 3, 'segmentation': [[1210.0, 710.0, 1172.0, 732.0, 1172.0, 710.0, 1206.0, 692.0, 1210.0, 710.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_2/000077.JPG', 'height': 3264, 'width': 2448, 'image_id': 754, 'annotations': [{'iscrowd': 0, 'bbox': [298.0, 534.0, 1325.0, 1869.0], 'category_id': 6, 'segmentation': [[1491.0, 1654.0, 1400.0, 1740.0, 1320.0, 1833.0, 1324.0, 1898.0, 1316.0, 2025.0, 1326.0, 2052.0, 1331.0, 2081.0, 1334.0, 2096.0, 1347.0, 2110.0, 1347.0, 2149.0, 1360.0, 2199.0, 1316.0, 2259.0, 1329.0, 2299.0, 1346.0, 2336.0, 1194.0, 2403.0, 827.0, 2328.0, 678.0, 2272.0, 521.0, 2242.0, 298.0, 2199.0, 386.0, 2156.0, 438.0, 2130.0, 477.0, 2094.0, 491.0, 2039.0, 476.0, 2000.0, 418.0, 1977.0, 340.0, 1962.0, 400.0, 1784.0, 451.0, 1794.0, 476.0, 1787.0, 500.0, 1760.0, 508.0, 1740.0, 508.0, 1709.0, 489.0, 1685.0, 458.0, 1647.0, 473.0, 1617.0, 512.0, 1548.0, 549.0, 1499.0, 571.0, 1450.0, 611.0, 1416.0, 646.0, 1367.0, 670.0, 1332.0, 691.0, 1296.0, 718.0, 1255.0, 753.0, 1188.0, 770.0, 1130.0, 782.0, 1095.0, 793.0, 1062.0, 811.0, 1011.0, 835.0, 968.0, 893.0, 885.0, 897.0, 865.0, 900.0, 854.0, 909.0, 828.0, 918.0, 809.0, 920.0, 801.0, 930.0, 773.0, 943.0, 753.0, 948.0, 741.0, 962.0, 715.0, 985.0, 688.0, 1009.0, 663.0, 1034.0, 637.0, 1056.0, 611.0, 1074.0, 597.0, 1109.0, 583.0, 1130.0, 581.0, 1144.0, 569.0, 1158.0, 557.0, 1190.0, 548.0, 1210.0, 544.0, 1214.0, 535.0, 1220.0, 534.0, 1222.0, 538.0, 1241.0, 539.0, 1241.0, 548.0, 1250.0, 563.0, 1250.0, 573.0, 1249.0, 580.0, 1261.0, 584.0, 1249.0, 608.0, 1269.0, 609.0, 1273.0, 625.0, 1287.0, 628.0, 1293.0, 640.0, 1310.0, 646.0, 1317.0, 659.0, 1336.0, 671.0, 1350.0, 680.0, 1355.0, 691.0, 1371.0, 701.0, 1376.0, 720.0, 1389.0, 727.0, 1390.0, 743.0, 1402.0, 758.0, 1402.0, 774.0, 1412.0, 784.0, 1411.0, 806.0, 1426.0, 817.0, 1436.0, 833.0, 1450.0, 850.0, 1448.0, 862.0, 1457.0, 870.0, 1470.0, 868.0, 1468.0, 879.0, 1478.0, 892.0, 1483.0, 902.0, 1499.0, 901.0, 1518.0, 912.0, 1512.0, 923.0, 1531.0, 922.0, 1529.0, 931.0, 1542.0, 933.0, 1538.0, 939.0, 1557.0, 934.0, 1552.0, 940.0, 1560.0, 941.0, 1559.0, 947.0, 1564.0, 947.0, 1565.0, 953.0, 1575.0, 953.0, 1573.0, 962.0, 1581.0, 963.0, 1579.0, 975.0, 1584.0, 982.0, 1581.0, 991.0, 1585.0, 986.0, 1580.0, 1003.0, 1588.0, 1003.0, 1585.0, 1010.0, 1591.0, 1011.0, 1589.0, 1017.0, 1600.0, 1037.0, 1602.0, 1053.0, 1598.0, 1066.0, 1594.0, 1096.0, 1585.0, 1118.0, 1599.0, 1128.0, 1604.0, 1145.0, 1611.0, 1177.0, 1614.0, 1189.0, 1616.0, 1200.0, 1615.0, 1218.0, 1623.0, 1233.0, 1619.0, 1259.0, 1617.0, 1284.0, 1615.0, 1294.0, 1618.0, 1308.0, 1612.0, 1340.0, 1611.0, 1364.0, 1612.0, 1378.0, 1610.0, 1398.0, 1603.0, 1434.0, 1599.0, 1470.0, 1579.0, 1508.0, 1491.0, 1654.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [828.0, 2949.0, 309.0, 313.0], 'category_id': 6, 'segmentation': [[828.0, 3262.0, 885.0, 3095.0, 904.0, 3024.0, 970.0, 2962.0, 1013.0, 2949.0, 1056.0, 2960.0, 1102.0, 3007.0, 1125.0, 3071.0, 1137.0, 3219.0, 1137.0, 3259.0, 828.0, 3262.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_2/000079.JPG', 'height': 3264, 'width': 2448, 'image_id': 755, 'annotations': [{'iscrowd': 0, 'bbox': [772.0, 2276.0, 244.0, 296.0], 'category_id': 6, 'segmentation': [[808.0, 2544.0, 824.0, 2553.0, 924.0, 2572.0, 928.0, 2556.0, 936.0, 2550.0, 949.0, 2550.0, 977.0, 2395.0, 970.0, 2387.0, 976.0, 2358.0, 966.0, 2356.0, 966.0, 2348.0, 963.0, 2347.0, 971.0, 2315.0, 978.0, 2309.0, 974.0, 2335.0, 986.0, 2335.0, 989.0, 2330.0, 993.0, 2332.0, 1003.0, 2329.0, 1010.0, 2303.0, 1013.0, 2304.0, 1016.0, 2280.0, 1010.0, 2276.0, 866.0, 2286.0, 862.0, 2281.0, 854.0, 2290.0, 851.0, 2298.0, 841.0, 2305.0, 832.0, 2319.0, 772.0, 2341.0, 775.0, 2342.0, 804.0, 2335.0, 809.0, 2339.0, 827.0, 2333.0, 818.0, 2347.0, 827.0, 2354.0, 822.0, 2364.0, 813.0, 2354.0, 798.0, 2427.0, 803.0, 2447.0, 799.0, 2478.0, 794.0, 2501.0, 786.0, 2518.0, 792.0, 2524.0, 798.0, 2522.0, 808.0, 2531.0, 808.0, 2544.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [1083.0, 1614.0, 200.0, 200.0], 'category_id': 0, 'segmentation': [[1083.0, 1740.0, 1087.0, 1750.0, 1099.0, 1776.0, 1120.0, 1796.0, 1133.0, 1802.0, 1177.0, 1814.0, 1197.0, 1798.0, 1228.0, 1770.0, 1244.0, 1749.0, 1254.0, 1729.0, 1269.0, 1690.0, 1275.0, 1679.0, 1280.0, 1679.0, 1283.0, 1666.0, 1277.0, 1661.0, 1277.0, 1655.0, 1265.0, 1643.0, 1260.0, 1629.0, 1244.0, 1617.0, 1231.0, 1614.0, 1219.0, 1620.0, 1217.0, 1626.0, 1200.0, 1634.0, 1168.0, 1648.0, 1162.0, 1646.0, 1119.0, 1691.0, 1106.0, 1706.0, 1092.0, 1727.0, 1083.0, 1740.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [1573.0, 2869.0, 372.0, 395.0], 'category_id': 6, 'segmentation': [[1573.0, 3264.0, 1608.0, 3202.0, 1628.0, 3135.0, 1685.0, 3010.0, 1751.0, 2900.0, 1802.0, 2869.0, 1871.0, 2883.0, 1922.0, 2942.0, 1943.0, 3022.0, 1945.0, 3113.0, 1938.0, 3200.0, 1932.0, 3244.0, 1925.0, 3264.0, 1573.0, 3264.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [606.0, 2938.0, 28.0, 22.0], 'category_id': 3, 'segmentation': [[634.0, 2950.0, 608.0, 2960.0, 606.0, 2946.0, 634.0, 2938.0, 634.0, 2950.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [1548.0, 358.0, 58.0, 44.0], 'category_id': 3, 'segmentation': [[1558.0, 402.0, 1570.0, 394.0, 1606.0, 364.0, 1602.0, 360.0, 1584.0, 358.0, 1548.0, 392.0, 1558.0, 402.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_2/000088.JPG', 'height': 3264, 'width': 2448, 'image_id': 765, 'annotations': [{'iscrowd': 0, 'bbox': [1488.0, 1407.0, 444.0, 466.0], 'category_id': 0, 'segmentation': [[1778.0, 1429.0, 1800.0, 1418.0, 1822.0, 1407.0, 1841.0, 1425.0, 1882.0, 1429.0, 1891.0, 1439.0, 1891.0, 1450.0, 1905.0, 1458.0, 1917.0, 1457.0, 1923.0, 1462.0, 1928.0, 1473.0, 1932.0, 1484.0, 1930.0, 1503.0, 1923.0, 1524.0, 1910.0, 1541.0, 1892.0, 1571.0, 1818.0, 1667.0, 1769.0, 1729.0, 1717.0, 1766.0, 1661.0, 1803.0, 1627.0, 1823.0, 1608.0, 1835.0, 1599.0, 1837.0, 1596.0, 1833.0, 1587.0, 1843.0, 1588.0, 1848.0, 1583.0, 1852.0, 1581.0, 1854.0, 1578.0, 1863.0, 1552.0, 1873.0, 1543.0, 1871.0, 1535.0, 1862.0, 1520.0, 1848.0, 1507.0, 1833.0, 1490.0, 1812.0, 1488.0, 1807.0, 1497.0, 1787.0, 1500.0, 1784.0, 1506.0, 1781.0, 1508.0, 1774.0, 1517.0, 1769.0, 1520.0, 1761.0, 1519.0, 1757.0, 1538.0, 1712.0, 1568.0, 1643.0, 1605.0, 1600.0, 1656.0, 1542.0, 1718.0, 1476.0, 1772.0, 1429.0, 1778.0, 1429.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [1488.0, 1786.0, 92.0, 87.0], 'category_id': 1, 'segmentation': [[1500.0, 1786.0, 1517.0, 1792.0, 1532.0, 1800.0, 1544.0, 1811.0, 1558.0, 1826.0, 1573.0, 1843.0, 1579.0, 1856.0, 1580.0, 1861.0, 1552.0, 1873.0, 1544.0, 1871.0, 1532.0, 1859.0, 1519.0, 1848.0, 1489.0, 1814.0, 1488.0, 1806.0, 1500.0, 1786.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_3/IMG_4978.JPG', 'height': 3264, 'width': 2448, 'image_id': 780, 'annotations': [{'iscrowd': 0, 'bbox': [1088.0, 1045.0, 320.0, 593.0], 'category_id': 2, 'segmentation': [[1088.0, 1503.0, 1090.0, 1525.0, 1096.0, 1544.0, 1103.0, 1555.0, 1111.0, 1574.0, 1124.0, 1591.0, 1147.0, 1610.0, 1173.0, 1624.0, 1200.0, 1634.0, 1229.0, 1638.0, 1255.0, 1636.0, 1284.0, 1627.0, 1307.0, 1611.0, 1322.0, 1594.0, 1336.0, 1573.0, 1361.0, 1548.0, 1370.0, 1523.0, 1385.0, 1478.0, 1397.0, 1431.0, 1408.0, 1346.0, 1407.0, 1318.0, 1403.0, 1292.0, 1403.0, 1272.0, 1384.0, 1100.0, 1382.0, 1082.0, 1359.0, 1061.0, 1338.0, 1051.0, 1311.0, 1046.0, 1286.0, 1045.0, 1262.0, 1050.0, 1236.0, 1060.0, 1217.0, 1075.0, 1200.0, 1087.0, 1164.0, 1135.0, 1162.0, 1165.0, 1160.0, 1196.0, 1161.0, 1232.0, 1155.0, 1265.0, 1153.0, 1331.0, 1152.0, 1346.0, 1128.0, 1393.0, 1105.0, 1441.0, 1092.0, 1469.0, 1089.0, 1485.0, 1088.0, 1503.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [1182.0, 1512.0, 79.0, 58.0], 'category_id': 8, 'segmentation': [[1260.0, 1538.0, 1261.0, 1546.0, 1254.0, 1553.0, 1241.0, 1565.0, 1235.0, 1569.0, 1218.0, 1570.0, 1205.0, 1566.0, 1194.0, 1560.0, 1187.0, 1554.0, 1182.0, 1545.0, 1183.0, 1538.0, 1189.0, 1529.0, 1200.0, 1518.0, 1208.0, 1512.0, 1221.0, 1513.0, 1232.0, 1516.0, 1241.0, 1521.0, 1251.0, 1527.0, 1260.0, 1538.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_3/IMG_4992.JPG', 'height': 3264, 'width': 2448, 'image_id': 782, 'annotations': [{'iscrowd': 0, 'bbox': [997.0, 897.0, 453.0, 491.0], 'category_id': 0, 'segmentation': [[1186.0, 972.0, 1210.0, 1001.0, 1224.0, 1019.0, 1231.0, 1029.0, 1247.0, 1046.0, 1258.0, 1054.0, 1261.0, 1054.0, 1266.0, 1057.0, 1275.0, 1063.0, 1285.0, 1064.0, 1326.0, 1100.0, 1392.0, 1152.0, 1405.0, 1216.0, 1418.0, 1310.0, 1418.0, 1314.0, 1424.0, 1320.0, 1426.0, 1320.0, 1430.0, 1320.0, 1433.0, 1320.0, 1434.0, 1321.0, 1436.0, 1326.0, 1437.0, 1330.0, 1438.0, 1335.0, 1443.0, 1343.0, 1450.0, 1349.0, 1449.0, 1355.0, 1445.0, 1361.0, 1440.0, 1368.0, 1433.0, 1376.0, 1426.0, 1384.0, 1421.0, 1388.0, 1415.0, 1388.0, 1412.0, 1386.0, 1408.0, 1384.0, 1404.0, 1382.0, 1403.0, 1379.0, 1398.0, 1377.0, 1394.0, 1377.0, 1385.0, 1370.0, 1373.0, 1357.0, 1358.0, 1357.0, 1341.0, 1355.0, 1319.0, 1352.0, 1297.0, 1347.0, 1272.0, 1342.0, 1267.0, 1341.0, 1262.0, 1341.0, 1260.0, 1325.0, 1254.0, 1322.0, 1249.0, 1322.0, 1242.0, 1321.0, 1238.0, 1322.0, 1232.0, 1320.0, 1223.0, 1324.0, 1214.0, 1318.0, 1222.0, 1314.0, 1224.0, 1309.0, 1230.0, 1309.0, 1232.0, 1303.0, 1235.0, 1298.0, 1236.0, 1290.0, 1231.0, 1287.0, 1231.0, 1282.0, 1227.0, 1279.0, 1222.0, 1278.0, 1221.0, 1272.0, 1208.0, 1272.0, 1203.0, 1274.0, 1197.0, 1278.0, 1193.0, 1286.0, 1195.0, 1295.0, 1190.0, 1295.0, 1183.0, 1289.0, 1189.0, 1285.0, 1194.0, 1278.0, 1197.0, 1270.0, 1196.0, 1261.0, 1192.0, 1256.0, 1182.0, 1255.0, 1173.0, 1257.0, 1167.0, 1263.0, 1166.0, 1269.0, 1156.0, 1259.0, 1152.0, 1254.0, 1152.0, 1248.0, 1149.0, 1246.0, 1148.0, 1240.0, 1144.0, 1235.0, 1137.0, 1208.0, 1134.0, 1192.0, 1136.0, 1186.0, 1135.0, 1181.0, 1133.0, 1176.0, 1131.0, 1172.0, 1127.0, 1170.0, 1123.0, 1168.0, 1118.0, 1163.0, 1100.0, 1142.0, 1094.0, 1133.0, 1071.0, 1111.0, 1053.0, 1094.0, 1038.0, 1075.0, 1026.0, 1058.0, 1016.0, 1043.0, 1010.0, 1035.0, 1005.0, 1021.0, 1003.0, 1014.0, 1001.0, 1005.0, 1001.0, 997.0, 998.0, 992.0, 997.0, 979.0, 998.0, 971.0, 999.0, 965.0, 1001.0, 960.0, 1004.0, 953.0, 1006.0, 948.0, 1017.0, 934.0, 1022.0, 927.0, 1024.0, 924.0, 1035.0, 913.0, 1041.0, 908.0, 1050.0, 908.0, 1053.0, 906.0, 1057.0, 901.0, 1066.0, 897.0, 1081.0, 898.0, 1085.0, 900.0, 1090.0, 898.0, 1097.0, 899.0, 1110.0, 909.0, 1115.0, 911.0, 1125.0, 917.0, 1135.0, 922.0, 1144.0, 927.0, 1151.0, 938.0, 1165.0, 953.0, 1168.0, 957.0, 1186.0, 972.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [1173.0, 687.0, 53.0, 48.0], 'category_id': 1, 'segmentation': [[1179.0, 729.0, 1183.0, 733.0, 1188.0, 734.0, 1197.0, 735.0, 1208.0, 732.0, 1216.0, 727.0, 1223.0, 721.0, 1226.0, 712.0, 1224.0, 703.0, 1221.0, 695.0, 1217.0, 688.0, 1210.0, 687.0, 1199.0, 687.0, 1192.0, 689.0, 1184.0, 691.0, 1178.0, 696.0, 1174.0, 699.0, 1173.0, 707.0, 1174.0, 715.0, 1176.0, 725.0, 1179.0, 729.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_3/IMG_5049.JPG', 'height': 3264, 'width': 2448, 'image_id': 799, 'annotations': [{'iscrowd': 0, 'bbox': [145.0, 286.0, 1433.0, 2103.0], 'category_id': 7, 'segmentation': [[743.0, 872.0, 754.0, 827.0, 754.0, 743.0, 754.0, 649.0, 771.0, 561.0, 832.0, 595.0, 865.0, 618.0, 874.0, 601.0, 884.0, 535.0, 895.0, 482.0, 926.0, 430.0, 902.0, 435.0, 836.0, 348.0, 846.0, 303.0, 911.0, 286.0, 963.0, 317.0, 1052.0, 359.0, 1132.0, 449.0, 1207.0, 548.0, 1140.0, 676.0, 1207.0, 841.0, 1228.0, 1005.0, 1307.0, 1088.0, 1394.0, 1176.0, 1416.0, 1252.0, 1431.0, 1287.0, 1476.0, 1326.0, 1528.0, 1376.0, 1557.0, 1432.0, 1578.0, 1525.0, 1576.0, 1608.0, 1557.0, 1625.0, 1538.0, 1679.0, 1533.0, 1763.0, 1511.0, 1801.0, 1486.0, 1806.0, 1486.0, 1851.0, 1514.0, 1870.0, 1478.0, 1912.0, 1469.0, 1934.0, 1459.0, 1954.0, 1443.0, 1967.0, 1422.0, 1988.0, 1403.0, 1996.0, 1377.0, 1994.0, 1353.0, 2000.0, 1323.0, 2006.0, 1277.0, 1990.0, 1176.0, 2033.0, 1085.0, 2074.0, 997.0, 2105.0, 936.0, 2114.0, 860.0, 2153.0, 801.0, 2157.0, 658.0, 2188.0, 664.0, 2262.0, 654.0, 2289.0, 643.0, 2336.0, 623.0, 2356.0, 587.0, 2382.0, 540.0, 2389.0, 517.0, 2382.0, 475.0, 2276.0, 396.0, 2249.0, 365.0, 2236.0, 346.0, 2234.0, 321.0, 2223.0, 302.0, 2206.0, 315.0, 2179.0, 311.0, 2110.0, 309.0, 2076.0, 298.0, 2062.0, 184.0, 2005.0, 145.0, 1941.0, 161.0, 1919.0, 159.0, 1828.0, 172.0, 1832.0, 179.0, 1808.0, 302.0, 1713.0, 372.0, 1634.0, 422.0, 1580.0, 478.0, 1517.0, 550.0, 1404.0, 743.0, 872.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_3/IMG_4854.JPG', 'height': 2448, 'width': 3264, 'image_id': 811, 'annotations': [{'iscrowd': 0, 'bbox': [1793.0, 978.0, 392.0, 406.0], 'category_id': 4, 'segmentation': [[1929.0, 1382.0, 1898.0, 1325.0, 1837.0, 1199.0, 1801.0, 1126.0, 1797.0, 1122.0, 1793.0, 1121.0, 1800.0, 1109.0, 1810.0, 1097.0, 1837.0, 1076.0, 1826.0, 1070.0, 1823.0, 1063.0, 1818.0, 1056.0, 1819.0, 1051.0, 1882.0, 1025.0, 1933.0, 1005.0, 1969.0, 978.0, 2044.0, 1050.0, 2180.0, 1188.0, 2185.0, 1201.0, 2166.0, 1220.0, 2132.0, 1255.0, 2123.0, 1262.0, 2125.0, 1267.0, 2050.0, 1317.0, 2027.0, 1333.0, 2008.0, 1345.0, 1985.0, 1361.0, 1959.0, 1374.0, 1940.0, 1380.0, 1932.0, 1384.0, 1929.0, 1382.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_3/IMG_4878.JPG', 'height': 2448, 'width': 3264, 'image_id': 824, 'annotations': [{'iscrowd': 0, 'bbox': [576.0, 30.0, 1507.0, 840.0], 'category_id': 6, 'segmentation': [[929.0, 870.0, 1785.0, 739.0, 2083.0, 662.0, 1985.0, 34.0, 1968.0, 30.0, 1356.0, 126.0, 1279.0, 139.0, 1166.0, 163.0, 961.0, 224.0, 957.0, 273.0, 881.0, 289.0, 844.0, 288.0, 806.0, 282.0, 754.0, 270.0, 682.0, 250.0, 613.0, 225.0, 621.0, 191.0, 612.0, 185.0, 584.0, 189.0, 576.0, 201.0, 583.0, 243.0, 686.0, 851.0, 742.0, 859.0, 929.0, 870.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [825.0, 1188.0, 1624.0, 1141.0], 'category_id': 7, 'segmentation': [[867.0, 1837.0, 849.0, 1794.0, 849.0, 1731.0, 844.0, 1700.0, 843.0, 1611.0, 831.0, 1568.0, 825.0, 1482.0, 910.0, 1481.0, 1061.0, 1452.0, 1094.0, 1433.0, 1149.0, 1418.0, 1414.0, 1321.0, 1693.0, 1206.0, 1789.0, 1198.0, 2174.0, 1188.0, 2270.0, 1200.0, 2302.0, 1211.0, 2325.0, 1225.0, 2329.0, 1242.0, 2354.0, 1248.0, 2409.0, 1240.0, 2415.0, 1279.0, 2424.0, 1443.0, 2432.0, 1610.0, 2449.0, 1715.0, 2447.0, 1789.0, 2445.0, 2044.0, 2430.0, 2065.0, 2400.0, 2113.0, 2351.0, 2135.0, 2332.0, 2134.0, 2304.0, 2116.0, 2271.0, 2103.0, 2012.0, 2225.0, 1868.0, 2299.0, 1842.0, 2297.0, 1722.0, 2282.0, 1595.0, 2258.0, 1482.0, 2218.0, 1439.0, 2210.0, 1359.0, 2215.0, 1342.0, 2269.0, 1308.0, 2289.0, 1245.0, 2314.0, 1195.0, 2329.0, 1158.0, 2325.0, 1176.0, 2289.0, 1194.0, 2207.0, 1156.0, 2154.0, 1077.0, 2048.0, 1052.0, 2024.0, 1030.0, 2009.0, 1020.0, 1968.0, 998.0, 1929.0, 963.0, 1896.0, 913.0, 1866.0, 867.0, 1837.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_3/IMG_4913.JPG', 'height': 3264, 'width': 2448, 'image_id': 838, 'annotations': [{'iscrowd': 0, 'bbox': [488.0, 457.0, 1755.0, 1094.0], 'category_id': 7, 'segmentation': [[532.0, 1423.0, 581.0, 1407.0, 637.0, 1411.0, 796.0, 1430.0, 918.0, 1444.0, 955.0, 1444.0, 1061.0, 1440.0, 1190.0, 1440.0, 1409.0, 1439.0, 1430.0, 1440.0, 1464.0, 1451.0, 1518.0, 1472.0, 1610.0, 1498.0, 1729.0, 1526.0, 1770.0, 1530.0, 1793.0, 1534.0, 1820.0, 1534.0, 1863.0, 1551.0, 1907.0, 1551.0, 1977.0, 1543.0, 2027.0, 1528.0, 2064.0, 1514.0, 2091.0, 1505.0, 2113.0, 1493.0, 2142.0, 1477.0, 2161.0, 1454.0, 2179.0, 1432.0, 2190.0, 1416.0, 2207.0, 1394.0, 2223.0, 1391.0, 2235.0, 1383.0, 2222.0, 1376.0, 2216.0, 1371.0, 2225.0, 1344.0, 2228.0, 1286.0, 2233.0, 1253.0, 2229.0, 1208.0, 2243.0, 1147.0, 2242.0, 1107.0, 2229.0, 1086.0, 2207.0, 1068.0, 2200.0, 1047.0, 2168.0, 1029.0, 2138.0, 1011.0, 2086.0, 983.0, 2084.0, 968.0, 2065.0, 922.0, 2035.0, 870.0, 2009.0, 843.0, 2003.0, 825.0, 1974.0, 811.0, 1934.0, 786.0, 1925.0, 786.0, 1910.0, 773.0, 1887.0, 767.0, 1864.0, 764.0, 1835.0, 757.0, 1783.0, 743.0, 1733.0, 724.0, 1693.0, 707.0, 1679.0, 697.0, 1626.0, 678.0, 1572.0, 668.0, 1538.0, 662.0, 1527.0, 656.0, 1415.0, 641.0, 1392.0, 620.0, 1366.0, 588.0, 1364.0, 569.0, 1331.0, 554.0, 1289.0, 547.0, 1215.0, 529.0, 1178.0, 523.0, 1151.0, 514.0, 1110.0, 513.0, 1075.0, 499.0, 957.0, 534.0, 854.0, 511.0, 833.0, 514.0, 816.0, 507.0, 763.0, 472.0, 633.0, 457.0, 553.0, 457.0, 526.0, 466.0, 513.0, 532.0, 506.0, 554.0, 526.0, 656.0, 537.0, 740.0, 546.0, 762.0, 557.0, 779.0, 528.0, 798.0, 509.0, 830.0, 497.0, 879.0, 497.0, 923.0, 511.0, 971.0, 503.0, 1057.0, 497.0, 1131.0, 491.0, 1179.0, 488.0, 1228.0, 493.0, 1281.0, 509.0, 1334.0, 522.0, 1405.0, 532.0, 1423.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [108.0, 1582.0, 578.0, 451.0], 'category_id': 5, 'segmentation': [[210.0, 1666.0, 255.0, 1636.0, 320.0, 1606.0, 374.0, 1595.0, 445.0, 1582.0, 493.0, 1583.0, 568.0, 1598.0, 605.0, 1616.0, 647.0, 1656.0, 669.0, 1689.0, 682.0, 1739.0, 686.0, 1800.0, 662.0, 1864.0, 637.0, 1901.0, 584.0, 1949.0, 543.0, 1980.0, 491.0, 2008.0, 448.0, 2022.0, 389.0, 2033.0, 333.0, 2033.0, 280.0, 2031.0, 220.0, 2011.0, 175.0, 1981.0, 121.0, 1911.0, 108.0, 1869.0, 114.0, 1801.0, 123.0, 1770.0, 160.0, 1721.0, 210.0, 1666.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [1413.0, 1673.0, 492.0, 401.0], 'category_id': 5, 'segmentation': [[1430.0, 1942.0, 1458.0, 1980.0, 1496.0, 2015.0, 1545.0, 2045.0, 1589.0, 2060.0, 1650.0, 2071.0, 1687.0, 2074.0, 1716.0, 2066.0, 1736.0, 2044.0, 1753.0, 2021.0, 1768.0, 2005.0, 1798.0, 1988.0, 1824.0, 1973.0, 1852.0, 1961.0, 1881.0, 1951.0, 1889.0, 1949.0, 1904.0, 1916.0, 1905.0, 1869.0, 1893.0, 1822.0, 1861.0, 1774.0, 1829.0, 1740.0, 1790.0, 1714.0, 1753.0, 1695.0, 1718.0, 1681.0, 1666.0, 1674.0, 1618.0, 1673.0, 1566.0, 1682.0, 1531.0, 1697.0, 1503.0, 1713.0, 1470.0, 1736.0, 1442.0, 1765.0, 1424.0, 1802.0, 1413.0, 1852.0, 1417.0, 1899.0, 1430.0, 1942.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [712.0, 1799.0, 733.0, 894.0], 'category_id': 6, 'segmentation': [[724.0, 2293.0, 776.0, 2463.0, 800.0, 2526.0, 842.0, 2580.0, 881.0, 2616.0, 938.0, 2654.0, 1018.0, 2682.0, 1096.0, 2693.0, 1157.0, 2686.0, 1231.0, 2657.0, 1299.0, 2620.0, 1347.0, 2572.0, 1403.0, 2496.0, 1429.0, 2423.0, 1436.0, 2353.0, 1445.0, 2226.0, 1444.0, 2124.0, 1429.0, 2063.0, 1412.0, 2030.0, 1401.0, 1995.0, 1387.0, 1947.0, 1345.0, 1896.0, 1297.0, 1854.0, 1263.0, 1831.0, 1233.0, 1816.0, 1186.0, 1808.0, 1134.0, 1800.0, 1087.0, 1799.0, 999.0, 1808.0, 943.0, 1822.0, 881.0, 1855.0, 830.0, 1891.0, 785.0, 1935.0, 752.0, 1975.0, 739.0, 2018.0, 719.0, 2080.0, 719.0, 2138.0, 712.0, 2184.0, 715.0, 2234.0, 724.0, 2293.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [1555.0, 1937.0, 861.0, 1048.0], 'category_id': 6, 'segmentation': [[1594.0, 2262.0, 1555.0, 2589.0, 1565.0, 2667.0, 1587.0, 2740.0, 1634.0, 2814.0, 1684.0, 2876.0, 1750.0, 2928.0, 1811.0, 2957.0, 1875.0, 2973.0, 1937.0, 2985.0, 2029.0, 2978.0, 2080.0, 2964.0, 2152.0, 2920.0, 2203.0, 2867.0, 2230.0, 2831.0, 2269.0, 2752.0, 2318.0, 2675.0, 2365.0, 2601.0, 2402.0, 2530.0, 2416.0, 2428.0, 2407.0, 2351.0, 2392.0, 2301.0, 2383.0, 2235.0, 2369.0, 2185.0, 2347.0, 2139.0, 2312.0, 2093.0, 2274.0, 2057.0, 2226.0, 2018.0, 2157.0, 1977.0, 2091.0, 1954.0, 2048.0, 1943.0, 1973.0, 1937.0, 1911.0, 1945.0, 1871.0, 1955.0, 1836.0, 1967.0, 1803.0, 1984.0, 1758.0, 2014.0, 1737.0, 2043.0, 1723.0, 2062.0, 1702.0, 2077.0, 1671.0, 2103.0, 1649.0, 2130.0, 1629.0, 2162.0, 1607.0, 2212.0, 1594.0, 2262.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_3/IMG_4939.JPG', 'height': 3264, 'width': 2448, 'image_id': 852, 'annotations': [{'iscrowd': 0, 'bbox': [686.0, 21.0, 869.0, 1032.0], 'category_id': 4, 'segmentation': [[1496.0, 574.0, 1407.0, 1053.0, 1209.0, 1009.0, 911.0, 952.0, 790.0, 650.0, 726.0, 576.0, 694.0, 488.0, 686.0, 416.0, 689.0, 374.0, 701.0, 323.0, 720.0, 283.0, 742.0, 245.0, 783.0, 170.0, 865.0, 101.0, 928.0, 71.0, 993.0, 47.0, 1098.0, 21.0, 1204.0, 21.0, 1287.0, 29.0, 1374.0, 64.0, 1442.0, 116.0, 1484.0, 180.0, 1493.0, 201.0, 1522.0, 251.0, 1541.0, 328.0, 1555.0, 397.0, 1543.0, 473.0, 1521.0, 540.0, 1496.0, 574.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [686.0, 19.0, 863.0, 725.0], 'category_id': 5, 'segmentation': [[742.0, 595.0, 829.0, 669.0, 931.0, 714.0, 1074.0, 744.0, 1206.0, 731.0, 1364.0, 674.0, 1478.0, 596.0, 1519.0, 537.0, 1549.0, 423.0, 1544.0, 328.0, 1516.0, 234.0, 1486.0, 196.0, 1473.0, 156.0, 1417.0, 92.0, 1343.0, 48.0, 1283.0, 29.0, 1212.0, 23.0, 1108.0, 19.0, 1039.0, 35.0, 991.0, 49.0, 909.0, 78.0, 871.0, 99.0, 838.0, 121.0, 783.0, 173.0, 755.0, 217.0, 736.0, 256.0, 716.0, 284.0, 708.0, 311.0, 696.0, 341.0, 687.0, 385.0, 686.0, 421.0, 696.0, 499.0, 721.0, 564.0, 742.0, 595.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [0.0, 923.0, 2097.0, 2336.0], 'category_id': 6, 'segmentation': [[651.0, 1084.0, 658.0, 1493.0, 524.0, 1686.0, 422.0, 1863.0, 396.0, 1908.0, 354.0, 1937.0, 312.0, 2018.0, 254.0, 2179.0, 201.0, 2240.0, 117.0, 2369.0, 84.0, 2438.0, 41.0, 2546.0, 0.0, 2635.0, 2.0, 2860.0, 115.0, 2889.0, 217.0, 2915.0, 259.0, 2920.0, 368.0, 2909.0, 449.0, 2895.0, 500.0, 2879.0, 599.0, 2840.0, 676.0, 2809.0, 767.0, 2786.0, 875.0, 2869.0, 931.0, 2924.0, 947.0, 2932.0, 1017.0, 3051.0, 1167.0, 3259.0, 1430.0, 3254.0, 1515.0, 3077.0, 1584.0, 2920.0, 1664.0, 2712.0, 1692.0, 2668.0, 1763.0, 2583.0, 1787.0, 2540.0, 1802.0, 2455.0, 1895.0, 2130.0, 2000.0, 1764.0, 2046.0, 1528.0, 2075.0, 1375.0, 2097.0, 1227.0, 2086.0, 1189.0, 2049.0, 1178.0, 2042.0, 1128.0, 1999.0, 1162.0, 1467.0, 1072.0, 1206.0, 1006.0, 1062.0, 986.0, 907.0, 954.0, 827.0, 934.0, 749.0, 923.0, 701.0, 934.0, 664.0, 952.0, 652.0, 975.0, 651.0, 1015.0, 651.0, 1084.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_3/IMG_4966.JPG', 'height': 2448, 'width': 3264, 'image_id': 858, 'annotations': [{'iscrowd': 0, 'bbox': [1258.0, 1269.0, 218.0, 209.0], 'category_id': 7, 'segmentation': [[1294.0, 1478.0, 1339.0, 1477.0, 1370.0, 1476.0, 1409.0, 1476.0, 1443.0, 1477.0, 1476.0, 1475.0, 1474.0, 1470.0, 1475.0, 1465.0, 1474.0, 1459.0, 1475.0, 1456.0, 1476.0, 1432.0, 1471.0, 1404.0, 1464.0, 1370.0, 1464.0, 1361.0, 1459.0, 1348.0, 1459.0, 1337.0, 1459.0, 1329.0, 1456.0, 1310.0, 1456.0, 1306.0, 1454.0, 1285.0, 1453.0, 1273.0, 1448.0, 1271.0, 1435.0, 1273.0, 1419.0, 1281.0, 1399.0, 1296.0, 1376.0, 1281.0, 1364.0, 1269.0, 1348.0, 1281.0, 1333.0, 1290.0, 1330.0, 1294.0, 1329.0, 1301.0, 1326.0, 1309.0, 1325.0, 1317.0, 1322.0, 1317.0, 1320.0, 1312.0, 1312.0, 1315.0, 1305.0, 1317.0, 1295.0, 1321.0, 1288.0, 1322.0, 1283.0, 1322.0, 1274.0, 1332.0, 1268.0, 1334.0, 1258.0, 1333.0, 1259.0, 1341.0, 1265.0, 1349.0, 1272.0, 1353.0, 1267.0, 1361.0, 1266.0, 1366.0, 1265.0, 1376.0, 1265.0, 1386.0, 1266.0, 1388.0, 1283.0, 1389.0, 1289.0, 1388.0, 1289.0, 1404.0, 1282.0, 1405.0, 1275.0, 1404.0, 1262.0, 1400.0, 1264.0, 1415.0, 1266.0, 1426.0, 1268.0, 1436.0, 1273.0, 1445.0, 1279.0, 1453.0, 1284.0, 1457.0, 1286.0, 1466.0, 1286.0, 1473.0, 1294.0, 1478.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [1830.0, 1744.0, 39.0, 11.0], 'category_id': 6, 'segmentation': [[1830.0, 1755.0, 1856.0, 1754.0, 1860.0, 1750.0, 1869.0, 1749.0, 1853.0, 1744.0, 1836.0, 1746.0, 1830.0, 1748.0, 1830.0, 1755.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [1879.0, 1493.0, 35.0, 8.0], 'category_id': 6, 'segmentation': [[1879.0, 1493.0, 1914.0, 1497.0, 1913.0, 1501.0, 1894.0, 1499.0, 1879.0, 1493.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [1895.0, 1479.0, 14.0, 6.0], 'category_id': 6, 'segmentation': [[1895.0, 1479.0, 1909.0, 1480.0, 1908.0, 1485.0, 1897.0, 1483.0, 1895.0, 1479.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_3/IMG_4950.JPG', 'height': 2607, 'width': 2448, 'image_id': 864, 'annotations': [{'iscrowd': 0, 'bbox': [239.0, 565.0, 316.0, 197.0], 'category_id': 6, 'segmentation': [[341.0, 757.0, 310.0, 760.0, 239.0, 758.0, 250.0, 618.0, 246.0, 594.0, 548.0, 565.0, 555.0, 589.0, 549.0, 596.0, 546.0, 762.0, 426.0, 756.0, 401.0, 756.0, 380.0, 762.0, 341.0, 757.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [904.0, 988.0, 319.0, 330.0], 'category_id': 6, 'segmentation': [[906.0, 1096.0, 904.0, 1084.0, 949.0, 1050.0, 961.0, 1047.0, 996.0, 1049.0, 1020.0, 1048.0, 1051.0, 1033.0, 1078.0, 1020.0, 1117.0, 999.0, 1134.0, 988.0, 1145.0, 1011.0, 1163.0, 1055.0, 1178.0, 1089.0, 1211.0, 1093.0, 1204.0, 1113.0, 1207.0, 1133.0, 1213.0, 1146.0, 1221.0, 1153.0, 1223.0, 1168.0, 1192.0, 1184.0, 1127.0, 1188.0, 1144.0, 1216.0, 1149.0, 1236.0, 1141.0, 1263.0, 1155.0, 1269.0, 1191.0, 1292.0, 1192.0, 1318.0, 1175.0, 1311.0, 1161.0, 1308.0, 1099.0, 1251.0, 1092.0, 1239.0, 1080.0, 1257.0, 1067.0, 1271.0, 1058.0, 1270.0, 1046.0, 1262.0, 1039.0, 1247.0, 1041.0, 1229.0, 1042.0, 1220.0, 1009.0, 1190.0, 970.0, 1186.0, 947.0, 1182.0, 929.0, 1178.0, 917.0, 1094.0, 906.0, 1096.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [717.0, 1093.0, 444.0, 450.0], 'category_id': 7, 'segmentation': [[799.0, 1543.0, 769.0, 1510.0, 753.0, 1478.0, 741.0, 1427.0, 733.0, 1375.0, 729.0, 1331.0, 717.0, 1287.0, 737.0, 1256.0, 777.0, 1210.0, 808.0, 1170.0, 847.0, 1142.0, 880.0, 1116.0, 916.0, 1093.0, 928.0, 1179.0, 1012.0, 1193.0, 1037.0, 1218.0, 1042.0, 1259.0, 1060.0, 1272.0, 1073.0, 1266.0, 1099.0, 1251.0, 1161.0, 1306.0, 1161.0, 1318.0, 1150.0, 1333.0, 1145.0, 1345.0, 1011.0, 1435.0, 910.0, 1501.0, 799.0, 1543.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_4/000010.JPG', 'height': 3264, 'width': 2448, 'image_id': 887, 'annotations': [{'iscrowd': 0, 'bbox': [528.0, 1457.0, 417.0, 256.0], 'category_id': 6, 'segmentation': [[537.0, 1625.0, 551.0, 1612.0, 564.0, 1602.0, 585.0, 1578.0, 610.0, 1557.0, 628.0, 1544.0, 669.0, 1532.0, 699.0, 1519.0, 718.0, 1504.0, 721.0, 1498.0, 735.0, 1496.0, 750.0, 1487.0, 769.0, 1476.0, 805.0, 1462.0, 834.0, 1457.0, 882.0, 1461.0, 902.0, 1463.0, 911.0, 1464.0, 938.0, 1467.0, 945.0, 1476.0, 943.0, 1484.0, 919.0, 1498.0, 827.0, 1556.0, 774.0, 1591.0, 702.0, 1637.0, 633.0, 1680.0, 602.0, 1701.0, 581.0, 1713.0, 571.0, 1712.0, 545.0, 1691.0, 534.0, 1665.0, 528.0, 1648.0, 531.0, 1635.0, 537.0, 1625.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [714.0, 1190.0, 60.0, 32.0], 'category_id': 6, 'segmentation': [[714.0, 1192.0, 718.0, 1196.0, 716.0, 1203.0, 723.0, 1212.0, 736.0, 1215.0, 746.0, 1216.0, 756.0, 1218.0, 769.0, 1219.0, 773.0, 1222.0, 774.0, 1214.0, 772.0, 1207.0, 764.0, 1202.0, 759.0, 1197.0, 753.0, 1192.0, 734.0, 1190.0, 723.0, 1190.0, 714.0, 1192.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [1883.0, 1599.0, 243.0, 170.0], 'category_id': 6, 'segmentation': [[1884.0, 1760.0, 1918.0, 1735.0, 1967.0, 1700.0, 1978.0, 1690.0, 2009.0, 1668.0, 2039.0, 1645.0, 2071.0, 1628.0, 2094.0, 1612.0, 2115.0, 1600.0, 2119.0, 1599.0, 2126.0, 1606.0, 2123.0, 1611.0, 2115.0, 1618.0, 2086.0, 1636.0, 2055.0, 1655.0, 2030.0, 1672.0, 2024.0, 1675.0, 2015.0, 1679.0, 1999.0, 1674.0, 1978.0, 1690.0, 1995.0, 1696.0, 1983.0, 1705.0, 1953.0, 1727.0, 1932.0, 1742.0, 1910.0, 1759.0, 1895.0, 1769.0, 1889.0, 1769.0, 1883.0, 1764.0, 1884.0, 1760.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_4/000023.JPG', 'height': 2448, 'width': 3264, 'image_id': 899, 'annotations': [{'iscrowd': 0, 'bbox': [2069.0, 1254.0, 206.0, 121.0], 'category_id': 1, 'segmentation': [[2152.0, 1374.0, 2206.0, 1375.0, 2239.0, 1366.0, 2262.0, 1358.0, 2275.0, 1342.0, 2270.0, 1323.0, 2259.0, 1312.0, 2249.0, 1308.0, 2251.0, 1291.0, 2236.0, 1270.0, 2218.0, 1259.0, 2191.0, 1254.0, 2149.0, 1256.0, 2125.0, 1259.0, 2109.0, 1272.0, 2098.0, 1285.0, 2093.0, 1294.0, 2090.0, 1307.0, 2080.0, 1314.0, 2069.0, 1324.0, 2073.0, 1347.0, 2095.0, 1363.0, 2122.0, 1370.0, 2152.0, 1374.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_4/000054.JPG', 'height': 2448, 'width': 3264, 'image_id': 924, 'annotations': [{'iscrowd': 0, 'bbox': [1611.0, 364.0, 477.0, 406.0], 'category_id': 6, 'segmentation': [[1663.0, 750.0, 1716.0, 745.0, 1740.0, 763.0, 1777.0, 770.0, 1818.0, 763.0, 1841.0, 733.0, 1865.0, 696.0, 1880.0, 651.0, 1926.0, 633.0, 1972.0, 626.0, 2039.0, 598.0, 2087.0, 540.0, 2088.0, 512.0, 2074.0, 446.0, 2068.0, 380.0, 2036.0, 380.0, 1986.0, 392.0, 1947.0, 414.0, 1938.0, 443.0, 1907.0, 458.0, 1900.0, 419.0, 1900.0, 393.0, 1853.0, 364.0, 1825.0, 366.0, 1759.0, 414.0, 1701.0, 458.0, 1651.0, 508.0, 1632.0, 516.0, 1611.0, 509.0, 1611.0, 527.0, 1624.0, 571.0, 1643.0, 602.0, 1664.0, 598.0, 1683.0, 620.0, 1670.0, 655.0, 1660.0, 696.0, 1650.0, 720.0, 1663.0, 750.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [1636.0, 1502.0, 217.0, 192.0], 'category_id': 6, 'segmentation': [[1641.0, 1631.0, 1646.0, 1648.0, 1739.0, 1677.0, 1813.0, 1689.0, 1835.0, 1694.0, 1849.0, 1691.0, 1853.0, 1675.0, 1853.0, 1655.0, 1844.0, 1601.0, 1832.0, 1577.0, 1820.0, 1550.0, 1796.0, 1502.0, 1771.0, 1512.0, 1748.0, 1524.0, 1720.0, 1532.0, 1691.0, 1537.0, 1680.0, 1557.0, 1667.0, 1576.0, 1636.0, 1606.0, 1641.0, 1631.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [1738.0, 1871.0, 234.0, 250.0], 'category_id': 6, 'segmentation': [[1832.0, 2103.0, 1833.0, 2108.0, 1836.0, 2112.0, 1841.0, 2117.0, 1846.0, 2121.0, 1875.0, 2106.0, 1899.0, 2091.0, 1943.0, 2060.0, 1962.0, 2034.0, 1972.0, 2004.0, 1972.0, 1971.0, 1968.0, 1944.0, 1955.0, 1919.0, 1933.0, 1895.0, 1899.0, 1876.0, 1863.0, 1871.0, 1828.0, 1877.0, 1802.0, 1891.0, 1785.0, 1910.0, 1765.0, 1940.0, 1759.0, 1959.0, 1740.0, 1999.0, 1738.0, 2015.0, 1765.0, 2033.0, 1797.0, 2056.0, 1804.0, 2061.0, 1822.0, 2037.0, 1811.0, 2025.0, 1804.0, 2011.0, 1796.0, 1990.0, 1802.0, 1984.0, 1801.0, 1971.0, 1800.0, 1958.0, 1809.0, 1934.0, 1826.0, 1917.0, 1851.0, 1909.0, 1862.0, 1912.0, 1871.0, 1914.0, 1885.0, 1910.0, 1907.0, 1920.0, 1927.0, 1944.0, 1938.0, 1965.0, 1937.0, 2000.0, 1923.0, 2031.0, 1896.0, 2051.0, 1883.0, 2050.0, 1873.0, 2048.0, 1861.0, 2055.0, 1840.0, 2052.0, 1822.0, 2038.0, 1803.0, 2063.0, 1826.0, 2093.0, 1832.0, 2103.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [523.0, 966.0, 584.0, 614.0], 'category_id': 6, 'segmentation': [[824.0, 1580.0, 833.0, 1577.0, 839.0, 1570.0, 842.0, 1563.0, 839.0, 1553.0, 834.0, 1548.0, 825.0, 1544.0, 806.0, 1536.0, 792.0, 1527.0, 778.0, 1514.0, 768.0, 1500.0, 762.0, 1485.0, 761.0, 1469.0, 758.0, 1379.0, 794.0, 1367.0, 798.0, 1362.0, 823.0, 1351.0, 847.0, 1340.0, 865.0, 1329.0, 891.0, 1306.0, 910.0, 1282.0, 921.0, 1264.0, 927.0, 1248.0, 931.0, 1218.0, 927.0, 1198.0, 922.0, 1189.0, 910.0, 1172.0, 899.0, 1162.0, 889.0, 1150.0, 880.0, 1141.0, 878.0, 1137.0, 891.0, 1144.0, 922.0, 1172.0, 938.0, 1184.0, 957.0, 1200.0, 978.0, 1221.0, 998.0, 1232.0, 1015.0, 1239.0, 1022.0, 1242.0, 1050.0, 1246.0, 1074.0, 1244.0, 1082.0, 1245.0, 1088.0, 1241.0, 1105.0, 1231.0, 1107.0, 1225.0, 1097.0, 1223.0, 1082.0, 1223.0, 1079.0, 1223.0, 1067.0, 1224.0, 1047.0, 1223.0, 1029.0, 1217.0, 1002.0, 1203.0, 969.0, 1181.0, 947.0, 1165.0, 927.0, 1151.0, 899.0, 1126.0, 885.0, 1111.0, 870.0, 1113.0, 866.0, 1119.0, 858.0, 1123.0, 814.0, 1095.0, 784.0, 1081.0, 764.0, 1076.0, 742.0, 1073.0, 718.0, 1076.0, 705.0, 1081.0, 694.0, 1090.0, 681.0, 1102.0, 672.0, 1114.0, 659.0, 1132.0, 643.0, 1155.0, 650.0, 1172.0, 671.0, 1140.0, 690.0, 1110.0, 708.0, 1093.0, 727.0, 1086.0, 747.0, 1083.0, 767.0, 1089.0, 791.0, 1098.0, 817.0, 1114.0, 840.0, 1130.0, 867.0, 1151.0, 882.0, 1166.0, 898.0, 1182.0, 906.0, 1195.0, 912.0, 1212.0, 913.0, 1229.0, 908.0, 1245.0, 905.0, 1259.0, 879.0, 1293.0, 863.0, 1310.0, 851.0, 1318.0, 835.0, 1328.0, 819.0, 1335.0, 793.0, 1344.0, 770.0, 1353.0, 746.0, 1360.0, 725.0, 1364.0, 716.0, 1364.0, 710.0, 1362.0, 686.0, 1359.0, 670.0, 1353.0, 652.0, 1345.0, 636.0, 1332.0, 622.0, 1317.0, 605.0, 1291.0, 601.0, 1273.0, 601.0, 1256.0, 609.0, 1234.0, 623.0, 1212.0, 650.0, 1171.0, 642.0, 1156.0, 622.0, 1185.0, 620.0, 1183.0, 634.0, 1147.0, 639.0, 1100.0, 637.0, 1076.0, 630.0, 1052.0, 621.0, 1029.0, 610.0, 1016.0, 592.0, 999.0, 566.0, 981.0, 550.0, 974.0, 538.0, 968.0, 527.0, 966.0, 523.0, 970.0, 530.0, 988.0, 538.0, 996.0, 553.0, 1003.0, 567.0, 1012.0, 588.0, 1033.0, 600.0, 1053.0, 606.0, 1076.0, 609.0, 1097.0, 606.0, 1125.0, 601.0, 1148.0, 594.0, 1169.0, 587.0, 1184.0, 583.0, 1192.0, 589.0, 1204.0, 605.0, 1207.0, 598.0, 1223.0, 591.0, 1237.0, 587.0, 1253.0, 588.0, 1274.0, 591.0, 1291.0, 597.0, 1307.0, 608.0, 1324.0, 618.0, 1335.0, 627.0, 1346.0, 642.0, 1352.0, 676.0, 1364.0, 686.0, 1370.0, 709.0, 1384.0, 722.0, 1389.0, 733.0, 1389.0, 733.0, 1458.0, 735.0, 1488.0, 742.0, 1517.0, 752.0, 1536.0, 771.0, 1551.0, 791.0, 1565.0, 810.0, 1574.0, 824.0, 1580.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_4/000056.JPG', 'height': 2448, 'width': 3264, 'image_id': 926, 'annotations': [{'iscrowd': 0, 'bbox': [1898.0, 1563.0, 215.0, 93.0], 'category_id': 6, 'segmentation': [[1932.0, 1644.0, 1913.0, 1622.0, 1901.0, 1603.0, 1898.0, 1585.0, 1902.0, 1574.0, 1910.0, 1570.0, 1929.0, 1568.0, 1945.0, 1570.0, 1958.0, 1572.0, 1971.0, 1567.0, 1988.0, 1563.0, 2007.0, 1568.0, 2032.0, 1577.0, 2066.0, 1589.0, 2084.0, 1596.0, 2092.0, 1597.0, 2098.0, 1586.0, 2103.0, 1591.0, 2113.0, 1603.0, 2110.0, 1617.0, 2099.0, 1620.0, 2085.0, 1616.0, 2032.0, 1599.0, 2018.0, 1595.0, 2008.0, 1594.0, 1995.0, 1596.0, 1983.0, 1603.0, 1971.0, 1616.0, 1970.0, 1638.0, 1965.0, 1653.0, 1956.0, 1656.0, 1947.0, 1647.0, 1932.0, 1644.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_4/000071.JPG', 'height': 2448, 'width': 3264, 'image_id': 939, 'annotations': [{'iscrowd': 0, 'bbox': [1153.0, 1083.0, 496.0, 586.0], 'category_id': 6, 'segmentation': [[1320.0, 1669.0, 1335.0, 1617.0, 1352.0, 1618.0, 1381.0, 1618.0, 1436.0, 1637.0, 1488.0, 1650.0, 1530.0, 1649.0, 1576.0, 1639.0, 1586.0, 1633.0, 1588.0, 1600.0, 1599.0, 1570.0, 1623.0, 1530.0, 1645.0, 1515.0, 1649.0, 1466.0, 1644.0, 1419.0, 1636.0, 1373.0, 1612.0, 1349.0, 1568.0, 1315.0, 1547.0, 1289.0, 1526.0, 1273.0, 1501.0, 1243.0, 1484.0, 1233.0, 1473.0, 1229.0, 1455.0, 1229.0, 1429.0, 1220.0, 1396.0, 1212.0, 1387.0, 1200.0, 1376.0, 1188.0, 1281.0, 1084.0, 1271.0, 1083.0, 1252.0, 1091.0, 1234.0, 1106.0, 1220.0, 1118.0, 1207.0, 1124.0, 1190.0, 1136.0, 1179.0, 1145.0, 1166.0, 1151.0, 1161.0, 1160.0, 1166.0, 1167.0, 1162.0, 1174.0, 1161.0, 1179.0, 1170.0, 1192.0, 1190.0, 1219.0, 1205.0, 1235.0, 1226.0, 1248.0, 1241.0, 1256.0, 1257.0, 1264.0, 1275.0, 1274.0, 1276.0, 1280.0, 1274.0, 1287.0, 1270.0, 1290.0, 1258.0, 1298.0, 1239.0, 1306.0, 1227.0, 1315.0, 1216.0, 1318.0, 1207.0, 1323.0, 1200.0, 1323.0, 1188.0, 1334.0, 1179.0, 1337.0, 1176.0, 1351.0, 1191.0, 1355.0, 1205.0, 1354.0, 1221.0, 1356.0, 1230.0, 1360.0, 1225.0, 1373.0, 1219.0, 1393.0, 1214.0, 1406.0, 1208.0, 1419.0, 1200.0, 1419.0, 1194.0, 1425.0, 1195.0, 1443.0, 1197.0, 1450.0, 1187.0, 1449.0, 1172.0, 1450.0, 1163.0, 1458.0, 1153.0, 1467.0, 1154.0, 1478.0, 1165.0, 1483.0, 1182.0, 1481.0, 1196.0, 1484.0, 1205.0, 1489.0, 1217.0, 1485.0, 1229.0, 1479.0, 1226.0, 1487.0, 1204.0, 1521.0, 1182.0, 1534.0, 1168.0, 1570.0, 1185.0, 1567.0, 1198.0, 1547.0, 1216.0, 1530.0, 1246.0, 1507.0, 1293.0, 1490.0, 1319.0, 1480.0, 1330.0, 1475.0, 1328.0, 1481.0, 1310.0, 1516.0, 1300.0, 1554.0, 1285.0, 1578.0, 1279.0, 1595.0, 1279.0, 1615.0, 1280.0, 1631.0, 1293.0, 1644.0, 1298.0, 1638.0, 1302.0, 1648.0, 1305.0, 1663.0, 1320.0, 1669.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_4/000097.JPG', 'height': 3264, 'width': 2448, 'image_id': 962, 'annotations': [{'iscrowd': 0, 'bbox': [1567.0, 1375.0, 262.0, 122.0], 'category_id': 0, 'segmentation': [[1573.0, 1399.0, 1585.0, 1384.0, 1600.0, 1375.0, 1665.0, 1380.0, 1721.0, 1384.0, 1747.0, 1389.0, 1788.0, 1407.0, 1801.0, 1405.0, 1811.0, 1411.0, 1824.0, 1414.0, 1829.0, 1437.0, 1829.0, 1457.0, 1823.0, 1478.0, 1816.0, 1485.0, 1801.0, 1488.0, 1792.0, 1485.0, 1770.0, 1486.0, 1745.0, 1495.0, 1693.0, 1497.0, 1640.0, 1493.0, 1591.0, 1486.0, 1576.0, 1477.0, 1571.0, 1464.0, 1567.0, 1448.0, 1570.0, 1432.0, 1571.0, 1414.0, 1573.0, 1399.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [841.0, 1834.0, 426.0, 315.0], 'category_id': 6, 'segmentation': [[841.0, 2040.0, 863.0, 2049.0, 885.0, 2064.0, 909.0, 2086.0, 937.0, 2105.0, 953.0, 2118.0, 969.0, 2135.0, 1002.0, 2137.0, 1019.0, 2145.0, 1087.0, 2149.0, 1126.0, 2120.0, 1144.0, 2104.0, 1172.0, 2085.0, 1195.0, 2058.0, 1228.0, 2040.0, 1239.0, 2023.0, 1249.0, 2006.0, 1267.0, 1982.0, 1267.0, 1966.0, 1264.0, 1957.0, 1257.0, 1949.0, 1240.0, 1940.0, 1248.0, 1932.0, 1256.0, 1923.0, 1267.0, 1902.0, 1263.0, 1883.0, 1256.0, 1865.0, 1253.0, 1859.0, 1239.0, 1850.0, 1220.0, 1837.0, 1213.0, 1834.0, 1194.0, 1841.0, 1175.0, 1849.0, 1163.0, 1860.0, 1156.0, 1872.0, 1155.0, 1882.0, 1157.0, 1887.0, 1161.0, 1896.0, 1154.0, 1908.0, 1134.0, 1908.0, 1103.0, 1897.0, 1079.0, 1895.0, 1037.0, 1908.0, 987.0, 1948.0, 934.0, 1984.0, 905.0, 1999.0, 879.0, 2011.0, 856.0, 2027.0, 843.0, 2033.0, 841.0, 2040.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [1611.0, 1676.0, 266.0, 149.0], 'category_id': 7, 'segmentation': [[1611.0, 1711.0, 1624.0, 1722.0, 1633.0, 1728.0, 1644.0, 1738.0, 1657.0, 1753.0, 1678.0, 1780.0, 1701.0, 1814.0, 1711.0, 1825.0, 1741.0, 1817.0, 1762.0, 1813.0, 1784.0, 1811.0, 1806.0, 1800.0, 1829.0, 1797.0, 1867.0, 1783.0, 1877.0, 1779.0, 1858.0, 1752.0, 1842.0, 1738.0, 1832.0, 1731.0, 1822.0, 1719.0, 1804.0, 1701.0, 1775.0, 1687.0, 1747.0, 1679.0, 1714.0, 1676.0, 1685.0, 1684.0, 1661.0, 1694.0, 1645.0, 1700.0, 1625.0, 1700.0, 1611.0, 1711.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [1320.0, 1558.0, 39.0, 19.0], 'category_id': 6, 'segmentation': [[1320.0, 1571.0, 1326.0, 1577.0, 1359.0, 1559.0, 1345.0, 1558.0, 1322.0, 1564.0, 1320.0, 1571.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [1367.0, 1616.0, 35.0, 30.0], 'category_id': 6, 'segmentation': [[1367.0, 1646.0, 1394.0, 1642.0, 1400.0, 1639.0, 1400.0, 1629.0, 1402.0, 1616.0, 1394.0, 1619.0, 1381.0, 1626.0, 1369.0, 1634.0, 1367.0, 1646.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [1527.0, 1610.0, 132.0, 29.0], 'category_id': 6, 'segmentation': [[1528.0, 1613.0, 1527.0, 1617.0, 1563.0, 1625.0, 1595.0, 1633.0, 1616.0, 1639.0, 1624.0, 1636.0, 1633.0, 1637.0, 1656.0, 1638.0, 1659.0, 1635.0, 1643.0, 1624.0, 1633.0, 1618.0, 1595.0, 1612.0, 1573.0, 1610.0, 1553.0, 1610.0, 1528.0, 1613.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [1559.0, 1589.0, 40.0, 17.0], 'category_id': 6, 'segmentation': [[1559.0, 1592.0, 1570.0, 1589.0, 1580.0, 1589.0, 1590.0, 1591.0, 1593.0, 1592.0, 1599.0, 1599.0, 1598.0, 1603.0, 1595.0, 1603.0, 1592.0, 1602.0, 1588.0, 1606.0, 1580.0, 1606.0, 1568.0, 1601.0, 1560.0, 1596.0, 1559.0, 1592.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [1504.0, 1390.0, 82.0, 95.0], 'category_id': 6, 'segmentation': [[1507.0, 1390.0, 1504.0, 1394.0, 1511.0, 1406.0, 1518.0, 1410.0, 1520.0, 1419.0, 1520.0, 1430.0, 1529.0, 1446.0, 1528.0, 1460.0, 1532.0, 1467.0, 1546.0, 1471.0, 1559.0, 1479.0, 1564.0, 1481.0, 1586.0, 1485.0, 1577.0, 1476.0, 1569.0, 1463.0, 1566.0, 1449.0, 1567.0, 1441.0, 1538.0, 1417.0, 1507.0, 1390.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_5/000074.JPG', 'height': 3264, 'width': 2448, 'image_id': 967, 'annotations': [{'iscrowd': 0, 'bbox': [1002.0, 1141.0, 1055.0, 530.0], 'category_id': 9, 'segmentation': [[1035.0, 1152.0, 1505.0, 1383.0, 1794.0, 1526.0, 1897.0, 1573.0, 1987.0, 1617.0, 2057.0, 1652.0, 2046.0, 1671.0, 1832.0, 1571.0, 1586.0, 1448.0, 1253.0, 1288.0, 1125.0, 1223.0, 1002.0, 1164.0, 1005.0, 1147.0, 1012.0, 1141.0, 1035.0, 1152.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_5/000075.JPG', 'height': 3264, 'width': 2448, 'image_id': 968, 'annotations': [{'iscrowd': 0, 'bbox': [1584.0, 1486.0, 147.0, 262.0], 'category_id': 6, 'segmentation': [[1658.0, 1567.0, 1625.0, 1619.0, 1611.0, 1654.0, 1596.0, 1695.0, 1584.0, 1723.0, 1588.0, 1748.0, 1600.0, 1732.0, 1617.0, 1683.0, 1634.0, 1641.0, 1658.0, 1606.0, 1682.0, 1567.0, 1695.0, 1552.0, 1708.0, 1556.0, 1713.0, 1543.0, 1731.0, 1534.0, 1730.0, 1519.0, 1727.0, 1506.0, 1708.0, 1497.0, 1714.0, 1486.0, 1693.0, 1494.0, 1684.0, 1510.0, 1683.0, 1517.0, 1668.0, 1518.0, 1658.0, 1512.0, 1653.0, 1515.0, 1662.0, 1525.0, 1671.0, 1532.0, 1674.0, 1542.0, 1658.0, 1567.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_5/000085.JPG', 'height': 2448, 'width': 3264, 'image_id': 976, 'annotations': [{'iscrowd': 0, 'bbox': [1615.0, 732.0, 225.0, 166.0], 'category_id': 6, 'segmentation': [[1714.0, 762.0, 1688.0, 780.0, 1685.0, 795.0, 1673.0, 795.0, 1648.0, 809.0, 1644.0, 820.0, 1615.0, 839.0, 1632.0, 855.0, 1648.0, 853.0, 1675.0, 876.0, 1712.0, 898.0, 1736.0, 879.0, 1763.0, 868.0, 1795.0, 850.0, 1824.0, 826.0, 1836.0, 813.0, 1840.0, 801.0, 1831.0, 777.0, 1817.0, 762.0, 1815.0, 743.0, 1810.0, 732.0, 1780.0, 742.0, 1762.0, 753.0, 1743.0, 751.0, 1714.0, 762.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [1222.0, 1300.0, 809.0, 192.0], 'category_id': 7, 'segmentation': [[2027.0, 1419.0, 1681.0, 1452.0, 1462.0, 1478.0, 1268.0, 1492.0, 1225.0, 1438.0, 1222.0, 1404.0, 1242.0, 1385.0, 1821.0, 1318.0, 1970.0, 1300.0, 2012.0, 1300.0, 2020.0, 1341.0, 2031.0, 1375.0, 2031.0, 1394.0, 2027.0, 1419.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [394.0, 900.0, 499.0, 401.0], 'category_id': 6, 'segmentation': [[643.0, 1041.0, 650.0, 1034.0, 648.0, 1023.0, 610.0, 1010.0, 574.0, 997.0, 537.0, 986.0, 556.0, 988.0, 574.0, 987.0, 602.0, 997.0, 598.0, 987.0, 571.0, 971.0, 547.0, 948.0, 557.0, 920.0, 562.0, 917.0, 564.0, 906.0, 570.0, 900.0, 588.0, 911.0, 598.0, 917.0, 640.0, 929.0, 660.0, 935.0, 675.0, 935.0, 711.0, 941.0, 723.0, 951.0, 738.0, 960.0, 763.0, 963.0, 786.0, 963.0, 806.0, 985.0, 821.0, 1013.0, 835.0, 1033.0, 849.0, 1042.0, 856.0, 1063.0, 867.0, 1080.0, 876.0, 1110.0, 884.0, 1139.0, 893.0, 1160.0, 884.0, 1200.0, 877.0, 1223.0, 874.0, 1232.0, 805.0, 1186.0, 759.0, 1218.0, 731.0, 1231.0, 725.0, 1243.0, 744.0, 1257.0, 759.0, 1252.0, 781.0, 1262.0, 793.0, 1277.0, 773.0, 1284.0, 759.0, 1290.0, 760.0, 1301.0, 717.0, 1291.0, 678.0, 1284.0, 661.0, 1271.0, 653.0, 1256.0, 550.0, 1206.0, 531.0, 1198.0, 500.0, 1204.0, 487.0, 1192.0, 458.0, 1192.0, 442.0, 1195.0, 418.0, 1183.0, 394.0, 1172.0, 402.0, 1157.0, 422.0, 1160.0, 436.0, 1039.0, 461.0, 1045.0, 477.0, 1033.0, 542.0, 1038.0, 570.0, 1044.0, 593.0, 1036.0, 622.0, 1034.0, 636.0, 1039.0, 645.0, 1052.0, 624.0, 1061.0, 601.0, 1090.0, 580.0, 1122.0, 556.0, 1148.0, 548.0, 1181.0, 553.0, 1196.0, 660.0, 1248.0, 684.0, 1245.0, 692.0, 1259.0, 711.0, 1277.0, 731.0, 1280.0, 754.0, 1272.0, 744.0, 1255.0, 724.0, 1242.0, 702.0, 1238.0, 747.0, 1199.0, 743.0, 1175.0, 728.0, 1166.0, 727.0, 1141.0, 712.0, 1134.0, 707.0, 1111.0, 677.0, 1099.0, 659.0, 1096.0, 672.0, 1085.0, 648.0, 1052.0, 643.0, 1041.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_5/000094.JPG', 'height': 2448, 'width': 3264, 'image_id': 985, 'annotations': [{'iscrowd': 0, 'bbox': [349.0, 1532.0, 419.0, 324.0], 'category_id': 1, 'segmentation': [[497.0, 1760.0, 567.0, 1791.0, 642.0, 1831.0, 695.0, 1856.0, 758.0, 1817.0, 768.0, 1773.0, 762.0, 1717.0, 739.0, 1657.0, 695.0, 1604.0, 653.0, 1566.0, 587.0, 1539.0, 517.0, 1532.0, 453.0, 1557.0, 413.0, 1587.0, 388.0, 1609.0, 370.0, 1631.0, 353.0, 1669.0, 349.0, 1701.0, 353.0, 1738.0, 357.0, 1748.0, 384.0, 1746.0, 441.0, 1746.0, 462.0, 1748.0, 497.0, 1760.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [1084.0, 1854.0, 222.0, 205.0], 'category_id': 6, 'segmentation': [[1175.0, 2059.0, 1194.0, 2049.0, 1203.0, 2031.0, 1231.0, 2027.0, 1263.0, 2027.0, 1296.0, 2009.0, 1306.0, 1980.0, 1294.0, 1961.0, 1271.0, 1944.0, 1277.0, 1930.0, 1265.0, 1912.0, 1263.0, 1890.0, 1245.0, 1876.0, 1232.0, 1876.0, 1220.0, 1876.0, 1202.0, 1854.0, 1177.0, 1859.0, 1170.0, 1877.0, 1157.0, 1890.0, 1137.0, 1882.0, 1109.0, 1886.0, 1101.0, 1910.0, 1096.0, 1929.0, 1086.0, 1954.0, 1084.0, 1976.0, 1088.0, 2000.0, 1092.0, 2023.0, 1106.0, 2030.0, 1125.0, 2050.0, 1144.0, 2053.0, 1156.0, 2054.0, 1175.0, 2059.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_5/000069.JPG', 'height': 3264, 'width': 2448, 'image_id': 998, 'annotations': [{'iscrowd': 0, 'bbox': [1009.0, 1434.0, 371.0, 261.0], 'category_id': 7, 'segmentation': [[1329.0, 1695.0, 1351.0, 1618.0, 1351.0, 1611.0, 1364.0, 1570.0, 1380.0, 1527.0, 1364.0, 1521.0, 1103.0, 1444.0, 1067.0, 1434.0, 1036.0, 1526.0, 1009.0, 1597.0, 1034.0, 1606.0, 1073.0, 1616.0, 1188.0, 1657.0, 1209.0, 1661.0, 1329.0, 1695.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [19.0, 197.0, 238.0, 200.0], 'category_id': 6, 'segmentation': [[151.0, 197.0, 201.0, 233.0, 213.0, 238.0, 229.0, 246.0, 243.0, 258.0, 257.0, 273.0, 248.0, 275.0, 227.0, 301.0, 213.0, 314.0, 200.0, 329.0, 184.0, 346.0, 161.0, 368.0, 153.0, 379.0, 147.0, 389.0, 133.0, 395.0, 127.0, 397.0, 104.0, 397.0, 42.0, 354.0, 23.0, 338.0, 19.0, 329.0, 20.0, 321.0, 36.0, 313.0, 57.0, 292.0, 137.0, 209.0, 141.0, 198.0, 151.0, 197.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_5/000070.JPG', 'height': 3264, 'width': 2448, 'image_id': 999, 'annotations': [{'iscrowd': 0, 'bbox': [1230.0, 1046.0, 181.0, 424.0], 'category_id': 0, 'segmentation': [[1274.0, 1136.0, 1272.0, 1157.0, 1270.0, 1167.0, 1263.0, 1205.0, 1257.0, 1238.0, 1248.0, 1255.0, 1239.0, 1285.0, 1230.0, 1322.0, 1230.0, 1343.0, 1237.0, 1372.0, 1245.0, 1397.0, 1251.0, 1413.0, 1257.0, 1424.0, 1258.0, 1429.0, 1251.0, 1434.0, 1250.0, 1441.0, 1252.0, 1445.0, 1251.0, 1454.0, 1257.0, 1460.0, 1268.0, 1466.0, 1282.0, 1470.0, 1292.0, 1465.0, 1293.0, 1459.0, 1298.0, 1455.0, 1302.0, 1448.0, 1301.0, 1443.0, 1317.0, 1431.0, 1336.0, 1414.0, 1347.0, 1404.0, 1364.0, 1397.0, 1374.0, 1380.0, 1382.0, 1353.0, 1385.0, 1325.0, 1392.0, 1299.0, 1395.0, 1270.0, 1398.0, 1235.0, 1405.0, 1175.0, 1410.0, 1133.0, 1411.0, 1108.0, 1405.0, 1091.0, 1396.0, 1071.0, 1388.0, 1059.0, 1379.0, 1056.0, 1369.0, 1052.0, 1352.0, 1046.0, 1342.0, 1048.0, 1334.0, 1048.0, 1314.0, 1053.0, 1309.0, 1057.0, 1296.0, 1066.0, 1291.0, 1080.0, 1280.0, 1116.0, 1274.0, 1136.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [2222.0, 1064.0, 42.0, 12.0], 'category_id': 3, 'segmentation': [[2262.0, 1076.0, 2222.0, 1072.0, 2222.0, 1064.0, 2264.0, 1066.0, 2262.0, 1076.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [510.0, 90.0, 16.0, 20.0], 'category_id': 3, 'segmentation': [[522.0, 110.0, 526.0, 90.0, 518.0, 92.0, 510.0, 108.0, 522.0, 110.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [22.0, 1722.0, 30.0, 36.0], 'category_id': 3, 'segmentation': [[52.0, 1750.0, 32.0, 1722.0, 22.0, 1726.0, 34.0, 1758.0, 52.0, 1750.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_5/000009.JPG', 'height': 3264, 'width': 2448, 'image_id': 1026, 'annotations': [{'iscrowd': 0, 'bbox': [775.0, 1749.0, 404.0, 226.0], 'category_id': 9, 'segmentation': [[787.0, 1975.0, 1179.0, 1766.0, 1178.0, 1754.0, 1170.0, 1749.0, 775.0, 1962.0, 787.0, 1975.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [1476.0, 1010.0, 97.0, 363.0], 'category_id': 9, 'segmentation': [[1559.0, 1012.0, 1476.0, 1373.0, 1493.0, 1370.0, 1573.0, 1014.0, 1566.0, 1010.0, 1559.0, 1012.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [1413.0, 1227.0, 184.0, 137.0], 'category_id': 5, 'segmentation': [[1425.0, 1316.0, 1447.0, 1340.0, 1470.0, 1354.0, 1485.0, 1360.0, 1518.0, 1364.0, 1546.0, 1356.0, 1584.0, 1336.0, 1593.0, 1315.0, 1591.0, 1279.0, 1597.0, 1271.0, 1584.0, 1256.0, 1577.0, 1250.0, 1572.0, 1258.0, 1575.0, 1266.0, 1564.0, 1276.0, 1552.0, 1283.0, 1543.0, 1295.0, 1547.0, 1301.0, 1553.0, 1303.0, 1551.0, 1313.0, 1542.0, 1317.0, 1534.0, 1325.0, 1518.0, 1335.0, 1514.0, 1327.0, 1507.0, 1324.0, 1482.0, 1325.0, 1471.0, 1327.0, 1477.0, 1317.0, 1471.0, 1309.0, 1475.0, 1297.0, 1467.0, 1294.0, 1462.0, 1291.0, 1453.0, 1279.0, 1453.0, 1263.0, 1465.0, 1246.0, 1473.0, 1248.0, 1490.0, 1265.0, 1490.0, 1269.0, 1496.0, 1281.0, 1507.0, 1271.0, 1520.0, 1263.0, 1537.0, 1246.0, 1545.0, 1241.0, 1558.0, 1240.0, 1564.0, 1249.0, 1570.0, 1251.0, 1570.0, 1246.0, 1559.0, 1239.0, 1549.0, 1236.0, 1537.0, 1246.0, 1528.0, 1243.0, 1503.0, 1243.0, 1501.0, 1238.0, 1503.0, 1227.0, 1487.0, 1227.0, 1469.0, 1230.0, 1452.0, 1236.0, 1437.0, 1243.0, 1428.0, 1251.0, 1419.0, 1261.0, 1419.0, 1264.0, 1414.0, 1280.0, 1413.0, 1292.0, 1418.0, 1305.0, 1425.0, 1316.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_5/000017.JPG', 'height': 3264, 'width': 2448, 'image_id': 1034, 'annotations': [{'iscrowd': 0, 'bbox': [1292.0, 1318.0, 73.0, 69.0], 'category_id': 8, 'segmentation': [[1305.0, 1347.0, 1325.0, 1338.0, 1347.0, 1321.0, 1355.0, 1318.0, 1360.0, 1321.0, 1365.0, 1340.0, 1362.0, 1359.0, 1361.0, 1363.0, 1344.0, 1370.0, 1323.0, 1378.0, 1308.0, 1386.0, 1300.0, 1387.0, 1295.0, 1383.0, 1292.0, 1378.0, 1292.0, 1372.0, 1293.0, 1365.0, 1295.0, 1359.0, 1299.0, 1351.0, 1305.0, 1347.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [907.0, 1125.0, 459.0, 321.0], 'category_id': 2, 'segmentation': [[1364.0, 1298.0, 1366.0, 1313.0, 1366.0, 1327.0, 1365.0, 1336.0, 1363.0, 1353.0, 1357.0, 1366.0, 1351.0, 1379.0, 1346.0, 1390.0, 1338.0, 1405.0, 1330.0, 1416.0, 1324.0, 1424.0, 1304.0, 1416.0, 1297.0, 1427.0, 1304.0, 1438.0, 1297.0, 1443.0, 1291.0, 1446.0, 1280.0, 1446.0, 1266.0, 1441.0, 1250.0, 1435.0, 1223.0, 1424.0, 1152.0, 1392.0, 965.0, 1304.0, 947.0, 1291.0, 937.0, 1281.0, 915.0, 1270.0, 911.0, 1261.0, 907.0, 1231.0, 911.0, 1206.0, 920.0, 1178.0, 933.0, 1159.0, 947.0, 1144.0, 969.0, 1130.0, 983.0, 1125.0, 996.0, 1127.0, 1007.0, 1131.0, 1323.0, 1262.0, 1339.0, 1272.0, 1353.0, 1281.0, 1360.0, 1288.0, 1364.0, 1298.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_5/000025.JPG', 'height': 3264, 'width': 2448, 'image_id': 1042, 'annotations': [{'iscrowd': 0, 'bbox': [1292.0, 1677.0, 181.0, 110.0], 'category_id': 4, 'segmentation': [[1293.0, 1731.0, 1296.0, 1751.0, 1304.0, 1769.0, 1313.0, 1782.0, 1326.0, 1787.0, 1339.0, 1786.0, 1347.0, 1782.0, 1358.0, 1776.0, 1407.0, 1762.0, 1461.0, 1745.0, 1467.0, 1739.0, 1472.0, 1727.0, 1473.0, 1717.0, 1471.0, 1705.0, 1467.0, 1694.0, 1462.0, 1685.0, 1457.0, 1682.0, 1440.0, 1680.0, 1424.0, 1681.0, 1396.0, 1679.0, 1335.0, 1681.0, 1327.0, 1677.0, 1317.0, 1677.0, 1306.0, 1683.0, 1300.0, 1690.0, 1295.0, 1701.0, 1292.0, 1714.0, 1292.0, 1722.0, 1293.0, 1731.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_5/000034.JPG', 'height': 3264, 'width': 2448, 'image_id': 1050, 'annotations': [{'iscrowd': 0, 'bbox': [1250.0, 1608.0, 279.0, 344.0], 'category_id': 6, 'segmentation': [[1371.0, 1634.0, 1401.0, 1656.0, 1478.0, 1691.0, 1504.0, 1712.0, 1523.0, 1718.0, 1529.0, 1754.0, 1520.0, 1798.0, 1510.0, 1833.0, 1480.0, 1892.0, 1463.0, 1921.0, 1454.0, 1933.0, 1455.0, 1944.0, 1451.0, 1952.0, 1438.0, 1951.0, 1383.0, 1927.0, 1341.0, 1908.0, 1321.0, 1882.0, 1328.0, 1861.0, 1333.0, 1832.0, 1310.0, 1810.0, 1289.0, 1797.0, 1254.0, 1773.0, 1250.0, 1761.0, 1272.0, 1704.0, 1292.0, 1661.0, 1301.0, 1662.0, 1319.0, 1665.0, 1321.0, 1647.0, 1329.0, 1628.0, 1337.0, 1612.0, 1345.0, 1608.0, 1363.0, 1610.0, 1363.0, 1622.0, 1371.0, 1634.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [1244.0, 1484.0, 36.0, 46.0], 'category_id': 3, 'segmentation': [[1260.0, 1530.0, 1280.0, 1484.0, 1272.0, 1484.0, 1262.0, 1484.0, 1244.0, 1528.0, 1260.0, 1530.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_5/000051.JPG', 'height': 3264, 'width': 2448, 'image_id': 1066, 'annotations': [{'iscrowd': 0, 'bbox': [1151.0, 1282.0, 56.0, 60.0], 'category_id': 8, 'segmentation': [[1156.0, 1318.0, 1181.0, 1290.0, 1187.0, 1285.0, 1195.0, 1282.0, 1202.0, 1283.0, 1206.0, 1288.0, 1207.0, 1297.0, 1197.0, 1312.0, 1169.0, 1340.0, 1159.0, 1342.0, 1151.0, 1335.0, 1153.0, 1325.0, 1156.0, 1318.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [865.0, 1143.0, 353.0, 254.0], 'category_id': 2, 'segmentation': [[1130.0, 1205.0, 1168.0, 1218.0, 1180.0, 1228.0, 1187.0, 1236.0, 1195.0, 1246.0, 1202.0, 1248.0, 1211.0, 1257.0, 1217.0, 1270.0, 1218.0, 1291.0, 1216.0, 1308.0, 1211.0, 1329.0, 1203.0, 1348.0, 1194.0, 1366.0, 1181.0, 1383.0, 1167.0, 1395.0, 1152.0, 1396.0, 1135.0, 1394.0, 1099.0, 1397.0, 1072.0, 1388.0, 1036.0, 1374.0, 1049.0, 1364.0, 1060.0, 1365.0, 1072.0, 1359.0, 1079.0, 1358.0, 1079.0, 1351.0, 1081.0, 1341.0, 1081.0, 1327.0, 1073.0, 1317.0, 1067.0, 1311.0, 1058.0, 1305.0, 1049.0, 1293.0, 1044.0, 1289.0, 1039.0, 1283.0, 1030.0, 1286.0, 1023.0, 1287.0, 1012.0, 1286.0, 1006.0, 1287.0, 1001.0, 1294.0, 967.0, 1288.0, 967.0, 1297.0, 967.0, 1309.0, 965.0, 1314.0, 963.0, 1315.0, 964.0, 1329.0, 957.0, 1330.0, 955.0, 1314.0, 952.0, 1308.0, 944.0, 1299.0, 937.0, 1292.0, 930.0, 1289.0, 916.0, 1287.0, 905.0, 1292.0, 898.0, 1295.0, 889.0, 1297.0, 876.0, 1301.0, 872.0, 1294.0, 868.0, 1280.0, 866.0, 1266.0, 865.0, 1252.0, 865.0, 1237.0, 870.0, 1213.0, 879.0, 1194.0, 886.0, 1183.0, 902.0, 1166.0, 914.0, 1155.0, 931.0, 1145.0, 942.0, 1143.0, 952.0, 1143.0, 993.0, 1157.0, 1130.0, 1205.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_5/000052.JPG', 'height': 3264, 'width': 2448, 'image_id': 1067, 'annotations': [{'iscrowd': 0, 'bbox': [1517.0, 976.0, 86.0, 236.0], 'category_id': 0, 'segmentation': [[1536.0, 1059.0, 1534.0, 1077.0, 1528.0, 1087.0, 1520.0, 1107.0, 1517.0, 1132.0, 1519.0, 1148.0, 1522.0, 1156.0, 1525.0, 1162.0, 1523.0, 1176.0, 1525.0, 1183.0, 1528.0, 1200.0, 1527.0, 1204.0, 1530.0, 1209.0, 1536.0, 1212.0, 1538.0, 1204.0, 1541.0, 1204.0, 1544.0, 1207.0, 1546.0, 1209.0, 1547.0, 1212.0, 1551.0, 1210.0, 1553.0, 1207.0, 1553.0, 1203.0, 1556.0, 1196.0, 1558.0, 1191.0, 1560.0, 1187.0, 1563.0, 1186.0, 1566.0, 1178.0, 1567.0, 1169.0, 1579.0, 1152.0, 1583.0, 1134.0, 1585.0, 1112.0, 1588.0, 1091.0, 1588.0, 1074.0, 1588.0, 1059.0, 1593.0, 1043.0, 1600.0, 1021.0, 1603.0, 1009.0, 1603.0, 997.0, 1600.0, 988.0, 1595.0, 982.0, 1581.0, 979.0, 1563.0, 976.0, 1553.0, 977.0, 1542.0, 987.0, 1535.0, 1001.0, 1536.0, 1017.0, 1538.0, 1033.0, 1538.0, 1046.0, 1536.0, 1059.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_5/000059.JPG', 'height': 3264, 'width': 2448, 'image_id': 1073, 'annotations': [{'iscrowd': 0, 'bbox': [1077.0, 1612.0, 367.0, 285.0], 'category_id': 7, 'segmentation': [[1079.0, 1642.0, 1095.0, 1661.0, 1106.0, 1681.0, 1118.0, 1693.0, 1127.0, 1717.0, 1143.0, 1727.0, 1169.0, 1777.0, 1173.0, 1785.0, 1172.0, 1799.0, 1166.0, 1835.0, 1159.0, 1870.0, 1159.0, 1883.0, 1160.0, 1897.0, 1172.0, 1895.0, 1189.0, 1893.0, 1199.0, 1890.0, 1206.0, 1890.0, 1214.0, 1890.0, 1222.0, 1887.0, 1239.0, 1886.0, 1245.0, 1882.0, 1297.0, 1881.0, 1340.0, 1874.0, 1380.0, 1872.0, 1391.0, 1869.0, 1421.0, 1869.0, 1438.0, 1860.0, 1444.0, 1846.0, 1442.0, 1831.0, 1429.0, 1817.0, 1407.0, 1796.0, 1394.0, 1775.0, 1373.0, 1753.0, 1355.0, 1732.0, 1345.0, 1717.0, 1340.0, 1689.0, 1335.0, 1668.0, 1353.0, 1632.0, 1352.0, 1625.0, 1352.0, 1615.0, 1344.0, 1613.0, 1312.0, 1614.0, 1275.0, 1612.0, 1254.0, 1612.0, 1229.0, 1614.0, 1200.0, 1615.0, 1174.0, 1616.0, 1152.0, 1616.0, 1133.0, 1617.0, 1118.0, 1620.0, 1101.0, 1622.0, 1089.0, 1625.0, 1080.0, 1629.0, 1077.0, 1634.0, 1079.0, 1642.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_5/000060.JPG', 'height': 3264, 'width': 2448, 'image_id': 1074, 'annotations': [{'iscrowd': 0, 'bbox': [1302.0, 843.0, 147.0, 241.0], 'category_id': 4, 'segmentation': [[1429.0, 954.0, 1413.0, 1008.0, 1396.0, 1064.0, 1384.0, 1075.0, 1372.0, 1080.0, 1349.0, 1084.0, 1327.0, 1079.0, 1312.0, 1065.0, 1306.0, 1046.0, 1303.0, 1027.0, 1308.0, 911.0, 1307.0, 906.0, 1304.0, 897.0, 1302.0, 882.0, 1308.0, 869.0, 1316.0, 860.0, 1326.0, 853.0, 1343.0, 846.0, 1360.0, 843.0, 1385.0, 844.0, 1412.0, 851.0, 1431.0, 862.0, 1442.0, 875.0, 1449.0, 889.0, 1448.0, 907.0, 1441.0, 920.0, 1429.0, 954.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [1360.0, 1304.0, 272.0, 177.0], 'category_id': 4, 'segmentation': [[1366.0, 1451.0, 1374.0, 1476.0, 1381.0, 1481.0, 1407.0, 1480.0, 1578.0, 1458.0, 1602.0, 1457.0, 1609.0, 1460.0, 1624.0, 1456.0, 1631.0, 1445.0, 1632.0, 1419.0, 1629.0, 1392.0, 1623.0, 1368.0, 1619.0, 1344.0, 1610.0, 1320.0, 1602.0, 1310.0, 1594.0, 1304.0, 1580.0, 1307.0, 1572.0, 1317.0, 1558.0, 1323.0, 1378.0, 1378.0, 1363.0, 1384.0, 1360.0, 1406.0, 1361.0, 1425.0, 1366.0, 1451.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_6/000101.JPG', 'height': 1968, 'width': 2624, 'image_id': 1080, 'annotations': [{'iscrowd': 0, 'bbox': [1074.0, 1344.0, 154.0, 124.0], 'category_id': 0, 'segmentation': [[1199.0, 1452.0, 1218.0, 1441.0, 1228.0, 1416.0, 1226.0, 1390.0, 1205.0, 1373.0, 1180.0, 1360.0, 1165.0, 1351.0, 1148.0, 1346.0, 1123.0, 1344.0, 1101.0, 1349.0, 1095.0, 1357.0, 1093.0, 1368.0, 1084.0, 1384.0, 1075.0, 1398.0, 1074.0, 1408.0, 1093.0, 1431.0, 1100.0, 1448.0, 1121.0, 1463.0, 1149.0, 1468.0, 1186.0, 1461.0, 1199.0, 1452.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [1501.0, 1125.0, 203.0, 63.0], 'category_id': 7, 'segmentation': [[1537.0, 1171.0, 1515.0, 1171.0, 1501.0, 1164.0, 1506.0, 1132.0, 1514.0, 1131.0, 1520.0, 1135.0, 1536.0, 1131.0, 1552.0, 1125.0, 1561.0, 1135.0, 1571.0, 1139.0, 1578.0, 1140.0, 1591.0, 1132.0, 1606.0, 1134.0, 1630.0, 1141.0, 1641.0, 1148.0, 1671.0, 1166.0, 1690.0, 1178.0, 1704.0, 1183.0, 1701.0, 1188.0, 1691.0, 1188.0, 1667.0, 1177.0, 1646.0, 1179.0, 1635.0, 1187.0, 1612.0, 1177.0, 1610.0, 1169.0, 1598.0, 1158.0, 1590.0, 1145.0, 1583.0, 1156.0, 1572.0, 1154.0, 1565.0, 1152.0, 1559.0, 1170.0, 1553.0, 1174.0, 1537.0, 1171.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_6/000097.JPG', 'height': 2760, 'width': 3680, 'image_id': 1084, 'annotations': [{'iscrowd': 0, 'bbox': [1450.0, 1257.0, 468.0, 212.0], 'category_id': 0, 'segmentation': [[1568.0, 1257.0, 1581.0, 1258.0, 1888.0, 1292.0, 1918.0, 1305.0, 1913.0, 1392.0, 1897.0, 1456.0, 1819.0, 1430.0, 1886.0, 1469.0, 1699.0, 1443.0, 1594.0, 1431.0, 1565.0, 1426.0, 1533.0, 1411.0, 1511.0, 1376.0, 1495.0, 1371.0, 1475.0, 1371.0, 1456.0, 1368.0, 1450.0, 1360.0, 1453.0, 1338.0, 1458.0, 1307.0, 1466.0, 1290.0, 1491.0, 1285.0, 1510.0, 1287.0, 1514.0, 1294.0, 1526.0, 1292.0, 1546.0, 1274.0, 1568.0, 1257.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [1570.0, 1455.0, 512.0, 227.0], 'category_id': 0, 'segmentation': [[1689.0, 1597.0, 1832.0, 1636.0, 1961.0, 1667.0, 2026.0, 1682.0, 2053.0, 1666.0, 2060.0, 1635.0, 2076.0, 1622.0, 2076.0, 1609.0, 2070.0, 1597.0, 2082.0, 1575.0, 2062.0, 1551.0, 2005.0, 1531.0, 1729.0, 1455.0, 1703.0, 1455.0, 1639.0, 1458.0, 1623.0, 1462.0, 1588.0, 1456.0, 1579.0, 1463.0, 1571.0, 1484.0, 1570.0, 1505.0, 1572.0, 1514.0, 1600.0, 1524.0, 1612.0, 1530.0, 1642.0, 1562.0, 1660.0, 1580.0, 1689.0, 1597.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [1452.0, 1283.0, 41.0, 87.0], 'category_id': 1, 'segmentation': [[1476.0, 1370.0, 1476.0, 1352.0, 1478.0, 1332.0, 1482.0, 1309.0, 1493.0, 1286.0, 1481.0, 1283.0, 1468.0, 1287.0, 1457.0, 1305.0, 1453.0, 1331.0, 1452.0, 1360.0, 1458.0, 1368.0, 1476.0, 1370.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [1569.0, 1456.0, 39.0, 63.0], 'category_id': 1, 'segmentation': [[1590.0, 1519.0, 1592.0, 1505.0, 1595.0, 1485.0, 1601.0, 1465.0, 1608.0, 1459.0, 1590.0, 1456.0, 1583.0, 1460.0, 1576.0, 1468.0, 1572.0, 1481.0, 1569.0, 1493.0, 1570.0, 1500.0, 1569.0, 1511.0, 1572.0, 1514.0, 1590.0, 1519.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [1918.0, 1134.0, 201.0, 245.0], 'category_id': 7, 'segmentation': [[1956.0, 1373.0, 2031.0, 1349.0, 2073.0, 1336.0, 2100.0, 1326.0, 2119.0, 1304.0, 2118.0, 1272.0, 2109.0, 1190.0, 2105.0, 1134.0, 2077.0, 1152.0, 1958.0, 1281.0, 1919.0, 1337.0, 1918.0, 1374.0, 1928.0, 1379.0, 1956.0, 1373.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [2066.0, 1515.0, 89.0, 121.0], 'category_id': 7, 'segmentation': [[2150.0, 1636.0, 2155.0, 1515.0, 2134.0, 1520.0, 2120.0, 1541.0, 2123.0, 1561.0, 2129.0, 1583.0, 2123.0, 1597.0, 2095.0, 1572.0, 2084.0, 1575.0, 2072.0, 1592.0, 2071.0, 1599.0, 2076.0, 1606.0, 2077.0, 1619.0, 2068.0, 1631.0, 2066.0, 1632.0, 2150.0, 1636.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [1307.0, 1190.0, 79.0, 106.0], 'category_id': 6, 'segmentation': [[1324.0, 1296.0, 1365.0, 1229.0, 1386.0, 1200.0, 1367.0, 1190.0, 1355.0, 1196.0, 1307.0, 1273.0, 1324.0, 1296.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_6/000080.JPG', 'height': 2448, 'width': 3264, 'image_id': 1099, 'annotations': [{'iscrowd': 0, 'bbox': [737.0, 1948.0, 477.0, 162.0], 'category_id': 0, 'segmentation': [[759.0, 2076.0, 878.0, 2083.0, 929.0, 2075.0, 965.0, 2083.0, 987.0, 2100.0, 1058.0, 2106.0, 1097.0, 2110.0, 1143.0, 2090.0, 1180.0, 2076.0, 1209.0, 2076.0, 1214.0, 2042.0, 1211.0, 2028.0, 1198.0, 2024.0, 1183.0, 2031.0, 1154.0, 2001.0, 1120.0, 1981.0, 1073.0, 1970.0, 1013.0, 1968.0, 963.0, 1974.0, 896.0, 1964.0, 821.0, 1960.0, 782.0, 1948.0, 757.0, 1965.0, 740.0, 1995.0, 737.0, 2038.0, 741.0, 2059.0, 759.0, 2076.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [1193.0, 2024.0, 22.0, 53.0], 'category_id': 1, 'segmentation': [[1193.0, 2074.0, 1193.0, 2057.0, 1193.0, 2042.0, 1197.0, 2030.0, 1200.0, 2024.0, 1211.0, 2024.0, 1215.0, 2043.0, 1212.0, 2060.0, 1210.0, 2074.0, 1203.0, 2077.0, 1193.0, 2074.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_6/000062.JPG', 'height': 2448, 'width': 3264, 'image_id': 1116, 'annotations': [{'iscrowd': 0, 'bbox': [1131.0, 1561.0, 402.0, 341.0], 'category_id': 7, 'segmentation': [[1131.0, 1862.0, 1186.0, 1762.0, 1219.0, 1728.0, 1316.0, 1644.0, 1347.0, 1638.0, 1383.0, 1635.0, 1357.0, 1618.0, 1371.0, 1603.0, 1399.0, 1588.0, 1443.0, 1574.0, 1479.0, 1561.0, 1459.0, 1580.0, 1489.0, 1573.0, 1507.0, 1579.0, 1523.0, 1595.0, 1529.0, 1614.0, 1510.0, 1619.0, 1512.0, 1632.0, 1533.0, 1637.0, 1525.0, 1655.0, 1519.0, 1670.0, 1504.0, 1686.0, 1413.0, 1702.0, 1418.0, 1729.0, 1407.0, 1744.0, 1396.0, 1747.0, 1393.0, 1775.0, 1380.0, 1800.0, 1362.0, 1825.0, 1336.0, 1849.0, 1315.0, 1835.0, 1292.0, 1837.0, 1273.0, 1856.0, 1252.0, 1879.0, 1236.0, 1888.0, 1198.0, 1902.0, 1169.0, 1890.0, 1147.0, 1881.0, 1131.0, 1862.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_6/000050.JPG', 'height': 3264, 'width': 2448, 'image_id': 1128, 'annotations': [{'iscrowd': 0, 'bbox': [1038.0, 989.0, 96.0, 38.0], 'category_id': 6, 'segmentation': [[1038.0, 993.0, 1051.0, 1012.0, 1068.0, 1027.0, 1123.0, 1027.0, 1134.0, 1024.0, 1131.0, 1005.0, 1092.0, 1003.0, 1080.0, 989.0, 1038.0, 993.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_6/000043.JPG', 'height': 2448, 'width': 3264, 'image_id': 1134, 'annotations': [{'iscrowd': 0, 'bbox': [1107.0, 701.0, 435.0, 569.0], 'category_id': 7, 'segmentation': [[1155.0, 763.0, 1140.0, 812.0, 1123.0, 852.0, 1119.0, 876.0, 1107.0, 931.0, 1113.0, 1035.0, 1116.0, 1085.0, 1143.0, 1163.0, 1172.0, 1210.0, 1183.0, 1221.0, 1202.0, 1229.0, 1235.0, 1238.0, 1270.0, 1238.0, 1286.0, 1232.0, 1317.0, 1252.0, 1327.0, 1256.0, 1355.0, 1270.0, 1387.0, 1265.0, 1398.0, 1263.0, 1428.0, 1245.0, 1441.0, 1233.0, 1471.0, 1266.0, 1485.0, 1254.0, 1500.0, 1245.0, 1509.0, 1248.0, 1514.0, 1242.0, 1528.0, 1229.0, 1527.0, 1220.0, 1528.0, 1205.0, 1525.0, 1199.0, 1530.0, 1188.0, 1524.0, 1178.0, 1525.0, 1166.0, 1523.0, 1144.0, 1507.0, 1141.0, 1502.0, 1138.0, 1511.0, 1129.0, 1521.0, 1119.0, 1532.0, 1095.0, 1538.0, 1072.0, 1542.0, 1042.0, 1539.0, 1007.0, 1534.0, 983.0, 1522.0, 950.0, 1519.0, 920.0, 1503.0, 896.0, 1490.0, 888.0, 1459.0, 845.0, 1405.0, 783.0, 1375.0, 751.0, 1342.0, 743.0, 1301.0, 728.0, 1258.0, 707.0, 1238.0, 702.0, 1230.0, 701.0, 1187.0, 715.0, 1170.0, 739.0, 1155.0, 763.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [2205.0, 1736.0, 284.0, 278.0], 'category_id': 7, 'segmentation': [[2419.0, 1736.0, 2426.0, 1741.0, 2442.0, 1765.0, 2466.0, 1802.0, 2489.0, 1846.0, 2488.0, 1854.0, 2474.0, 1866.0, 2464.0, 1870.0, 2438.0, 1894.0, 2435.0, 1898.0, 2464.0, 1960.0, 2483.0, 1996.0, 2470.0, 2003.0, 2439.0, 2009.0, 2403.0, 2014.0, 2363.0, 2012.0, 2339.0, 2010.0, 2318.0, 2009.0, 2311.0, 2007.0, 2281.0, 1993.0, 2274.0, 1987.0, 2272.0, 1980.0, 2273.0, 1964.0, 2252.0, 1936.0, 2236.0, 1908.0, 2231.0, 1898.0, 2226.0, 1896.0, 2213.0, 1879.0, 2205.0, 1862.0, 2207.0, 1825.0, 2214.0, 1806.0, 2221.0, 1800.0, 2232.0, 1801.0, 2292.0, 1801.0, 2324.0, 1803.0, 2334.0, 1805.0, 2355.0, 1792.0, 2359.0, 1792.0, 2364.0, 1784.0, 2372.0, 1774.0, 2386.0, 1761.0, 2419.0, 1736.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_6/000037.JPG', 'height': 1968, 'width': 2624, 'image_id': 1140, 'annotations': [{'iscrowd': 0, 'bbox': [1.0, 1340.0, 187.0, 93.0], 'category_id': 2, 'segmentation': [[2.0, 1340.0, 175.0, 1369.0, 185.0, 1383.0, 188.0, 1396.0, 182.0, 1421.0, 169.0, 1433.0, 148.0, 1433.0, 89.0, 1423.0, 1.0, 1408.0, 2.0, 1340.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [883.0, 1050.0, 225.0, 143.0], 'category_id': 0, 'segmentation': [[931.0, 1190.0, 953.0, 1177.0, 978.0, 1162.0, 1001.0, 1154.0, 1028.0, 1144.0, 1056.0, 1130.0, 1072.0, 1114.0, 1083.0, 1100.0, 1090.0, 1084.0, 1108.0, 1077.0, 1094.0, 1050.0, 1077.0, 1056.0, 1062.0, 1051.0, 1050.0, 1053.0, 1032.0, 1057.0, 983.0, 1079.0, 962.0, 1093.0, 950.0, 1100.0, 918.0, 1112.0, 892.0, 1123.0, 884.0, 1130.0, 883.0, 1142.0, 889.0, 1153.0, 900.0, 1175.0, 906.0, 1190.0, 919.0, 1193.0, 931.0, 1190.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [1616.0, 705.0, 261.0, 248.0], 'category_id': 0, 'segmentation': [[1826.0, 953.0, 1691.0, 823.0, 1683.0, 814.0, 1681.0, 799.0, 1670.0, 780.0, 1652.0, 759.0, 1616.0, 728.0, 1630.0, 710.0, 1636.0, 705.0, 1666.0, 730.0, 1688.0, 751.0, 1702.0, 761.0, 1716.0, 762.0, 1737.0, 767.0, 1872.0, 892.0, 1877.0, 903.0, 1859.0, 924.0, 1840.0, 943.0, 1826.0, 953.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [1753.0, 159.0, 148.0, 79.0], 'category_id': 7, 'segmentation': [[1774.0, 201.0, 1766.0, 194.0, 1758.0, 177.0, 1753.0, 169.0, 1753.0, 165.0, 1767.0, 166.0, 1783.0, 168.0, 1804.0, 164.0, 1826.0, 163.0, 1850.0, 161.0, 1870.0, 159.0, 1878.0, 173.0, 1883.0, 187.0, 1888.0, 201.0, 1890.0, 220.0, 1892.0, 229.0, 1901.0, 236.0, 1876.0, 237.0, 1844.0, 238.0, 1826.0, 223.0, 1816.0, 227.0, 1812.0, 225.0, 1810.0, 215.0, 1799.0, 212.0, 1795.0, 205.0, 1800.0, 199.0, 1794.0, 193.0, 1785.0, 193.0, 1774.0, 201.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [2168.0, 320.0, 78.0, 94.0], 'category_id': 7, 'segmentation': [[2223.0, 413.0, 2245.0, 414.0, 2246.0, 408.0, 2244.0, 393.0, 2235.0, 368.0, 2230.0, 362.0, 2216.0, 333.0, 2198.0, 326.0, 2187.0, 322.0, 2177.0, 320.0, 2168.0, 329.0, 2175.0, 337.0, 2188.0, 348.0, 2199.0, 360.0, 2210.0, 368.0, 2205.0, 378.0, 2216.0, 400.0, 2223.0, 413.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [2326.0, 390.0, 88.0, 95.0], 'category_id': 7, 'segmentation': [[2357.0, 456.0, 2337.0, 422.0, 2326.0, 408.0, 2351.0, 390.0, 2378.0, 390.0, 2398.0, 423.0, 2402.0, 438.0, 2386.0, 443.0, 2414.0, 469.0, 2414.0, 477.0, 2406.0, 485.0, 2385.0, 468.0, 2366.0, 465.0, 2357.0, 456.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [1733.0, 252.0, 88.0, 51.0], 'category_id': 6, 'segmentation': [[1752.0, 300.0, 1764.0, 293.0, 1777.0, 295.0, 1801.0, 287.0, 1807.0, 290.0, 1807.0, 303.0, 1818.0, 298.0, 1821.0, 288.0, 1820.0, 273.0, 1813.0, 261.0, 1805.0, 253.0, 1794.0, 252.0, 1777.0, 258.0, 1764.0, 263.0, 1759.0, 265.0, 1745.0, 262.0, 1735.0, 268.0, 1733.0, 278.0, 1737.0, 287.0, 1744.0, 289.0, 1743.0, 298.0, 1752.0, 300.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [1912.0, 238.0, 58.0, 141.0], 'category_id': 6, 'segmentation': [[1932.0, 379.0, 1940.0, 372.0, 1949.0, 365.0, 1947.0, 351.0, 1954.0, 341.0, 1960.0, 326.0, 1955.0, 309.0, 1955.0, 301.0, 1965.0, 288.0, 1969.0, 281.0, 1970.0, 265.0, 1969.0, 250.0, 1963.0, 246.0, 1964.0, 264.0, 1964.0, 279.0, 1954.0, 292.0, 1951.0, 281.0, 1948.0, 262.0, 1955.0, 242.0, 1953.0, 239.0, 1945.0, 238.0, 1936.0, 239.0, 1937.0, 254.0, 1934.0, 270.0, 1934.0, 277.0, 1927.0, 283.0, 1923.0, 295.0, 1923.0, 301.0, 1936.0, 310.0, 1933.0, 323.0, 1928.0, 329.0, 1921.0, 334.0, 1912.0, 343.0, 1912.0, 365.0, 1918.0, 372.0, 1932.0, 379.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [822.0, 338.0, 29.0, 23.0], 'category_id': 6, 'segmentation': [[829.0, 361.0, 839.0, 355.0, 849.0, 348.0, 849.0, 342.0, 851.0, 338.0, 845.0, 339.0, 829.0, 344.0, 823.0, 350.0, 822.0, 361.0, 829.0, 361.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [741.0, 397.0, 43.0, 19.0], 'category_id': 6, 'segmentation': [[749.0, 416.0, 752.0, 416.0, 752.0, 411.0, 763.0, 408.0, 775.0, 403.0, 784.0, 397.0, 745.0, 397.0, 741.0, 401.0, 744.0, 410.0, 749.0, 416.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [1046.0, 275.0, 13.0, 15.0], 'category_id': 6, 'segmentation': [[1046.0, 290.0, 1055.0, 289.0, 1059.0, 286.0, 1059.0, 281.0, 1055.0, 276.0, 1048.0, 275.0, 1046.0, 280.0, 1046.0, 290.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [805.0, 1054.0, 26.0, 33.0], 'category_id': 6, 'segmentation': [[818.0, 1084.0, 823.0, 1087.0, 831.0, 1083.0, 830.0, 1078.0, 821.0, 1061.0, 813.0, 1054.0, 805.0, 1055.0, 805.0, 1063.0, 811.0, 1070.0, 818.0, 1084.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_6/000026.JPG', 'height': 3264, 'width': 2448, 'image_id': 1150, 'annotations': [{'iscrowd': 0, 'bbox': [701.0, 1444.0, 795.0, 859.0], 'category_id': 7, 'segmentation': [[740.0, 2054.0, 813.0, 2127.0, 885.0, 2194.0, 936.0, 2241.0, 982.0, 2276.0, 1024.0, 2303.0, 1065.0, 2254.0, 1106.0, 2213.0, 1100.0, 2201.0, 1087.0, 2198.0, 1083.0, 2186.0, 1104.0, 2194.0, 1138.0, 2150.0, 1211.0, 2055.0, 1229.0, 2029.0, 1237.0, 2013.0, 1294.0, 1920.0, 1263.0, 1905.0, 1260.0, 1893.0, 1308.0, 1884.0, 1317.0, 1864.0, 1322.0, 1854.0, 1364.0, 1804.0, 1416.0, 1712.0, 1468.0, 1604.0, 1477.0, 1581.0, 1496.0, 1556.0, 1382.0, 1504.0, 1372.0, 1529.0, 1378.0, 1540.0, 1373.0, 1554.0, 1363.0, 1556.0, 1354.0, 1549.0, 1354.0, 1537.0, 1365.0, 1532.0, 1371.0, 1510.0, 1334.0, 1487.0, 1309.0, 1472.0, 1229.0, 1444.0, 1215.0, 1464.0, 1222.0, 1485.0, 1204.0, 1496.0, 1199.0, 1485.0, 1072.0, 1476.0, 1051.0, 1566.0, 1036.0, 1626.0, 1035.0, 1644.0, 1043.0, 1670.0, 1022.0, 1687.0, 923.0, 1775.0, 873.0, 1824.0, 879.0, 1857.0, 801.0, 1899.0, 751.0, 1955.0, 716.0, 1995.0, 704.0, 2016.0, 701.0, 2032.0, 713.0, 2049.0, 740.0, 2054.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_6/000020.JPG', 'height': 3264, 'width': 2448, 'image_id': 1156, 'annotations': [{'iscrowd': 0, 'bbox': [1241.0, 1750.0, 250.0, 174.0], 'category_id': 7, 'segmentation': [[1305.0, 1820.0, 1406.0, 1772.0, 1420.0, 1767.0, 1435.0, 1765.0, 1435.0, 1760.0, 1455.0, 1750.0, 1462.0, 1774.0, 1465.0, 1792.0, 1470.0, 1819.0, 1491.0, 1820.0, 1474.0, 1832.0, 1462.0, 1835.0, 1445.0, 1844.0, 1420.0, 1856.0, 1305.0, 1912.0, 1290.0, 1922.0, 1271.0, 1924.0, 1259.0, 1920.0, 1241.0, 1895.0, 1251.0, 1886.0, 1263.0, 1877.0, 1263.0, 1865.0, 1263.0, 1850.0, 1272.0, 1834.0, 1273.0, 1826.0, 1282.0, 1823.0, 1305.0, 1820.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_6/000014.JPG', 'height': 3264, 'width': 2448, 'image_id': 1161, 'annotations': [{'iscrowd': 0, 'bbox': [718.0, 1321.0, 253.0, 281.0], 'category_id': 0, 'segmentation': [[749.0, 1429.0, 785.0, 1480.0, 798.0, 1489.0, 796.0, 1504.0, 817.0, 1529.0, 828.0, 1553.0, 852.0, 1563.0, 906.0, 1587.0, 925.0, 1598.0, 941.0, 1602.0, 963.0, 1588.0, 971.0, 1572.0, 963.0, 1557.0, 953.0, 1548.0, 950.0, 1523.0, 948.0, 1498.0, 920.0, 1464.0, 891.0, 1442.0, 874.0, 1425.0, 858.0, 1401.0, 805.0, 1330.0, 794.0, 1321.0, 770.0, 1325.0, 749.0, 1330.0, 738.0, 1339.0, 727.0, 1349.0, 720.0, 1364.0, 718.0, 1382.0, 735.0, 1408.0, 749.0, 1429.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [754.0, 1488.0, 22.0, 28.0], 'category_id': 3, 'segmentation': [[776.0, 1516.0, 776.0, 1490.0, 754.0, 1488.0, 758.0, 1516.0, 776.0, 1516.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [596.0, 1420.0, 32.0, 44.0], 'category_id': 3, 'segmentation': [[628.0, 1454.0, 610.0, 1420.0, 596.0, 1426.0, 616.0, 1464.0, 628.0, 1454.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [1340.0, 1782.0, 60.0, 46.0], 'category_id': 3, 'segmentation': [[1386.0, 1828.0, 1340.0, 1800.0, 1352.0, 1782.0, 1400.0, 1816.0, 1386.0, 1828.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [1400.0, 2196.0, 54.0, 32.0], 'category_id': 3, 'segmentation': [[1452.0, 2220.0, 1404.0, 2228.0, 1400.0, 2210.0, 1444.0, 2196.0, 1454.0, 2212.0, 1452.0, 2220.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [1680.0, 2208.0, 42.0, 52.0], 'category_id': 3, 'segmentation': [[1720.0, 2248.0, 1710.0, 2228.0, 1692.0, 2208.0, 1680.0, 2218.0, 1710.0, 2252.0, 1722.0, 2260.0, 1720.0, 2248.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [336.0, 2346.0, 66.0, 54.0], 'category_id': 3, 'segmentation': [[346.0, 2400.0, 402.0, 2352.0, 400.0, 2346.0, 378.0, 2350.0, 336.0, 2388.0, 346.0, 2400.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_6/000009.JPG', 'height': 2448, 'width': 3264, 'image_id': 1165, 'annotations': [{'iscrowd': 0, 'bbox': [766.0, 571.0, 1451.0, 1096.0], 'category_id': 6, 'segmentation': [[1393.0, 1667.0, 820.0, 1204.0, 806.0, 1157.0, 766.0, 1042.0, 1593.0, 571.0, 2196.0, 860.0, 2217.0, 885.0, 2200.0, 993.0, 2172.0, 1040.0, 1393.0, 1667.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_6/000005.JPG', 'height': 3264, 'width': 2448, 'image_id': 1169, 'annotations': [{'iscrowd': 0, 'bbox': [939.0, 1657.0, 349.0, 222.0], 'category_id': 7, 'segmentation': [[942.0, 1784.0, 960.0, 1802.0, 973.0, 1814.0, 977.0, 1813.0, 990.0, 1835.0, 994.0, 1840.0, 1024.0, 1857.0, 1045.0, 1866.0, 1066.0, 1870.0, 1096.0, 1874.0, 1131.0, 1875.0, 1191.0, 1879.0, 1218.0, 1876.0, 1246.0, 1871.0, 1258.0, 1868.0, 1266.0, 1864.0, 1273.0, 1852.0, 1270.0, 1846.0, 1268.0, 1827.0, 1268.0, 1812.0, 1272.0, 1796.0, 1279.0, 1775.0, 1280.0, 1764.0, 1288.0, 1746.0, 1283.0, 1747.0, 1270.0, 1758.0, 1258.0, 1759.0, 1248.0, 1763.0, 1239.0, 1756.0, 1212.0, 1730.0, 1200.0, 1719.0, 1188.0, 1707.0, 1178.0, 1696.0, 1161.0, 1681.0, 1149.0, 1671.0, 1140.0, 1671.0, 1134.0, 1674.0, 1078.0, 1676.0, 1053.0, 1676.0, 1046.0, 1676.0, 1034.0, 1674.0, 1020.0, 1670.0, 1004.0, 1666.0, 992.0, 1664.0, 978.0, 1661.0, 964.0, 1662.0, 954.0, 1661.0, 948.0, 1657.0, 947.0, 1662.0, 948.0, 1667.0, 966.0, 1684.0, 977.0, 1696.0, 984.0, 1708.0, 986.0, 1714.0, 982.0, 1716.0, 972.0, 1714.0, 959.0, 1708.0, 957.0, 1727.0, 954.0, 1729.0, 940.0, 1764.0, 939.0, 1770.0, 942.0, 1784.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [1686.0, 2828.0, 58.0, 34.0], 'category_id': 3, 'segmentation': [[1744.0, 2850.0, 1690.0, 2862.0, 1686.0, 2848.0, 1742.0, 2828.0, 1744.0, 2850.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [1820.0, 3030.0, 70.0, 74.0], 'category_id': 3, 'segmentation': [[1820.0, 3078.0, 1872.0, 3030.0, 1890.0, 3060.0, 1832.0, 3104.0, 1820.0, 3078.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_6/000003.JPG', 'height': 3264, 'width': 2448, 'image_id': 1170, 'annotations': [{'iscrowd': 0, 'bbox': [1356.0, 1425.0, 215.0, 223.0], 'category_id': 6, 'segmentation': [[1366.0, 1425.0, 1409.0, 1460.0, 1431.0, 1484.0, 1475.0, 1533.0, 1485.0, 1543.0, 1508.0, 1556.0, 1532.0, 1575.0, 1544.0, 1588.0, 1562.0, 1604.0, 1571.0, 1614.0, 1570.0, 1619.0, 1565.0, 1621.0, 1557.0, 1614.0, 1545.0, 1606.0, 1536.0, 1598.0, 1534.0, 1600.0, 1545.0, 1610.0, 1554.0, 1618.0, 1562.0, 1625.0, 1569.0, 1633.0, 1569.0, 1636.0, 1562.0, 1633.0, 1556.0, 1627.0, 1545.0, 1618.0, 1536.0, 1611.0, 1530.0, 1606.0, 1525.0, 1603.0, 1525.0, 1606.0, 1565.0, 1637.0, 1564.0, 1639.0, 1560.0, 1637.0, 1553.0, 1635.0, 1521.0, 1612.0, 1519.0, 1614.0, 1554.0, 1642.0, 1557.0, 1645.0, 1555.0, 1648.0, 1543.0, 1645.0, 1516.0, 1629.0, 1504.0, 1618.0, 1491.0, 1604.0, 1484.0, 1586.0, 1481.0, 1572.0, 1479.0, 1562.0, 1473.0, 1553.0, 1458.0, 1536.0, 1440.0, 1520.0, 1415.0, 1497.0, 1397.0, 1482.0, 1380.0, 1462.0, 1362.0, 1442.0, 1356.0, 1432.0, 1358.0, 1427.0, 1366.0, 1425.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [2022.0, 1172.0, 46.0, 54.0], 'category_id': 3, 'segmentation': [[2048.0, 1226.0, 2068.0, 1180.0, 2044.0, 1172.0, 2022.0, 1216.0, 2030.0, 1226.0, 2048.0, 1226.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_6/000001.JPG', 'height': 3264, 'width': 2448, 'image_id': 1172, 'annotations': [{'iscrowd': 0, 'bbox': [646.0, 2065.0, 908.0, 439.0], 'category_id': 7, 'segmentation': [[646.0, 2168.0, 675.0, 2481.0, 708.0, 2499.0, 749.0, 2504.0, 822.0, 2486.0, 886.0, 2462.0, 966.0, 2445.0, 1135.0, 2384.0, 1237.0, 2337.0, 1329.0, 2302.0, 1379.0, 2273.0, 1411.0, 2301.0, 1418.0, 2314.0, 1454.0, 2313.0, 1466.0, 2315.0, 1475.0, 2281.0, 1479.0, 2222.0, 1484.0, 2191.0, 1554.0, 2217.0, 1523.0, 2183.0, 1495.0, 2134.0, 1460.0, 2114.0, 1447.0, 2095.0, 1440.0, 2075.0, 1455.0, 2065.0, 1385.0, 2066.0, 1287.0, 2077.0, 1147.0, 2089.0, 1053.0, 2099.0, 962.0, 2121.0, 865.0, 2152.0, 779.0, 2156.0, 646.0, 2168.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [1865.0, 1732.0, 576.0, 680.0], 'category_id': 7, 'segmentation': [[2028.0, 1970.0, 1974.0, 2050.0, 1941.0, 2090.0, 1904.0, 2138.0, 1893.0, 2148.0, 1879.0, 2165.0, 1865.0, 2187.0, 1991.0, 2273.0, 2057.0, 2323.0, 2078.0, 2337.0, 2102.0, 2355.0, 2167.0, 2412.0, 2183.0, 2386.0, 2230.0, 2283.0, 2244.0, 2251.0, 2252.0, 2231.0, 2268.0, 2199.0, 2301.0, 2120.0, 2328.0, 2054.0, 2348.0, 1990.0, 2357.0, 1964.0, 2380.0, 1938.0, 2382.0, 1906.0, 2392.0, 1884.0, 2405.0, 1886.0, 2420.0, 1868.0, 2441.0, 1844.0, 2434.0, 1838.0, 2423.0, 1841.0, 2418.0, 1837.0, 2347.0, 1814.0, 2334.0, 1807.0, 2306.0, 1802.0, 2291.0, 1800.0, 2279.0, 1806.0, 2295.0, 1819.0, 2298.0, 1828.0, 2286.0, 1832.0, 2253.0, 1830.0, 2215.0, 1831.0, 2244.0, 1800.0, 2222.0, 1783.0, 2171.0, 1761.0, 2148.0, 1745.0, 2116.0, 1732.0, 2105.0, 1751.0, 2095.0, 1780.0, 2087.0, 1787.0, 2079.0, 1816.0, 2099.0, 1845.0, 2094.0, 1864.0, 2082.0, 1886.0, 2057.0, 1929.0, 2028.0, 1970.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [601.0, 1104.0, 1050.0, 590.0], 'category_id': 7, 'segmentation': [[885.0, 1357.0, 1240.0, 1168.0, 1377.0, 1104.0, 1521.0, 1135.0, 1540.0, 1146.0, 1613.0, 1215.0, 1646.0, 1263.0, 1646.0, 1279.0, 1651.0, 1311.0, 1627.0, 1328.0, 1571.0, 1356.0, 1489.0, 1405.0, 1421.0, 1451.0, 1350.0, 1496.0, 1332.0, 1483.0, 1291.0, 1449.0, 1148.0, 1523.0, 1147.0, 1548.0, 1168.0, 1601.0, 1046.0, 1694.0, 1022.0, 1692.0, 928.0, 1655.0, 783.0, 1643.0, 736.0, 1625.0, 672.0, 1604.0, 661.0, 1630.0, 642.0, 1624.0, 605.0, 1551.0, 601.0, 1527.0, 601.0, 1480.0, 631.0, 1470.0, 650.0, 1459.0, 683.0, 1465.0, 804.0, 1405.0, 843.0, 1384.0, 885.0, 1357.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [1146.0, 1450.0, 527.0, 727.0], 'category_id': 6, 'segmentation': [[1357.0, 1958.0, 1264.0, 1801.0, 1188.0, 1643.0, 1146.0, 1547.0, 1147.0, 1525.0, 1169.0, 1513.0, 1252.0, 1470.0, 1290.0, 1450.0, 1316.0, 1471.0, 1354.0, 1511.0, 1466.0, 1630.0, 1559.0, 1726.0, 1641.0, 1849.0, 1648.0, 1874.0, 1640.0, 1918.0, 1621.0, 1970.0, 1649.0, 2049.0, 1673.0, 2100.0, 1654.0, 2112.0, 1604.0, 2149.0, 1563.0, 2169.0, 1523.0, 2177.0, 1495.0, 2134.0, 1470.0, 2118.0, 1474.0, 2102.0, 1452.0, 2084.0, 1442.0, 2077.0, 1441.0, 2076.0, 1455.0, 2065.0, 1425.0, 2064.0, 1401.0, 2030.0, 1357.0, 1958.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [1870.0, 1438.0, 139.0, 395.0], 'category_id': 6, 'segmentation': [[1954.0, 1831.0, 1972.0, 1824.0, 1989.0, 1803.0, 1996.0, 1779.0, 1995.0, 1754.0, 1984.0, 1704.0, 1974.0, 1648.0, 1971.0, 1624.0, 1972.0, 1605.0, 1985.0, 1587.0, 2004.0, 1561.0, 2009.0, 1537.0, 2004.0, 1493.0, 1991.0, 1468.0, 1980.0, 1442.0, 1970.0, 1449.0, 1967.0, 1542.0, 1962.0, 1541.0, 1954.0, 1445.0, 1947.0, 1447.0, 1939.0, 1486.0, 1937.0, 1526.0, 1937.0, 1546.0, 1929.0, 1543.0, 1922.0, 1446.0, 1917.0, 1444.0, 1912.0, 1453.0, 1906.0, 1530.0, 1903.0, 1532.0, 1892.0, 1446.0, 1888.0, 1438.0, 1879.0, 1451.0, 1870.0, 1488.0, 1872.0, 1525.0, 1886.0, 1560.0, 1903.0, 1581.0, 1914.0, 1608.0, 1913.0, 1640.0, 1909.0, 1684.0, 1902.0, 1739.0, 1898.0, 1767.0, 1900.0, 1780.0, 1909.0, 1801.0, 1918.0, 1815.0, 1936.0, 1828.0, 1944.0, 1833.0, 1943.0, 1832.0, 1954.0, 1831.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_7/000016.JPG', 'height': 3264, 'width': 2448, 'image_id': 1187, 'annotations': [{'iscrowd': 0, 'bbox': [358.0, 844.0, 345.0, 120.0], 'category_id': 0, 'segmentation': [[374.0, 862.0, 399.0, 859.0, 406.0, 859.0, 414.0, 856.0, 426.0, 856.0, 432.0, 857.0, 446.0, 854.0, 458.0, 855.0, 465.0, 852.0, 485.0, 851.0, 499.0, 848.0, 516.0, 850.0, 571.0, 845.0, 584.0, 844.0, 593.0, 854.0, 598.0, 865.0, 614.0, 845.0, 620.0, 846.0, 609.0, 868.0, 612.0, 872.0, 633.0, 849.0, 642.0, 848.0, 650.0, 849.0, 656.0, 854.0, 660.0, 859.0, 666.0, 857.0, 670.0, 856.0, 694.0, 858.0, 700.0, 869.0, 703.0, 884.0, 702.0, 899.0, 699.0, 905.0, 693.0, 908.0, 679.0, 910.0, 668.0, 911.0, 652.0, 925.0, 639.0, 931.0, 615.0, 935.0, 587.0, 941.0, 552.0, 946.0, 521.0, 949.0, 493.0, 954.0, 453.0, 959.0, 429.0, 961.0, 399.0, 964.0, 387.0, 963.0, 377.0, 955.0, 369.0, 941.0, 361.0, 911.0, 358.0, 891.0, 358.0, 876.0, 361.0, 868.0, 367.0, 863.0, 374.0, 862.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_7/000029.JPG', 'height': 3264, 'width': 2448, 'image_id': 1197, 'annotations': [{'iscrowd': 0, 'bbox': [629.0, 1572.0, 712.0, 999.0], 'category_id': 4, 'segmentation': [[1299.0, 1944.0, 1212.0, 2414.0, 1158.0, 2501.0, 1069.0, 2555.0, 987.0, 2571.0, 900.0, 2566.0, 830.0, 2520.0, 795.0, 2469.0, 749.0, 2321.0, 681.0, 2018.0, 679.0, 1988.0, 630.0, 1918.0, 629.0, 1799.0, 657.0, 1738.0, 698.0, 1672.0, 798.0, 1607.0, 919.0, 1577.0, 1031.0, 1572.0, 1150.0, 1591.0, 1231.0, 1627.0, 1268.0, 1681.0, 1303.0, 1722.0, 1337.0, 1790.0, 1341.0, 1843.0, 1325.0, 1915.0, 1299.0, 1944.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [618.0, 1574.0, 722.0, 488.0], 'category_id': 5, 'segmentation': [[677.0, 1985.0, 721.0, 2010.0, 798.0, 2042.0, 885.0, 2059.0, 971.0, 2062.0, 1048.0, 2057.0, 1124.0, 2040.0, 1197.0, 2013.0, 1264.0, 1978.0, 1306.0, 1940.0, 1330.0, 1896.0, 1340.0, 1841.0, 1331.0, 1782.0, 1300.0, 1714.0, 1261.0, 1676.0, 1229.0, 1638.0, 1175.0, 1602.0, 1110.0, 1587.0, 1028.0, 1574.0, 948.0, 1578.0, 872.0, 1587.0, 792.0, 1612.0, 750.0, 1639.0, 702.0, 1674.0, 678.0, 1710.0, 654.0, 1746.0, 630.0, 1792.0, 624.0, 1825.0, 618.0, 1864.0, 627.0, 1910.0, 646.0, 1951.0, 677.0, 1985.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [1208.0, 2144.0, 652.0, 545.0], 'category_id': 6, 'segmentation': [[1260.0, 2241.0, 1259.0, 2271.0, 1266.0, 2299.0, 1271.0, 2412.0, 1291.0, 2455.0, 1244.0, 2549.0, 1244.0, 2565.0, 1229.0, 2569.0, 1230.0, 2600.0, 1224.0, 2616.0, 1208.0, 2617.0, 1209.0, 2636.0, 1226.0, 2646.0, 1248.0, 2662.0, 1281.0, 2650.0, 1308.0, 2650.0, 1363.0, 2667.0, 1409.0, 2667.0, 1451.0, 2689.0, 1588.0, 2641.0, 1635.0, 2529.0, 1682.0, 2523.0, 1680.0, 2533.0, 1731.0, 2535.0, 1770.0, 2522.0, 1784.0, 2449.0, 1787.0, 2426.0, 1821.0, 2421.0, 1858.0, 2425.0, 1860.0, 2397.0, 1841.0, 2357.0, 1820.0, 2322.0, 1803.0, 2273.0, 1766.0, 2233.0, 1723.0, 2197.0, 1652.0, 2168.0, 1591.0, 2153.0, 1525.0, 2144.0, 1472.0, 2149.0, 1440.0, 2163.0, 1394.0, 2196.0, 1366.0, 2218.0, 1338.0, 2244.0, 1260.0, 2241.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_7/000031.JPG', 'height': 3264, 'width': 2448, 'image_id': 1199, 'annotations': [{'iscrowd': 0, 'bbox': [373.0, 1047.0, 1439.0, 1389.0], 'category_id': 4, 'segmentation': [[865.0, 1304.0, 416.0, 2000.0, 373.0, 2118.0, 392.0, 2234.0, 455.0, 2341.0, 546.0, 2416.0, 589.0, 2436.0, 662.0, 2396.0, 745.0, 2365.0, 855.0, 2359.0, 930.0, 2396.0, 1198.0, 2221.0, 1622.0, 1972.0, 1698.0, 1946.0, 1740.0, 1892.0, 1775.0, 1830.0, 1782.0, 1752.0, 1812.0, 1706.0, 1810.0, 1618.0, 1725.0, 1463.0, 1595.0, 1316.0, 1481.0, 1206.0, 1354.0, 1119.0, 1234.0, 1060.0, 1160.0, 1047.0, 1105.0, 1064.0, 1078.0, 1092.0, 1028.0, 1084.0, 960.0, 1106.0, 934.0, 1138.0, 880.0, 1162.0, 866.0, 1194.0, 863.0, 1243.0, 865.0, 1304.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [863.0, 1045.0, 946.0, 922.0], 'category_id': 5, 'segmentation': [[1157.0, 1045.0, 1109.0, 1060.0, 1079.0, 1092.0, 1026.0, 1084.0, 957.0, 1104.0, 929.0, 1141.0, 878.0, 1164.0, 863.0, 1217.0, 867.0, 1279.0, 887.0, 1342.0, 914.0, 1403.0, 974.0, 1496.0, 1060.0, 1614.0, 1145.0, 1698.0, 1275.0, 1810.0, 1389.0, 1887.0, 1503.0, 1944.0, 1587.0, 1962.0, 1634.0, 1967.0, 1701.0, 1948.0, 1749.0, 1879.0, 1777.0, 1832.0, 1783.0, 1754.0, 1809.0, 1709.0, 1809.0, 1619.0, 1755.0, 1514.0, 1695.0, 1428.0, 1598.0, 1316.0, 1480.0, 1203.0, 1356.0, 1119.0, 1231.0, 1058.0, 1157.0, 1045.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_7/000036.JPG', 'height': 2448, 'width': 3264, 'image_id': 1203, 'annotations': [{'iscrowd': 0, 'bbox': [1029.0, 933.0, 285.0, 276.0], 'category_id': 6, 'segmentation': [[1079.0, 1209.0, 1081.0, 1196.0, 1075.0, 1174.0, 1066.0, 1120.0, 1043.0, 1003.0, 1034.0, 974.0, 1029.0, 968.0, 1038.0, 962.0, 1053.0, 962.0, 1076.0, 963.0, 1096.0, 956.0, 1126.0, 951.0, 1167.0, 945.0, 1195.0, 943.0, 1200.0, 944.0, 1222.0, 935.0, 1240.0, 933.0, 1253.0, 987.0, 1279.0, 1075.0, 1293.0, 1120.0, 1303.0, 1146.0, 1314.0, 1152.0, 1303.0, 1159.0, 1203.0, 1184.0, 1119.0, 1202.0, 1079.0, 1209.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [1132.0, 1412.0, 308.0, 303.0], 'category_id': 6, 'segmentation': [[1136.0, 1542.0, 1142.0, 1546.0, 1147.0, 1557.0, 1154.0, 1567.0, 1178.0, 1593.0, 1200.0, 1615.0, 1220.0, 1635.0, 1235.0, 1654.0, 1247.0, 1665.0, 1258.0, 1679.0, 1297.0, 1715.0, 1308.0, 1710.0, 1438.0, 1583.0, 1440.0, 1489.0, 1401.0, 1447.0, 1363.0, 1412.0, 1288.0, 1428.0, 1136.0, 1529.0, 1132.0, 1538.0, 1136.0, 1542.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [1383.0, 779.0, 186.0, 73.0], 'category_id': 9, 'segmentation': [[1393.0, 852.0, 1490.0, 799.0, 1510.0, 788.0, 1517.0, 787.0, 1525.0, 790.0, 1563.0, 815.0, 1569.0, 814.0, 1568.0, 811.0, 1527.0, 782.0, 1518.0, 779.0, 1508.0, 780.0, 1478.0, 798.0, 1383.0, 848.0, 1393.0, 852.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [1379.0, 1115.0, 388.0, 408.0], 'category_id': 7, 'segmentation': [[1379.0, 1423.0, 1380.0, 1416.0, 1382.0, 1402.0, 1389.0, 1383.0, 1397.0, 1364.0, 1404.0, 1362.0, 1408.0, 1352.0, 1420.0, 1330.0, 1420.0, 1323.0, 1430.0, 1315.0, 1435.0, 1307.0, 1440.0, 1306.0, 1449.0, 1263.0, 1445.0, 1251.0, 1436.0, 1240.0, 1464.0, 1189.0, 1472.0, 1169.0, 1489.0, 1157.0, 1501.0, 1152.0, 1521.0, 1146.0, 1532.0, 1139.0, 1536.0, 1139.0, 1547.0, 1130.0, 1560.0, 1129.0, 1565.0, 1127.0, 1570.0, 1122.0, 1573.0, 1119.0, 1582.0, 1115.0, 1584.0, 1120.0, 1587.0, 1127.0, 1586.0, 1129.0, 1589.0, 1129.0, 1589.0, 1127.0, 1593.0, 1124.0, 1596.0, 1119.0, 1602.0, 1120.0, 1607.0, 1119.0, 1612.0, 1120.0, 1616.0, 1127.0, 1625.0, 1131.0, 1637.0, 1140.0, 1648.0, 1153.0, 1653.0, 1158.0, 1666.0, 1166.0, 1672.0, 1182.0, 1680.0, 1189.0, 1689.0, 1204.0, 1695.0, 1214.0, 1705.0, 1208.0, 1713.0, 1197.0, 1727.0, 1191.0, 1738.0, 1192.0, 1748.0, 1201.0, 1743.0, 1228.0, 1753.0, 1241.0, 1758.0, 1273.0, 1767.0, 1345.0, 1736.0, 1420.0, 1707.0, 1452.0, 1654.0, 1475.0, 1608.0, 1502.0, 1560.0, 1515.0, 1518.0, 1522.0, 1481.0, 1523.0, 1451.0, 1518.0, 1442.0, 1511.0, 1441.0, 1491.0, 1416.0, 1460.0, 1396.0, 1439.0, 1379.0, 1423.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [1681.0, 952.0, 532.0, 326.0], 'category_id': 7, 'segmentation': [[1738.0, 1166.0, 1713.0, 1136.0, 1695.0, 1103.0, 1691.0, 1094.0, 1700.0, 1074.0, 1696.0, 1037.0, 1681.0, 1029.0, 1691.0, 1018.0, 1696.0, 1002.0, 1697.0, 993.0, 1711.0, 993.0, 1738.0, 984.0, 1760.0, 972.0, 1780.0, 957.0, 1806.0, 952.0, 1824.0, 959.0, 1837.0, 968.0, 1842.0, 977.0, 1851.0, 973.0, 1866.0, 974.0, 1883.0, 975.0, 1892.0, 969.0, 1910.0, 968.0, 1919.0, 964.0, 1934.0, 961.0, 1940.0, 960.0, 1957.0, 969.0, 1966.0, 969.0, 1984.0, 963.0, 1995.0, 961.0, 2003.0, 968.0, 2026.0, 984.0, 2034.0, 982.0, 2046.0, 982.0, 2058.0, 988.0, 2070.0, 998.0, 2079.0, 1010.0, 2087.0, 1018.0, 2094.0, 1032.0, 2112.0, 1043.0, 2119.0, 1053.0, 2131.0, 1068.0, 2137.0, 1079.0, 2157.0, 1101.0, 2177.0, 1117.0, 2191.0, 1140.0, 2213.0, 1204.0, 2207.0, 1229.0, 2197.0, 1247.0, 2192.0, 1243.0, 2180.0, 1219.0, 2166.0, 1204.0, 2137.0, 1180.0, 2103.0, 1166.0, 2075.0, 1158.0, 2042.0, 1155.0, 2004.0, 1158.0, 1971.0, 1170.0, 1952.0, 1182.0, 1933.0, 1200.0, 1923.0, 1217.0, 1914.0, 1251.0, 1906.0, 1278.0, 1849.0, 1256.0, 1815.0, 1236.0, 1793.0, 1224.0, 1773.0, 1204.0, 1755.0, 1184.0, 1738.0, 1166.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [1612.0, 864.0, 370.0, 402.0], 'category_id': 7, 'segmentation': [[1612.0, 1118.0, 1623.0, 1108.0, 1641.0, 1089.0, 1654.0, 1063.0, 1673.0, 1041.0, 1686.0, 1035.0, 1686.0, 1033.0, 1710.0, 991.0, 1726.0, 964.0, 1762.0, 902.0, 1799.0, 865.0, 1809.0, 864.0, 1822.0, 872.0, 1869.0, 912.0, 1895.0, 920.0, 1906.0, 926.0, 1915.0, 935.0, 1942.0, 944.0, 1947.0, 948.0, 1982.0, 963.0, 1967.0, 969.0, 1956.0, 967.0, 1940.0, 960.0, 1919.0, 964.0, 1908.0, 967.0, 1891.0, 968.0, 1882.0, 975.0, 1852.0, 973.0, 1841.0, 977.0, 1837.0, 967.0, 1825.0, 958.0, 1806.0, 952.0, 1780.0, 958.0, 1757.0, 974.0, 1738.0, 984.0, 1719.0, 990.0, 1711.0, 993.0, 1709.0, 990.0, 1686.0, 1033.0, 1692.0, 1036.0, 1696.0, 1042.0, 1701.0, 1073.0, 1691.0, 1093.0, 1713.0, 1136.0, 1760.0, 1189.0, 1792.0, 1224.0, 1842.0, 1252.0, 1842.0, 1266.0, 1788.0, 1247.0, 1743.0, 1226.0, 1748.0, 1201.0, 1738.0, 1193.0, 1726.0, 1191.0, 1713.0, 1197.0, 1705.0, 1206.0, 1695.0, 1214.0, 1681.0, 1189.0, 1671.0, 1182.0, 1666.0, 1166.0, 1650.0, 1155.0, 1637.0, 1139.0, 1625.0, 1130.0, 1616.0, 1127.0, 1612.0, 1118.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [1881.0, 1158.0, 318.0, 395.0], 'category_id': 2, 'segmentation': [[1881.0, 1433.0, 1925.0, 1213.0, 1951.0, 1180.0, 2008.0, 1158.0, 2069.0, 1159.0, 2125.0, 1177.0, 2164.0, 1201.0, 2192.0, 1250.0, 2199.0, 1302.0, 2133.0, 1496.0, 2115.0, 1523.0, 2068.0, 1548.0, 2001.0, 1553.0, 1940.0, 1530.0, 1903.0, 1500.0, 1883.0, 1455.0, 1881.0, 1433.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [913.0, 548.0, 91.0, 45.0], 'category_id': 6, 'segmentation': [[918.0, 583.0, 913.0, 579.0, 913.0, 574.0, 925.0, 574.0, 924.0, 569.0, 931.0, 562.0, 945.0, 564.0, 955.0, 564.0, 957.0, 560.0, 966.0, 561.0, 966.0, 556.0, 972.0, 555.0, 984.0, 555.0, 995.0, 550.0, 1004.0, 548.0, 1003.0, 556.0, 996.0, 569.0, 997.0, 580.0, 988.0, 577.0, 987.0, 584.0, 966.0, 585.0, 960.0, 593.0, 952.0, 582.0, 918.0, 583.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_7/000039.JPG', 'height': 3264, 'width': 2448, 'image_id': 1206, 'annotations': [{'iscrowd': 0, 'bbox': [604.0, 1668.0, 516.0, 465.0], 'category_id': 6, 'segmentation': [[963.0, 1708.0, 1047.0, 1766.0, 1047.0, 1774.0, 1114.0, 1828.0, 1120.0, 1849.0, 1120.0, 1874.0, 1108.0, 1898.0, 1094.0, 1912.0, 1096.0, 1926.0, 1092.0, 1945.0, 1083.0, 1962.0, 1062.0, 1985.0, 992.0, 2043.0, 896.0, 2125.0, 878.0, 2133.0, 860.0, 2127.0, 839.0, 2116.0, 825.0, 2107.0, 770.0, 2052.0, 715.0, 1994.0, 604.0, 1905.0, 604.0, 1902.0, 616.0, 1884.0, 618.0, 1864.0, 625.0, 1841.0, 639.0, 1823.0, 706.0, 1760.0, 742.0, 1726.0, 794.0, 1686.0, 814.0, 1677.0, 826.0, 1671.0, 837.0, 1668.0, 851.0, 1669.0, 869.0, 1670.0, 887.0, 1674.0, 905.0, 1682.0, 924.0, 1693.0, 945.0, 1707.0, 955.0, 1705.0, 963.0, 1708.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [903.0, 1573.0, 67.0, 50.0], 'category_id': 6, 'segmentation': [[916.0, 1582.0, 915.0, 1590.0, 907.0, 1597.0, 903.0, 1606.0, 904.0, 1619.0, 909.0, 1623.0, 916.0, 1619.0, 925.0, 1620.0, 939.0, 1621.0, 947.0, 1623.0, 970.0, 1604.0, 961.0, 1598.0, 955.0, 1588.0, 946.0, 1586.0, 937.0, 1584.0, 937.0, 1575.0, 932.0, 1577.0, 928.0, 1573.0, 920.0, 1577.0, 916.0, 1582.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [1163.0, 1997.0, 140.0, 86.0], 'category_id': 6, 'segmentation': [[1172.0, 1997.0, 1303.0, 2018.0, 1297.0, 2083.0, 1164.0, 2074.0, 1166.0, 2030.0, 1163.0, 2018.0, 1172.0, 1997.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [1174.0, 1554.0, 87.0, 54.0], 'category_id': 7, 'segmentation': [[1174.0, 1570.0, 1197.0, 1569.0, 1235.0, 1559.0, 1255.0, 1554.0, 1261.0, 1592.0, 1241.0, 1594.0, 1203.0, 1601.0, 1184.0, 1608.0, 1181.0, 1589.0, 1174.0, 1570.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [441.0, 2996.0, 241.0, 136.0], 'category_id': 7, 'segmentation': [[441.0, 3126.0, 491.0, 3030.0, 527.0, 3011.0, 549.0, 3000.0, 587.0, 2996.0, 622.0, 3029.0, 668.0, 3088.0, 682.0, 3111.0, 652.0, 3103.0, 592.0, 3082.0, 569.0, 3068.0, 547.0, 3074.0, 522.0, 3100.0, 508.0, 3114.0, 491.0, 3123.0, 455.0, 3132.0, 441.0, 3126.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [2288.0, 1932.0, 62.0, 34.0], 'category_id': 3, 'segmentation': [[2340.0, 1966.0, 2288.0, 1950.0, 2298.0, 1932.0, 2350.0, 1948.0, 2340.0, 1966.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [2326.0, 1918.0, 66.0, 28.0], 'category_id': 3, 'segmentation': [[2392.0, 1946.0, 2326.0, 1936.0, 2336.0, 1918.0, 2392.0, 1928.0, 2392.0, 1946.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_7/000056.JPG', 'height': 3264, 'width': 2448, 'image_id': 1220, 'annotations': [{'iscrowd': 0, 'bbox': [850.0, 1603.0, 164.0, 283.0], 'category_id': 6, 'segmentation': [[931.0, 1635.0, 850.0, 1731.0, 865.0, 1761.0, 886.0, 1789.0, 920.0, 1828.0, 949.0, 1857.0, 980.0, 1886.0, 979.0, 1882.0, 1014.0, 1675.0, 965.0, 1622.0, 947.0, 1603.0, 944.0, 1608.0, 948.0, 1611.0, 931.0, 1635.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_7/000069.JPG', 'height': 3264, 'width': 2448, 'image_id': 1231, 'annotations': [{'iscrowd': 0, 'bbox': [1200.0, 1795.0, 221.0, 227.0], 'category_id': 7, 'segmentation': [[1200.0, 1847.0, 1245.0, 1924.0, 1260.0, 1941.0, 1286.0, 1983.0, 1309.0, 2016.0, 1338.0, 2022.0, 1400.0, 1976.0, 1415.0, 1905.0, 1421.0, 1888.0, 1388.0, 1868.0, 1374.0, 1867.0, 1358.0, 1828.0, 1336.0, 1795.0, 1303.0, 1817.0, 1276.0, 1831.0, 1251.0, 1832.0, 1200.0, 1847.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_7/000072.JPG', 'height': 3264, 'width': 2448, 'image_id': 1234, 'annotations': [{'iscrowd': 0, 'bbox': [1070.0, 1284.0, 443.0, 317.0], 'category_id': 0, 'segmentation': [[1119.0, 1297.0, 1157.0, 1285.0, 1207.0, 1284.0, 1264.0, 1295.0, 1299.0, 1315.0, 1316.0, 1333.0, 1344.0, 1331.0, 1365.0, 1331.0, 1479.0, 1451.0, 1513.0, 1489.0, 1479.0, 1474.0, 1445.0, 1499.0, 1428.0, 1549.0, 1415.0, 1601.0, 1354.0, 1601.0, 1334.0, 1595.0, 1292.0, 1571.0, 1250.0, 1585.0, 1196.0, 1586.0, 1174.0, 1580.0, 1176.0, 1527.0, 1175.0, 1492.0, 1138.0, 1445.0, 1077.0, 1375.0, 1070.0, 1352.0, 1075.0, 1332.0, 1087.0, 1316.0, 1119.0, 1297.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [2033.0, 2806.0, 337.0, 282.0], 'category_id': 0, 'segmentation': [[2037.0, 2970.0, 2095.0, 2927.0, 2137.0, 2918.0, 2159.0, 2903.0, 2184.0, 2875.0, 2218.0, 2843.0, 2263.0, 2837.0, 2278.0, 2821.0, 2307.0, 2806.0, 2340.0, 2818.0, 2370.0, 2843.0, 2362.0, 2870.0, 2340.0, 2908.0, 2316.0, 2919.0, 2305.0, 2947.0, 2267.0, 2977.0, 2228.0, 2976.0, 2201.0, 3005.0, 2157.0, 3058.0, 2108.0, 3088.0, 2070.0, 3068.0, 2049.0, 3033.0, 2033.0, 2997.0, 2037.0, 2970.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [448.0, 350.0, 427.0, 376.0], 'category_id': 6, 'segmentation': [[448.0, 414.0, 508.0, 406.0, 593.0, 350.0, 635.0, 350.0, 742.0, 448.0, 816.0, 554.0, 866.0, 633.0, 875.0, 726.0, 774.0, 651.0, 645.0, 531.0, 556.0, 442.0, 448.0, 414.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [1016.0, 3036.0, 30.0, 74.0], 'category_id': 3, 'segmentation': [[1016.0, 3110.0, 1018.0, 3036.0, 1046.0, 3040.0, 1046.0, 3108.0, 1016.0, 3110.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [458.0, 3090.0, 90.0, 54.0], 'category_id': 3, 'segmentation': [[542.0, 3144.0, 458.0, 3108.0, 484.0, 3090.0, 548.0, 3118.0, 542.0, 3144.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_7/000082.JPG', 'height': 2448, 'width': 3264, 'image_id': 1243, 'annotations': [{'iscrowd': 0, 'bbox': [886.0, 1343.0, 265.0, 220.0], 'category_id': 0, 'segmentation': [[928.0, 1480.0, 961.0, 1504.0, 976.0, 1504.0, 1021.0, 1534.0, 1045.0, 1552.0, 1074.0, 1563.0, 1101.0, 1556.0, 1120.0, 1549.0, 1142.0, 1525.0, 1149.0, 1498.0, 1151.0, 1480.0, 1137.0, 1450.0, 1112.0, 1429.0, 1061.0, 1402.0, 1038.0, 1398.0, 1024.0, 1383.0, 988.0, 1359.0, 952.0, 1344.0, 929.0, 1343.0, 901.0, 1353.0, 886.0, 1355.0, 888.0, 1375.0, 928.0, 1480.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_7/000088.JPG', 'height': 3264, 'width': 2448, 'image_id': 1249, 'annotations': [{'iscrowd': 0, 'bbox': [1312.0, 1524.0, 101.0, 43.0], 'category_id': 0, 'segmentation': [[1334.0, 1524.0, 1343.0, 1526.0, 1347.0, 1528.0, 1358.0, 1527.0, 1371.0, 1527.0, 1386.0, 1528.0, 1394.0, 1531.0, 1399.0, 1536.0, 1403.0, 1541.0, 1411.0, 1544.0, 1413.0, 1549.0, 1413.0, 1555.0, 1411.0, 1558.0, 1399.0, 1559.0, 1395.0, 1564.0, 1388.0, 1567.0, 1373.0, 1567.0, 1353.0, 1563.0, 1347.0, 1560.0, 1333.0, 1561.0, 1326.0, 1561.0, 1319.0, 1557.0, 1312.0, 1551.0, 1312.0, 1543.0, 1315.0, 1537.0, 1315.0, 1531.0, 1319.0, 1527.0, 1325.0, 1525.0, 1334.0, 1524.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_7/000098.JPG', 'height': 2448, 'width': 3264, 'image_id': 1259, 'annotations': [{'iscrowd': 0, 'bbox': [1103.0, 1273.0, 1131.0, 402.0], 'category_id': 6, 'segmentation': [[1103.0, 1617.0, 1119.0, 1567.0, 1150.0, 1479.0, 1171.0, 1425.0, 1200.0, 1368.0, 1230.0, 1330.0, 1279.0, 1303.0, 1357.0, 1291.0, 1401.0, 1289.0, 1441.0, 1278.0, 1508.0, 1273.0, 1544.0, 1282.0, 1605.0, 1317.0, 1838.0, 1423.0, 1989.0, 1501.0, 2074.0, 1549.0, 2156.0, 1603.0, 2211.0, 1644.0, 2234.0, 1667.0, 2226.0, 1673.0, 2196.0, 1667.0, 2165.0, 1674.0, 2123.0, 1675.0, 2079.0, 1657.0, 2010.0, 1636.0, 1961.0, 1615.0, 1877.0, 1588.0, 1836.0, 1576.0, 1781.0, 1566.0, 1741.0, 1550.0, 1692.0, 1527.0, 1668.0, 1510.0, 1644.0, 1514.0, 1565.0, 1493.0, 1482.0, 1475.0, 1415.0, 1450.0, 1365.0, 1443.0, 1325.0, 1421.0, 1305.0, 1405.0, 1316.0, 1381.0, 1304.0, 1385.0, 1258.0, 1391.0, 1221.0, 1398.0, 1190.0, 1449.0, 1171.0, 1496.0, 1136.0, 1584.0, 1121.0, 1618.0, 1103.0, 1617.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_7/000101.JPG', 'height': 2448, 'width': 3264, 'image_id': 1261, 'annotations': [{'iscrowd': 0, 'bbox': [1867.0, 1374.0, 408.0, 360.0], 'category_id': 6, 'segmentation': [[1931.0, 1511.0, 1913.0, 1501.0, 1906.0, 1490.0, 1899.0, 1484.0, 1885.0, 1476.0, 1876.0, 1474.0, 1873.0, 1468.0, 1871.0, 1452.0, 1869.0, 1446.0, 1878.0, 1446.0, 1868.0, 1429.0, 1867.0, 1421.0, 1869.0, 1416.0, 1873.0, 1397.0, 1884.0, 1388.0, 1895.0, 1383.0, 1905.0, 1381.0, 1916.0, 1381.0, 1921.0, 1381.0, 1936.0, 1387.0, 1942.0, 1386.0, 1950.0, 1385.0, 1956.0, 1385.0, 1958.0, 1384.0, 1959.0, 1377.0, 1964.0, 1374.0, 1969.0, 1377.0, 1972.0, 1381.0, 1974.0, 1384.0, 1978.0, 1384.0, 1982.0, 1385.0, 1986.0, 1387.0, 1991.0, 1388.0, 1998.0, 1391.0, 2001.0, 1397.0, 2003.0, 1400.0, 2004.0, 1406.0, 2010.0, 1412.0, 2023.0, 1419.0, 2037.0, 1428.0, 2049.0, 1437.0, 2055.0, 1444.0, 2058.0, 1452.0, 2062.0, 1467.0, 2076.0, 1471.0, 2088.0, 1474.0, 2098.0, 1477.0, 2105.0, 1478.0, 2108.0, 1482.0, 2115.0, 1485.0, 2133.0, 1485.0, 2145.0, 1486.0, 2151.0, 1488.0, 2158.0, 1492.0, 2170.0, 1500.0, 2187.0, 1514.0, 2204.0, 1529.0, 2221.0, 1538.0, 2230.0, 1547.0, 2240.0, 1547.0, 2249.0, 1552.0, 2260.0, 1564.0, 2270.0, 1576.0, 2275.0, 1589.0, 2275.0, 1605.0, 2269.0, 1622.0, 2259.0, 1637.0, 2244.0, 1653.0, 2226.0, 1666.0, 2204.0, 1680.0, 2173.0, 1692.0, 2152.0, 1711.0, 2124.0, 1726.0, 2094.0, 1734.0, 2066.0, 1732.0, 2042.0, 1727.0, 2036.0, 1721.0, 2032.0, 1719.0, 2015.0, 1719.0, 2011.0, 1714.0, 1995.0, 1681.0, 1988.0, 1664.0, 1968.0, 1649.0, 1943.0, 1619.0, 1932.0, 1607.0, 1938.0, 1599.0, 1947.0, 1596.0, 1948.0, 1588.0, 1951.0, 1581.0, 1961.0, 1586.0, 1973.0, 1589.0, 1980.0, 1592.0, 1991.0, 1592.0, 1996.0, 1588.0, 1983.0, 1580.0, 1973.0, 1573.0, 1967.0, 1574.0, 1962.0, 1569.0, 1959.0, 1564.0, 1960.0, 1557.0, 1967.0, 1549.0, 1956.0, 1553.0, 1954.0, 1549.0, 1954.0, 1544.0, 1949.0, 1539.0, 1950.0, 1532.0, 1955.0, 1528.0, 1931.0, 1511.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_7/000113.JPG', 'height': 2448, 'width': 3264, 'image_id': 1272, 'annotations': [{'iscrowd': 0, 'bbox': [1537.0, 1554.0, 181.0, 151.0], 'category_id': 0, 'segmentation': [[1559.0, 1609.0, 1571.0, 1602.0, 1588.0, 1591.0, 1623.0, 1570.0, 1634.0, 1565.0, 1642.0, 1561.0, 1660.0, 1554.0, 1665.0, 1554.0, 1673.0, 1556.0, 1679.0, 1557.0, 1685.0, 1562.0, 1698.0, 1571.0, 1707.0, 1574.0, 1714.0, 1582.0, 1717.0, 1594.0, 1718.0, 1605.0, 1717.0, 1621.0, 1709.0, 1636.0, 1700.0, 1646.0, 1677.0, 1665.0, 1669.0, 1673.0, 1657.0, 1670.0, 1641.0, 1676.0, 1639.0, 1680.0, 1643.0, 1684.0, 1657.0, 1685.0, 1650.0, 1691.0, 1633.0, 1699.0, 1624.0, 1704.0, 1606.0, 1705.0, 1593.0, 1705.0, 1580.0, 1702.0, 1568.0, 1694.0, 1565.0, 1693.0, 1555.0, 1699.0, 1546.0, 1698.0, 1540.0, 1693.0, 1538.0, 1686.0, 1538.0, 1682.0, 1541.0, 1677.0, 1545.0, 1673.0, 1542.0, 1668.0, 1538.0, 1658.0, 1537.0, 1643.0, 1539.0, 1629.0, 1544.0, 1622.0, 1548.0, 1617.0, 1559.0, 1609.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [1538.0, 1670.0, 30.0, 29.0], 'category_id': 1, 'segmentation': [[1538.0, 1680.0, 1548.0, 1672.0, 1553.0, 1670.0, 1560.0, 1671.0, 1566.0, 1677.0, 1568.0, 1684.0, 1567.0, 1691.0, 1563.0, 1695.0, 1555.0, 1699.0, 1546.0, 1698.0, 1541.0, 1694.0, 1538.0, 1687.0, 1538.0, 1680.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_7/000118.JPG', 'height': 2448, 'width': 3264, 'image_id': 1276, 'annotations': [{'iscrowd': 0, 'bbox': [1674.0, 1217.0, 223.0, 267.0], 'category_id': 2, 'segmentation': [[1716.0, 1391.0, 1706.0, 1368.0, 1698.0, 1347.0, 1687.0, 1319.0, 1674.0, 1291.0, 1676.0, 1283.0, 1682.0, 1275.0, 1682.0, 1269.0, 1699.0, 1254.0, 1716.0, 1243.0, 1742.0, 1227.0, 1758.0, 1219.0, 1765.0, 1217.0, 1770.0, 1217.0, 1772.0, 1219.0, 1782.0, 1218.0, 1787.0, 1218.0, 1816.0, 1246.0, 1821.0, 1251.0, 1841.0, 1278.0, 1867.0, 1311.0, 1869.0, 1314.0, 1869.0, 1317.0, 1870.0, 1318.0, 1873.0, 1327.0, 1884.0, 1361.0, 1892.0, 1391.0, 1894.0, 1404.0, 1894.0, 1418.0, 1897.0, 1425.0, 1896.0, 1431.0, 1882.0, 1447.0, 1865.0, 1459.0, 1845.0, 1471.0, 1825.0, 1480.0, 1813.0, 1484.0, 1805.0, 1484.0, 1801.0, 1481.0, 1797.0, 1475.0, 1771.0, 1466.0, 1735.0, 1433.0, 1716.0, 1391.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_7/000126.JPG', 'height': 2448, 'width': 3264, 'image_id': 1284, 'annotations': [{'iscrowd': 0, 'bbox': [1094.0, 1642.0, 99.0, 96.0], 'category_id': 1, 'segmentation': [[1106.0, 1722.0, 1102.0, 1713.0, 1094.0, 1687.0, 1097.0, 1669.0, 1109.0, 1654.0, 1126.0, 1646.0, 1144.0, 1642.0, 1160.0, 1643.0, 1175.0, 1646.0, 1185.0, 1652.0, 1192.0, 1666.0, 1193.0, 1698.0, 1185.0, 1716.0, 1174.0, 1729.0, 1158.0, 1736.0, 1140.0, 1738.0, 1124.0, 1734.0, 1113.0, 1728.0, 1106.0, 1722.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_7/000139.JPG', 'height': 3264, 'width': 2448, 'image_id': 1296, 'annotations': [{'iscrowd': 0, 'bbox': [1700.0, 939.0, 296.0, 156.0], 'category_id': 6, 'segmentation': [[1700.0, 1051.0, 1723.0, 1029.0, 1741.0, 1002.0, 1756.0, 1005.0, 1771.0, 997.0, 1847.0, 969.0, 1873.0, 947.0, 1875.0, 939.0, 1901.0, 943.0, 1923.0, 959.0, 1944.0, 978.0, 1976.0, 1021.0, 1968.0, 1040.0, 1991.0, 1060.0, 1996.0, 1075.0, 1993.0, 1083.0, 1987.0, 1083.0, 1985.0, 1073.0, 1990.0, 1059.0, 1968.0, 1041.0, 1950.0, 1064.0, 1922.0, 1059.0, 1892.0, 1053.0, 1869.0, 1051.0, 1836.0, 1051.0, 1824.0, 1049.0, 1789.0, 1053.0, 1764.0, 1058.0, 1756.0, 1065.0, 1742.0, 1079.0, 1731.0, 1095.0, 1727.0, 1095.0, 1722.0, 1085.0, 1715.0, 1075.0, 1706.0, 1066.0, 1702.0, 1059.0, 1700.0, 1051.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [1859.0, 768.0, 52.0, 25.0], 'category_id': 6, 'segmentation': [[1859.0, 793.0, 1911.0, 768.0, 1911.0, 777.0, 1859.0, 793.0]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_8/000012.jpg', 'height': 3264, 'width': 2448, 'image_id': 1312, 'annotations': [{'iscrowd': 0, 'bbox': [964.3333, 1254.4286, 400.0, 323.0], 'category_id': 0, 'segmentation': [[1025, 1471, 1053, 1422, 1125, 1369, 1168, 1338, 1213, 1317, 1227, 1306, 1250, 1279, 1271, 1259, 1297, 1254, 1310, 1258, 1318, 1272, 1334, 1277, 1345, 1286, 1344, 1306, 1354, 1316, 1364, 1329, 1359, 1348, 1360, 1368, 1319, 1386, 1289, 1393, 1260, 1421, 1223, 1456, 1175, 1490, 1140, 1517, 1114, 1529, 1069, 1535, 1028, 1552, 998, 1577, 981, 1567, 968, 1547, 964, 1535, 986, 1512, 1000, 1509, 1015, 1489]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [963.381, 1517.3333, 54.0, 64.0], 'category_id': 1, 'segmentation': [[963, 1534, 981, 1517, 996, 1533, 1005, 1544, 1017, 1564, 994, 1581, 983, 1571, 967, 1547]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [2276.0952, 2907.9524, 74.0, 50.0], 'category_id': 6, 'segmentation': [[2276, 2920, 2328, 2951, 2350, 2958, 2335, 2934, 2284, 2908]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_8/000041.jpg', 'height': 2448, 'width': 3264, 'image_id': 1341, 'annotations': [{'iscrowd': 0, 'bbox': [1129.0, 735.0, 357.0, 298.0], 'category_id': 0, 'segmentation': [[1187, 787, 1255, 773, 1289, 756, 1356, 735, 1406, 740, 1457, 769, 1472, 815, 1486, 888, 1446, 951, 1418, 959, 1381, 979, 1354, 985, 1254, 1033, 1224, 1031, 1179, 991, 1150, 952, 1129, 913, 1131, 874, 1149, 830, 1167, 799]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_8/000045.jpg', 'height': 2448, 'width': 3264, 'image_id': 1345, 'annotations': [{'iscrowd': 0, 'bbox': [1224.9999999999998, 1334.9999999999998, 188.00000000000023, 64.00000000000023], 'category_id': 0, 'segmentation': [[1227, 1350, 1225, 1377, 1235, 1391, 1292, 1398, 1332, 1399, 1405, 1392, 1413, 1380, 1400, 1359, 1383, 1348, 1341, 1347, 1328, 1346, 1308, 1341, 1245, 1335, 1233, 1340]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_8/000046.jpg', 'height': 2448, 'width': 3264, 'image_id': 1346, 'annotations': [{'iscrowd': 0, 'bbox': [1280.0, 1081.0, 204.0, 113.0], 'category_id': 6, 'segmentation': [[1280, 1122, 1401, 1081, 1475, 1081, 1484, 1127, 1476, 1149, 1383, 1193, 1291, 1194]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [2440.0, 996.0, 44.0, 52.0], 'category_id': 6, 'segmentation': [[2440, 1024, 2468, 996, 2484, 1031, 2447, 1048]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_8/000048.jpg', 'height': 2448, 'width': 3264, 'image_id': 1348, 'annotations': [{'iscrowd': 0, 'bbox': [1750.7143999999998, 1768.0475999999999, 606.0, 181.0], 'category_id': 0, 'segmentation': [[1899, 1949, 2000, 1941, 2039, 1939, 2057, 1930, 2081, 1931, 2100, 1938, 2248, 1932, 2314, 1930, 2343, 1912, 2348, 1894, 2357, 1877, 2353, 1854, 2350, 1826, 2345, 1807, 2328, 1778, 2300, 1768, 2206, 1768, 2083, 1773, 2066, 1784, 2045, 1786, 2023, 1774, 1888, 1779, 1853, 1784, 1826, 1798, 1793, 1835, 1755, 1835, 1751, 1858, 1754, 1883, 1759, 1897, 1790, 1896, 1803, 1907, 1828, 1925, 1863, 1945]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [1747.6189999999997, 1836.0476, 30.0, 61.99999999999977], 'category_id': 1, 'segmentation': [[1754, 1836, 1773, 1836, 1778, 1862, 1776, 1886, 1774, 1898, 1756, 1897, 1751, 1879, 1748, 1857]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_8/000057.jpg', 'height': 1600, 'width': 1200, 'image_id': 1357, 'annotations': [{'iscrowd': 0, 'bbox': [505.0, 791.0000000000002, 94.0, 85.99999999999977], 'category_id': 6, 'segmentation': [[505, 838, 534, 818, 568, 791, 599, 831, 544, 874, 531, 877]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [588.0, 966.0, 25.0, 28.0], 'category_id': 6, 'segmentation': [[588, 966, 604, 994, 613, 987, 599, 970]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_8/000058.jpg', 'height': 1600, 'width': 1200, 'image_id': 1358, 'annotations': [{'iscrowd': 0, 'bbox': [544.5, 695.0, 168.0, 158.0000000000001], 'category_id': 7, 'segmentation': [[544, 755, 580, 794, 618, 827, 660, 853, 684, 826, 712, 798, 712, 784, 668, 753, 600, 695, 584, 717]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [597.0, 930.6667, 28.0, 21.000000000000114], 'category_id': 3, 'segmentation': [[597, 941, 624, 931, 625, 941, 600, 952]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_8/000068.jpg', 'height': 3264, 'width': 2448, 'image_id': 1368, 'annotations': [{'iscrowd': 0, 'bbox': [1061.0, 767.0, 112.0, 78.0], 'category_id': 7, 'segmentation': [[1061, 819, 1103, 767, 1173, 789, 1137, 845]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_8/000082.jpg', 'height': 4032, 'width': 2268, 'image_id': 1382, 'annotations': [{'iscrowd': 0, 'bbox': [408.0, 1834.9048, 496.0, 368.9999999999998], 'category_id': 6, 'segmentation': [[512, 1835, 543, 1847, 636, 1840, 713, 1868, 756, 1878, 812, 1846, 852, 1852, 863, 1871, 857, 1904, 828, 1919, 745, 1921, 764, 1941, 748, 1967, 748, 1991, 766, 2002, 783, 2001, 853, 2023, 897, 2047, 904, 2066, 893, 2083, 862, 2086, 799, 2071, 821, 2134, 821, 2180, 801, 2202, 785, 2204, 749, 2172, 738, 2131, 735, 2114, 704, 2140, 632, 2080, 665, 2015, 630, 2013, 617, 2026, 615, 2046, 579, 2032, 527, 2004, 495, 1978, 442, 1934, 408, 1900, 412, 1881, 440, 1864, 465, 1857]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_8/000091.jpg', 'height': 4032, 'width': 2268, 'image_id': 1391, 'annotations': [{'iscrowd': 0, 'bbox': [917.0, 1432.0, 569.0, 564.0], 'category_id': 6, 'segmentation': [[961, 1564, 1002, 1521, 1067, 1485, 1129, 1459, 1198, 1437, 1256, 1432, 1318, 1444, 1375, 1474, 1430, 1539, 1444, 1564, 1467, 1601, 1475, 1626, 1472, 1647, 1486, 1689, 1485, 1730, 1453, 1808, 1420, 1875, 1398, 1914, 1381, 1929, 1339, 1956, 1295, 1970, 1240, 1983, 1186, 1990, 1152, 1996, 1087, 1980, 1033, 1961, 1018, 1949, 967, 1891, 936, 1829, 920, 1776, 917, 1701, 921, 1644, 936, 1607]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [2054.0, 1943.0, 200.0, 276.0], 'category_id': 6, 'segmentation': [[2158, 1943, 2247, 1989, 2254, 2001, 2129, 2219, 2082, 2198, 2093, 2164, 2094, 2107, 2054, 2114, 2146, 1947]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_8/000095.jpg', 'height': 4032, 'width': 2268, 'image_id': 1395, 'annotations': [{'iscrowd': 0, 'bbox': [671.9999999999999, 2391.0, 715.9999999999999, 345.0], 'category_id': 2, 'segmentation': [[681, 2668, 1287, 2736, 1317, 2730, 1335, 2713, 1363, 2716, 1380, 2612, 1388, 2492, 1363, 2483, 1351, 2479, 1346, 2496, 1318, 2493, 1300, 2451, 1183, 2438, 1179, 2474, 1109, 2469, 1071, 2460, 1003, 2467, 933, 2527, 895, 2522, 881, 2512, 926, 2446, 958, 2413, 766, 2391, 756, 2422, 756, 2451, 748, 2495, 752, 2519, 747, 2540, 748, 2561, 758, 2616, 762, 2632, 694, 2602, 672, 2639]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [536.0, 3535.9999999999995, 102.99999999999989, 122.0], 'category_id': 3, 'segmentation': [[536, 3558, 597, 3658, 622, 3658, 639, 3631, 581, 3536, 551, 3537]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_9/000024.jpg', 'height': 3264, 'width': 2448, 'image_id': 1424, 'annotations': [{'iscrowd': 0, 'bbox': [813.0, 2307.0, 908.0, 517.0], 'category_id': 7, 'segmentation': [[813, 2502, 895, 2529, 992, 2560, 1159, 2601, 1325, 2660, 1353, 2702, 1380, 2718, 1462, 2696, 1503, 2682, 1581, 2772, 1654, 2824, 1691, 2753, 1702, 2753, 1717, 2723, 1721, 2685, 1679, 2638, 1667, 2620, 1627, 2592, 1592, 2577, 1528, 2568, 1483, 2522, 1445, 2490, 1372, 2465, 1203, 2399, 1072, 2351, 993, 2330, 950, 2307, 864, 2421, 835, 2454]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_9/000030.jpg', 'height': 3264, 'width': 2448, 'image_id': 1430, 'annotations': [{'iscrowd': 0, 'bbox': [873.3333, 2352.9048, 254.00009999999997, 257.0], 'category_id': 7, 'segmentation': [[884, 2605, 892, 2563, 873, 2487, 889, 2428, 914, 2391, 954, 2369, 1013, 2353, 1065, 2364, 1098, 2380, 1108, 2426, 1127, 2473, 1124, 2509, 1097, 2553, 1038, 2567, 1006, 2597, 954, 2585, 920, 2595, 909, 2610]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [1532.3334, 1806.4762, 109.0, 99.0], 'category_id': 7, 'segmentation': [[1532, 1905, 1577, 1816, 1604, 1806, 1641, 1819, 1637, 1854, 1619, 1871, 1597, 1861, 1579, 1867, 1576, 1889]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_9/000032.jpg', 'height': 3264, 'width': 2448, 'image_id': 1432, 'annotations': [{'iscrowd': 0, 'bbox': [681.0, 1710.0, 1052.9999999999995, 810.0], 'category_id': 7, 'segmentation': [[860, 1870, 926, 1832, 1021, 1778, 1063, 1758, 1109, 1740, 1143, 1719, 1177, 1710, 1195, 1729, 1209, 1725, 1253, 1756, 1283, 1798, 1315, 1834, 1335, 1853, 1376, 1856, 1392, 1866, 1422, 1933, 1429, 1969, 1481, 2019, 1485, 2009, 1467, 1982, 1437, 1936, 1425, 1897, 1450, 1915, 1467, 1927, 1534, 1950, 1562, 1963, 1638, 1971, 1674, 1982, 1711, 1980, 1734, 2000, 1734, 2022, 1702, 2064, 1692, 2046, 1673, 2095, 1593, 2165, 1518, 2229, 1409, 2346, 1340, 2392, 1270, 2416, 1185, 2434, 1133, 2427, 1081, 2435, 1043, 2452, 993, 2496, 917, 2502, 842, 2520, 808, 2500, 796, 2468, 813, 2442, 825, 2393, 851, 2359, 909, 2357, 950, 2313, 956, 2217, 911, 2217, 811, 2191, 713, 2154, 681, 2111, 704, 2096, 743, 2046, 776, 1992, 796, 1995, 795, 1959, 818, 1917]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_9/000040.jpg', 'height': 3264, 'width': 2448, 'image_id': 1440, 'annotations': [{'iscrowd': 0, 'bbox': [1282.8572, 1590.0, 150.95240000000013, 393.80960000000005], 'category_id': 9, 'segmentation': [[1283, 1596, 1365, 1828, 1384, 1880, 1402, 1879, 1302, 1590], [1394, 1908, 1408, 1937, 1415, 1984, 1425, 1984, 1434, 1978, 1407, 1892]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [476.33334, 2920.4287, 91.99995999999999, 116.0], 'category_id': 3, 'segmentation': [[476, 3027, 492, 2991, 526, 2940, 542, 2920, 568, 2936, 531, 2989, 497, 3036]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_9/000045.jpg', 'height': 3264, 'width': 2448, 'image_id': 1445, 'annotations': [{'iscrowd': 0, 'bbox': [623.0, 1655.0, 355.0, 397.0], 'category_id': 7, 'segmentation': [[653, 1918, 722, 1802, 775, 1695, 847, 1655, 882, 1655, 978, 1737, 907, 1832, 851, 1932, 785, 1891, 727, 2000, 623, 2052, 631, 1984]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_9/000047.jpg', 'height': 3264, 'width': 2448, 'image_id': 1447, 'annotations': [{'iscrowd': 0, 'bbox': [844.0, 2285.0, 185.0, 191.0], 'category_id': 7, 'segmentation': [[971, 2457, 962, 2406, 928, 2351, 890, 2292, 844, 2287, 889, 2285, 938, 2322, 1002, 2404, 1010, 2428, 1029, 2465, 982, 2476]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [917.0, 1145.0, 319.0, 333.0], 'category_id': 7, 'segmentation': [[937, 1408, 957, 1333, 985, 1257, 973, 1213, 978, 1145, 1151, 1205, 1223, 1233, 1236, 1291, 1185, 1380, 1219, 1434, 1139, 1422, 980, 1377, 958, 1374, 945, 1466, 917, 1478]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_9/000052.jpg', 'height': 2448, 'width': 3264, 'image_id': 1452, 'annotations': [{'iscrowd': 0, 'bbox': [1527.0, 1157.0, 1221.0, 455.0], 'category_id': 6, 'segmentation': [[1619, 1507, 1901, 1610, 1929, 1612, 1979, 1602, 2022, 1581, 2049, 1547, 2222, 1519, 2292, 1517, 2331, 1503, 2461, 1494, 2493, 1495, 2521, 1506, 2576, 1530, 2658, 1559, 2744, 1576, 2748, 1561, 2678, 1529, 2596, 1473, 2499, 1398, 2437, 1357, 2384, 1326, 2337, 1323, 2316, 1328, 2305, 1362, 2275, 1364, 2108, 1417, 2084, 1433, 2059, 1462, 2041, 1474, 1994, 1472, 1949, 1453, 1933, 1496, 1932, 1460, 1727, 1375, 1623, 1323, 1592, 1302, 1610, 1257, 1627, 1239, 1648, 1239, 1643, 1191, 1626, 1193, 1624, 1157, 1580, 1216, 1568, 1224, 1540, 1204, 1537, 1253, 1554, 1270, 1527, 1398, 1531, 1432, 1557, 1475]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [1402.0, 912.0, 61.0, 33.0], 'category_id': 3, 'segmentation': [[1402, 929, 1402, 945, 1431, 942, 1463, 927, 1458, 912]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_9/000066.jpg', 'height': 3264, 'width': 2448, 'image_id': 1466, 'annotations': [{'iscrowd': 0, 'bbox': [225.0, 2260.0, 147.0, 44.0], 'category_id': 3, 'segmentation': [[225, 2282, 361, 2304, 372, 2280, 228, 2260]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [812.0, 1855.0, 384.0, 302.0], 'category_id': 4, 'segmentation': [[813, 2012, 1090, 2145, 1095, 2157, 1114, 2153, 1155, 2110, 1178, 2061, 1196, 1992, 1195, 1959, 1188, 1937, 1164, 1934, 1143, 1934, 875, 1855, 835, 1906, 812, 1967]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_9/000070.jpg', 'height': 4000, 'width': 1824, 'image_id': 1470, 'annotations': [{'iscrowd': 0, 'bbox': [1277.0, 592.0, 109.0, 29.0], 'category_id': 6, 'segmentation': [[1277, 605, 1315, 621, 1346, 613, 1386, 610, 1385, 597, 1338, 603, 1305, 592]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [822.0, 1317.0, 310.0, 141.0], 'category_id': 0, 'segmentation': [[925, 1453, 995, 1430, 1021, 1425, 1083, 1406, 1101, 1403, 1121, 1388, 1132, 1374, 1130, 1338, 1111, 1318, 1069, 1317, 1006, 1337, 977, 1346, 936, 1354, 881, 1372, 852, 1398, 839, 1413, 822, 1419, 823, 1444, 847, 1444, 898, 1458]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [821.0, 1415.0, 21.0, 30.0], 'category_id': 1, 'segmentation': [[836, 1415, 842, 1438, 834, 1445, 822, 1444, 821, 1420]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [742.0, 2518.0, 184.0, 137.0], 'category_id': 5, 'segmentation': [[834, 2655, 883, 2643, 905, 2627, 922, 2613, 926, 2577, 910, 2540, 887, 2525, 846, 2518, 791, 2527, 761, 2546, 742, 2583, 743, 2606, 763, 2634, 788, 2646]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [105.0, 1393.0, 22.0, 42.0], 'category_id': 7, 'segmentation': [[105, 1421, 124, 1435, 127, 1418, 127, 1393, 109, 1400]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [282.0, 1767.0, 71.0, 50.0], 'category_id': 6, 'segmentation': [[282, 1786, 293, 1813, 318, 1817, 342, 1813, 353, 1776, 326, 1780, 317, 1767, 304, 1781]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_9/000073.jpg', 'height': 4000, 'width': 1824, 'image_id': 1473, 'annotations': [{'iscrowd': 0, 'bbox': [757.0, 2359.0, 263.0, 206.0], 'category_id': 7, 'segmentation': [[767, 2382, 802, 2363, 830, 2359, 930, 2421, 1020, 2498, 998, 2516, 983, 2529, 972, 2546, 944, 2565, 757, 2404]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [1088.5, 1761.0, 280.0, 215.0], 'category_id': 6, 'segmentation': [[1122, 1967, 1088, 1901, 1118, 1853, 1214, 1777, 1270, 1761, 1304, 1762, 1348, 1804, 1348, 1820, 1368, 1853, 1356, 1880, 1342, 1887, 1336, 1833, 1308, 1832, 1288, 1820, 1290, 1834, 1284, 1843, 1264, 1823, 1268, 1842, 1258, 1855, 1290, 1880, 1308, 1883, 1316, 1893, 1306, 1902, 1286, 1896, 1296, 1909, 1284, 1913, 1270, 1907, 1270, 1937, 1284, 1964, 1272, 1964, 1252, 1944, 1248, 1957, 1234, 1959, 1226, 1945, 1202, 1941, 1186, 1976]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_9/000089.jpg', 'height': 4000, 'width': 1824, 'image_id': 1489, 'annotations': [{'iscrowd': 0, 'bbox': [743.0, 1521.0, 46.0, 30.0], 'category_id': 0, 'segmentation': [[743, 1540, 750, 1551, 770, 1545, 780, 1539, 789, 1527, 778, 1521, 757, 1530]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [960.0, 3351.0, 88.0, 84.0], 'category_id': 6, 'segmentation': [[960, 3360, 1032, 3435, 1048, 3426, 976, 3351]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}, {'file_name': '/content/official/batch_9/000090.jpg', 'height': 4000, 'width': 1824, 'image_id': 1490, 'annotations': [{'iscrowd': 0, 'bbox': [612.0, 1278.0, 117.0, 160.0], 'category_id': 2, 'segmentation': [[612, 1323, 657, 1427, 681, 1438, 721, 1432, 729, 1396, 706, 1343, 674, 1278, 644, 1278, 612, 1288]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [789.0, 1447.0, 283.0, 259.0], 'category_id': 7, 'segmentation': [[851, 1506, 922, 1447, 978, 1520, 1062, 1587, 1072, 1598, 1063, 1632, 1030, 1670, 1013, 1706, 986, 1706, 994, 1695, 973, 1687, 966, 1698, 934, 1680, 936, 1666, 951, 1666, 959, 1652, 990, 1644, 991, 1625, 1014, 1604, 1000, 1593, 981, 1566, 962, 1587, 945, 1603, 905, 1614, 904, 1575, 877, 1581, 839, 1590, 825, 1564, 797, 1574, 789, 1553, 800, 1525, 819, 1515, 837, 1517]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [1482.0, 1710.0, 97.0, 59.0], 'category_id': 6, 'segmentation': [[1482, 1732, 1505, 1710, 1566, 1733, 1579, 1757, 1538, 1769, 1495, 1760]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [835.0, 2467.0, 535.0, 418.0], 'category_id': 0, 'segmentation': [[874, 2625, 910, 2657, 934, 2661, 1051, 2757, 1124, 2816, 1166, 2847, 1205, 2862, 1263, 2867, 1297, 2865, 1338, 2885, 1370, 2822, 1346, 2799, 1328, 2792, 1322, 2771, 1297, 2728, 1262, 2720, 1272, 2709, 1235, 2665, 1116, 2601, 1051, 2559, 1005, 2518, 959, 2476, 930, 2467, 887, 2467, 872, 2502, 835, 2547, 839, 2587, 856, 2609]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}, {'iscrowd': 0, 'bbox': [1315.0, 2802.0, 55.0, 85.0], 'category_id': 1, 'segmentation': [[1315, 2872, 1321, 2848, 1332, 2827, 1346, 2802, 1370, 2816, 1340, 2887, 1324, 2882]], 'bbox_mode': <BoxMode.XYWH_ABS: 1>}]}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_cfg = cfg_solov2.clone()\n",
        "with open(\"/content/TACO-expl/taco_train_solov2.yaml\", \"w\") as f:\n",
        "  f.write(train_cfg.dump())"
      ],
      "metadata": {
        "id": "rhuvntPZn9Ar"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_cfg_loaded = get_cfg()\n",
        "train_cfg_loaded.set_new_allowed(True)\n",
        "train_cfg_loaded.merge_from_file(\"/content/TACO-expl/solov2_config/taco_train_solov2.yaml\")\n",
        "print(train_cfg_loaded.SOLVER.IMS_PER_BATCH)\n",
        "print(train_cfg_loaded.DATALOADER.NUM_WORKERS)\n",
        "print(train_cfg_loaded.OUTPUT_DIR)\n",
        "print(train_cfg_loaded.MODEL.WEIGHTS)"
      ],
      "metadata": {
        "id": "hDjfTaa9n9W8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b9791bc-565e-4cbe-e233-c020d56cbbe6"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8\n",
            "4\n",
            "/content/output/chkpt/\n",
            "/content/output/chkpt/model_0001949.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/TACO-expl/AdelaiDet/tools/\n",
        "from train_net import Trainer\n",
        "!python -m pip install numpy==1.23.1\n",
        "import numpy as np\n",
        "np.bool = np.bool_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4MsfHBcWn_O1",
        "outputId": "5bb7adb7-50f0-4ccf-b5c4-7c50b8ecee57"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/TACO-expl/AdelaiDet/tools\n",
            "Requirement already satisfied: numpy==1.23.1 in /usr/local/lib/python3.10/dist-packages (1.23.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L107epvvZ8i4",
        "outputId": "34a9b272-e214-414a-a3ba-1fea1101662e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(train_cfg_loaded)\n",
        "trainer.build_hooks()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6N9mz87nF0TI",
        "outputId": "06b0c2c2-eca7-45cc-af60-a4a96a23c155"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05/10 06:29:47 d2.engine.defaults]: Model:\n",
            "SOLOv2(\n",
            "  (backbone): FPN(\n",
            "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (top_block): LastLevelMaxPool()\n",
            "    (bottom_up): ResNet(\n",
            "      (stem): BasicStem(\n",
            "        (conv1): Conv2d(\n",
            "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (res2): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res3): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res4): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (4): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (5): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res5): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (ins_head): SOLOv2InsHead(\n",
            "    (cate_tower): Sequential(\n",
            "      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
            "      (2): ReLU(inplace=True)\n",
            "      (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (4): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
            "      (5): ReLU(inplace=True)\n",
            "      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (7): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
            "      (8): ReLU(inplace=True)\n",
            "      (9): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (10): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
            "      (11): ReLU(inplace=True)\n",
            "    )\n",
            "    (kernel_tower): Sequential(\n",
            "      (0): Conv2d(258, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
            "      (2): ReLU(inplace=True)\n",
            "      (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (4): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
            "      (5): ReLU(inplace=True)\n",
            "      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (7): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
            "      (8): ReLU(inplace=True)\n",
            "      (9): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (10): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
            "      (11): ReLU(inplace=True)\n",
            "    )\n",
            "    (cate_pred): Conv2d(512, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (kernel_pred): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  )\n",
            "  (mask_head): SOLOv2MaskHead(\n",
            "    (convs_all_levels): ModuleList(\n",
            "      (0): Sequential(\n",
            "        (conv0): Sequential(\n",
            "          (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
            "          (2): ReLU()\n",
            "        )\n",
            "      )\n",
            "      (1): Sequential(\n",
            "        (conv0): Sequential(\n",
            "          (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
            "          (2): ReLU()\n",
            "        )\n",
            "        (upsample0): Upsample(scale_factor=2.0, mode='bilinear')\n",
            "      )\n",
            "      (2): Sequential(\n",
            "        (conv0): Sequential(\n",
            "          (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
            "          (2): ReLU()\n",
            "        )\n",
            "        (upsample0): Upsample(scale_factor=2.0, mode='bilinear')\n",
            "        (conv1): Sequential(\n",
            "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
            "          (2): ReLU()\n",
            "        )\n",
            "        (upsample1): Upsample(scale_factor=2.0, mode='bilinear')\n",
            "      )\n",
            "      (3): Sequential(\n",
            "        (conv0): Sequential(\n",
            "          (0): Conv2d(258, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
            "          (2): ReLU()\n",
            "        )\n",
            "        (upsample0): Upsample(scale_factor=2.0, mode='bilinear')\n",
            "        (conv1): Sequential(\n",
            "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
            "          (2): ReLU()\n",
            "        )\n",
            "        (upsample1): Upsample(scale_factor=2.0, mode='bilinear')\n",
            "        (conv2): Sequential(\n",
            "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
            "          (2): ReLU()\n",
            "        )\n",
            "        (upsample2): Upsample(scale_factor=2.0, mode='bilinear')\n",
            "      )\n",
            "    )\n",
            "    (conv_pred): Sequential(\n",
            "      (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
            "      (2): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "[05/10 06:29:48 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
            "[05/10 06:29:48 d2.data.datasets.coco]: Loaded 1200 images in COCO format from /content/TACO-expl/data/annotations_off_0_train.json\n",
            "[05/10 06:29:48 d2.data.build]: Removed 0 images with no usable annotations. 1200 images left.\n",
            "[05/10 06:29:48 d2.data.build]: Using training sampler TrainingSampler\n",
            "[05/10 06:29:48 d2.data.common]: Serializing 1200 elements to byte tensors and concatenating them all ...\n",
            "[05/10 06:29:48 d2.data.common]: Serialized dataset takes 1.79 MiB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<detectron2.engine.hooks.IterationTimer at 0x7b40e0ab1d80>,\n",
              " <detectron2.engine.hooks.LRScheduler at 0x7b40e0a8a050>,\n",
              " None,\n",
              " <detectron2.engine.hooks.PeriodicCheckpointer at 0x7b40e0a88cd0>,\n",
              " <detectron2.engine.hooks.EvalHook at 0x7b40e0a89ea0>,\n",
              " <detectron2.engine.hooks.PeriodicWriter at 0x7b40e0a88e20>]"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "some_dict = trainer.checkpointer.resume_or_load(resume = True, path = '/content/output/chkpt/model_0001949.pth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2MogRKNqIuEZ",
        "outputId": "5697f731-ef8b-4ea3-b2a0-ae247e252759"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05/10 07:01:43 d2.checkpoint.c2_model_loading]: Following weights matched with model:\n",
            "| Names in Model                              | Names in Checkpoint                                                                                  | Shapes                                          |\n",
            "|:--------------------------------------------|:-----------------------------------------------------------------------------------------------------|:------------------------------------------------|\n",
            "| backbone.bottom_up.res2.0.conv1.*           | backbone.bottom_up.res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |\n",
            "| backbone.bottom_up.res2.0.conv2.*           | backbone.bottom_up.res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
            "| backbone.bottom_up.res2.0.conv3.*           | backbone.bottom_up.res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
            "| backbone.bottom_up.res2.0.shortcut.*        | backbone.bottom_up.res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
            "| backbone.bottom_up.res2.1.conv1.*           | backbone.bottom_up.res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
            "| backbone.bottom_up.res2.1.conv2.*           | backbone.bottom_up.res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
            "| backbone.bottom_up.res2.1.conv3.*           | backbone.bottom_up.res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
            "| backbone.bottom_up.res2.2.conv1.*           | backbone.bottom_up.res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
            "| backbone.bottom_up.res2.2.conv2.*           | backbone.bottom_up.res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
            "| backbone.bottom_up.res2.2.conv3.*           | backbone.bottom_up.res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
            "| backbone.bottom_up.res3.0.conv1.*           | backbone.bottom_up.res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |\n",
            "| backbone.bottom_up.res3.0.conv2.*           | backbone.bottom_up.res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
            "| backbone.bottom_up.res3.0.conv3.*           | backbone.bottom_up.res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
            "| backbone.bottom_up.res3.0.shortcut.*        | backbone.bottom_up.res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |\n",
            "| backbone.bottom_up.res3.1.conv1.*           | backbone.bottom_up.res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
            "| backbone.bottom_up.res3.1.conv2.*           | backbone.bottom_up.res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
            "| backbone.bottom_up.res3.1.conv3.*           | backbone.bottom_up.res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
            "| backbone.bottom_up.res3.2.conv1.*           | backbone.bottom_up.res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
            "| backbone.bottom_up.res3.2.conv2.*           | backbone.bottom_up.res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
            "| backbone.bottom_up.res3.2.conv3.*           | backbone.bottom_up.res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
            "| backbone.bottom_up.res3.3.conv1.*           | backbone.bottom_up.res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
            "| backbone.bottom_up.res3.3.conv2.*           | backbone.bottom_up.res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
            "| backbone.bottom_up.res3.3.conv3.*           | backbone.bottom_up.res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
            "| backbone.bottom_up.res4.0.conv1.*           | backbone.bottom_up.res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |\n",
            "| backbone.bottom_up.res4.0.conv2.*           | backbone.bottom_up.res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| backbone.bottom_up.res4.0.conv3.*           | backbone.bottom_up.res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.0.shortcut.*        | backbone.bottom_up.res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |\n",
            "| backbone.bottom_up.res4.1.conv1.*           | backbone.bottom_up.res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.1.conv2.*           | backbone.bottom_up.res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| backbone.bottom_up.res4.1.conv3.*           | backbone.bottom_up.res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.2.conv1.*           | backbone.bottom_up.res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.2.conv2.*           | backbone.bottom_up.res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| backbone.bottom_up.res4.2.conv3.*           | backbone.bottom_up.res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.3.conv1.*           | backbone.bottom_up.res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.3.conv2.*           | backbone.bottom_up.res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| backbone.bottom_up.res4.3.conv3.*           | backbone.bottom_up.res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.4.conv1.*           | backbone.bottom_up.res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.4.conv2.*           | backbone.bottom_up.res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| backbone.bottom_up.res4.4.conv3.*           | backbone.bottom_up.res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.5.conv1.*           | backbone.bottom_up.res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.5.conv2.*           | backbone.bottom_up.res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| backbone.bottom_up.res4.5.conv3.*           | backbone.bottom_up.res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res5.0.conv1.*           | backbone.bottom_up.res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |\n",
            "| backbone.bottom_up.res5.0.conv2.*           | backbone.bottom_up.res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
            "| backbone.bottom_up.res5.0.conv3.*           | backbone.bottom_up.res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
            "| backbone.bottom_up.res5.0.shortcut.*        | backbone.bottom_up.res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |\n",
            "| backbone.bottom_up.res5.1.conv1.*           | backbone.bottom_up.res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
            "| backbone.bottom_up.res5.1.conv2.*           | backbone.bottom_up.res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
            "| backbone.bottom_up.res5.1.conv3.*           | backbone.bottom_up.res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
            "| backbone.bottom_up.res5.2.conv1.*           | backbone.bottom_up.res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
            "| backbone.bottom_up.res5.2.conv2.*           | backbone.bottom_up.res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
            "| backbone.bottom_up.res5.2.conv3.*           | backbone.bottom_up.res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
            "| backbone.bottom_up.stem.conv1.*             | backbone.bottom_up.stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |\n",
            "| backbone.fpn_lateral2.*                     | backbone.fpn_lateral2.{bias,weight}                                                                  | (256,) (256,256,1,1)                            |\n",
            "| backbone.fpn_lateral3.*                     | backbone.fpn_lateral3.{bias,weight}                                                                  | (256,) (256,512,1,1)                            |\n",
            "| backbone.fpn_lateral4.*                     | backbone.fpn_lateral4.{bias,weight}                                                                  | (256,) (256,1024,1,1)                           |\n",
            "| backbone.fpn_lateral5.*                     | backbone.fpn_lateral5.{bias,weight}                                                                  | (256,) (256,2048,1,1)                           |\n",
            "| backbone.fpn_output2.*                      | backbone.fpn_output2.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
            "| backbone.fpn_output3.*                      | backbone.fpn_output3.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
            "| backbone.fpn_output4.*                      | backbone.fpn_output4.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
            "| backbone.fpn_output5.*                      | backbone.fpn_output5.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
            "| ins_head.cate_pred.*                        | ins_head.cate_pred.{bias,weight}                                                                     | (10,) (10,512,3,3)                              |\n",
            "| ins_head.cate_tower.0.weight                | ins_head.cate_tower.0.weight                                                                         | (512, 256, 3, 3)                                |\n",
            "| ins_head.cate_tower.1.*                     | ins_head.cate_tower.1.{bias,weight}                                                                  | (512,) (512,)                                   |\n",
            "| ins_head.cate_tower.10.*                    | ins_head.cate_tower.10.{bias,weight}                                                                 | (512,) (512,)                                   |\n",
            "| ins_head.cate_tower.3.weight                | ins_head.cate_tower.3.weight                                                                         | (512, 512, 3, 3)                                |\n",
            "| ins_head.cate_tower.4.*                     | ins_head.cate_tower.4.{bias,weight}                                                                  | (512,) (512,)                                   |\n",
            "| ins_head.cate_tower.6.weight                | ins_head.cate_tower.6.weight                                                                         | (512, 512, 3, 3)                                |\n",
            "| ins_head.cate_tower.7.*                     | ins_head.cate_tower.7.{bias,weight}                                                                  | (512,) (512,)                                   |\n",
            "| ins_head.cate_tower.9.weight                | ins_head.cate_tower.9.weight                                                                         | (512, 512, 3, 3)                                |\n",
            "| ins_head.kernel_pred.*                      | ins_head.kernel_pred.{bias,weight}                                                                   | (256,) (256,512,3,3)                            |\n",
            "| ins_head.kernel_tower.0.weight              | ins_head.kernel_tower.0.weight                                                                       | (512, 258, 3, 3)                                |\n",
            "| ins_head.kernel_tower.1.*                   | ins_head.kernel_tower.1.{bias,weight}                                                                | (512,) (512,)                                   |\n",
            "| ins_head.kernel_tower.10.*                  | ins_head.kernel_tower.10.{bias,weight}                                                               | (512,) (512,)                                   |\n",
            "| ins_head.kernel_tower.3.weight              | ins_head.kernel_tower.3.weight                                                                       | (512, 512, 3, 3)                                |\n",
            "| ins_head.kernel_tower.4.*                   | ins_head.kernel_tower.4.{bias,weight}                                                                | (512,) (512,)                                   |\n",
            "| ins_head.kernel_tower.6.weight              | ins_head.kernel_tower.6.weight                                                                       | (512, 512, 3, 3)                                |\n",
            "| ins_head.kernel_tower.7.*                   | ins_head.kernel_tower.7.{bias,weight}                                                                | (512,) (512,)                                   |\n",
            "| ins_head.kernel_tower.9.weight              | ins_head.kernel_tower.9.weight                                                                       | (512, 512, 3, 3)                                |\n",
            "| mask_head.conv_pred.0.weight                | mask_head.conv_pred.0.weight                                                                         | (256, 128, 1, 1)                                |\n",
            "| mask_head.conv_pred.1.*                     | mask_head.conv_pred.1.{bias,weight}                                                                  | (256,) (256,)                                   |\n",
            "| mask_head.convs_all_levels.0.conv0.0.weight | mask_head.convs_all_levels.0.conv0.0.weight                                                          | (128, 256, 3, 3)                                |\n",
            "| mask_head.convs_all_levels.0.conv0.1.*      | mask_head.convs_all_levels.0.conv0.1.{bias,weight}                                                   | (128,) (128,)                                   |\n",
            "| mask_head.convs_all_levels.1.conv0.0.weight | mask_head.convs_all_levels.1.conv0.0.weight                                                          | (128, 256, 3, 3)                                |\n",
            "| mask_head.convs_all_levels.1.conv0.1.*      | mask_head.convs_all_levels.1.conv0.1.{bias,weight}                                                   | (128,) (128,)                                   |\n",
            "| mask_head.convs_all_levels.2.conv0.0.weight | mask_head.convs_all_levels.2.conv0.0.weight                                                          | (128, 256, 3, 3)                                |\n",
            "| mask_head.convs_all_levels.2.conv0.1.*      | mask_head.convs_all_levels.2.conv0.1.{bias,weight}                                                   | (128,) (128,)                                   |\n",
            "| mask_head.convs_all_levels.2.conv1.0.weight | mask_head.convs_all_levels.2.conv1.0.weight                                                          | (128, 128, 3, 3)                                |\n",
            "| mask_head.convs_all_levels.2.conv1.1.*      | mask_head.convs_all_levels.2.conv1.1.{bias,weight}                                                   | (128,) (128,)                                   |\n",
            "| mask_head.convs_all_levels.3.conv0.0.weight | mask_head.convs_all_levels.3.conv0.0.weight                                                          | (128, 258, 3, 3)                                |\n",
            "| mask_head.convs_all_levels.3.conv0.1.*      | mask_head.convs_all_levels.3.conv0.1.{bias,weight}                                                   | (128,) (128,)                                   |\n",
            "| mask_head.convs_all_levels.3.conv1.0.weight | mask_head.convs_all_levels.3.conv1.0.weight                                                          | (128, 128, 3, 3)                                |\n",
            "| mask_head.convs_all_levels.3.conv1.1.*      | mask_head.convs_all_levels.3.conv1.1.{bias,weight}                                                   | (128,) (128,)                                   |\n",
            "| mask_head.convs_all_levels.3.conv2.0.weight | mask_head.convs_all_levels.3.conv2.0.weight                                                          | (128, 128, 3, 3)                                |\n",
            "| mask_head.convs_all_levels.3.conv2.1.*      | mask_head.convs_all_levels.3.conv2.1.{bias,weight}                                                   | (128,) (128,)                                   |\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "last_chkpt_path = '/content/output/chkpt/model_0001949.pth'\n",
        "with open('/content/output/chkpt/last_checkpoint', 'w', encoding = 'ascii') as f:\n",
        "  f.write(last_chkpt_path)"
      ],
      "metadata": {
        "id": "Pokgx82hSL1D"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/output/chkpt/last_checkpoint', 'r', encoding = 'ascii') as f:\n",
        "  print(f.read())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ddU2TqiOVlyB",
        "outputId": "9b0d5db3-74cd-4841-c0ca-c68e5de40919"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/output/chkpt/model_0001949.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(some_dict.keys())\n",
        "#print(some_dict['optimizer'])\n",
        "#print('_________')\n",
        "#print(some_dict['iteration'])\n",
        "#print(trainer.scheduler._step_count)\n",
        "#trainer.resume_or_load(resume = True)\n",
        "#print(trainer.start_iter)\n",
        "#print(trainer.resume_or_load(resume = True))\n",
        "trainer.checkpointer.has_checkpoint()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ub2XU79lJVfg",
        "outputId": "f9be1024-f1ac-4524-9bf6-c3f4f6a6bb67"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['optimizer', 'scheduler', 'iteration', 'matching_heuristics'])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#trainer = Trainer(train_cfg_loaded)\n",
        "#trainer.build_hooks()\n",
        "trainer.resume_or_load(resume = True)  # load last checkpoint or MODEL.WEIGHTS\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xvnHug9_oDE_",
        "outputId": "13616596-b8f3-454a-a135-4df36ebd2e44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05/10 07:19:26 d2.checkpoint.c2_model_loading]: Following weights matched with model:\n",
            "| Names in Model                              | Names in Checkpoint                                                                                  | Shapes                                          |\n",
            "|:--------------------------------------------|:-----------------------------------------------------------------------------------------------------|:------------------------------------------------|\n",
            "| backbone.bottom_up.res2.0.conv1.*           | backbone.bottom_up.res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |\n",
            "| backbone.bottom_up.res2.0.conv2.*           | backbone.bottom_up.res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
            "| backbone.bottom_up.res2.0.conv3.*           | backbone.bottom_up.res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
            "| backbone.bottom_up.res2.0.shortcut.*        | backbone.bottom_up.res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
            "| backbone.bottom_up.res2.1.conv1.*           | backbone.bottom_up.res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
            "| backbone.bottom_up.res2.1.conv2.*           | backbone.bottom_up.res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
            "| backbone.bottom_up.res2.1.conv3.*           | backbone.bottom_up.res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
            "| backbone.bottom_up.res2.2.conv1.*           | backbone.bottom_up.res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
            "| backbone.bottom_up.res2.2.conv2.*           | backbone.bottom_up.res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
            "| backbone.bottom_up.res2.2.conv3.*           | backbone.bottom_up.res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
            "| backbone.bottom_up.res3.0.conv1.*           | backbone.bottom_up.res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |\n",
            "| backbone.bottom_up.res3.0.conv2.*           | backbone.bottom_up.res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
            "| backbone.bottom_up.res3.0.conv3.*           | backbone.bottom_up.res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
            "| backbone.bottom_up.res3.0.shortcut.*        | backbone.bottom_up.res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |\n",
            "| backbone.bottom_up.res3.1.conv1.*           | backbone.bottom_up.res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
            "| backbone.bottom_up.res3.1.conv2.*           | backbone.bottom_up.res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
            "| backbone.bottom_up.res3.1.conv3.*           | backbone.bottom_up.res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
            "| backbone.bottom_up.res3.2.conv1.*           | backbone.bottom_up.res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
            "| backbone.bottom_up.res3.2.conv2.*           | backbone.bottom_up.res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
            "| backbone.bottom_up.res3.2.conv3.*           | backbone.bottom_up.res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
            "| backbone.bottom_up.res3.3.conv1.*           | backbone.bottom_up.res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
            "| backbone.bottom_up.res3.3.conv2.*           | backbone.bottom_up.res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
            "| backbone.bottom_up.res3.3.conv3.*           | backbone.bottom_up.res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
            "| backbone.bottom_up.res4.0.conv1.*           | backbone.bottom_up.res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |\n",
            "| backbone.bottom_up.res4.0.conv2.*           | backbone.bottom_up.res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| backbone.bottom_up.res4.0.conv3.*           | backbone.bottom_up.res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.0.shortcut.*        | backbone.bottom_up.res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |\n",
            "| backbone.bottom_up.res4.1.conv1.*           | backbone.bottom_up.res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.1.conv2.*           | backbone.bottom_up.res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| backbone.bottom_up.res4.1.conv3.*           | backbone.bottom_up.res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.2.conv1.*           | backbone.bottom_up.res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.2.conv2.*           | backbone.bottom_up.res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| backbone.bottom_up.res4.2.conv3.*           | backbone.bottom_up.res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.3.conv1.*           | backbone.bottom_up.res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.3.conv2.*           | backbone.bottom_up.res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| backbone.bottom_up.res4.3.conv3.*           | backbone.bottom_up.res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.4.conv1.*           | backbone.bottom_up.res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.4.conv2.*           | backbone.bottom_up.res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| backbone.bottom_up.res4.4.conv3.*           | backbone.bottom_up.res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.5.conv1.*           | backbone.bottom_up.res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.5.conv2.*           | backbone.bottom_up.res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| backbone.bottom_up.res4.5.conv3.*           | backbone.bottom_up.res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res5.0.conv1.*           | backbone.bottom_up.res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |\n",
            "| backbone.bottom_up.res5.0.conv2.*           | backbone.bottom_up.res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
            "| backbone.bottom_up.res5.0.conv3.*           | backbone.bottom_up.res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
            "| backbone.bottom_up.res5.0.shortcut.*        | backbone.bottom_up.res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |\n",
            "| backbone.bottom_up.res5.1.conv1.*           | backbone.bottom_up.res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
            "| backbone.bottom_up.res5.1.conv2.*           | backbone.bottom_up.res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
            "| backbone.bottom_up.res5.1.conv3.*           | backbone.bottom_up.res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
            "| backbone.bottom_up.res5.2.conv1.*           | backbone.bottom_up.res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
            "| backbone.bottom_up.res5.2.conv2.*           | backbone.bottom_up.res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
            "| backbone.bottom_up.res5.2.conv3.*           | backbone.bottom_up.res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
            "| backbone.bottom_up.stem.conv1.*             | backbone.bottom_up.stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |\n",
            "| backbone.fpn_lateral2.*                     | backbone.fpn_lateral2.{bias,weight}                                                                  | (256,) (256,256,1,1)                            |\n",
            "| backbone.fpn_lateral3.*                     | backbone.fpn_lateral3.{bias,weight}                                                                  | (256,) (256,512,1,1)                            |\n",
            "| backbone.fpn_lateral4.*                     | backbone.fpn_lateral4.{bias,weight}                                                                  | (256,) (256,1024,1,1)                           |\n",
            "| backbone.fpn_lateral5.*                     | backbone.fpn_lateral5.{bias,weight}                                                                  | (256,) (256,2048,1,1)                           |\n",
            "| backbone.fpn_output2.*                      | backbone.fpn_output2.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
            "| backbone.fpn_output3.*                      | backbone.fpn_output3.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
            "| backbone.fpn_output4.*                      | backbone.fpn_output4.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
            "| backbone.fpn_output5.*                      | backbone.fpn_output5.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
            "| ins_head.cate_pred.*                        | ins_head.cate_pred.{bias,weight}                                                                     | (10,) (10,512,3,3)                              |\n",
            "| ins_head.cate_tower.0.weight                | ins_head.cate_tower.0.weight                                                                         | (512, 256, 3, 3)                                |\n",
            "| ins_head.cate_tower.1.*                     | ins_head.cate_tower.1.{bias,weight}                                                                  | (512,) (512,)                                   |\n",
            "| ins_head.cate_tower.10.*                    | ins_head.cate_tower.10.{bias,weight}                                                                 | (512,) (512,)                                   |\n",
            "| ins_head.cate_tower.3.weight                | ins_head.cate_tower.3.weight                                                                         | (512, 512, 3, 3)                                |\n",
            "| ins_head.cate_tower.4.*                     | ins_head.cate_tower.4.{bias,weight}                                                                  | (512,) (512,)                                   |\n",
            "| ins_head.cate_tower.6.weight                | ins_head.cate_tower.6.weight                                                                         | (512, 512, 3, 3)                                |\n",
            "| ins_head.cate_tower.7.*                     | ins_head.cate_tower.7.{bias,weight}                                                                  | (512,) (512,)                                   |\n",
            "| ins_head.cate_tower.9.weight                | ins_head.cate_tower.9.weight                                                                         | (512, 512, 3, 3)                                |\n",
            "| ins_head.kernel_pred.*                      | ins_head.kernel_pred.{bias,weight}                                                                   | (256,) (256,512,3,3)                            |\n",
            "| ins_head.kernel_tower.0.weight              | ins_head.kernel_tower.0.weight                                                                       | (512, 258, 3, 3)                                |\n",
            "| ins_head.kernel_tower.1.*                   | ins_head.kernel_tower.1.{bias,weight}                                                                | (512,) (512,)                                   |\n",
            "| ins_head.kernel_tower.10.*                  | ins_head.kernel_tower.10.{bias,weight}                                                               | (512,) (512,)                                   |\n",
            "| ins_head.kernel_tower.3.weight              | ins_head.kernel_tower.3.weight                                                                       | (512, 512, 3, 3)                                |\n",
            "| ins_head.kernel_tower.4.*                   | ins_head.kernel_tower.4.{bias,weight}                                                                | (512,) (512,)                                   |\n",
            "| ins_head.kernel_tower.6.weight              | ins_head.kernel_tower.6.weight                                                                       | (512, 512, 3, 3)                                |\n",
            "| ins_head.kernel_tower.7.*                   | ins_head.kernel_tower.7.{bias,weight}                                                                | (512,) (512,)                                   |\n",
            "| ins_head.kernel_tower.9.weight              | ins_head.kernel_tower.9.weight                                                                       | (512, 512, 3, 3)                                |\n",
            "| mask_head.conv_pred.0.weight                | mask_head.conv_pred.0.weight                                                                         | (256, 128, 1, 1)                                |\n",
            "| mask_head.conv_pred.1.*                     | mask_head.conv_pred.1.{bias,weight}                                                                  | (256,) (256,)                                   |\n",
            "| mask_head.convs_all_levels.0.conv0.0.weight | mask_head.convs_all_levels.0.conv0.0.weight                                                          | (128, 256, 3, 3)                                |\n",
            "| mask_head.convs_all_levels.0.conv0.1.*      | mask_head.convs_all_levels.0.conv0.1.{bias,weight}                                                   | (128,) (128,)                                   |\n",
            "| mask_head.convs_all_levels.1.conv0.0.weight | mask_head.convs_all_levels.1.conv0.0.weight                                                          | (128, 256, 3, 3)                                |\n",
            "| mask_head.convs_all_levels.1.conv0.1.*      | mask_head.convs_all_levels.1.conv0.1.{bias,weight}                                                   | (128,) (128,)                                   |\n",
            "| mask_head.convs_all_levels.2.conv0.0.weight | mask_head.convs_all_levels.2.conv0.0.weight                                                          | (128, 256, 3, 3)                                |\n",
            "| mask_head.convs_all_levels.2.conv0.1.*      | mask_head.convs_all_levels.2.conv0.1.{bias,weight}                                                   | (128,) (128,)                                   |\n",
            "| mask_head.convs_all_levels.2.conv1.0.weight | mask_head.convs_all_levels.2.conv1.0.weight                                                          | (128, 128, 3, 3)                                |\n",
            "| mask_head.convs_all_levels.2.conv1.1.*      | mask_head.convs_all_levels.2.conv1.1.{bias,weight}                                                   | (128,) (128,)                                   |\n",
            "| mask_head.convs_all_levels.3.conv0.0.weight | mask_head.convs_all_levels.3.conv0.0.weight                                                          | (128, 258, 3, 3)                                |\n",
            "| mask_head.convs_all_levels.3.conv0.1.*      | mask_head.convs_all_levels.3.conv0.1.{bias,weight}                                                   | (128,) (128,)                                   |\n",
            "| mask_head.convs_all_levels.3.conv1.0.weight | mask_head.convs_all_levels.3.conv1.0.weight                                                          | (128, 128, 3, 3)                                |\n",
            "| mask_head.convs_all_levels.3.conv1.1.*      | mask_head.convs_all_levels.3.conv1.1.{bias,weight}                                                   | (128,) (128,)                                   |\n",
            "| mask_head.convs_all_levels.3.conv2.0.weight | mask_head.convs_all_levels.3.conv2.0.weight                                                          | (128, 128, 3, 3)                                |\n",
            "| mask_head.convs_all_levels.3.conv2.1.*      | mask_head.convs_all_levels.3.conv2.1.{bias,weight}                                                   | (128,) (128,)                                   |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05/10 07:20:08 d2.utils.events]:  eta: 3:27:05  iter: 1959  total_loss: 1.25  loss_ins: 0.9572  loss_cate: 0.2914  time: 3.7122  data_time: 2.2751  lr: 0.00076578  max_mem: 8286M\n",
            "[05/10 07:21:13 d2.utils.events]:  eta: 2:58:10  iter: 1979  total_loss: 1.426  loss_ins: 1.122  loss_cate: 0.2944  time: 3.3850  data_time: 1.6352  lr: 0.00076145  max_mem: 8419M\n",
            "[05/10 07:22:24 d2.data.datasets.coco]: Loaded 150 images in COCO format from /content/TACO-expl/data/annotations_off_0_val.json\n",
            "[05/10 07:22:24 d2.data.build]: Distribution of instances among all 10 categories:\n",
            "|  category  | #instances   |   category    | #instances   |  category  | #instances   |\n",
            "|:----------:|:-------------|:-------------:|:-------------|:----------:|:-------------|\n",
            "|   Bottle   | 50           |  Bottle cap   | 30           |    Can     | 21           |\n",
            "| Cigarette  | 42           |      Cup      | 21           |    Lid     | 8            |\n",
            "|   Other    | 135          | Plastic bag.. | 77           |  Pop tab   | 10           |\n",
            "|   Straw    | 16           |               |              |            |              |\n",
            "|   total    | 410          |               |              |            |              |\n",
            "[05/10 07:22:24 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "[05/10 07:22:24 d2.data.common]: Serializing 150 elements to byte tensors and concatenating them all ...\n",
            "[05/10 07:22:24 d2.data.common]: Serialized dataset takes 0.22 MiB\n",
            "WARNING [05/10 07:22:24 d2.evaluation.coco_evaluation]: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
            "[05/10 07:22:24 d2.evaluation.evaluator]: Start inference on 150 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05/10 07:22:58 d2.evaluation.evaluator]: Inference done 11/150. Dataloading: 0.0019 s/iter. Inference: 0.2404 s/iter. Eval: 4.2811 s/iter. Total: 4.5234 s/iter. ETA=0:10:28\n",
            "[05/10 07:23:04 d2.evaluation.evaluator]: Inference done 12/150. Dataloading: 0.0021 s/iter. Inference: 0.2417 s/iter. Eval: 4.4006 s/iter. Total: 4.6453 s/iter. ETA=0:10:41\n",
            "[05/10 07:23:15 d2.evaluation.evaluator]: Inference done 15/150. Dataloading: 0.0036 s/iter. Inference: 0.2469 s/iter. Eval: 4.1582 s/iter. Total: 4.4099 s/iter. ETA=0:09:55\n",
            "[05/10 07:23:23 d2.evaluation.evaluator]: Inference done 18/150. Dataloading: 0.0033 s/iter. Inference: 0.2304 s/iter. Eval: 3.7105 s/iter. Total: 3.9452 s/iter. ETA=0:08:40\n",
            "[05/10 07:23:33 d2.evaluation.evaluator]: Inference done 19/150. Dataloading: 0.0033 s/iter. Inference: 0.2293 s/iter. Eval: 4.1802 s/iter. Total: 4.4139 s/iter. ETA=0:09:38\n",
            "[05/10 07:23:48 d2.evaluation.evaluator]: Inference done 21/150. Dataloading: 0.0033 s/iter. Inference: 0.2462 s/iter. Eval: 4.5581 s/iter. Total: 4.8089 s/iter. ETA=0:10:20\n",
            "[05/10 07:23:55 d2.evaluation.evaluator]: Inference done 22/150. Dataloading: 0.0033 s/iter. Inference: 0.2433 s/iter. Eval: 4.6548 s/iter. Total: 4.9026 s/iter. ETA=0:10:27\n",
            "[05/10 07:24:02 d2.evaluation.evaluator]: Inference done 23/150. Dataloading: 0.0033 s/iter. Inference: 0.2431 s/iter. Eval: 4.8095 s/iter. Total: 5.0573 s/iter. ETA=0:10:42\n",
            "[05/10 07:24:13 d2.evaluation.evaluator]: Inference done 24/150. Dataloading: 0.0033 s/iter. Inference: 0.2514 s/iter. Eval: 5.1147 s/iter. Total: 5.3709 s/iter. ETA=0:11:16\n",
            "[05/10 07:24:20 d2.evaluation.evaluator]: Inference done 25/150. Dataloading: 0.0033 s/iter. Inference: 0.2491 s/iter. Eval: 5.1629 s/iter. Total: 5.4168 s/iter. ETA=0:11:17\n",
            "[05/10 07:24:32 d2.evaluation.evaluator]: Inference done 27/150. Dataloading: 0.0038 s/iter. Inference: 0.2466 s/iter. Eval: 5.2476 s/iter. Total: 5.4996 s/iter. ETA=0:11:16\n",
            "[05/10 07:24:48 d2.evaluation.evaluator]: Inference done 28/150. Dataloading: 0.0038 s/iter. Inference: 0.2558 s/iter. Eval: 5.6865 s/iter. Total: 5.9479 s/iter. ETA=0:12:05\n",
            "[05/10 07:25:01 d2.evaluation.evaluator]: Inference done 29/150. Dataloading: 0.0037 s/iter. Inference: 0.2638 s/iter. Eval: 5.9541 s/iter. Total: 6.2237 s/iter. ETA=0:12:33\n",
            "[05/10 07:25:14 d2.evaluation.evaluator]: Inference done 31/150. Dataloading: 0.0037 s/iter. Inference: 0.2606 s/iter. Eval: 5.9951 s/iter. Total: 6.2614 s/iter. ETA=0:12:25\n",
            "[05/10 07:25:19 d2.evaluation.evaluator]: Inference done 32/150. Dataloading: 0.0037 s/iter. Inference: 0.2587 s/iter. Eval: 5.9580 s/iter. Total: 6.2225 s/iter. ETA=0:12:14\n",
            "[05/10 07:25:26 d2.evaluation.evaluator]: Inference done 33/150. Dataloading: 0.0036 s/iter. Inference: 0.2568 s/iter. Eval: 5.9783 s/iter. Total: 6.2408 s/iter. ETA=0:12:10\n",
            "[05/10 07:25:39 d2.evaluation.evaluator]: Inference done 34/150. Dataloading: 0.0036 s/iter. Inference: 0.2553 s/iter. Eval: 6.2093 s/iter. Total: 6.4703 s/iter. ETA=0:12:30\n",
            "[05/10 07:25:50 d2.evaluation.evaluator]: Inference done 35/150. Dataloading: 0.0036 s/iter. Inference: 0.2554 s/iter. Eval: 6.3733 s/iter. Total: 6.6344 s/iter. ETA=0:12:42\n",
            "[05/10 07:26:00 d2.evaluation.evaluator]: Inference done 37/150. Dataloading: 0.0035 s/iter. Inference: 0.2522 s/iter. Eval: 6.2512 s/iter. Total: 6.5090 s/iter. ETA=0:12:15\n",
            "[05/10 07:26:12 d2.evaluation.evaluator]: Inference done 38/150. Dataloading: 0.0035 s/iter. Inference: 0.2520 s/iter. Eval: 6.4444 s/iter. Total: 6.7020 s/iter. ETA=0:12:30\n",
            "[05/10 07:26:25 d2.evaluation.evaluator]: Inference done 39/150. Dataloading: 0.0035 s/iter. Inference: 0.2517 s/iter. Eval: 6.6297 s/iter. Total: 6.8871 s/iter. ETA=0:12:44\n",
            "[05/10 07:26:44 d2.evaluation.evaluator]: Inference done 40/150. Dataloading: 0.0036 s/iter. Inference: 0.2587 s/iter. Eval: 6.9469 s/iter. Total: 7.2115 s/iter. ETA=0:13:13\n",
            "[05/10 07:26:55 d2.evaluation.evaluator]: Inference done 41/150. Dataloading: 0.0036 s/iter. Inference: 0.2577 s/iter. Eval: 7.0708 s/iter. Total: 7.3343 s/iter. ETA=0:13:19\n",
            "[05/10 07:27:12 d2.evaluation.evaluator]: Inference done 42/150. Dataloading: 0.0036 s/iter. Inference: 0.2572 s/iter. Eval: 7.3195 s/iter. Total: 7.5828 s/iter. ETA=0:13:38\n",
            "[05/10 07:27:29 d2.evaluation.evaluator]: Inference done 44/150. Dataloading: 0.0036 s/iter. Inference: 0.2550 s/iter. Eval: 7.3752 s/iter. Total: 7.6360 s/iter. ETA=0:13:29\n",
            "[05/10 07:27:43 d2.evaluation.evaluator]: Inference done 45/150. Dataloading: 0.0037 s/iter. Inference: 0.2547 s/iter. Eval: 7.5426 s/iter. Total: 7.8032 s/iter. ETA=0:13:39\n",
            "[05/10 07:27:51 d2.evaluation.evaluator]: Inference done 46/150. Dataloading: 0.0037 s/iter. Inference: 0.2536 s/iter. Eval: 7.5336 s/iter. Total: 7.7932 s/iter. ETA=0:13:30\n",
            "[05/10 07:28:01 d2.evaluation.evaluator]: Inference done 47/150. Dataloading: 0.0038 s/iter. Inference: 0.2531 s/iter. Eval: 7.5960 s/iter. Total: 7.8551 s/iter. ETA=0:13:29\n",
            "[05/10 07:28:17 d2.evaluation.evaluator]: Inference done 48/150. Dataloading: 0.0037 s/iter. Inference: 0.2569 s/iter. Eval: 7.7864 s/iter. Total: 8.0494 s/iter. ETA=0:13:41\n",
            "[05/10 07:28:25 d2.evaluation.evaluator]: Inference done 49/150. Dataloading: 0.0037 s/iter. Inference: 0.2558 s/iter. Eval: 7.7683 s/iter. Total: 8.0302 s/iter. ETA=0:13:31\n",
            "[05/10 07:28:36 d2.evaluation.evaluator]: Inference done 51/150. Dataloading: 0.0038 s/iter. Inference: 0.2535 s/iter. Eval: 7.6604 s/iter. Total: 7.9199 s/iter. ETA=0:13:04\n",
            "[05/10 07:28:50 d2.evaluation.evaluator]: Inference done 53/150. Dataloading: 0.0037 s/iter. Inference: 0.2510 s/iter. Eval: 7.6278 s/iter. Total: 7.8849 s/iter. ETA=0:12:44\n",
            "[05/10 07:28:56 d2.evaluation.evaluator]: Inference done 55/150. Dataloading: 0.0037 s/iter. Inference: 0.2492 s/iter. Eval: 7.4457 s/iter. Total: 7.7009 s/iter. ETA=0:12:11\n",
            "[05/10 07:29:08 d2.evaluation.evaluator]: Inference done 57/150. Dataloading: 0.0037 s/iter. Inference: 0.2477 s/iter. Eval: 7.3829 s/iter. Total: 7.6366 s/iter. ETA=0:11:50\n",
            "[05/10 07:29:15 d2.evaluation.evaluator]: Inference done 59/150. Dataloading: 0.0037 s/iter. Inference: 0.2458 s/iter. Eval: 7.2232 s/iter. Total: 7.4749 s/iter. ETA=0:11:20\n",
            "[05/10 07:29:24 d2.evaluation.evaluator]: Inference done 63/150. Dataloading: 0.0036 s/iter. Inference: 0.2417 s/iter. Eval: 6.8629 s/iter. Total: 7.1103 s/iter. ETA=0:10:18\n",
            "[05/10 07:29:30 d2.evaluation.evaluator]: Inference done 66/150. Dataloading: 0.0036 s/iter. Inference: 0.2388 s/iter. Eval: 6.6178 s/iter. Total: 6.8623 s/iter. ETA=0:09:36\n",
            "[05/10 07:29:36 d2.evaluation.evaluator]: Inference done 68/150. Dataloading: 0.0036 s/iter. Inference: 0.2375 s/iter. Eval: 6.5002 s/iter. Total: 6.7434 s/iter. ETA=0:09:12\n",
            "[05/10 07:29:42 d2.evaluation.evaluator]: Inference done 69/150. Dataloading: 0.0036 s/iter. Inference: 0.2372 s/iter. Eval: 6.4811 s/iter. Total: 6.7239 s/iter. ETA=0:09:04\n",
            "[05/10 07:29:50 d2.evaluation.evaluator]: Inference done 71/150. Dataloading: 0.0035 s/iter. Inference: 0.2364 s/iter. Eval: 6.4005 s/iter. Total: 6.6425 s/iter. ETA=0:08:44\n",
            "[05/10 07:29:59 d2.evaluation.evaluator]: Inference done 73/150. Dataloading: 0.0035 s/iter. Inference: 0.2349 s/iter. Eval: 6.3395 s/iter. Total: 6.5800 s/iter. ETA=0:08:26\n",
            "[05/10 07:30:04 d2.evaluation.evaluator]: Inference done 74/150. Dataloading: 0.0035 s/iter. Inference: 0.2346 s/iter. Eval: 6.3169 s/iter. Total: 6.5571 s/iter. ETA=0:08:18\n",
            "[05/10 07:30:09 d2.evaluation.evaluator]: Inference done 75/150. Dataloading: 0.0035 s/iter. Inference: 0.2343 s/iter. Eval: 6.2976 s/iter. Total: 6.5375 s/iter. ETA=0:08:10\n",
            "[05/10 07:30:15 d2.evaluation.evaluator]: Inference done 78/150. Dataloading: 0.0035 s/iter. Inference: 0.2326 s/iter. Eval: 6.1124 s/iter. Total: 6.3506 s/iter. ETA=0:07:37\n",
            "[05/10 07:30:22 d2.evaluation.evaluator]: Inference done 80/150. Dataloading: 0.0035 s/iter. Inference: 0.2317 s/iter. Eval: 6.0370 s/iter. Total: 6.2742 s/iter. ETA=0:07:19\n",
            "[05/10 07:30:28 d2.evaluation.evaluator]: Inference done 83/150. Dataloading: 0.0035 s/iter. Inference: 0.2297 s/iter. Eval: 5.8776 s/iter. Total: 6.1129 s/iter. ETA=0:06:49\n",
            "[05/10 07:30:34 d2.evaluation.evaluator]: Inference done 85/150. Dataloading: 0.0035 s/iter. Inference: 0.2287 s/iter. Eval: 5.7980 s/iter. Total: 6.0322 s/iter. ETA=0:06:32\n",
            "[05/10 07:30:39 d2.evaluation.evaluator]: Inference done 86/150. Dataloading: 0.0034 s/iter. Inference: 0.2285 s/iter. Eval: 5.7937 s/iter. Total: 6.0277 s/iter. ETA=0:06:25\n",
            "[05/10 07:30:45 d2.evaluation.evaluator]: Inference done 89/150. Dataloading: 0.0034 s/iter. Inference: 0.2260 s/iter. Eval: 5.6502 s/iter. Total: 5.8816 s/iter. ETA=0:05:58\n",
            "[05/10 07:30:52 d2.evaluation.evaluator]: Inference done 91/150. Dataloading: 0.0034 s/iter. Inference: 0.2255 s/iter. Eval: 5.5913 s/iter. Total: 5.8222 s/iter. ETA=0:05:43\n",
            "[05/10 07:30:58 d2.evaluation.evaluator]: Inference done 94/150. Dataloading: 0.0034 s/iter. Inference: 0.2237 s/iter. Eval: 5.4687 s/iter. Total: 5.6977 s/iter. ETA=0:05:19\n",
            "[05/10 07:31:05 d2.evaluation.evaluator]: Inference done 96/150. Dataloading: 0.0034 s/iter. Inference: 0.2233 s/iter. Eval: 5.4149 s/iter. Total: 5.6435 s/iter. ETA=0:05:04\n",
            "[05/10 07:31:11 d2.evaluation.evaluator]: Inference done 97/150. Dataloading: 0.0034 s/iter. Inference: 0.2232 s/iter. Eval: 5.4215 s/iter. Total: 5.6501 s/iter. ETA=0:04:59\n",
            "[05/10 07:31:21 d2.evaluation.evaluator]: Inference done 99/150. Dataloading: 0.0034 s/iter. Inference: 0.2227 s/iter. Eval: 5.4119 s/iter. Total: 5.6401 s/iter. ETA=0:04:47\n",
            "[05/10 07:31:26 d2.evaluation.evaluator]: Inference done 101/150. Dataloading: 0.0034 s/iter. Inference: 0.2214 s/iter. Eval: 5.3482 s/iter. Total: 5.5749 s/iter. ETA=0:04:33\n",
            "[05/10 07:31:35 d2.evaluation.evaluator]: Inference done 103/150. Dataloading: 0.0035 s/iter. Inference: 0.2213 s/iter. Eval: 5.3217 s/iter. Total: 5.5484 s/iter. ETA=0:04:20\n",
            "[05/10 07:31:40 d2.evaluation.evaluator]: Inference done 106/150. Dataloading: 0.0034 s/iter. Inference: 0.2201 s/iter. Eval: 5.2128 s/iter. Total: 5.4383 s/iter. ETA=0:03:59\n",
            "[05/10 07:31:50 d2.evaluation.evaluator]: Inference done 109/150. Dataloading: 0.0034 s/iter. Inference: 0.2184 s/iter. Eval: 5.1535 s/iter. Total: 5.3772 s/iter. ETA=0:03:40\n",
            "[05/10 07:31:59 d2.evaluation.evaluator]: Inference done 111/150. Dataloading: 0.0034 s/iter. Inference: 0.2182 s/iter. Eval: 5.1310 s/iter. Total: 5.3546 s/iter. ETA=0:03:28\n",
            "[05/10 07:32:07 d2.evaluation.evaluator]: Inference done 113/150. Dataloading: 0.0034 s/iter. Inference: 0.2181 s/iter. Eval: 5.1105 s/iter. Total: 5.3340 s/iter. ETA=0:03:17\n",
            "[05/10 07:32:15 d2.evaluation.evaluator]: Inference done 115/150. Dataloading: 0.0035 s/iter. Inference: 0.2175 s/iter. Eval: 5.0883 s/iter. Total: 5.3113 s/iter. ETA=0:03:05\n",
            "[05/10 07:32:24 d2.evaluation.evaluator]: Inference done 117/150. Dataloading: 0.0035 s/iter. Inference: 0.2172 s/iter. Eval: 5.0671 s/iter. Total: 5.2898 s/iter. ETA=0:02:54\n",
            "[05/10 07:32:30 d2.evaluation.evaluator]: Inference done 119/150. Dataloading: 0.0035 s/iter. Inference: 0.2166 s/iter. Eval: 5.0278 s/iter. Total: 5.2498 s/iter. ETA=0:02:42\n",
            "[05/10 07:32:38 d2.evaluation.evaluator]: Inference done 120/150. Dataloading: 0.0035 s/iter. Inference: 0.2169 s/iter. Eval: 5.0510 s/iter. Total: 5.2733 s/iter. ETA=0:02:38\n",
            "[05/10 07:32:46 d2.evaluation.evaluator]: Inference done 122/150. Dataloading: 0.0034 s/iter. Inference: 0.2162 s/iter. Eval: 5.0328 s/iter. Total: 5.2545 s/iter. ETA=0:02:27\n",
            "[05/10 07:32:54 d2.evaluation.evaluator]: Inference done 125/150. Dataloading: 0.0034 s/iter. Inference: 0.2155 s/iter. Eval: 4.9710 s/iter. Total: 5.1919 s/iter. ETA=0:02:09\n",
            "[05/10 07:33:00 d2.evaluation.evaluator]: Inference done 127/150. Dataloading: 0.0035 s/iter. Inference: 0.2153 s/iter. Eval: 4.9370 s/iter. Total: 5.1578 s/iter. ETA=0:01:58\n",
            "[05/10 07:33:06 d2.evaluation.evaluator]: Inference done 129/150. Dataloading: 0.0035 s/iter. Inference: 0.2148 s/iter. Eval: 4.9022 s/iter. Total: 5.1224 s/iter. ETA=0:01:47\n",
            "[05/10 07:33:13 d2.evaluation.evaluator]: Inference done 136/150. Dataloading: 0.0034 s/iter. Inference: 0.2109 s/iter. Eval: 4.6845 s/iter. Total: 4.9007 s/iter. ETA=0:01:08\n",
            "[05/10 07:33:21 d2.evaluation.evaluator]: Inference done 138/150. Dataloading: 0.0035 s/iter. Inference: 0.2111 s/iter. Eval: 4.6715 s/iter. Total: 4.8880 s/iter. ETA=0:00:58\n",
            "[05/10 07:33:27 d2.evaluation.evaluator]: Inference done 141/150. Dataloading: 0.0035 s/iter. Inference: 0.2101 s/iter. Eval: 4.6028 s/iter. Total: 4.8183 s/iter. ETA=0:00:43\n",
            "[05/10 07:33:34 d2.evaluation.evaluator]: Inference done 145/150. Dataloading: 0.0035 s/iter. Inference: 0.2082 s/iter. Eval: 4.5172 s/iter. Total: 4.7308 s/iter. ETA=0:00:23\n",
            "[05/10 07:33:39 d2.evaluation.evaluator]: Inference done 147/150. Dataloading: 0.0035 s/iter. Inference: 0.2080 s/iter. Eval: 4.4871 s/iter. Total: 4.7004 s/iter. ETA=0:00:14\n",
            "[05/10 07:33:46 d2.evaluation.evaluator]: Inference done 150/150. Dataloading: 0.0034 s/iter. Inference: 0.2072 s/iter. Eval: 4.4400 s/iter. Total: 4.6526 s/iter. ETA=0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05/10 07:33:46 d2.evaluation.evaluator]: Total inference time: 0:11:15.079947 (4.655724 s / iter per device, on 1 devices)\n",
            "[05/10 07:33:46 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:30 (0.207239 s / iter per device, on 1 devices)\n",
            "[05/10 07:33:47 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...\n",
            "[05/10 07:33:47 d2.evaluation.coco_evaluation]: Saving results to /content/output/chkpt/inference/coco_instances_results.json\n",
            "[05/10 07:33:47 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "[05/10 07:33:47 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*\n",
            "[05/10 07:33:47 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.10 seconds.\n",
            "[05/10 07:33:47 d2.evaluation.fast_eval_api]: Accumulating evaluation results...\n",
            "[05/10 07:33:47 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.04 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
            "[05/10 07:33:47 d2.evaluation.coco_evaluation]: Evaluation results for bbox: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 0.000 | 0.000  | 0.000  | 0.000 | 0.000 | 0.000 |\n",
            "[05/10 07:33:47 d2.evaluation.coco_evaluation]: Per-category bbox AP: \n",
            "| category   | AP    | category              | AP    | category   | AP    |\n",
            "|:-----------|:------|:----------------------|:------|:-----------|:------|\n",
            "| Bottle     | 0.000 | Bottle cap            | 0.000 | Can        | 0.000 |\n",
            "| Cigarette  | 0.000 | Cup                   | 0.000 | Lid        | 0.000 |\n",
            "| Other      | 0.000 | Plastic bag & wrapper | 0.000 | Pop tab    | 0.000 |\n",
            "| Straw      | 0.000 |                       |       |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.49s)\n",
            "creating index...\n",
            "index created!\n",
            "[05/10 07:33:48 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*\n",
            "[05/10 07:33:48 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.47 seconds.\n",
            "[05/10 07:33:48 d2.evaluation.fast_eval_api]: Accumulating evaluation results...\n",
            "[05/10 07:33:48 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.04 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.077\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.169\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.068\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.015\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.104\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.164\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.219\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.224\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.047\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.281\n",
            "[05/10 07:33:49 d2.evaluation.coco_evaluation]: Evaluation results for segm: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 7.737 | 16.911 | 6.802  | 0.000 | 1.456 | 10.448 |\n",
            "[05/10 07:33:49 d2.evaluation.coco_evaluation]: Per-category segm AP: \n",
            "| category   | AP     | category              | AP     | category   | AP    |\n",
            "|:-----------|:-------|:----------------------|:-------|:-----------|:------|\n",
            "| Bottle     | 21.822 | Bottle cap            | 15.255 | Can        | 4.151 |\n",
            "| Cigarette  | 0.010  | Cup                   | 7.223  | Lid        | 7.332 |\n",
            "| Other      | 5.988  | Plastic bag & wrapper | 14.754 | Pop tab    | 0.000 |\n",
            "| Straw      | 0.835  |                       |        |            |       |\n",
            "[05/10 07:33:49 d2.engine.defaults]: Evaluation results for TACO_val in csv format:\n",
            "[05/10 07:33:49 d2.evaluation.testing]: copypaste: Task: bbox\n",
            "[05/10 07:33:49 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl\n",
            "[05/10 07:33:49 d2.evaluation.testing]: copypaste: 0.0000,0.0000,0.0000,0.0000,0.0000,0.0000\n",
            "[05/10 07:33:49 d2.evaluation.testing]: copypaste: Task: segm\n",
            "[05/10 07:33:49 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl\n",
            "[05/10 07:33:49 d2.evaluation.testing]: copypaste: 7.7369,16.9112,6.8023,0.0000,1.4561,10.4480\n",
            "[05/10 07:33:49 d2.utils.events]:  eta: 3:02:08  iter: 1999  total_loss: 1.472  loss_ins: 1.163  loss_cate: 0.3255  time: 3.4421  data_time: 1.9671  lr: 0.0007571  max_mem: 9678M\n",
            "[05/10 07:34:53 d2.utils.events]:  eta: 3:02:11  iter: 2019  total_loss: 1.308  loss_ins: 1.053  loss_cate: 0.2845  time: 3.3715  data_time: 1.6192  lr: 0.00075272  max_mem: 9678M\n",
            "[05/10 07:35:55 d2.utils.events]:  eta: 3:04:19  iter: 2039  total_loss: 1.3  loss_ins: 0.9957  loss_cate: 0.3025  time: 3.3082  data_time: 1.5307  lr: 0.00074831  max_mem: 9678M\n",
            "[05/10 07:37:04 d2.utils.events]:  eta: 3:06:19  iter: 2059  total_loss: 1.281  loss_ins: 0.9672  loss_cate: 0.322  time: 3.3393  data_time: 1.9391  lr: 0.00074389  max_mem: 9678M\n",
            "[05/10 07:38:08 d2.utils.events]:  eta: 3:04:04  iter: 2079  total_loss: 1.173  loss_ins: 0.9213  loss_cate: 0.2996  time: 3.3139  data_time: 1.6639  lr: 0.00073943  max_mem: 9678M\n",
            "[05/10 07:39:14 d2.utils.events]:  eta: 3:01:43  iter: 2099  total_loss: 1.286  loss_ins: 0.9513  loss_cate: 0.3036  time: 3.2814  data_time: 1.6493  lr: 0.00073496  max_mem: 9678M\n",
            "[05/10 07:40:20 d2.utils.events]:  eta: 3:00:21  iter: 2119  total_loss: 1.168  loss_ins: 0.8917  loss_cate: 0.2764  time: 3.2823  data_time: 1.7660  lr: 0.00073047  max_mem: 9678M\n",
            "[05/10 07:41:26 d2.utils.events]:  eta: 3:01:04  iter: 2139  total_loss: 1.129  loss_ins: 0.839  loss_cate: 0.2878  time: 3.2844  data_time: 1.7783  lr: 0.00072595  max_mem: 9678M\n",
            "[05/10 07:42:30 d2.utils.events]:  eta: 2:58:44  iter: 2159  total_loss: 1.179  loss_ins: 0.8976  loss_cate: 0.279  time: 3.2772  data_time: 1.7192  lr: 0.00072141  max_mem: 9678M\n",
            "[05/10 07:43:33 d2.utils.events]:  eta: 2:57:22  iter: 2179  total_loss: 1.238  loss_ins: 0.9812  loss_cate: 0.269  time: 3.2672  data_time: 1.6318  lr: 0.00071685  max_mem: 9678M\n",
            "[05/10 07:44:41 d2.utils.events]:  eta: 2:56:31  iter: 2199  total_loss: 1.239  loss_ins: 0.948  loss_cate: 0.2917  time: 3.2781  data_time: 1.8914  lr: 0.00071228  max_mem: 9678M\n",
            "[05/10 07:45:49 d2.utils.events]:  eta: 2:55:31  iter: 2219  total_loss: 1.269  loss_ins: 0.9701  loss_cate: 0.2756  time: 3.2846  data_time: 1.8822  lr: 0.00070768  max_mem: 9678M\n",
            "[05/10 07:46:54 d2.utils.events]:  eta: 2:54:44  iter: 2239  total_loss: 1.303  loss_ins: 0.9867  loss_cate: 0.2919  time: 3.2815  data_time: 1.8008  lr: 0.00070306  max_mem: 9678M\n",
            "[05/10 07:48:04 d2.utils.events]:  eta: 2:53:45  iter: 2259  total_loss: 1.181  loss_ins: 0.882  loss_cate: 0.2764  time: 3.2955  data_time: 1.8797  lr: 0.00069843  max_mem: 9678M\n",
            "[05/10 07:49:03 d2.utils.events]:  eta: 2:52:18  iter: 2279  total_loss: 1.062  loss_ins: 0.7971  loss_cate: 0.2592  time: 3.2727  data_time: 1.5038  lr: 0.00069377  max_mem: 9678M\n",
            "[05/10 07:50:18 d2.utils.events]:  eta: 2:52:00  iter: 2299  total_loss: 1.207  loss_ins: 0.9595  loss_cate: 0.2707  time: 3.3003  data_time: 2.1982  lr: 0.0006891  max_mem: 9678M\n",
            "[05/10 07:51:23 d2.utils.events]:  eta: 2:51:00  iter: 2319  total_loss: 1.229  loss_ins: 0.9293  loss_cate: 0.296  time: 3.2992  data_time: 1.7892  lr: 0.00068442  max_mem: 9678M\n",
            "[05/10 07:52:29 d2.utils.events]:  eta: 2:50:11  iter: 2339  total_loss: 1.041  loss_ins: 0.7833  loss_cate: 0.2555  time: 3.2981  data_time: 1.7105  lr: 0.00067972  max_mem: 9678M\n",
            "[05/10 07:53:32 d2.utils.events]:  eta: 2:51:06  iter: 2359  total_loss: 1.331  loss_ins: 1.008  loss_cate: 0.285  time: 3.2914  data_time: 1.6173  lr: 0.000675  max_mem: 9678M\n",
            "[05/10 07:54:45 d2.utils.events]:  eta: 2:51:13  iter: 2379  total_loss: 1.22  loss_ins: 0.9586  loss_cate: 0.2599  time: 3.3073  data_time: 2.0074  lr: 0.00067027  max_mem: 9678M\n",
            "[05/10 07:55:48 d2.utils.events]:  eta: 2:50:39  iter: 2399  total_loss: 1.007  loss_ins: 0.7421  loss_cate: 0.2531  time: 3.2954  data_time: 1.5659  lr: 0.00066552  max_mem: 9678M\n",
            "[05/10 07:56:52 d2.utils.events]:  eta: 2:48:08  iter: 2419  total_loss: 1.189  loss_ins: 0.9339  loss_cate: 0.2472  time: 3.2896  data_time: 1.6156  lr: 0.00066076  max_mem: 9678M\n",
            "[05/10 07:57:59 d2.utils.events]:  eta: 2:46:50  iter: 2439  total_loss: 1.255  loss_ins: 1.006  loss_cate: 0.2825  time: 3.2920  data_time: 1.7294  lr: 0.00065598  max_mem: 9678M\n",
            "[05/10 07:59:07 d2.utils.events]:  eta: 2:45:19  iter: 2459  total_loss: 1.213  loss_ins: 0.9349  loss_cate: 0.2699  time: 3.2972  data_time: 1.8672  lr: 0.0006512  max_mem: 9678M\n",
            "[05/10 08:00:12 d2.utils.events]:  eta: 2:44:49  iter: 2479  total_loss: 0.9918  loss_ins: 0.7071  loss_cate: 0.2697  time: 3.2945  data_time: 1.7647  lr: 0.0006464  max_mem: 9678M\n",
            "[05/10 08:01:19 d2.data.datasets.coco]: Loaded 150 images in COCO format from /content/TACO-expl/data/annotations_off_0_val.json\n",
            "[05/10 08:01:19 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "[05/10 08:01:19 d2.data.common]: Serializing 150 elements to byte tensors and concatenating them all ...\n",
            "[05/10 08:01:19 d2.data.common]: Serialized dataset takes 0.22 MiB\n",
            "WARNING [05/10 08:01:19 d2.evaluation.coco_evaluation]: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
            "[05/10 08:01:19 d2.evaluation.evaluator]: Start inference on 150 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05/10 08:01:56 d2.evaluation.evaluator]: Inference done 11/150. Dataloading: 0.0028 s/iter. Inference: 0.2040 s/iter. Eval: 4.3886 s/iter. Total: 4.5955 s/iter. ETA=0:10:38\n",
            "[05/10 08:02:01 d2.evaluation.evaluator]: Inference done 13/150. Dataloading: 0.0027 s/iter. Inference: 0.2028 s/iter. Eval: 3.8762 s/iter. Total: 4.0821 s/iter. ETA=0:09:19\n",
            "[05/10 08:02:16 d2.evaluation.evaluator]: Inference done 15/150. Dataloading: 0.0038 s/iter. Inference: 0.2079 s/iter. Eval: 4.5357 s/iter. Total: 4.7480 s/iter. ETA=0:10:40\n",
            "[05/10 08:02:22 d2.evaluation.evaluator]: Inference done 18/150. Dataloading: 0.0046 s/iter. Inference: 0.2041 s/iter. Eval: 3.8998 s/iter. Total: 4.1092 s/iter. ETA=0:09:02\n",
            "[05/10 08:02:27 d2.evaluation.evaluator]: Inference done 20/150. Dataloading: 0.0044 s/iter. Inference: 0.1992 s/iter. Eval: 3.7039 s/iter. Total: 3.9081 s/iter. ETA=0:08:28\n",
            "[05/10 08:02:33 d2.evaluation.evaluator]: Inference done 21/150. Dataloading: 0.0044 s/iter. Inference: 0.1964 s/iter. Eval: 3.8379 s/iter. Total: 4.0394 s/iter. ETA=0:08:41\n",
            "[05/10 08:02:42 d2.evaluation.evaluator]: Inference done 23/150. Dataloading: 0.0044 s/iter. Inference: 0.1986 s/iter. Eval: 3.8816 s/iter. Total: 4.0854 s/iter. ETA=0:08:38\n",
            "[05/10 08:02:49 d2.evaluation.evaluator]: Inference done 25/150. Dataloading: 0.0048 s/iter. Inference: 0.2017 s/iter. Eval: 3.7939 s/iter. Total: 4.0012 s/iter. ETA=0:08:20\n",
            "[05/10 08:03:01 d2.evaluation.evaluator]: Inference done 27/150. Dataloading: 0.0053 s/iter. Inference: 0.2029 s/iter. Eval: 3.9736 s/iter. Total: 4.1827 s/iter. ETA=0:08:34\n",
            "[05/10 08:03:12 d2.evaluation.evaluator]: Inference done 28/150. Dataloading: 0.0056 s/iter. Inference: 0.2041 s/iter. Eval: 4.2881 s/iter. Total: 4.4988 s/iter. ETA=0:09:08\n",
            "[05/10 08:03:21 d2.evaluation.evaluator]: Inference done 29/150. Dataloading: 0.0055 s/iter. Inference: 0.2056 s/iter. Eval: 4.4791 s/iter. Total: 4.6915 s/iter. ETA=0:09:27\n",
            "[05/10 08:03:28 d2.evaluation.evaluator]: Inference done 31/150. Dataloading: 0.0053 s/iter. Inference: 0.2034 s/iter. Eval: 4.3884 s/iter. Total: 4.5983 s/iter. ETA=0:09:07\n",
            "[05/10 08:03:42 d2.evaluation.evaluator]: Inference done 34/150. Dataloading: 0.0072 s/iter. Inference: 0.2035 s/iter. Eval: 4.3736 s/iter. Total: 4.5857 s/iter. ETA=0:08:51\n",
            "[05/10 08:03:48 d2.evaluation.evaluator]: Inference done 35/150. Dataloading: 0.0071 s/iter. Inference: 0.2041 s/iter. Eval: 4.4205 s/iter. Total: 4.6331 s/iter. ETA=0:08:52\n",
            "[05/10 08:03:55 d2.evaluation.evaluator]: Inference done 37/150. Dataloading: 0.0068 s/iter. Inference: 0.2053 s/iter. Eval: 4.3547 s/iter. Total: 4.5683 s/iter. ETA=0:08:36\n",
            "[05/10 08:04:06 d2.evaluation.evaluator]: Inference done 39/150. Dataloading: 0.0066 s/iter. Inference: 0.2058 s/iter. Eval: 4.4205 s/iter. Total: 4.6343 s/iter. ETA=0:08:34\n",
            "[05/10 08:04:15 d2.evaluation.evaluator]: Inference done 40/150. Dataloading: 0.0067 s/iter. Inference: 0.2064 s/iter. Eval: 4.5467 s/iter. Total: 4.7612 s/iter. ETA=0:08:43\n",
            "[05/10 08:04:23 d2.evaluation.evaluator]: Inference done 41/150. Dataloading: 0.0066 s/iter. Inference: 0.2064 s/iter. Eval: 4.6153 s/iter. Total: 4.8299 s/iter. ETA=0:08:46\n",
            "[05/10 08:04:30 d2.evaluation.evaluator]: Inference done 42/150. Dataloading: 0.0065 s/iter. Inference: 0.2064 s/iter. Eval: 4.6840 s/iter. Total: 4.8984 s/iter. ETA=0:08:49\n",
            "[05/10 08:04:37 d2.evaluation.evaluator]: Inference done 44/150. Dataloading: 0.0065 s/iter. Inference: 0.2058 s/iter. Eval: 4.6138 s/iter. Total: 4.8278 s/iter. ETA=0:08:31\n",
            "[05/10 08:04:45 d2.evaluation.evaluator]: Inference done 46/150. Dataloading: 0.0066 s/iter. Inference: 0.2060 s/iter. Eval: 4.5686 s/iter. Total: 4.7829 s/iter. ETA=0:08:17\n",
            "[05/10 08:04:50 d2.evaluation.evaluator]: Inference done 47/150. Dataloading: 0.0065 s/iter. Inference: 0.2063 s/iter. Eval: 4.5811 s/iter. Total: 4.7958 s/iter. ETA=0:08:13\n",
            "[05/10 08:04:58 d2.evaluation.evaluator]: Inference done 48/150. Dataloading: 0.0065 s/iter. Inference: 0.2066 s/iter. Eval: 4.6464 s/iter. Total: 4.8613 s/iter. ETA=0:08:15\n",
            "[05/10 08:05:04 d2.evaluation.evaluator]: Inference done 50/150. Dataloading: 0.0064 s/iter. Inference: 0.2065 s/iter. Eval: 4.5762 s/iter. Total: 4.7909 s/iter. ETA=0:07:59\n",
            "[05/10 08:05:10 d2.evaluation.evaluator]: Inference done 52/150. Dataloading: 0.0065 s/iter. Inference: 0.2064 s/iter. Eval: 4.4845 s/iter. Total: 4.6991 s/iter. ETA=0:07:40\n",
            "[05/10 08:05:16 d2.evaluation.evaluator]: Inference done 53/150. Dataloading: 0.0065 s/iter. Inference: 0.2066 s/iter. Eval: 4.5137 s/iter. Total: 4.7286 s/iter. ETA=0:07:38\n",
            "[05/10 08:05:23 d2.evaluation.evaluator]: Inference done 56/150. Dataloading: 0.0062 s/iter. Inference: 0.2046 s/iter. Eval: 4.3692 s/iter. Total: 4.5817 s/iter. ETA=0:07:10\n",
            "[05/10 08:05:31 d2.evaluation.evaluator]: Inference done 58/150. Dataloading: 0.0063 s/iter. Inference: 0.2048 s/iter. Eval: 4.3543 s/iter. Total: 4.5670 s/iter. ETA=0:07:00\n",
            "[05/10 08:05:36 d2.evaluation.evaluator]: Inference done 62/150. Dataloading: 0.0060 s/iter. Inference: 0.2033 s/iter. Eval: 4.1308 s/iter. Total: 4.3418 s/iter. ETA=0:06:22\n",
            "[05/10 08:05:42 d2.evaluation.evaluator]: Inference done 66/150. Dataloading: 0.0058 s/iter. Inference: 0.2017 s/iter. Eval: 3.9441 s/iter. Total: 4.1533 s/iter. ETA=0:05:48\n",
            "[05/10 08:05:53 d2.evaluation.evaluator]: Inference done 69/150. Dataloading: 0.0057 s/iter. Inference: 0.2003 s/iter. Eval: 3.9206 s/iter. Total: 4.1282 s/iter. ETA=0:05:34\n",
            "[05/10 08:05:59 d2.evaluation.evaluator]: Inference done 72/150. Dataloading: 0.0056 s/iter. Inference: 0.2001 s/iter. Eval: 3.8255 s/iter. Total: 4.0327 s/iter. ETA=0:05:14\n",
            "[05/10 08:06:04 d2.evaluation.evaluator]: Inference done 73/150. Dataloading: 0.0055 s/iter. Inference: 0.1998 s/iter. Eval: 3.8444 s/iter. Total: 4.0513 s/iter. ETA=0:05:11\n",
            "[05/10 08:06:12 d2.evaluation.evaluator]: Inference done 75/150. Dataloading: 0.0054 s/iter. Inference: 0.2000 s/iter. Eval: 3.8377 s/iter. Total: 4.0449 s/iter. ETA=0:05:03\n",
            "[05/10 08:06:22 d2.evaluation.evaluator]: Inference done 80/150. Dataloading: 0.0052 s/iter. Inference: 0.1971 s/iter. Eval: 3.7075 s/iter. Total: 3.9115 s/iter. ETA=0:04:33\n",
            "[05/10 08:06:29 d2.evaluation.evaluator]: Inference done 83/150. Dataloading: 0.0052 s/iter. Inference: 0.1971 s/iter. Eval: 3.6458 s/iter. Total: 3.8497 s/iter. ETA=0:04:17\n",
            "[05/10 08:06:39 d2.evaluation.evaluator]: Inference done 86/150. Dataloading: 0.0052 s/iter. Inference: 0.1968 s/iter. Eval: 3.6256 s/iter. Total: 3.8292 s/iter. ETA=0:04:05\n",
            "[05/10 08:06:46 d2.evaluation.evaluator]: Inference done 89/150. Dataloading: 0.0051 s/iter. Inference: 0.1961 s/iter. Eval: 3.5698 s/iter. Total: 3.7726 s/iter. ETA=0:03:50\n",
            "[05/10 08:06:51 d2.evaluation.evaluator]: Inference done 91/150. Dataloading: 0.0051 s/iter. Inference: 0.1965 s/iter. Eval: 3.5412 s/iter. Total: 3.7443 s/iter. ETA=0:03:40\n",
            "[05/10 08:06:57 d2.evaluation.evaluator]: Inference done 93/150. Dataloading: 0.0051 s/iter. Inference: 0.1965 s/iter. Eval: 3.5307 s/iter. Total: 3.7338 s/iter. ETA=0:03:32\n",
            "[05/10 08:07:06 d2.evaluation.evaluator]: Inference done 96/150. Dataloading: 0.0050 s/iter. Inference: 0.1963 s/iter. Eval: 3.4982 s/iter. Total: 3.7011 s/iter. ETA=0:03:19\n",
            "[05/10 08:07:12 d2.evaluation.evaluator]: Inference done 98/150. Dataloading: 0.0050 s/iter. Inference: 0.1967 s/iter. Eval: 3.4854 s/iter. Total: 3.6887 s/iter. ETA=0:03:11\n",
            "[05/10 08:07:20 d2.evaluation.evaluator]: Inference done 99/150. Dataloading: 0.0049 s/iter. Inference: 0.1973 s/iter. Eval: 3.5372 s/iter. Total: 3.7410 s/iter. ETA=0:03:10\n",
            "[05/10 08:07:29 d2.evaluation.evaluator]: Inference done 102/150. Dataloading: 0.0049 s/iter. Inference: 0.1973 s/iter. Eval: 3.5122 s/iter. Total: 3.7160 s/iter. ETA=0:02:58\n",
            "[05/10 08:07:35 d2.evaluation.evaluator]: Inference done 105/150. Dataloading: 0.0049 s/iter. Inference: 0.1971 s/iter. Eval: 3.4590 s/iter. Total: 3.6625 s/iter. ETA=0:02:44\n",
            "[05/10 08:07:41 d2.evaluation.evaluator]: Inference done 108/150. Dataloading: 0.0048 s/iter. Inference: 0.1952 s/iter. Eval: 3.4110 s/iter. Total: 3.6126 s/iter. ETA=0:02:31\n",
            "[05/10 08:07:47 d2.evaluation.evaluator]: Inference done 110/150. Dataloading: 0.0048 s/iter. Inference: 0.1951 s/iter. Eval: 3.3961 s/iter. Total: 3.5975 s/iter. ETA=0:02:23\n",
            "[05/10 08:07:52 d2.evaluation.evaluator]: Inference done 111/150. Dataloading: 0.0048 s/iter. Inference: 0.1955 s/iter. Eval: 3.4160 s/iter. Total: 3.6179 s/iter. ETA=0:02:21\n",
            "[05/10 08:08:01 d2.evaluation.evaluator]: Inference done 113/150. Dataloading: 0.0048 s/iter. Inference: 0.1957 s/iter. Eval: 3.4271 s/iter. Total: 3.6291 s/iter. ETA=0:02:14\n",
            "[05/10 08:08:09 d2.evaluation.evaluator]: Inference done 115/150. Dataloading: 0.0048 s/iter. Inference: 0.1955 s/iter. Eval: 3.4363 s/iter. Total: 3.6381 s/iter. ETA=0:02:07\n",
            "[05/10 08:08:17 d2.evaluation.evaluator]: Inference done 117/150. Dataloading: 0.0047 s/iter. Inference: 0.1957 s/iter. Eval: 3.4417 s/iter. Total: 3.6436 s/iter. ETA=0:02:00\n",
            "[05/10 08:08:23 d2.evaluation.evaluator]: Inference done 119/150. Dataloading: 0.0047 s/iter. Inference: 0.1957 s/iter. Eval: 3.4269 s/iter. Total: 3.6289 s/iter. ETA=0:01:52\n",
            "[05/10 08:08:29 d2.evaluation.evaluator]: Inference done 120/150. Dataloading: 0.0047 s/iter. Inference: 0.1961 s/iter. Eval: 3.4528 s/iter. Total: 3.6551 s/iter. ETA=0:01:49\n",
            "[05/10 08:08:36 d2.evaluation.evaluator]: Inference done 124/150. Dataloading: 0.0046 s/iter. Inference: 0.1948 s/iter. Eval: 3.3892 s/iter. Total: 3.5902 s/iter. ETA=0:01:33\n",
            "[05/10 08:08:44 d2.evaluation.evaluator]: Inference done 126/150. Dataloading: 0.0047 s/iter. Inference: 0.1945 s/iter. Eval: 3.3934 s/iter. Total: 3.5941 s/iter. ETA=0:01:26\n",
            "[05/10 08:08:52 d2.evaluation.evaluator]: Inference done 129/150. Dataloading: 0.0046 s/iter. Inference: 0.1944 s/iter. Eval: 3.3729 s/iter. Total: 3.5734 s/iter. ETA=0:01:15\n",
            "[05/10 08:08:57 d2.evaluation.evaluator]: Inference done 132/150. Dataloading: 0.0046 s/iter. Inference: 0.1935 s/iter. Eval: 3.3291 s/iter. Total: 3.5287 s/iter. ETA=0:01:03\n",
            "[05/10 08:09:06 d2.evaluation.evaluator]: Inference done 138/150. Dataloading: 0.0045 s/iter. Inference: 0.1918 s/iter. Eval: 3.2365 s/iter. Total: 3.4342 s/iter. ETA=0:00:41\n",
            "[05/10 08:09:12 d2.evaluation.evaluator]: Inference done 142/150. Dataloading: 0.0045 s/iter. Inference: 0.1915 s/iter. Eval: 3.1797 s/iter. Total: 3.3771 s/iter. ETA=0:00:27\n",
            "[05/10 08:09:18 d2.evaluation.evaluator]: Inference done 145/150. Dataloading: 0.0044 s/iter. Inference: 0.1902 s/iter. Eval: 3.1557 s/iter. Total: 3.3517 s/iter. ETA=0:00:16\n",
            "[05/10 08:09:25 d2.evaluation.evaluator]: Inference done 148/150. Dataloading: 0.0044 s/iter. Inference: 0.1898 s/iter. Eval: 3.1336 s/iter. Total: 3.3292 s/iter. ETA=0:00:06\n",
            "[05/10 08:09:27 d2.evaluation.evaluator]: Total inference time: 0:07:58.100213 (3.297243 s / iter per device, on 1 devices)\n",
            "[05/10 08:09:27 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:27 (0.189312 s / iter per device, on 1 devices)\n",
            "[05/10 08:09:27 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...\n",
            "[05/10 08:09:27 d2.evaluation.coco_evaluation]: Saving results to /content/output/chkpt/inference/coco_instances_results.json\n",
            "[05/10 08:09:27 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "[05/10 08:09:27 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*\n",
            "[05/10 08:09:27 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.08 seconds.\n",
            "[05/10 08:09:27 d2.evaluation.fast_eval_api]: Accumulating evaluation results...\n",
            "[05/10 08:09:28 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.04 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
            "[05/10 08:09:28 d2.evaluation.coco_evaluation]: Evaluation results for bbox: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 0.000 | 0.000  | 0.000  | 0.000 | 0.000 | 0.000 |\n",
            "[05/10 08:09:28 d2.evaluation.coco_evaluation]: Per-category bbox AP: \n",
            "| category   | AP    | category              | AP    | category   | AP    |\n",
            "|:-----------|:------|:----------------------|:------|:-----------|:------|\n",
            "| Bottle     | 0.000 | Bottle cap            | 0.000 | Can        | 0.000 |\n",
            "| Cigarette  | 0.000 | Cup                   | 0.000 | Lid        | 0.000 |\n",
            "| Other      | 0.000 | Plastic bag & wrapper | 0.000 | Pop tab    | 0.000 |\n",
            "| Straw      | 0.000 |                       |       |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.36s)\n",
            "creating index...\n",
            "index created!\n",
            "[05/10 08:09:28 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*\n",
            "[05/10 08:09:28 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.39 seconds.\n",
            "[05/10 08:09:28 d2.evaluation.fast_eval_api]: Accumulating evaluation results...\n",
            "[05/10 08:09:28 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.04 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.088\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.194\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.064\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.062\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.114\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.180\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.230\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.234\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.094\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.278\n",
            "[05/10 08:09:28 d2.evaluation.coco_evaluation]: Evaluation results for segm: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 8.817 | 19.375 | 6.412  | 0.000 | 6.170 | 11.354 |\n",
            "[05/10 08:09:28 d2.evaluation.coco_evaluation]: Per-category segm AP: \n",
            "| category   | AP     | category              | AP     | category   | AP    |\n",
            "|:-----------|:-------|:----------------------|:-------|:-----------|:------|\n",
            "| Bottle     | 18.075 | Bottle cap            | 14.042 | Can        | 6.929 |\n",
            "| Cigarette  | 0.165  | Cup                   | 11.507 | Lid        | 8.148 |\n",
            "| Other      | 7.197  | Plastic bag & wrapper | 17.369 | Pop tab    | 0.545 |\n",
            "| Straw      | 4.193  |                       |        |            |       |\n",
            "[05/10 08:09:28 d2.engine.defaults]: Evaluation results for TACO_val in csv format:\n",
            "[05/10 08:09:28 d2.evaluation.testing]: copypaste: Task: bbox\n",
            "[05/10 08:09:28 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl\n",
            "[05/10 08:09:28 d2.evaluation.testing]: copypaste: 0.0000,0.0000,0.0000,0.0000,0.0000,0.0000\n",
            "[05/10 08:09:28 d2.evaluation.testing]: copypaste: Task: segm\n",
            "[05/10 08:09:28 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl\n",
            "[05/10 08:09:28 d2.evaluation.testing]: copypaste: 8.8169,19.3745,6.4117,0.0000,6.1696,11.3544\n",
            "[05/10 08:09:28 d2.utils.events]:  eta: 2:43:18  iter: 2499  total_loss: 1.203  loss_ins: 0.962  loss_cate: 0.2928  time: 3.2962  data_time: 1.8007  lr: 0.00064159  max_mem: 9678M\n",
            "[05/10 08:10:29 d2.utils.events]:  eta: 2:41:50  iter: 2519  total_loss: 1.005  loss_ins: 0.7515  loss_cate: 0.243  time: 3.2872  data_time: 1.5424  lr: 0.00063677  max_mem: 9678M\n",
            "[05/10 08:11:36 d2.utils.events]:  eta: 2:40:50  iter: 2539  total_loss: 1.128  loss_ins: 0.8399  loss_cate: 0.2665  time: 3.2879  data_time: 1.8199  lr: 0.00063193  max_mem: 9678M\n",
            "[05/10 08:12:37 d2.utils.events]:  eta: 2:39:31  iter: 2559  total_loss: 1.046  loss_ins: 0.8332  loss_cate: 0.2546  time: 3.2794  data_time: 1.6023  lr: 0.00062709  max_mem: 9678M\n",
            "[05/10 08:13:48 d2.utils.events]:  eta: 2:38:31  iter: 2579  total_loss: 1.083  loss_ins: 0.8568  loss_cate: 0.2317  time: 3.2874  data_time: 1.9943  lr: 0.00062224  max_mem: 9678M\n",
            "[05/10 08:14:53 d2.utils.events]:  eta: 2:37:31  iter: 2599  total_loss: 1.242  loss_ins: 0.9492  loss_cate: 0.2592  time: 3.2861  data_time: 1.6561  lr: 0.00061738  max_mem: 9678M\n",
            "[05/10 08:16:00 d2.utils.events]:  eta: 2:37:16  iter: 2619  total_loss: 1.232  loss_ins: 0.9394  loss_cate: 0.2712  time: 3.2877  data_time: 1.8110  lr: 0.00061251  max_mem: 9678M\n",
            "[05/10 08:17:04 d2.utils.events]:  eta: 2:36:58  iter: 2639  total_loss: 1.102  loss_ins: 0.8308  loss_cate: 0.2634  time: 3.2849  data_time: 1.5821  lr: 0.00060764  max_mem: 9678M\n",
            "[05/10 08:18:08 d2.utils.events]:  eta: 2:36:00  iter: 2659  total_loss: 1.057  loss_ins: 0.7928  loss_cate: 0.2425  time: 3.2836  data_time: 1.7452  lr: 0.00060276  max_mem: 9678M\n",
            "[05/10 08:19:13 d2.utils.events]:  eta: 2:34:44  iter: 2679  total_loss: 1.012  loss_ins: 0.7537  loss_cate: 0.2547  time: 3.2823  data_time: 1.7668  lr: 0.00059787  max_mem: 9678M\n",
            "[05/10 08:20:22 d2.utils.events]:  eta: 2:33:56  iter: 2699  total_loss: 0.99  loss_ins: 0.7662  loss_cate: 0.2274  time: 3.2845  data_time: 1.8436  lr: 0.00059298  max_mem: 9678M\n",
            "[05/10 08:21:28 d2.utils.events]:  eta: 2:32:43  iter: 2719  total_loss: 1.072  loss_ins: 0.8753  loss_cate: 0.2288  time: 3.2852  data_time: 1.7580  lr: 0.00058808  max_mem: 9678M\n",
            "[05/10 08:22:32 d2.utils.events]:  eta: 2:31:42  iter: 2739  total_loss: 1.11  loss_ins: 0.8961  loss_cate: 0.2455  time: 3.2820  data_time: 1.6302  lr: 0.00058317  max_mem: 9678M\n",
            "[05/10 08:23:37 d2.utils.events]:  eta: 2:30:54  iter: 2759  total_loss: 1.084  loss_ins: 0.8475  loss_cate: 0.2493  time: 3.2810  data_time: 1.7569  lr: 0.00057827  max_mem: 9678M\n",
            "[05/10 08:24:46 d2.utils.events]:  eta: 2:29:56  iter: 2779  total_loss: 1.013  loss_ins: 0.7398  loss_cate: 0.2433  time: 3.2854  data_time: 1.8941  lr: 0.00057335  max_mem: 9678M\n",
            "[05/10 08:25:49 d2.utils.events]:  eta: 2:29:06  iter: 2799  total_loss: 0.9794  loss_ins: 0.7623  loss_cate: 0.2183  time: 3.2830  data_time: 1.5931  lr: 0.00056844  max_mem: 9678M\n",
            "[05/10 08:26:55 d2.utils.events]:  eta: 2:27:55  iter: 2819  total_loss: 0.9813  loss_ins: 0.7702  loss_cate: 0.2317  time: 3.2824  data_time: 1.7304  lr: 0.00056353  max_mem: 9678M\n",
            "[05/10 08:27:57 d2.utils.events]:  eta: 2:26:52  iter: 2839  total_loss: 1.22  loss_ins: 0.9162  loss_cate: 0.2589  time: 3.2782  data_time: 1.4847  lr: 0.00055861  max_mem: 9678M\n",
            "[05/10 08:29:08 d2.utils.events]:  eta: 2:25:54  iter: 2859  total_loss: 1.021  loss_ins: 0.7949  loss_cate: 0.2327  time: 3.2835  data_time: 1.9498  lr: 0.00055369  max_mem: 9678M\n",
            "[05/10 08:30:12 d2.utils.events]:  eta: 2:24:12  iter: 2879  total_loss: 0.9429  loss_ins: 0.7488  loss_cate: 0.2105  time: 3.2816  data_time: 1.7160  lr: 0.00054877  max_mem: 9678M\n",
            "[05/10 08:31:14 d2.utils.events]:  eta: 2:22:47  iter: 2899  total_loss: 0.808  loss_ins: 0.5921  loss_cate: 0.2188  time: 3.2784  data_time: 1.7854  lr: 0.00054385  max_mem: 9678M\n",
            "[05/10 08:32:18 d2.utils.events]:  eta: 2:21:47  iter: 2919  total_loss: 1.101  loss_ins: 0.8361  loss_cate: 0.2422  time: 3.2764  data_time: 1.6447  lr: 0.00053893  max_mem: 9678M\n",
            "[05/10 08:33:27 d2.utils.events]:  eta: 2:20:47  iter: 2939  total_loss: 1.023  loss_ins: 0.8221  loss_cate: 0.2165  time: 3.2801  data_time: 1.8331  lr: 0.00053402  max_mem: 9678M\n",
            "[05/10 08:34:32 d2.utils.events]:  eta: 2:19:30  iter: 2959  total_loss: 1.051  loss_ins: 0.8258  loss_cate: 0.2508  time: 3.2794  data_time: 1.7321  lr: 0.0005291  max_mem: 9678M\n",
            "[05/10 08:35:39 d2.utils.events]:  eta: 2:18:46  iter: 2979  total_loss: 1.138  loss_ins: 0.8578  loss_cate: 0.2639  time: 3.2807  data_time: 1.7239  lr: 0.00052419  max_mem: 9678M\n",
            "[05/10 08:36:48 d2.data.datasets.coco]: Loaded 150 images in COCO format from /content/TACO-expl/data/annotations_off_0_val.json\n",
            "[05/10 08:36:48 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "[05/10 08:36:48 d2.data.common]: Serializing 150 elements to byte tensors and concatenating them all ...\n",
            "[05/10 08:36:48 d2.data.common]: Serialized dataset takes 0.22 MiB\n",
            "WARNING [05/10 08:36:48 d2.evaluation.coco_evaluation]: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
            "[05/10 08:36:48 d2.evaluation.evaluator]: Start inference on 150 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05/10 08:37:21 d2.evaluation.evaluator]: Inference done 11/150. Dataloading: 0.0023 s/iter. Inference: 0.2129 s/iter. Eval: 4.2606 s/iter. Total: 4.4759 s/iter. ETA=0:10:22\n",
            "[05/10 08:37:26 d2.evaluation.evaluator]: Inference done 12/150. Dataloading: 0.0025 s/iter. Inference: 0.2134 s/iter. Eval: 4.3381 s/iter. Total: 4.5550 s/iter. ETA=0:10:28\n",
            "[05/10 08:37:40 d2.evaluation.evaluator]: Inference done 15/150. Dataloading: 0.0042 s/iter. Inference: 0.2162 s/iter. Eval: 4.3072 s/iter. Total: 4.5287 s/iter. ETA=0:10:11\n",
            "[05/10 08:37:49 d2.evaluation.evaluator]: Inference done 19/150. Dataloading: 0.0040 s/iter. Inference: 0.2142 s/iter. Eval: 3.6855 s/iter. Total: 3.9048 s/iter. ETA=0:08:31\n",
            "[05/10 08:37:59 d2.evaluation.evaluator]: Inference done 21/150. Dataloading: 0.0038 s/iter. Inference: 0.2106 s/iter. Eval: 3.7991 s/iter. Total: 4.0145 s/iter. ETA=0:08:37\n",
            "[05/10 08:38:07 d2.evaluation.evaluator]: Inference done 22/150. Dataloading: 0.0039 s/iter. Inference: 0.2118 s/iter. Eval: 4.0601 s/iter. Total: 4.2770 s/iter. ETA=0:09:07\n",
            "[05/10 08:38:13 d2.evaluation.evaluator]: Inference done 23/150. Dataloading: 0.0038 s/iter. Inference: 0.2118 s/iter. Eval: 4.1560 s/iter. Total: 4.3732 s/iter. ETA=0:09:15\n",
            "[05/10 08:38:20 d2.evaluation.evaluator]: Inference done 24/150. Dataloading: 0.0038 s/iter. Inference: 0.2125 s/iter. Eval: 4.2584 s/iter. Total: 4.4762 s/iter. ETA=0:09:24\n",
            "[05/10 08:38:27 d2.evaluation.evaluator]: Inference done 26/150. Dataloading: 0.0036 s/iter. Inference: 0.2135 s/iter. Eval: 4.1930 s/iter. Total: 4.4115 s/iter. ETA=0:09:07\n",
            "[05/10 08:38:35 d2.evaluation.evaluator]: Inference done 27/150. Dataloading: 0.0036 s/iter. Inference: 0.2153 s/iter. Eval: 4.3414 s/iter. Total: 4.5620 s/iter. ETA=0:09:21\n",
            "[05/10 08:38:46 d2.evaluation.evaluator]: Inference done 28/150. Dataloading: 0.0036 s/iter. Inference: 0.2162 s/iter. Eval: 4.6477 s/iter. Total: 4.8693 s/iter. ETA=0:09:54\n",
            "[05/10 08:38:56 d2.evaluation.evaluator]: Inference done 29/150. Dataloading: 0.0037 s/iter. Inference: 0.2172 s/iter. Eval: 4.8588 s/iter. Total: 5.0815 s/iter. ETA=0:10:14\n",
            "[05/10 08:39:06 d2.evaluation.evaluator]: Inference done 31/150. Dataloading: 0.0044 s/iter. Inference: 0.2193 s/iter. Eval: 4.8333 s/iter. Total: 5.0588 s/iter. ETA=0:10:01\n",
            "[05/10 08:39:12 d2.evaluation.evaluator]: Inference done 33/150. Dataloading: 0.0042 s/iter. Inference: 0.2170 s/iter. Eval: 4.6721 s/iter. Total: 4.8950 s/iter. ETA=0:09:32\n",
            "[05/10 08:39:22 d2.evaluation.evaluator]: Inference done 34/150. Dataloading: 0.0045 s/iter. Inference: 0.2174 s/iter. Eval: 4.8531 s/iter. Total: 5.0767 s/iter. ETA=0:09:48\n",
            "[05/10 08:39:27 d2.evaluation.evaluator]: Inference done 35/150. Dataloading: 0.0045 s/iter. Inference: 0.2168 s/iter. Eval: 4.8658 s/iter. Total: 5.0888 s/iter. ETA=0:09:45\n",
            "[05/10 08:39:37 d2.evaluation.evaluator]: Inference done 37/150. Dataloading: 0.0044 s/iter. Inference: 0.2185 s/iter. Eval: 4.8465 s/iter. Total: 5.0713 s/iter. ETA=0:09:33\n",
            "[05/10 08:39:47 d2.evaluation.evaluator]: Inference done 38/150. Dataloading: 0.0043 s/iter. Inference: 0.2245 s/iter. Eval: 4.9918 s/iter. Total: 5.2225 s/iter. ETA=0:09:44\n",
            "[05/10 08:39:55 d2.evaluation.evaluator]: Inference done 39/150. Dataloading: 0.0043 s/iter. Inference: 0.2250 s/iter. Eval: 5.0706 s/iter. Total: 5.3019 s/iter. ETA=0:09:48\n",
            "[05/10 08:40:08 d2.evaluation.evaluator]: Inference done 40/150. Dataloading: 0.0042 s/iter. Inference: 0.2311 s/iter. Eval: 5.2890 s/iter. Total: 5.5264 s/iter. ETA=0:10:07\n",
            "[05/10 08:40:15 d2.evaluation.evaluator]: Inference done 41/150. Dataloading: 0.0042 s/iter. Inference: 0.2307 s/iter. Eval: 5.3332 s/iter. Total: 5.5701 s/iter. ETA=0:10:07\n",
            "[05/10 08:40:25 d2.evaluation.evaluator]: Inference done 42/150. Dataloading: 0.0042 s/iter. Inference: 0.2313 s/iter. Eval: 5.4555 s/iter. Total: 5.6932 s/iter. ETA=0:10:14\n",
            "[05/10 08:40:33 d2.evaluation.evaluator]: Inference done 44/150. Dataloading: 0.0041 s/iter. Inference: 0.2305 s/iter. Eval: 5.3751 s/iter. Total: 5.6119 s/iter. ETA=0:09:54\n",
            "[05/10 08:40:41 d2.evaluation.evaluator]: Inference done 46/150. Dataloading: 0.0040 s/iter. Inference: 0.2291 s/iter. Eval: 5.2924 s/iter. Total: 5.5277 s/iter. ETA=0:09:34\n",
            "[05/10 08:40:50 d2.evaluation.evaluator]: Inference done 47/150. Dataloading: 0.0040 s/iter. Inference: 0.2290 s/iter. Eval: 5.3726 s/iter. Total: 5.6077 s/iter. ETA=0:09:37\n",
            "[05/10 08:41:02 d2.evaluation.evaluator]: Inference done 48/150. Dataloading: 0.0040 s/iter. Inference: 0.2292 s/iter. Eval: 5.5176 s/iter. Total: 5.7531 s/iter. ETA=0:09:46\n",
            "[05/10 08:41:09 d2.evaluation.evaluator]: Inference done 50/150. Dataloading: 0.0039 s/iter. Inference: 0.2278 s/iter. Eval: 5.4248 s/iter. Total: 5.6587 s/iter. ETA=0:09:25\n",
            "[05/10 08:41:19 d2.evaluation.evaluator]: Inference done 53/150. Dataloading: 0.0041 s/iter. Inference: 0.2261 s/iter. Eval: 5.2843 s/iter. Total: 5.5166 s/iter. ETA=0:08:55\n",
            "[05/10 08:41:25 d2.evaluation.evaluator]: Inference done 55/150. Dataloading: 0.0040 s/iter. Inference: 0.2251 s/iter. Eval: 5.1805 s/iter. Total: 5.4117 s/iter. ETA=0:08:34\n",
            "[05/10 08:41:34 d2.evaluation.evaluator]: Inference done 57/150. Dataloading: 0.0040 s/iter. Inference: 0.2244 s/iter. Eval: 5.1372 s/iter. Total: 5.3678 s/iter. ETA=0:08:19\n",
            "[05/10 08:41:40 d2.evaluation.evaluator]: Inference done 58/150. Dataloading: 0.0040 s/iter. Inference: 0.2243 s/iter. Eval: 5.1569 s/iter. Total: 5.3872 s/iter. ETA=0:08:15\n",
            "[05/10 08:41:47 d2.evaluation.evaluator]: Inference done 61/150. Dataloading: 0.0042 s/iter. Inference: 0.2235 s/iter. Eval: 4.9884 s/iter. Total: 5.2181 s/iter. ETA=0:07:44\n",
            "[05/10 08:41:52 d2.evaluation.evaluator]: Inference done 65/150. Dataloading: 0.0044 s/iter. Inference: 0.2244 s/iter. Eval: 4.7271 s/iter. Total: 4.9580 s/iter. ETA=0:07:01\n",
            "[05/10 08:42:01 d2.evaluation.evaluator]: Inference done 68/150. Dataloading: 0.0043 s/iter. Inference: 0.2239 s/iter. Eval: 4.6280 s/iter. Total: 4.8583 s/iter. ETA=0:06:38\n",
            "[05/10 08:42:08 d2.evaluation.evaluator]: Inference done 70/150. Dataloading: 0.0043 s/iter. Inference: 0.2231 s/iter. Eval: 4.5953 s/iter. Total: 4.8247 s/iter. ETA=0:06:25\n",
            "[05/10 08:42:17 d2.evaluation.evaluator]: Inference done 73/150. Dataloading: 0.0042 s/iter. Inference: 0.2222 s/iter. Eval: 4.5119 s/iter. Total: 4.7403 s/iter. ETA=0:06:05\n",
            "[05/10 08:42:24 d2.evaluation.evaluator]: Inference done 74/150. Dataloading: 0.0042 s/iter. Inference: 0.2227 s/iter. Eval: 4.5434 s/iter. Total: 4.7722 s/iter. ETA=0:06:02\n",
            "[05/10 08:42:30 d2.evaluation.evaluator]: Inference done 77/150. Dataloading: 0.0041 s/iter. Inference: 0.2213 s/iter. Eval: 4.4268 s/iter. Total: 4.6542 s/iter. ETA=0:05:39\n",
            "[05/10 08:42:37 d2.evaluation.evaluator]: Inference done 80/150. Dataloading: 0.0041 s/iter. Inference: 0.2188 s/iter. Eval: 4.3377 s/iter. Total: 4.5625 s/iter. ETA=0:05:19\n",
            "[05/10 08:42:44 d2.evaluation.evaluator]: Inference done 83/150. Dataloading: 0.0040 s/iter. Inference: 0.2172 s/iter. Eval: 4.2547 s/iter. Total: 4.4779 s/iter. ETA=0:05:00\n",
            "[05/10 08:42:49 d2.evaluation.evaluator]: Inference done 85/150. Dataloading: 0.0040 s/iter. Inference: 0.2173 s/iter. Eval: 4.2132 s/iter. Total: 4.4364 s/iter. ETA=0:04:48\n",
            "[05/10 08:42:56 d2.evaluation.evaluator]: Inference done 87/150. Dataloading: 0.0041 s/iter. Inference: 0.2175 s/iter. Eval: 4.1905 s/iter. Total: 4.4140 s/iter. ETA=0:04:38\n",
            "[05/10 08:43:03 d2.evaluation.evaluator]: Inference done 90/150. Dataloading: 0.0041 s/iter. Inference: 0.2160 s/iter. Eval: 4.1180 s/iter. Total: 4.3400 s/iter. ETA=0:04:20\n",
            "[05/10 08:43:11 d2.evaluation.evaluator]: Inference done 93/150. Dataloading: 0.0040 s/iter. Inference: 0.2156 s/iter. Eval: 4.0588 s/iter. Total: 4.2803 s/iter. ETA=0:04:03\n",
            "[05/10 08:43:18 d2.evaluation.evaluator]: Inference done 95/150. Dataloading: 0.0040 s/iter. Inference: 0.2151 s/iter. Eval: 4.0416 s/iter. Total: 4.2626 s/iter. ETA=0:03:54\n",
            "[05/10 08:43:26 d2.evaluation.evaluator]: Inference done 97/150. Dataloading: 0.0040 s/iter. Inference: 0.2150 s/iter. Eval: 4.0315 s/iter. Total: 4.2523 s/iter. ETA=0:03:45\n",
            "[05/10 08:43:37 d2.evaluation.evaluator]: Inference done 99/150. Dataloading: 0.0039 s/iter. Inference: 0.2145 s/iter. Eval: 4.0602 s/iter. Total: 4.2806 s/iter. ETA=0:03:38\n",
            "[05/10 08:43:45 d2.evaluation.evaluator]: Inference done 102/150. Dataloading: 0.0039 s/iter. Inference: 0.2140 s/iter. Eval: 4.0079 s/iter. Total: 4.2277 s/iter. ETA=0:03:22\n",
            "[05/10 08:43:51 d2.evaluation.evaluator]: Inference done 105/150. Dataloading: 0.0039 s/iter. Inference: 0.2130 s/iter. Eval: 3.9448 s/iter. Total: 4.1634 s/iter. ETA=0:03:07\n",
            "[05/10 08:44:00 d2.evaluation.evaluator]: Inference done 109/150. Dataloading: 0.0038 s/iter. Inference: 0.2112 s/iter. Eval: 3.8783 s/iter. Total: 4.0951 s/iter. ETA=0:02:47\n",
            "[05/10 08:44:06 d2.evaluation.evaluator]: Inference done 111/150. Dataloading: 0.0039 s/iter. Inference: 0.2111 s/iter. Eval: 3.8536 s/iter. Total: 4.0703 s/iter. ETA=0:02:38\n",
            "[05/10 08:44:14 d2.evaluation.evaluator]: Inference done 113/150. Dataloading: 0.0039 s/iter. Inference: 0.2111 s/iter. Eval: 3.8486 s/iter. Total: 4.0653 s/iter. ETA=0:02:30\n",
            "[05/10 08:44:23 d2.evaluation.evaluator]: Inference done 115/150. Dataloading: 0.0038 s/iter. Inference: 0.2104 s/iter. Eval: 3.8588 s/iter. Total: 4.0749 s/iter. ETA=0:02:22\n",
            "[05/10 08:44:33 d2.evaluation.evaluator]: Inference done 117/150. Dataloading: 0.0038 s/iter. Inference: 0.2106 s/iter. Eval: 3.8803 s/iter. Total: 4.0965 s/iter. ETA=0:02:15\n",
            "[05/10 08:44:39 d2.evaluation.evaluator]: Inference done 119/150. Dataloading: 0.0038 s/iter. Inference: 0.2106 s/iter. Eval: 3.8574 s/iter. Total: 4.0737 s/iter. ETA=0:02:06\n",
            "[05/10 08:44:47 d2.evaluation.evaluator]: Inference done 120/150. Dataloading: 0.0038 s/iter. Inference: 0.2106 s/iter. Eval: 3.8886 s/iter. Total: 4.1048 s/iter. ETA=0:02:03\n",
            "[05/10 08:44:52 d2.evaluation.evaluator]: Inference done 122/150. Dataloading: 0.0038 s/iter. Inference: 0.2103 s/iter. Eval: 3.8683 s/iter. Total: 4.0843 s/iter. ETA=0:01:54\n",
            "[05/10 08:45:00 d2.evaluation.evaluator]: Inference done 125/150. Dataloading: 0.0038 s/iter. Inference: 0.2102 s/iter. Eval: 3.8314 s/iter. Total: 4.0472 s/iter. ETA=0:01:41\n",
            "[05/10 08:45:05 d2.evaluation.evaluator]: Inference done 127/150. Dataloading: 0.0038 s/iter. Inference: 0.2099 s/iter. Eval: 3.8092 s/iter. Total: 4.0248 s/iter. ETA=0:01:32\n",
            "[05/10 08:45:11 d2.evaluation.evaluator]: Inference done 130/150. Dataloading: 0.0038 s/iter. Inference: 0.2089 s/iter. Eval: 3.7548 s/iter. Total: 3.9694 s/iter. ETA=0:01:19\n",
            "[05/10 08:45:16 d2.evaluation.evaluator]: Inference done 134/150. Dataloading: 0.0038 s/iter. Inference: 0.2080 s/iter. Eval: 3.6759 s/iter. Total: 3.8895 s/iter. ETA=0:01:02\n",
            "[05/10 08:45:23 d2.evaluation.evaluator]: Inference done 137/150. Dataloading: 0.0039 s/iter. Inference: 0.2088 s/iter. Eval: 3.6369 s/iter. Total: 3.8514 s/iter. ETA=0:00:50\n",
            "[05/10 08:45:29 d2.evaluation.evaluator]: Inference done 139/150. Dataloading: 0.0039 s/iter. Inference: 0.2092 s/iter. Eval: 3.6251 s/iter. Total: 3.8401 s/iter. ETA=0:00:42\n",
            "[05/10 08:45:36 d2.evaluation.evaluator]: Inference done 144/150. Dataloading: 0.0039 s/iter. Inference: 0.2074 s/iter. Eval: 3.5363 s/iter. Total: 3.7495 s/iter. ETA=0:00:22\n",
            "[05/10 08:45:41 d2.evaluation.evaluator]: Inference done 145/150. Dataloading: 0.0039 s/iter. Inference: 0.2074 s/iter. Eval: 3.5460 s/iter. Total: 3.7591 s/iter. ETA=0:00:18\n",
            "[05/10 08:45:47 d2.evaluation.evaluator]: Inference done 147/150. Dataloading: 0.0039 s/iter. Inference: 0.2071 s/iter. Eval: 3.5344 s/iter. Total: 3.7472 s/iter. ETA=0:00:11\n",
            "[05/10 08:45:52 d2.evaluation.evaluator]: Inference done 149/150. Dataloading: 0.0039 s/iter. Inference: 0.2069 s/iter. Eval: 3.5224 s/iter. Total: 3.7350 s/iter. ETA=0:00:03\n",
            "[05/10 08:45:55 d2.evaluation.evaluator]: Total inference time: 0:09:00.397588 (3.726880 s / iter per device, on 1 devices)\n",
            "[05/10 08:45:55 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:29 (0.206471 s / iter per device, on 1 devices)\n",
            "[05/10 08:45:55 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...\n",
            "[05/10 08:45:55 d2.evaluation.coco_evaluation]: Saving results to /content/output/chkpt/inference/coco_instances_results.json\n",
            "[05/10 08:45:56 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "[05/10 08:45:56 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*\n",
            "[05/10 08:45:56 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.17 seconds.\n",
            "[05/10 08:45:56 d2.evaluation.fast_eval_api]: Accumulating evaluation results...\n",
            "[05/10 08:45:56 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.07 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
            "[05/10 08:45:56 d2.evaluation.coco_evaluation]: Evaluation results for bbox: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 0.000 | 0.000  | 0.000  | 0.000 | 0.000 | 0.000 |\n",
            "[05/10 08:45:56 d2.evaluation.coco_evaluation]: Per-category bbox AP: \n",
            "| category   | AP    | category              | AP    | category   | AP    |\n",
            "|:-----------|:------|:----------------------|:------|:-----------|:------|\n",
            "| Bottle     | 0.000 | Bottle cap            | 0.000 | Can        | 0.000 |\n",
            "| Cigarette  | 0.000 | Cup                   | 0.000 | Lid        | 0.000 |\n",
            "| Other      | 0.000 | Plastic bag & wrapper | 0.000 | Pop tab    | 0.000 |\n",
            "| Straw      | 0.000 |                       |       |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.81s)\n",
            "creating index...\n",
            "index created!\n",
            "[05/10 08:45:57 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*\n",
            "[05/10 08:45:58 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.71 seconds.\n",
            "[05/10 08:45:58 d2.evaluation.fast_eval_api]: Accumulating evaluation results...\n",
            "[05/10 08:45:58 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.07 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.113\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.213\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.104\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.034\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.158\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.202\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.260\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.268\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.082\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.351\n",
            "[05/10 08:45:58 d2.evaluation.coco_evaluation]: Evaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 11.259 | 21.301 | 10.423 | 0.000 | 3.431 | 15.772 |\n",
            "[05/10 08:45:58 d2.evaluation.coco_evaluation]: Per-category segm AP: \n",
            "| category   | AP     | category              | AP     | category   | AP     |\n",
            "|:-----------|:-------|:----------------------|:-------|:-----------|:-------|\n",
            "| Bottle     | 23.805 | Bottle cap            | 24.180 | Can        | 10.526 |\n",
            "| Cigarette  | 1.031  | Cup                   | 14.802 | Lid        | 9.588  |\n",
            "| Other      | 6.920  | Plastic bag & wrapper | 18.451 | Pop tab    | 1.089  |\n",
            "| Straw      | 2.201  |                       |        |            |        |\n",
            "[05/10 08:45:58 d2.engine.defaults]: Evaluation results for TACO_val in csv format:\n",
            "[05/10 08:45:58 d2.evaluation.testing]: copypaste: Task: bbox\n",
            "[05/10 08:45:58 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl\n",
            "[05/10 08:45:58 d2.evaluation.testing]: copypaste: 0.0000,0.0000,0.0000,0.0000,0.0000,0.0000\n",
            "[05/10 08:45:58 d2.evaluation.testing]: copypaste: Task: segm\n",
            "[05/10 08:45:58 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl\n",
            "[05/10 08:45:58 d2.evaluation.testing]: copypaste: 11.2592,21.3006,10.4227,0.0000,3.4313,15.7721\n",
            "[05/10 08:45:58 d2.utils.events]:  eta: 2:17:30  iter: 2999  total_loss: 0.89  loss_ins: 0.6638  loss_cate: 0.2254  time: 3.2828  data_time: 1.8523  lr: 0.00051928  max_mem: 9678M\n",
            "[05/10 08:47:06 d2.utils.events]:  eta: 2:16:46  iter: 3019  total_loss: 0.9785  loss_ins: 0.7669  loss_cate: 0.2346  time: 3.2846  data_time: 1.7103  lr: 0.00051437  max_mem: 9678M\n",
            "[05/10 08:48:09 d2.utils.events]:  eta: 2:15:30  iter: 3039  total_loss: 0.7796  loss_ins: 0.5646  loss_cate: 0.2154  time: 3.2823  data_time: 1.6730  lr: 0.00050947  max_mem: 9678M\n",
            "[05/10 08:49:11 d2.utils.events]:  eta: 2:13:51  iter: 3059  total_loss: 0.8766  loss_ins: 0.6666  loss_cate: 0.217  time: 3.2789  data_time: 1.5938  lr: 0.00050458  max_mem: 9678M\n",
            "[05/10 08:50:20 d2.utils.events]:  eta: 2:13:17  iter: 3079  total_loss: 0.9795  loss_ins: 0.7831  loss_cate: 0.2116  time: 3.2823  data_time: 1.8211  lr: 0.00049969  max_mem: 9678M\n",
            "[05/10 08:51:29 d2.utils.events]:  eta: 2:13:15  iter: 3099  total_loss: 1.009  loss_ins: 0.7739  loss_cate: 0.2163  time: 3.2849  data_time: 1.8226  lr: 0.0004948  max_mem: 9678M\n",
            "[05/10 08:52:38 d2.utils.events]:  eta: 2:12:53  iter: 3119  total_loss: 0.9542  loss_ins: 0.7272  loss_cate: 0.2314  time: 3.2881  data_time: 2.0080  lr: 0.00048992  max_mem: 9678M\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "help(trainer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Fe0bFSbvYO1",
        "outputId": "41e718fb-730f-4239-bb82-d12a3f61583e"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on Trainer in module train_net object:\n",
            "\n",
            "class Trainer(detectron2.engine.defaults.DefaultTrainer)\n",
            " |  Trainer(cfg)\n",
            " |  \n",
            " |  This is the same Trainer except that we rewrite the\n",
            " |  `build_train_loader`/`resume_or_load` method.\n",
            " |  \n",
            " |  Method resolution order:\n",
            " |      Trainer\n",
            " |      detectron2.engine.defaults.DefaultTrainer\n",
            " |      detectron2.engine.train_loop.TrainerBase\n",
            " |      builtins.object\n",
            " |  \n",
            " |  Methods defined here:\n",
            " |  \n",
            " |  build_hooks(self)\n",
            " |      Replace `DetectionCheckpointer` with `AdetCheckpointer`.\n",
            " |      \n",
            " |      Build a list of default hooks, including timing, evaluation,\n",
            " |      checkpointing, lr scheduling, precise BN, writing events.\n",
            " |  \n",
            " |  resume_or_load(self, resume=True)\n",
            " |      If `resume==True` and `cfg.OUTPUT_DIR` contains the last checkpoint (defined by\n",
            " |      a `last_checkpoint` file), resume from the file. Resuming means loading all\n",
            " |      available states (eg. optimizer and scheduler) and update iteration counter\n",
            " |      from the checkpoint. ``cfg.MODEL.WEIGHTS`` will not be used.\n",
            " |      \n",
            " |      Otherwise, this is considered as an independent training. The method will load model\n",
            " |      weights from the file `cfg.MODEL.WEIGHTS` (but will not load other states) and start\n",
            " |      from iteration 0.\n",
            " |      \n",
            " |      Args:\n",
            " |          resume (bool): whether to do resume or not\n",
            " |  \n",
            " |  train(self)\n",
            " |      Run training.\n",
            " |      \n",
            " |      Returns:\n",
            " |          OrderedDict of results, if evaluation is enabled. Otherwise None.\n",
            " |  \n",
            " |  train_loop(self, start_iter: int, max_iter: int)\n",
            " |      Args:\n",
            " |          start_iter, max_iter (int): See docs above\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Class methods defined here:\n",
            " |  \n",
            " |  build_evaluator(cfg, dataset_name, output_folder=None) from builtins.type\n",
            " |      Create evaluator(s) for a given dataset.\n",
            " |      This uses the special metadata \"evaluator_type\" associated with each builtin dataset.\n",
            " |      For your own dataset, you can simply create an evaluator manually in your\n",
            " |      script and do not have to worry about the hacky if-else logic here.\n",
            " |  \n",
            " |  build_train_loader(cfg) from builtins.type\n",
            " |      Returns:\n",
            " |          iterable\n",
            " |      \n",
            " |      It calls :func:`detectron2.data.build_detection_train_loader` with a customized\n",
            " |      DatasetMapper, which adds categorical labels as a semantic mask.\n",
            " |  \n",
            " |  test_with_TTA(cfg, model) from builtins.type\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from detectron2.engine.defaults.DefaultTrainer:\n",
            " |  \n",
            " |  __init__(self, cfg)\n",
            " |      Args:\n",
            " |          cfg (CfgNode):\n",
            " |  \n",
            " |  build_writers(self)\n",
            " |      Build a list of writers to be used using :func:`default_writers()`.\n",
            " |      If you'd like a different list of writers, you can overwrite it in\n",
            " |      your trainer.\n",
            " |      \n",
            " |      Returns:\n",
            " |          list[EventWriter]: a list of :class:`EventWriter` objects.\n",
            " |  \n",
            " |  load_state_dict(self, state_dict)\n",
            " |  \n",
            " |  run_step(self)\n",
            " |  \n",
            " |  state_dict(self)\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Class methods inherited from detectron2.engine.defaults.DefaultTrainer:\n",
            " |  \n",
            " |  build_lr_scheduler(cfg, optimizer) from builtins.type\n",
            " |      It now calls :func:`detectron2.solver.build_lr_scheduler`.\n",
            " |      Overwrite it if you'd like a different scheduler.\n",
            " |  \n",
            " |  build_model(cfg) from builtins.type\n",
            " |      Returns:\n",
            " |          torch.nn.Module:\n",
            " |      \n",
            " |      It now calls :func:`detectron2.modeling.build_model`.\n",
            " |      Overwrite it if you'd like a different model.\n",
            " |  \n",
            " |  build_optimizer(cfg, model) from builtins.type\n",
            " |      Returns:\n",
            " |          torch.optim.Optimizer:\n",
            " |      \n",
            " |      It now calls :func:`detectron2.solver.build_optimizer`.\n",
            " |      Overwrite it if you'd like a different optimizer.\n",
            " |  \n",
            " |  build_test_loader(cfg, dataset_name) from builtins.type\n",
            " |      Returns:\n",
            " |          iterable\n",
            " |      \n",
            " |      It now calls :func:`detectron2.data.build_detection_test_loader`.\n",
            " |      Overwrite it if you'd like a different data loader.\n",
            " |  \n",
            " |  test(cfg, model, evaluators=None) from builtins.type\n",
            " |      Evaluate the given model. The given model is expected to already contain\n",
            " |      weights to evaluate.\n",
            " |      \n",
            " |      Args:\n",
            " |          cfg (CfgNode):\n",
            " |          model (nn.Module):\n",
            " |          evaluators (list[DatasetEvaluator] or None): if None, will call\n",
            " |              :meth:`build_evaluator`. Otherwise, must have the same length as\n",
            " |              ``cfg.DATASETS.TEST``.\n",
            " |      \n",
            " |      Returns:\n",
            " |          dict: a dict of result metrics\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Static methods inherited from detectron2.engine.defaults.DefaultTrainer:\n",
            " |  \n",
            " |  auto_scale_workers(cfg, num_workers: int)\n",
            " |      When the config is defined for certain number of workers (according to\n",
            " |      ``cfg.SOLVER.REFERENCE_WORLD_SIZE``) that's different from the number of\n",
            " |      workers currently in use, returns a new cfg where the total batch size\n",
            " |      is scaled so that the per-GPU batch size stays the same as the\n",
            " |      original ``IMS_PER_BATCH // REFERENCE_WORLD_SIZE``.\n",
            " |      \n",
            " |      Other config options are also scaled accordingly:\n",
            " |      * training steps and warmup steps are scaled inverse proportionally.\n",
            " |      * learning rate are scaled proportionally, following :paper:`ImageNet in 1h`.\n",
            " |      \n",
            " |      For example, with the original config like the following:\n",
            " |      \n",
            " |      .. code-block:: yaml\n",
            " |      \n",
            " |          IMS_PER_BATCH: 16\n",
            " |          BASE_LR: 0.1\n",
            " |          REFERENCE_WORLD_SIZE: 8\n",
            " |          MAX_ITER: 5000\n",
            " |          STEPS: (4000,)\n",
            " |          CHECKPOINT_PERIOD: 1000\n",
            " |      \n",
            " |      When this config is used on 16 GPUs instead of the reference number 8,\n",
            " |      calling this method will return a new config with:\n",
            " |      \n",
            " |      .. code-block:: yaml\n",
            " |      \n",
            " |          IMS_PER_BATCH: 32\n",
            " |          BASE_LR: 0.2\n",
            " |          REFERENCE_WORLD_SIZE: 16\n",
            " |          MAX_ITER: 2500\n",
            " |          STEPS: (2000,)\n",
            " |          CHECKPOINT_PERIOD: 500\n",
            " |      \n",
            " |      Note that both the original config and this new config can be trained on 16 GPUs.\n",
            " |      It's up to user whether to enable this feature (by setting ``REFERENCE_WORLD_SIZE``).\n",
            " |      \n",
            " |      Returns:\n",
            " |          CfgNode: a new config. Same as original if ``cfg.SOLVER.REFERENCE_WORLD_SIZE==0``.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors inherited from detectron2.engine.defaults.DefaultTrainer:\n",
            " |  \n",
            " |  data_loader\n",
            " |  \n",
            " |  model\n",
            " |  \n",
            " |  optimizer\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from detectron2.engine.train_loop.TrainerBase:\n",
            " |  \n",
            " |  after_step(self)\n",
            " |  \n",
            " |  after_train(self)\n",
            " |  \n",
            " |  before_step(self)\n",
            " |  \n",
            " |  before_train(self)\n",
            " |  \n",
            " |  register_hooks(self, hooks: List[Optional[detectron2.engine.train_loop.HookBase]]) -> None\n",
            " |      Register hooks to the trainer. The hooks are executed in the order\n",
            " |      they are registered.\n",
            " |      \n",
            " |      Args:\n",
            " |          hooks (list[Optional[HookBase]]): list of hooks\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors inherited from detectron2.engine.train_loop.TrainerBase:\n",
            " |  \n",
            " |  __dict__\n",
            " |      dictionary for instance variables (if defined)\n",
            " |  \n",
            " |  __weakref__\n",
            " |      list of weak references to the object (if defined)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run this if you want to check how many trainable parameters we have"
      ],
      "metadata": {
        "id": "0JVZhhKDFYpo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from detectron2.modeling import build_model\n",
        "model = build_model(train_cfg_loaded)\n",
        "num_trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(num_trainable_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZljjMBcCFLtJ",
        "outputId": "52e790a5-9e9c-448d-9ecd-242ec3da4291"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "criterion.weight_dict  {'loss_ce': 4.0, 'loss_mask': 5.0, 'loss_dice': 5.0, 'loss_bbox': 5.0, 'loss_giou': 2.0, 'loss_ce_interm': 4.0, 'loss_mask_interm': 5.0, 'loss_dice_interm': 5.0, 'loss_bbox_interm': 5.0, 'loss_giou_interm': 2.0, 'loss_ce_dn': 4.0, 'loss_mask_dn': 5.0, 'loss_dice_dn': 5.0, 'loss_bbox_dn': 5.0, 'loss_giou_dn': 2.0, 'loss_ce_interm_dn': 4.0, 'loss_mask_interm_dn': 5.0, 'loss_dice_interm_dn': 5.0, 'loss_bbox_interm_dn': 5.0, 'loss_giou_interm_dn': 2.0, 'loss_ce_0': 4.0, 'loss_mask_0': 5.0, 'loss_dice_0': 5.0, 'loss_bbox_0': 5.0, 'loss_giou_0': 2.0, 'loss_ce_interm_0': 4.0, 'loss_mask_interm_0': 5.0, 'loss_dice_interm_0': 5.0, 'loss_bbox_interm_0': 5.0, 'loss_giou_interm_0': 2.0, 'loss_ce_dn_0': 4.0, 'loss_mask_dn_0': 5.0, 'loss_dice_dn_0': 5.0, 'loss_bbox_dn_0': 5.0, 'loss_giou_dn_0': 2.0, 'loss_ce_interm_dn_0': 4.0, 'loss_mask_interm_dn_0': 5.0, 'loss_dice_interm_dn_0': 5.0, 'loss_bbox_interm_dn_0': 5.0, 'loss_giou_interm_dn_0': 2.0, 'loss_ce_1': 4.0, 'loss_mask_1': 5.0, 'loss_dice_1': 5.0, 'loss_bbox_1': 5.0, 'loss_giou_1': 2.0, 'loss_ce_interm_1': 4.0, 'loss_mask_interm_1': 5.0, 'loss_dice_interm_1': 5.0, 'loss_bbox_interm_1': 5.0, 'loss_giou_interm_1': 2.0, 'loss_ce_dn_1': 4.0, 'loss_mask_dn_1': 5.0, 'loss_dice_dn_1': 5.0, 'loss_bbox_dn_1': 5.0, 'loss_giou_dn_1': 2.0, 'loss_ce_interm_dn_1': 4.0, 'loss_mask_interm_dn_1': 5.0, 'loss_dice_interm_dn_1': 5.0, 'loss_bbox_interm_dn_1': 5.0, 'loss_giou_interm_dn_1': 2.0, 'loss_ce_2': 4.0, 'loss_mask_2': 5.0, 'loss_dice_2': 5.0, 'loss_bbox_2': 5.0, 'loss_giou_2': 2.0, 'loss_ce_interm_2': 4.0, 'loss_mask_interm_2': 5.0, 'loss_dice_interm_2': 5.0, 'loss_bbox_interm_2': 5.0, 'loss_giou_interm_2': 2.0, 'loss_ce_dn_2': 4.0, 'loss_mask_dn_2': 5.0, 'loss_dice_dn_2': 5.0, 'loss_bbox_dn_2': 5.0, 'loss_giou_dn_2': 2.0, 'loss_ce_interm_dn_2': 4.0, 'loss_mask_interm_dn_2': 5.0, 'loss_dice_interm_dn_2': 5.0, 'loss_bbox_interm_dn_2': 5.0, 'loss_giou_interm_dn_2': 2.0, 'loss_ce_3': 4.0, 'loss_mask_3': 5.0, 'loss_dice_3': 5.0, 'loss_bbox_3': 5.0, 'loss_giou_3': 2.0, 'loss_ce_interm_3': 4.0, 'loss_mask_interm_3': 5.0, 'loss_dice_interm_3': 5.0, 'loss_bbox_interm_3': 5.0, 'loss_giou_interm_3': 2.0, 'loss_ce_dn_3': 4.0, 'loss_mask_dn_3': 5.0, 'loss_dice_dn_3': 5.0, 'loss_bbox_dn_3': 5.0, 'loss_giou_dn_3': 2.0, 'loss_ce_interm_dn_3': 4.0, 'loss_mask_interm_dn_3': 5.0, 'loss_dice_interm_dn_3': 5.0, 'loss_bbox_interm_dn_3': 5.0, 'loss_giou_interm_dn_3': 2.0, 'loss_ce_4': 4.0, 'loss_mask_4': 5.0, 'loss_dice_4': 5.0, 'loss_bbox_4': 5.0, 'loss_giou_4': 2.0, 'loss_ce_interm_4': 4.0, 'loss_mask_interm_4': 5.0, 'loss_dice_interm_4': 5.0, 'loss_bbox_interm_4': 5.0, 'loss_giou_interm_4': 2.0, 'loss_ce_dn_4': 4.0, 'loss_mask_dn_4': 5.0, 'loss_dice_dn_4': 5.0, 'loss_bbox_dn_4': 5.0, 'loss_giou_dn_4': 2.0, 'loss_ce_interm_dn_4': 4.0, 'loss_mask_interm_dn_4': 5.0, 'loss_dice_interm_dn_4': 5.0, 'loss_bbox_interm_dn_4': 5.0, 'loss_giou_interm_dn_4': 2.0, 'loss_ce_5': 4.0, 'loss_mask_5': 5.0, 'loss_dice_5': 5.0, 'loss_bbox_5': 5.0, 'loss_giou_5': 2.0, 'loss_ce_interm_5': 4.0, 'loss_mask_interm_5': 5.0, 'loss_dice_interm_5': 5.0, 'loss_bbox_interm_5': 5.0, 'loss_giou_interm_5': 2.0, 'loss_ce_dn_5': 4.0, 'loss_mask_dn_5': 5.0, 'loss_dice_dn_5': 5.0, 'loss_bbox_dn_5': 5.0, 'loss_giou_dn_5': 2.0, 'loss_ce_interm_dn_5': 4.0, 'loss_mask_interm_dn_5': 5.0, 'loss_dice_interm_dn_5': 5.0, 'loss_bbox_interm_dn_5': 5.0, 'loss_giou_interm_dn_5': 2.0, 'loss_ce_6': 4.0, 'loss_mask_6': 5.0, 'loss_dice_6': 5.0, 'loss_bbox_6': 5.0, 'loss_giou_6': 2.0, 'loss_ce_interm_6': 4.0, 'loss_mask_interm_6': 5.0, 'loss_dice_interm_6': 5.0, 'loss_bbox_interm_6': 5.0, 'loss_giou_interm_6': 2.0, 'loss_ce_dn_6': 4.0, 'loss_mask_dn_6': 5.0, 'loss_dice_dn_6': 5.0, 'loss_bbox_dn_6': 5.0, 'loss_giou_dn_6': 2.0, 'loss_ce_interm_dn_6': 4.0, 'loss_mask_interm_dn_6': 5.0, 'loss_dice_interm_dn_6': 5.0, 'loss_bbox_interm_dn_6': 5.0, 'loss_giou_interm_dn_6': 2.0, 'loss_ce_7': 4.0, 'loss_mask_7': 5.0, 'loss_dice_7': 5.0, 'loss_bbox_7': 5.0, 'loss_giou_7': 2.0, 'loss_ce_interm_7': 4.0, 'loss_mask_interm_7': 5.0, 'loss_dice_interm_7': 5.0, 'loss_bbox_interm_7': 5.0, 'loss_giou_interm_7': 2.0, 'loss_ce_dn_7': 4.0, 'loss_mask_dn_7': 5.0, 'loss_dice_dn_7': 5.0, 'loss_bbox_dn_7': 5.0, 'loss_giou_dn_7': 2.0, 'loss_ce_interm_dn_7': 4.0, 'loss_mask_interm_dn_7': 5.0, 'loss_dice_interm_dn_7': 5.0, 'loss_bbox_interm_dn_7': 5.0, 'loss_giou_interm_dn_7': 2.0, 'loss_ce_8': 4.0, 'loss_mask_8': 5.0, 'loss_dice_8': 5.0, 'loss_bbox_8': 5.0, 'loss_giou_8': 2.0, 'loss_ce_interm_8': 4.0, 'loss_mask_interm_8': 5.0, 'loss_dice_interm_8': 5.0, 'loss_bbox_interm_8': 5.0, 'loss_giou_interm_8': 2.0, 'loss_ce_dn_8': 4.0, 'loss_mask_dn_8': 5.0, 'loss_dice_dn_8': 5.0, 'loss_bbox_dn_8': 5.0, 'loss_giou_dn_8': 2.0, 'loss_ce_interm_dn_8': 4.0, 'loss_mask_interm_dn_8': 5.0, 'loss_dice_interm_dn_8': 5.0, 'loss_bbox_interm_dn_8': 5.0, 'loss_giou_interm_dn_8': 2.0}\n",
            "20361524\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "On training set: the maximum number of instances in a single image is 90.\n",
        "The average number of instances is 3.27\n",
        "On validation set: max is 16 mean is 2.59\n",
        "On test: max is 37 mean is 2.77"
      ],
      "metadata": {
        "id": "BblGWvwcsg_D"
      }
    }
  ]
}
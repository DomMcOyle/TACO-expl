{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "id": "7pzTIxbXnL6S",
        "outputId": "0aa4c1ff-3985-45bf-927e-9512ca491315"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2023 NVIDIA Corporation\n",
            "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
            "Cuda compilation tools, release 12.2, V12.2.140\n",
            "Build cuda_12.2.r12.2/compiler.33191640_0\n",
            "Tue May  7 15:00:21 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   65C    P8              11W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.2.1+cu121'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "!nvcc --version\n",
        "!nvidia-smi\n",
        "import torch\n",
        "torch.__version__"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install 'git+https://github.com/facebookresearch/detectron2.git@5aeb252b194b93dc2879b4ac34bc51a31b5aee13'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "WGL4szW1o_UM",
        "outputId": "f0782947-855f-4abe-af26-9030530b52fc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/facebookresearch/detectron2.git@5aeb252b194b93dc2879b4ac34bc51a31b5aee13\n",
            "  Cloning https://github.com/facebookresearch/detectron2.git (to revision 5aeb252b194b93dc2879b4ac34bc51a31b5aee13) to /tmp/pip-req-build-in6auqda\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/detectron2.git /tmp/pip-req-build-in6auqda\n",
            "  Running command git rev-parse -q --verify 'sha^5aeb252b194b93dc2879b4ac34bc51a31b5aee13'\n",
            "  Running command git fetch -q https://github.com/facebookresearch/detectron2.git 5aeb252b194b93dc2879b4ac34bc51a31b5aee13\n",
            "  Running command git checkout -q 5aeb252b194b93dc2879b4ac34bc51a31b5aee13\n",
            "  Resolved https://github.com/facebookresearch/detectron2.git to commit 5aeb252b194b93dc2879b4ac34bc51a31b5aee13\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: Pillow>=7.1 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (9.4.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (3.7.1)\n",
            "Requirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (2.0.7)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (2.4.0)\n",
            "Collecting yacs>=0.1.8 (from detectron2==0.6)\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (0.9.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (2.2.1)\n",
            "Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (4.66.2)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (2.15.2)\n",
            "Collecting fvcore<0.1.6,>=0.1.5 (from detectron2==0.6)\n",
            "  Downloading fvcore-0.1.5.post20221221.tar.gz (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m949.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting iopath<0.1.10,>=0.1.7 (from detectron2==0.6)\n",
            "  Downloading iopath-0.1.9-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (0.18.3)\n",
            "Requirement already satisfied: pydot in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (1.4.2)\n",
            "Collecting omegaconf>=2.1 (from detectron2==0.6)\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting hydra-core>=1.1 (from detectron2==0.6)\n",
            "  Downloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting black==22.3.0 (from detectron2==0.6)\n",
            "  Downloading black-22.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting timm (from detectron2==0.6)\n",
            "  Downloading timm-0.9.16-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m41.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fairscale (from detectron2==0.6)\n",
            "  Downloading fairscale-0.4.13.tar.gz (266 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m266.3/266.3 kB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (24.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from black==22.3.0->detectron2==0.6) (8.1.7)\n",
            "Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.10/dist-packages (from black==22.3.0->detectron2==0.6) (4.2.1)\n",
            "Collecting pathspec>=0.9.0 (from black==22.3.0->detectron2==0.6)\n",
            "  Downloading pathspec-0.12.1-py3-none-any.whl (31 kB)\n",
            "Collecting mypy-extensions>=0.4.3 (from black==22.3.0->detectron2==0.6)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from black==22.3.0->detectron2==0.6) (2.0.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (1.25.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (6.0.1)\n",
            "Collecting antlr4-python3-runtime==4.9.* (from hydra-core>=1.1->detectron2==0.6)\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting portalocker (from iopath<0.1.10,>=0.1.7->detectron2==0.6)\n",
            "  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (2.8.2)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from fairscale->detectron2==0.6) (2.2.1+cu121)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (1.63.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (3.6)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (2.31.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (67.7.2)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (3.0.2)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm->detectron2==0.6) (0.17.1+cu121)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (from timm->detectron2==0.6) (0.20.3)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm->detectron2==0.6) (0.4.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard->detectron2==0.6) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (2024.2.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->fairscale->detectron2==0.6) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->fairscale->detectron2==0.6) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->fairscale->detectron2==0.6) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->fairscale->detectron2==0.6) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->fairscale->detectron2==0.6) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->fairscale->detectron2==0.6) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.8.0->fairscale->detectron2==0.6)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.8.0->fairscale->detectron2==0.6)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.8.0->fairscale->detectron2==0.6)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.8.0->fairscale->detectron2==0.6)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.8.0->fairscale->detectron2==0.6)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.8.0->fairscale->detectron2==0.6)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.8.0->fairscale->detectron2==0.6)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.8.0->fairscale->detectron2==0.6)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.8.0->fairscale->detectron2==0.6)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch>=1.8.0->fairscale->detectron2==0.6)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.8.0->fairscale->detectron2==0.6)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->fairscale->detectron2==0.6) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.0->fairscale->detectron2==0.6)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard->detectron2==0.6) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard->detectron2==0.6) (3.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->fairscale->detectron2==0.6) (1.3.0)\n",
            "Building wheels for collected packages: detectron2, fvcore, antlr4-python3-runtime, fairscale\n",
            "  Building wheel for detectron2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for detectron2: filename=detectron2-0.6-cp310-cp310-linux_x86_64.whl size=6172639 sha256=6ce26ec62851882f743852ac7c3299ffd59e9edfeea98223ec09f27d366b7622\n",
            "  Stored in directory: /root/.cache/pip/wheels/93/68/da/76b0102912a9ea75cda929a4556a3eb0e5377b1d1ce0a79940\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fvcore: filename=fvcore-0.1.5.post20221221-py3-none-any.whl size=61400 sha256=a1099d5106f0f3ed4a00edc6fff64371eb79692ae4128420dd9319baea03ed32\n",
            "  Stored in directory: /root/.cache/pip/wheels/01/c0/af/77c1cf53a1be9e42a52b48e5af2169d40ec2e89f7362489dd0\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=48269d34550fe52752bc665600d71756aa4000821bc2ea79654b5f21ca06bc9d\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n",
            "  Building wheel for fairscale (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fairscale: filename=fairscale-0.4.13-py3-none-any.whl size=332108 sha256=c34f959967bb4aa27c769af6a3b7f7cfd475a35c484da704fcbd7c8cda3a14e7\n",
            "  Stored in directory: /root/.cache/pip/wheels/78/a4/c0/fb0a7ef03cff161611c3fa40c6cf898f76e58ec421b88e8cb3\n",
            "Successfully built detectron2 fvcore antlr4-python3-runtime fairscale\n",
            "Installing collected packages: antlr4-python3-runtime, yacs, portalocker, pathspec, omegaconf, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, mypy-extensions, nvidia-cusparse-cu12, nvidia-cudnn-cu12, iopath, hydra-core, black, nvidia-cusolver-cu12, fvcore, fairscale, timm, detectron2\n",
            "Successfully installed antlr4-python3-runtime-4.9.3 black-22.3.0 detectron2-0.6 fairscale-0.4.13 fvcore-0.1.5.post20221221 hydra-core-1.3.2 iopath-0.1.9 mypy-extensions-1.0.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 omegaconf-2.3.0 pathspec-0.12.1 portalocker-2.8.2 timm-0.9.16 yacs-0.1.8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pydevd_plugins"
                ]
              },
              "id": "25c231c423be4c7fbeff493898ebe8a7"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/aim-uofa/AdelaiDet.git\n",
        "%cd AdelaiDet\n",
        "!python setup.py build develop"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DBlcXLLaPGqd",
        "outputId": "53eeb5bb-f7ef-4fc8-d997-f8aff41d5ba6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'AdelaiDet'...\n",
            "remote: Enumerating objects: 2412, done.\u001b[K\n",
            "remote: Counting objects: 100% (95/95), done.\u001b[K\n",
            "remote: Compressing objects: 100% (67/67), done.\u001b[K\n",
            "remote: Total 2412 (delta 43), reused 60 (delta 28), pack-reused 2317\u001b[K\n",
            "Receiving objects: 100% (2412/2412), 673.96 KiB | 5.81 MiB/s, done.\n",
            "Resolving deltas: 100% (1476/1476), done.\n",
            "/content/AdelaiDet\n",
            "running build\n",
            "running build_py\n",
            "creating build\n",
            "creating build/lib.linux-x86_64-cpython-310\n",
            "creating build/lib.linux-x86_64-cpython-310/adet\n",
            "copying adet/__init__.py -> build/lib.linux-x86_64-cpython-310/adet\n",
            "creating build/lib.linux-x86_64-cpython-310/adet/checkpoint\n",
            "copying adet/checkpoint/adet_checkpoint.py -> build/lib.linux-x86_64-cpython-310/adet/checkpoint\n",
            "copying adet/checkpoint/__init__.py -> build/lib.linux-x86_64-cpython-310/adet/checkpoint\n",
            "creating build/lib.linux-x86_64-cpython-310/adet/utils\n",
            "copying adet/utils/comm.py -> build/lib.linux-x86_64-cpython-310/adet/utils\n",
            "copying adet/utils/measures.py -> build/lib.linux-x86_64-cpython-310/adet/utils\n",
            "copying adet/utils/__init__.py -> build/lib.linux-x86_64-cpython-310/adet/utils\n",
            "copying adet/utils/visualizer.py -> build/lib.linux-x86_64-cpython-310/adet/utils\n",
            "creating build/lib.linux-x86_64-cpython-310/adet/layers\n",
            "copying adet/layers/conv_with_kaiming_uniform.py -> build/lib.linux-x86_64-cpython-310/adet/layers\n",
            "copying adet/layers/gcn.py -> build/lib.linux-x86_64-cpython-310/adet/layers\n",
            "copying adet/layers/ml_nms.py -> build/lib.linux-x86_64-cpython-310/adet/layers\n",
            "copying adet/layers/iou_loss.py -> build/lib.linux-x86_64-cpython-310/adet/layers\n",
            "copying adet/layers/deform_conv.py -> build/lib.linux-x86_64-cpython-310/adet/layers\n",
            "copying adet/layers/bezier_align.py -> build/lib.linux-x86_64-cpython-310/adet/layers\n",
            "copying adet/layers/def_roi_align.py -> build/lib.linux-x86_64-cpython-310/adet/layers\n",
            "copying adet/layers/__init__.py -> build/lib.linux-x86_64-cpython-310/adet/layers\n",
            "copying adet/layers/naive_group_norm.py -> build/lib.linux-x86_64-cpython-310/adet/layers\n",
            "creating build/lib.linux-x86_64-cpython-310/adet/modeling\n",
            "copying adet/modeling/one_stage_detector.py -> build/lib.linux-x86_64-cpython-310/adet/modeling\n",
            "copying adet/modeling/poolers.py -> build/lib.linux-x86_64-cpython-310/adet/modeling\n",
            "copying adet/modeling/__init__.py -> build/lib.linux-x86_64-cpython-310/adet/modeling\n",
            "creating build/lib.linux-x86_64-cpython-310/adet/config\n",
            "copying adet/config/config.py -> build/lib.linux-x86_64-cpython-310/adet/config\n",
            "copying adet/config/defaults.py -> build/lib.linux-x86_64-cpython-310/adet/config\n",
            "copying adet/config/__init__.py -> build/lib.linux-x86_64-cpython-310/adet/config\n",
            "creating build/lib.linux-x86_64-cpython-310/adet/structures\n",
            "copying adet/structures/beziers.py -> build/lib.linux-x86_64-cpython-310/adet/structures\n",
            "copying adet/structures/__init__.py -> build/lib.linux-x86_64-cpython-310/adet/structures\n",
            "creating build/lib.linux-x86_64-cpython-310/adet/data\n",
            "copying adet/data/dataset_mapper.py -> build/lib.linux-x86_64-cpython-310/adet/data\n",
            "copying adet/data/fcpose_dataset_mapper.py -> build/lib.linux-x86_64-cpython-310/adet/data\n",
            "copying adet/data/augmentation.py -> build/lib.linux-x86_64-cpython-310/adet/data\n",
            "copying adet/data/builtin.py -> build/lib.linux-x86_64-cpython-310/adet/data\n",
            "copying adet/data/detection_utils.py -> build/lib.linux-x86_64-cpython-310/adet/data\n",
            "copying adet/data/__init__.py -> build/lib.linux-x86_64-cpython-310/adet/data\n",
            "creating build/lib.linux-x86_64-cpython-310/adet/evaluation\n",
            "copying adet/evaluation/rrc_evaluation_funcs.py -> build/lib.linux-x86_64-cpython-310/adet/evaluation\n",
            "copying adet/evaluation/text_eval_script_ic15.py -> build/lib.linux-x86_64-cpython-310/adet/evaluation\n",
            "copying adet/evaluation/rrc_evaluation_funcs_ic15.py -> build/lib.linux-x86_64-cpython-310/adet/evaluation\n",
            "copying adet/evaluation/text_eval_script.py -> build/lib.linux-x86_64-cpython-310/adet/evaluation\n",
            "copying adet/evaluation/text_evaluation_all.py -> build/lib.linux-x86_64-cpython-310/adet/evaluation\n",
            "copying adet/evaluation/__init__.py -> build/lib.linux-x86_64-cpython-310/adet/evaluation\n",
            "creating build/lib.linux-x86_64-cpython-310/adet/modeling/batext\n",
            "copying adet/modeling/batext/batext.py -> build/lib.linux-x86_64-cpython-310/adet/modeling/batext\n",
            "copying adet/modeling/batext/batext_outputs.py -> build/lib.linux-x86_64-cpython-310/adet/modeling/batext\n",
            "copying adet/modeling/batext/__init__.py -> build/lib.linux-x86_64-cpython-310/adet/modeling/batext\n",
            "creating build/lib.linux-x86_64-cpython-310/adet/modeling/fcpose\n",
            "copying adet/modeling/fcpose/fcpose_head.py -> build/lib.linux-x86_64-cpython-310/adet/modeling/fcpose\n",
            "copying adet/modeling/fcpose/fcpose_framework.py -> build/lib.linux-x86_64-cpython-310/adet/modeling/fcpose\n",
            "copying adet/modeling/fcpose/basis_module.py -> build/lib.linux-x86_64-cpython-310/adet/modeling/fcpose\n",
            "copying adet/modeling/fcpose/utils.py -> build/lib.linux-x86_64-cpython-310/adet/modeling/fcpose\n",
            "copying adet/modeling/fcpose/__init__.py -> build/lib.linux-x86_64-cpython-310/adet/modeling/fcpose\n",
            "creating build/lib.linux-x86_64-cpython-310/adet/modeling/blendmask\n",
            "copying adet/modeling/blendmask/blendmask.py -> build/lib.linux-x86_64-cpython-310/adet/modeling/blendmask\n",
            "copying adet/modeling/blendmask/basis_module.py -> build/lib.linux-x86_64-cpython-310/adet/modeling/blendmask\n",
            "copying adet/modeling/blendmask/__init__.py -> build/lib.linux-x86_64-cpython-310/adet/modeling/blendmask\n",
            "copying adet/modeling/blendmask/blender.py -> build/lib.linux-x86_64-cpython-310/adet/modeling/blendmask\n",
            "creating build/lib.linux-x86_64-cpython-310/adet/modeling/condinst\n",
            "copying adet/modeling/condinst/dynamic_mask_head.py -> build/lib.linux-x86_64-cpython-310/adet/modeling/condinst\n",
            "copying adet/modeling/condinst/mask_branch.py -> build/lib.linux-x86_64-cpython-310/adet/modeling/condinst\n",
            "copying adet/modeling/condinst/condinst.py -> build/lib.linux-x86_64-cpython-310/adet/modeling/condinst\n",
            "copying adet/modeling/condinst/__init__.py -> build/lib.linux-x86_64-cpython-310/adet/modeling/condinst\n",
            "creating build/lib.linux-x86_64-cpython-310/adet/modeling/backbone\n",
            "copying adet/modeling/backbone/resnet_interval.py -> build/lib.linux-x86_64-cpython-310/adet/modeling/backbone\n",
            "copying adet/modeling/backbone/resnet_lpf.py -> build/lib.linux-x86_64-cpython-310/adet/modeling/backbone\n",
            "copying adet/modeling/backbone/mobilenet.py -> build/lib.linux-x86_64-cpython-310/adet/modeling/backbone\n",
            "copying adet/modeling/backbone/bifpn.py -> build/lib.linux-x86_64-cpython-310/adet/modeling/backbone\n",
            "copying adet/modeling/backbone/dla.py -> build/lib.linux-x86_64-cpython-310/adet/modeling/backbone\n",
            "copying adet/modeling/backbone/fpn.py -> build/lib.linux-x86_64-cpython-310/adet/modeling/backbone\n",
            "copying adet/modeling/backbone/__init__.py -> build/lib.linux-x86_64-cpython-310/adet/modeling/backbone\n",
            "copying adet/modeling/backbone/vovnet.py -> build/lib.linux-x86_64-cpython-310/adet/modeling/backbone\n",
            "copying adet/modeling/backbone/lpf.py -> build/lib.linux-x86_64-cpython-310/adet/modeling/backbone\n",
            "creating build/lib.linux-x86_64-cpython-310/adet/modeling/solov2\n",
            "copying adet/modeling/solov2/solov2.py -> build/lib.linux-x86_64-cpython-310/adet/modeling/solov2\n",
            "copying adet/modeling/solov2/utils.py -> build/lib.linux-x86_64-cpython-310/adet/modeling/solov2\n",
            "copying adet/modeling/solov2/loss.py -> build/lib.linux-x86_64-cpython-310/adet/modeling/solov2\n",
            "copying adet/modeling/solov2/__init__.py -> build/lib.linux-x86_64-cpython-310/adet/modeling/solov2\n",
            "creating build/lib.linux-x86_64-cpython-310/adet/modeling/fcos\n",
            "copying adet/modeling/fcos/fcos_outputs.py -> build/lib.linux-x86_64-cpython-310/adet/modeling/fcos\n",
            "copying adet/modeling/fcos/fcos.py -> build/lib.linux-x86_64-cpython-310/adet/modeling/fcos\n",
            "copying adet/modeling/fcos/__init__.py -> build/lib.linux-x86_64-cpython-310/adet/modeling/fcos\n",
            "creating build/lib.linux-x86_64-cpython-310/adet/modeling/roi_heads\n",
            "copying adet/modeling/roi_heads/text_head.py -> build/lib.linux-x86_64-cpython-310/adet/modeling/roi_heads\n",
            "copying adet/modeling/roi_heads/attn_predictor.py -> build/lib.linux-x86_64-cpython-310/adet/modeling/roi_heads\n",
            "copying adet/modeling/roi_heads/__init__.py -> build/lib.linux-x86_64-cpython-310/adet/modeling/roi_heads\n",
            "creating build/lib.linux-x86_64-cpython-310/adet/modeling/MEInst\n",
            "copying adet/modeling/MEInst/MEInst.py -> build/lib.linux-x86_64-cpython-310/adet/modeling/MEInst\n",
            "copying adet/modeling/MEInst/MEInst_outputs.py -> build/lib.linux-x86_64-cpython-310/adet/modeling/MEInst\n",
            "copying adet/modeling/MEInst/MaskEncoding.py -> build/lib.linux-x86_64-cpython-310/adet/modeling/MEInst\n",
            "copying adet/modeling/MEInst/__init__.py -> build/lib.linux-x86_64-cpython-310/adet/modeling/MEInst\n",
            "creating build/lib.linux-x86_64-cpython-310/adet/modeling/MEInst/LME\n",
            "copying adet/modeling/MEInst/LME/mask_generation.py -> build/lib.linux-x86_64-cpython-310/adet/modeling/MEInst/LME\n",
            "copying adet/modeling/MEInst/LME/mask_evaluation.py -> build/lib.linux-x86_64-cpython-310/adet/modeling/MEInst/LME\n",
            "copying adet/modeling/MEInst/LME/MaskLoader.py -> build/lib.linux-x86_64-cpython-310/adet/modeling/MEInst/LME\n",
            "copying adet/modeling/MEInst/LME/utils.py -> build/lib.linux-x86_64-cpython-310/adet/modeling/MEInst/LME\n",
            "copying adet/modeling/MEInst/LME/__init__.py -> build/lib.linux-x86_64-cpython-310/adet/modeling/MEInst/LME\n",
            "running build_ext\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py:500: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n",
            "  warnings.warn(msg.format('we could not find ninja.'))\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py:415: UserWarning: The detected CUDA version (12.2) has a minor version mismatch with the version that was used to compile PyTorch (12.1). Most likely this shouldn't be a problem.\n",
            "  warnings.warn(CUDA_MISMATCH_WARN.format(cuda_str_version, torch.version.cuda))\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py:425: UserWarning: There are no x86_64-linux-gnu-g++ version bounds defined for CUDA version 12.2\n",
            "  warnings.warn(f'There are no {compiler_name} version bounds defined for CUDA version {cuda_str_version}')\n",
            "building 'adet._C' extension\n",
            "creating build/temp.linux-x86_64-cpython-310\n",
            "creating build/temp.linux-x86_64-cpython-310/content\n",
            "creating build/temp.linux-x86_64-cpython-310/content/AdelaiDet\n",
            "creating build/temp.linux-x86_64-cpython-310/content/AdelaiDet/adet\n",
            "creating build/temp.linux-x86_64-cpython-310/content/AdelaiDet/adet/layers\n",
            "creating build/temp.linux-x86_64-cpython-310/content/AdelaiDet/adet/layers/csrc\n",
            "creating build/temp.linux-x86_64-cpython-310/content/AdelaiDet/adet/layers/csrc/BezierAlign\n",
            "creating build/temp.linux-x86_64-cpython-310/content/AdelaiDet/adet/layers/csrc/DefROIAlign\n",
            "creating build/temp.linux-x86_64-cpython-310/content/AdelaiDet/adet/layers/csrc/ml_nms\n",
            "x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -DWITH_CUDA -I/content/AdelaiDet/adet/layers/csrc -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.10 -c /content/AdelaiDet/adet/layers/csrc/BezierAlign/BezierAlign_cpu.cpp -o build/temp.linux-x86_64-cpython-310/content/AdelaiDet/adet/layers/csrc/BezierAlign/BezierAlign_cpu.o -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
            "In file included from \u001b[01m\u001b[K/content/AdelaiDet/adet/layers/csrc/BezierAlign/BezierAlign_cpu.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/content/AdelaiDet/adet/layers/csrc/BezierAlign/BezierAlign.h:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kat::Tensor adet::BezierAlign_forward(const at::Tensor&, const at::Tensor&, float, int, int, int, bool)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K/content/AdelaiDet/adet/layers/csrc/BezierAlign/BezierAlign.h:62:17:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   62 |   if (\u001b[01;35m\u001b[Kinput.type()\u001b[m\u001b[K.is_cuda()) {\n",
            "      |       \u001b[01;35m\u001b[K~~~~~~~~~~^~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/TensorUtils.h:5\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/AdelaiDet/adet/layers/csrc/BezierAlign/BezierAlign_cpu.cpp:2\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:225:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  225 |   DeprecatedTypeProperties & \u001b[01;36m\u001b[Ktype\u001b[m\u001b[K() const {\n",
            "      |                              \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/content/AdelaiDet/adet/layers/csrc/BezierAlign/BezierAlign_cpu.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/content/AdelaiDet/adet/layers/csrc/BezierAlign/BezierAlign.h:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kat::Tensor adet::BezierAlign_backward(const at::Tensor&, const at::Tensor&, float, int, int, int, int, int, int, int, bool)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K/content/AdelaiDet/adet/layers/csrc/BezierAlign/BezierAlign.h:98:16:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   98 |   if (\u001b[01;35m\u001b[Kgrad.type()\u001b[m\u001b[K.is_cuda()) {\n",
            "      |       \u001b[01;35m\u001b[K~~~~~~~~~^~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/TensorUtils.h:5\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/AdelaiDet/adet/layers/csrc/BezierAlign/BezierAlign_cpu.cpp:2\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:225:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  225 |   DeprecatedTypeProperties & \u001b[01;36m\u001b[Ktype\u001b[m\u001b[K() const {\n",
            "      |                              \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/ATen.h:11\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/AdelaiDet/adet/layers/csrc/BezierAlign/BezierAlign.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/AdelaiDet/adet/layers/csrc/BezierAlign/BezierAlign_cpu.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/content/AdelaiDet/adet/layers/csrc/BezierAlign/BezierAlign_cpu.cpp:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[K/content/AdelaiDet/adet/layers/csrc/BezierAlign/BezierAlign_cpu.cpp:493:49:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  493 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\u001b[01;35m\u001b[Kinput.type()\u001b[m\u001b[K, \"BezierAlign_forward\", [&] {\n",
            "      |                                       \u001b[01;35m\u001b[K~~~~~~~~~~^~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:215:28:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro ‘\u001b[01m\u001b[KAT_DISPATCH_SWITCH\u001b[m\u001b[K’\n",
            "  215 |     const auto& the_type = \u001b[01;36m\u001b[KTYPE\u001b[m\u001b[K;                                            \\\n",
            "      |                            \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/AdelaiDet/adet/layers/csrc/BezierAlign/BezierAlign_cpu.cpp:493:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_DISPATCH_FLOATING_TYPES_AND_HALF\u001b[m\u001b[K’\n",
            "  493 |   \u001b[01;36m\u001b[KAT_DISPATCH_FLOATING_TYPES_AND_HALF\u001b[m\u001b[K(input.type(), \"BezierAlign_forward\", [&] {\n",
            "      |   \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/TensorUtils.h:5\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/AdelaiDet/adet/layers/csrc/BezierAlign/BezierAlign_cpu.cpp:2\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:225:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  225 |   DeprecatedTypeProperties & \u001b[01;36m\u001b[Ktype\u001b[m\u001b[K() const {\n",
            "      |                              \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/ATen.h:11\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/AdelaiDet/adet/layers/csrc/BezierAlign/BezierAlign.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/AdelaiDet/adet/layers/csrc/BezierAlign/BezierAlign_cpu.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:218:47:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kc10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)\u001b[m\u001b[K’ is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  218 |     at::ScalarType _st = \u001b[01;35m\u001b[K::detail::scalar_type(the_type)\u001b[m\u001b[K;                   \\\n",
            "      |                          \u001b[01;35m\u001b[K~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:245:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_DISPATCH_SWITCH\u001b[m\u001b[K’\n",
            "  245 |   \u001b[01;36m\u001b[KAT_DISPATCH_SWITCH\u001b[m\u001b[K(                                        \\\n",
            "      |   \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/AdelaiDet/adet/layers/csrc/BezierAlign/BezierAlign_cpu.cpp:493:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_DISPATCH_FLOATING_TYPES_AND_HALF\u001b[m\u001b[K’\n",
            "  493 |   \u001b[01;36m\u001b[KAT_DISPATCH_FLOATING_TYPES_AND_HALF\u001b[m\u001b[K(input.type(), \"BezierAlign_forward\", [&] {\n",
            "      |   \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:109:23:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  109 | inline at::ScalarType \u001b[01;36m\u001b[Kscalar_type\u001b[m\u001b[K(const at::DeprecatedTypeProperties& t) {\n",
            "      |                       \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/AdelaiDet/adet/layers/csrc/BezierAlign/BezierAlign_cpu.cpp:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[K/content/AdelaiDet/adet/layers/csrc/BezierAlign/BezierAlign_cpu.cpp:545:48:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  545 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\u001b[01;35m\u001b[Kgrad.type()\u001b[m\u001b[K, \"BezierAlign_forward\", [&] {\n",
            "      |                                       \u001b[01;35m\u001b[K~~~~~~~~~^~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:215:28:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro ‘\u001b[01m\u001b[KAT_DISPATCH_SWITCH\u001b[m\u001b[K’\n",
            "  215 |     const auto& the_type = \u001b[01;36m\u001b[KTYPE\u001b[m\u001b[K;                                            \\\n",
            "      |                            \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/AdelaiDet/adet/layers/csrc/BezierAlign/BezierAlign_cpu.cpp:545:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_DISPATCH_FLOATING_TYPES_AND_HALF\u001b[m\u001b[K’\n",
            "  545 |   \u001b[01;36m\u001b[KAT_DISPATCH_FLOATING_TYPES_AND_HALF\u001b[m\u001b[K(grad.type(), \"BezierAlign_forward\", [&] {\n",
            "      |   \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/TensorUtils.h:5\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/AdelaiDet/adet/layers/csrc/BezierAlign/BezierAlign_cpu.cpp:2\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:225:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  225 |   DeprecatedTypeProperties & \u001b[01;36m\u001b[Ktype\u001b[m\u001b[K() const {\n",
            "      |                              \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/ATen.h:11\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/AdelaiDet/adet/layers/csrc/BezierAlign/BezierAlign.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/AdelaiDet/adet/layers/csrc/BezierAlign/BezierAlign_cpu.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:218:47:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kc10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)\u001b[m\u001b[K’ is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  218 |     at::ScalarType _st = \u001b[01;35m\u001b[K::detail::scalar_type(the_type)\u001b[m\u001b[K;                   \\\n",
            "      |                          \u001b[01;35m\u001b[K~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:245:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_DISPATCH_SWITCH\u001b[m\u001b[K’\n",
            "  245 |   \u001b[01;36m\u001b[KAT_DISPATCH_SWITCH\u001b[m\u001b[K(                                        \\\n",
            "      |   \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/AdelaiDet/adet/layers/csrc/BezierAlign/BezierAlign_cpu.cpp:545:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_DISPATCH_FLOATING_TYPES_AND_HALF\u001b[m\u001b[K’\n",
            "  545 |   \u001b[01;36m\u001b[KAT_DISPATCH_FLOATING_TYPES_AND_HALF\u001b[m\u001b[K(grad.type(), \"BezierAlign_forward\", [&] {\n",
            "      |   \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:109:23:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  109 | inline at::ScalarType \u001b[01;36m\u001b[Kscalar_type\u001b[m\u001b[K(const at::DeprecatedTypeProperties& t) {\n",
            "      |                       \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
            "/content/AdelaiDet/adet/layers/csrc/BezierAlign/BezierAlign_cpu.cpp: In instantiation of ‘\u001b[01m\u001b[Kvoid {anonymous}::BezierAlignForward(int, const T*, const T&, int, int, int, int, int, int, const T*, T*, bool) [with T = double]\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K/content/AdelaiDet/adet/layers/csrc/BezierAlign/BezierAlign_cpu.cpp:493:3:\u001b[m\u001b[K   required from here\n",
            "\u001b[01m\u001b[K/content/AdelaiDet/adet/layers/csrc/BezierAlign/BezierAlign_cpu.cpp:168:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Koffset\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wunused-variable\u0007-Wunused-variable\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  168 |     T \u001b[01;35m\u001b[Koffset\u001b[m\u001b[K = aligned ? (T)0.5 : (T)0.0;\n",
            "      |       \u001b[01;35m\u001b[K^~~~~~\u001b[m\u001b[K\n",
            "/content/AdelaiDet/adet/layers/csrc/BezierAlign/BezierAlign_cpu.cpp: In instantiation of ‘\u001b[01m\u001b[Kvoid {anonymous}::BezierAlignForward(int, const T*, const T&, int, int, int, int, int, int, const T*, T*, bool) [with T = float]\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K/content/AdelaiDet/adet/layers/csrc/BezierAlign/BezierAlign_cpu.cpp:493:3:\u001b[m\u001b[K   required from here\n",
            "\u001b[01m\u001b[K/content/AdelaiDet/adet/layers/csrc/BezierAlign/BezierAlign_cpu.cpp:168:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Koffset\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wunused-variable\u0007-Wunused-variable\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "/content/AdelaiDet/adet/layers/csrc/BezierAlign/BezierAlign_cpu.cpp: In instantiation of ‘\u001b[01m\u001b[Kvoid {anonymous}::BezierAlignForward(int, const T*, const T&, int, int, int, int, int, int, const T*, T*, bool) [with T = c10::Half]\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K/content/AdelaiDet/adet/layers/csrc/BezierAlign/BezierAlign_cpu.cpp:493:3:\u001b[m\u001b[K   required from here\n",
            "\u001b[01m\u001b[K/content/AdelaiDet/adet/layers/csrc/BezierAlign/BezierAlign_cpu.cpp:168:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kvariable ‘\u001b[01m\u001b[Koffset\u001b[m\u001b[K’ set but not used [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wunused-but-set-variable\u0007-Wunused-but-set-variable\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "/usr/local/cuda/bin/nvcc -DWITH_CUDA -I/content/AdelaiDet/adet/layers/csrc -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.10 -c /content/AdelaiDet/adet/layers/csrc/BezierAlign/BezierAlign_cuda.cu -o build/temp.linux-x86_64-cpython-310/content/AdelaiDet/adet/layers/csrc/BezierAlign/BezierAlign_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -DCUDA_HAS_FP16=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++17\n",
            "/usr/local/cuda/bin/nvcc -DWITH_CUDA -I/content/AdelaiDet/adet/layers/csrc -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.10 -c /content/AdelaiDet/adet/layers/csrc/DefROIAlign/DefROIAlign_cuda.cu -o build/temp.linux-x86_64-cpython-310/content/AdelaiDet/adet/layers/csrc/DefROIAlign/DefROIAlign_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -DCUDA_HAS_FP16=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++17\n",
            "/usr/local/cuda/bin/nvcc -DWITH_CUDA -I/content/AdelaiDet/adet/layers/csrc -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.10 -c /content/AdelaiDet/adet/layers/csrc/cuda_version.cu -o build/temp.linux-x86_64-cpython-310/content/AdelaiDet/adet/layers/csrc/cuda_version.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -DCUDA_HAS_FP16=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++17\n",
            "/usr/local/cuda/bin/nvcc -DWITH_CUDA -I/content/AdelaiDet/adet/layers/csrc -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.10 -c /content/AdelaiDet/adet/layers/csrc/ml_nms/ml_nms.cu -o build/temp.linux-x86_64-cpython-310/content/AdelaiDet/adet/layers/csrc/ml_nms/ml_nms.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -DCUDA_HAS_FP16=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++17\n",
            "\u001b[01m\u001b[K/content/AdelaiDet/adet/layers/csrc/ml_nms/ml_nms.cu:4:10:\u001b[m\u001b[K \u001b[01;31m\u001b[Kfatal error: \u001b[m\u001b[KTHC/THC.h: No such file or directory\n",
            "    4 | #include \u001b[01;31m\u001b[K<THC/THC.h>\u001b[m\u001b[K\n",
            "      |          \u001b[01;31m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
            "compilation terminated.\n",
            "error: command '/usr/local/cuda/bin/nvcc' failed with exit code 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/\n",
        "!git clone https://github.com/DomMcOyle/TACO-expl.git\n",
        "%cd /content/TACO-expl\n",
        "!git checkout maskdino\n",
        "!git pull origin maskdino\n",
        "#%cd /content/TACO-expl/MaskDINO\n",
        "#!pip install -r requirements.txt\n",
        "#%cd /content/TACO-expl/MaskDINO/maskdino/modeling/pixel_decoder/ops\n",
        "#!sh make.sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X9P0HDTGnRDI",
        "outputId": "b24df389-4653-4fb1-c5f9-219d88e3c3c8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'TACO-expl'...\n",
            "remote: Enumerating objects: 1973, done.\u001b[K\n",
            "remote: Counting objects: 100% (1398/1398), done.\u001b[K\n",
            "remote: Compressing objects: 100% (784/784), done.\u001b[K\n",
            "remote: Total 1973 (delta 697), reused 1288 (delta 597), pack-reused 575\u001b[K\n",
            "Receiving objects: 100% (1973/1973), 122.51 MiB | 21.48 MiB/s, done.\n",
            "Resolving deltas: 100% (1070/1070), done.\n",
            "/content/TACO-expl\n",
            "Branch 'maskdino' set up to track remote branch 'maskdino' from 'origin'.\n",
            "Switched to a new branch 'maskdino'\n",
            "From https://github.com/DomMcOyle/TACO-expl\n",
            " * branch            maskdino   -> FETCH_HEAD\n",
            "Already up to date.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rapidfuzz==2.15.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "v1kqCskPxLoY",
        "outputId": "b22bdcc3-d99e-44fa-e97f-c980a92e997b"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rapidfuzz==2.15.1\n",
            "  Downloading rapidfuzz-2.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rapidfuzz\n",
            "  Attempting uninstall: rapidfuzz\n",
            "    Found existing installation: rapidfuzz 3.9.0\n",
            "    Uninstalling rapidfuzz-3.9.0:\n",
            "      Successfully uninstalled rapidfuzz-3.9.0\n",
            "Successfully installed rapidfuzz-2.15.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "rapidfuzz"
                ]
              },
              "id": "4558ed75f3f64162b685871d8ff9c9ae"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/MyDrive/\", force_remount = True)"
      ],
      "metadata": {
        "id": "yKG8tycQnkyb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c102040c-b1b0-4fc7-d6fb-ed0ba235b995"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/MyDrive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, detectron2\n",
        "!nvcc --version\n",
        "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
        "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
        "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
        "print(\"detectron2:\", detectron2.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJ444LmfnVe7",
        "outputId": "d23e89c5-415b-4baf-9261-bbf31ecdfb62"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2023 NVIDIA Corporation\n",
            "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
            "Cuda compilation tools, release 12.2, V12.2.140\n",
            "Build cuda_12.2.r12.2/compiler.33191640_0\n",
            "torch:  2.2 ; cuda:  cu121\n",
            "detectron2: 0.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Some basic setup:\n",
        "# Setup detectron2 logger\n",
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "\n",
        "# import some common libraries\n",
        "import numpy as np\n",
        "import os, json, cv2, random\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# import some common detectron2 utilities\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog, DatasetCatalog"
      ],
      "metadata": {
        "id": "LfdhgozHnZpe"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append(\"/content/TACO-expl/MaskDINO\")\n",
        "!cd /content/TACO-expl/MaskDINO/\n",
        "cfg_biggest_path = '/content/TACO-expl/MaskDINO/configs/coco/instance-segmentation/swin/maskdino_R50_bs16_50ep_4s_dowsample1_2048.yaml'\n",
        "model_biggest_weights_url = 'https://github.com/IDEA-Research/detrex-storage/releases/download/maskdino-v0.1.0/maskdino_swinl_50ep_300q_hid2048_3sd1_instance_maskenhanced_mask52.3ap_box59.0ap.pth'\n",
        "\n",
        "cfg_smallest_path = '/content/TACO-expl/MaskDINO/configs/coco/instance-segmentation/maskdino_R50_bs16_50ep_3s.yaml'\n",
        "model_smallest_weight_url = 'https://github.com/IDEA-Research/detrex-storage/releases/download/maskdino-v0.1.0/maskdino_r50_50ep_300q_hid1024_3sd1_instance_maskenhanced_mask46.1ap_box51.5ap.pth'\n",
        "\n",
        "cfg_solo_base_path = '/content/AdelaiDet/configs/SOLOv2/Base-SOLOv2.yaml'\n",
        "cfg_solo_r50_path = '/content/AdelaiDet/configs/SOLOv2/R50_3x.yaml'"
      ],
      "metadata": {
        "id": "tAagzHqSncrP"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "sys.path.append('/content/TACO-expl/MaskDINO/maskdino/')\n",
        "from config import add_maskdino_config\n",
        "%cd /content/TACO-expl/MaskDINO/maskdino/\n",
        "from detectron2.projects.deeplab import add_deeplab_config\n",
        "from maskdino import MaskDINO\n",
        "\n",
        "def setup_cfg(cfg_path, weights_url):\n",
        "    # load config from file and command-line arguments\n",
        "    cfg = get_cfg()\n",
        "    add_deeplab_config(cfg)\n",
        "    add_maskdino_config(cfg)\n",
        "    cfg.merge_from_file(cfg_path)\n",
        "    #cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5\n",
        "    #cfg.MODEL.RETINANET.SCORE_THRESH_TEST = 0.5\n",
        "    cfg.MODEL.WEIGHTS = weights_url\n",
        "    cfg.freeze()\n",
        "    return cfg\n",
        "\n",
        "cfg_alt_dino = setup_cfg(cfg_smallest_path, model_smallest_weight_url)\n",
        "cfg_modified = cfg_alt_dino.copy()\n",
        "print(cfg_modified[\"MODEL\"])\n",
        "\"\"\"\n",
        "import sys\n",
        "sys.path.append('/content/AdelaiDet/adet/config')\n",
        "from defaults import _C\n",
        "\n",
        "def setup_cfg(cfg_base, cfg_backbone):\n",
        "  cfg = _C\n",
        "  cfg.merge_from_file(cfg_base)\n",
        "  cfg.merge_from_file(cfg_backbone)\n",
        "  return cfg\n",
        "\n",
        "cfg_solov2 = setup_cfg(cfg_solo_base_path, cfg_solo_r50_path)\n",
        "print(cfg_solov2)\n",
        "#print(_C)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xFqN2ogZngcc",
        "outputId": "998a1f5d-3ca7-4f8b-95a5-7a1122d3c098"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDNN_BENCHMARK: False\n",
            "DATALOADER:\n",
            "  ASPECT_RATIO_GROUPING: True\n",
            "  FILTER_EMPTY_ANNOTATIONS: True\n",
            "  NUM_WORKERS: 4\n",
            "  REPEAT_THRESHOLD: 0.0\n",
            "  SAMPLER_TRAIN: TrainingSampler\n",
            "DATASETS:\n",
            "  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000\n",
            "  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000\n",
            "  PROPOSAL_FILES_TEST: ()\n",
            "  PROPOSAL_FILES_TRAIN: ()\n",
            "  TEST: ('coco_2017_val',)\n",
            "  TRAIN: ('coco_2017_train',)\n",
            "GLOBAL:\n",
            "  HACK: 1.0\n",
            "INPUT:\n",
            "  CROP:\n",
            "    CROP_INSTANCE: True\n",
            "    ENABLED: False\n",
            "    SIZE: [0.9, 0.9]\n",
            "    TYPE: relative_range\n",
            "  FORMAT: BGR\n",
            "  HFLIP_TRAIN: True\n",
            "  IS_ROTATE: False\n",
            "  MASK_FORMAT: bitmask\n",
            "  MAX_SIZE_TEST: 1333\n",
            "  MAX_SIZE_TRAIN: 1333\n",
            "  MIN_SIZE_TEST: 800\n",
            "  MIN_SIZE_TRAIN: (640, 672, 704, 736, 768, 800)\n",
            "  MIN_SIZE_TRAIN_SAMPLING: choice\n",
            "  RANDOM_FLIP: horizontal\n",
            "MODEL:\n",
            "  ANCHOR_GENERATOR:\n",
            "    ANGLES: [[-90, 0, 90]]\n",
            "    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]\n",
            "    NAME: DefaultAnchorGenerator\n",
            "    OFFSET: 0.0\n",
            "    SIZES: [[32, 64, 128, 256, 512]]\n",
            "  BACKBONE:\n",
            "    ANTI_ALIAS: False\n",
            "    FREEZE_AT: 2\n",
            "    NAME: build_resnet_fpn_backbone\n",
            "  BASIS_MODULE:\n",
            "    ANN_SET: coco\n",
            "    COMMON_STRIDE: 8\n",
            "    CONVS_DIM: 128\n",
            "    IN_FEATURES: ['p3', 'p4', 'p5']\n",
            "    LOSS_ON: False\n",
            "    LOSS_WEIGHT: 0.3\n",
            "    NAME: ProtoNet\n",
            "    NORM: SyncBN\n",
            "    NUM_BASES: 4\n",
            "    NUM_CLASSES: 80\n",
            "    NUM_CONVS: 3\n",
            "  BATEXT:\n",
            "    CANONICAL_SIZE: 96\n",
            "    CONV_DIM: 256\n",
            "    CUSTOM_DICT: \n",
            "    EVAL_TYPE: 3\n",
            "    IN_FEATURES: ['p2', 'p3', 'p4']\n",
            "    NUM_CHARS: 25\n",
            "    NUM_CONV: 2\n",
            "    POOLER_RESOLUTION: (8, 32)\n",
            "    POOLER_SCALES: (0.25, 0.125, 0.0625)\n",
            "    RECOGNITION_LOSS: ctc\n",
            "    RECOGNIZER: attn\n",
            "    SAMPLING_RATIO: 1\n",
            "    USE_AET: False\n",
            "    USE_COORDCONV: False\n",
            "    VOC_SIZE: 96\n",
            "  BLENDMASK:\n",
            "    ATTN_SIZE: 14\n",
            "    BOTTOM_RESOLUTION: 56\n",
            "    INSTANCE_LOSS_WEIGHT: 1.0\n",
            "    POOLER_SAMPLING_RATIO: 1\n",
            "    POOLER_SCALES: (0.25,)\n",
            "    POOLER_TYPE: ROIAlignV2\n",
            "    TOP_INTERP: bilinear\n",
            "    VISUALIZE: False\n",
            "  BOXINST:\n",
            "    BOTTOM_PIXELS_REMOVED: 10\n",
            "    ENABLED: False\n",
            "    PAIRWISE:\n",
            "      COLOR_THRESH: 0.3\n",
            "      DILATION: 2\n",
            "      SIZE: 3\n",
            "      WARMUP_ITERS: 10000\n",
            "  BiFPN:\n",
            "    IN_FEATURES: ['res2', 'res3', 'res4', 'res5']\n",
            "    NORM: \n",
            "    NUM_REPEATS: 6\n",
            "    OUT_CHANNELS: 160\n",
            "  CONDINST:\n",
            "    BOTTOM_PIXELS_REMOVED: -1\n",
            "    MASK_BRANCH:\n",
            "      CHANNELS: 128\n",
            "      IN_FEATURES: ['p3', 'p4', 'p5']\n",
            "      NORM: BN\n",
            "      NUM_CONVS: 4\n",
            "      OUT_CHANNELS: 8\n",
            "      SEMANTIC_LOSS_ON: False\n",
            "    MASK_HEAD:\n",
            "      CHANNELS: 8\n",
            "      DISABLE_REL_COORDS: False\n",
            "      NUM_LAYERS: 3\n",
            "      USE_FP16: False\n",
            "    MASK_OUT_STRIDE: 4\n",
            "    MAX_PROPOSALS: -1\n",
            "    TOPK_PROPOSALS_PER_IM: -1\n",
            "  DEVICE: cuda\n",
            "  DLA:\n",
            "    CONV_BODY: DLA34\n",
            "    NORM: FrozenBN\n",
            "    OUT_FEATURES: ['stage2', 'stage3', 'stage4', 'stage5']\n",
            "  FCOS:\n",
            "    BOX_QUALITY: ctrness\n",
            "    CENTER_SAMPLE: True\n",
            "    FPN_STRIDES: [8, 16, 32, 64, 128]\n",
            "    INFERENCE_TH_TEST: 0.05\n",
            "    INFERENCE_TH_TRAIN: 0.05\n",
            "    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']\n",
            "    LOC_LOSS_TYPE: giou\n",
            "    LOSS_ALPHA: 0.25\n",
            "    LOSS_GAMMA: 2.0\n",
            "    LOSS_NORMALIZER_CLS: fg\n",
            "    LOSS_WEIGHT_CLS: 1.0\n",
            "    NMS_TH: 0.6\n",
            "    NORM: GN\n",
            "    NUM_BOX_CONVS: 4\n",
            "    NUM_CLASSES: 80\n",
            "    NUM_CLS_CONVS: 4\n",
            "    NUM_SHARE_CONVS: 0\n",
            "    POST_NMS_TOPK_TEST: 100\n",
            "    POST_NMS_TOPK_TRAIN: 100\n",
            "    POS_RADIUS: 1.5\n",
            "    PRE_NMS_TOPK_TEST: 1000\n",
            "    PRE_NMS_TOPK_TRAIN: 1000\n",
            "    PRIOR_PROB: 0.01\n",
            "    SIZES_OF_INTEREST: [64, 128, 256, 512]\n",
            "    THRESH_WITH_CTR: False\n",
            "    TOP_LEVELS: 2\n",
            "    USE_DEFORMABLE: False\n",
            "    USE_RELU: True\n",
            "    USE_SCALE: True\n",
            "    YIELD_BOX_FEATURES: False\n",
            "    YIELD_PROPOSAL: False\n",
            "  FCPOSE:\n",
            "    ATTN_LEN: 2737\n",
            "    BASIS_MODULE:\n",
            "      BN_TYPE: SyncBN\n",
            "      COMMON_STRIDE: 8\n",
            "      CONVS_DIM: 128\n",
            "      LOSS_WEIGHT: 0.2\n",
            "      NUM_BASES: 32\n",
            "      NUM_CLASSES: 17\n",
            "    DISTANCE_NORM: 12.0\n",
            "    DYNAMIC_CHANNELS: 32\n",
            "    FOCAL_LOSS_ALPHA: 0.25\n",
            "    FOCAL_LOSS_GAMMA: 2.0\n",
            "    GT_HEATMAP_STRIDE: 2\n",
            "    HEAD_HEATMAP_SIGMA: 0.01\n",
            "    HEATMAP_SIGMA: 1.8\n",
            "    LOSS_WEIGHT_DIRECTION: 9.0\n",
            "    LOSS_WEIGHT_KEYPOINT: 2.5\n",
            "    MAX_PROPOSALS: 70\n",
            "    PROPOSALS_PER_INST: 70\n",
            "    SIGMA: 1\n",
            "  FCPOSE_ON: False\n",
            "  FPN:\n",
            "    FUSE_TYPE: sum\n",
            "    IN_FEATURES: ['res2', 'res3', 'res4', 'res5']\n",
            "    NORM: \n",
            "    OUT_CHANNELS: 256\n",
            "  KEYPOINT_ON: False\n",
            "  LOAD_PROPOSALS: False\n",
            "  MASK_ON: True\n",
            "  MEInst:\n",
            "    AGNOSTIC: True\n",
            "    CENTER_SAMPLE: True\n",
            "    DIM_MASK: 60\n",
            "    FLAG_PARAMETERS: False\n",
            "    FPN_STRIDES: [8, 16, 32, 64, 128]\n",
            "    GCN_KERNEL_SIZE: 9\n",
            "    INFERENCE_TH_TEST: 0.05\n",
            "    INFERENCE_TH_TRAIN: 0.05\n",
            "    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']\n",
            "    IOU_LABELS: [0, 1]\n",
            "    IOU_THRESHOLDS: [0.5]\n",
            "    LAST_DEFORMABLE: False\n",
            "    LOC_LOSS_TYPE: giou\n",
            "    LOSS_ALPHA: 0.25\n",
            "    LOSS_GAMMA: 2.0\n",
            "    LOSS_ON_MASK: False\n",
            "    MASK_LOSS_TYPE: mse\n",
            "    MASK_ON: True\n",
            "    MASK_SIZE: 28\n",
            "    NMS_TH: 0.6\n",
            "    NORM: GN\n",
            "    NUM_BOX_CONVS: 4\n",
            "    NUM_CLASSES: 80\n",
            "    NUM_CLS_CONVS: 4\n",
            "    NUM_MASK_CONVS: 4\n",
            "    NUM_SHARE_CONVS: 0\n",
            "    PATH_COMPONENTS: datasets/coco/components/coco_2017_train_class_agnosticTrue_whitenTrue_sigmoidTrue_60.npz\n",
            "    POST_NMS_TOPK_TEST: 100\n",
            "    POST_NMS_TOPK_TRAIN: 100\n",
            "    POS_RADIUS: 1.5\n",
            "    PRE_NMS_TOPK_TEST: 1000\n",
            "    PRE_NMS_TOPK_TRAIN: 1000\n",
            "    PRIOR_PROB: 0.01\n",
            "    SIGMOID: True\n",
            "    SIZES_OF_INTEREST: [64, 128, 256, 512]\n",
            "    THRESH_WITH_CTR: False\n",
            "    TOP_LEVELS: 2\n",
            "    TYPE_DEFORMABLE: DCNv1\n",
            "    USE_DEFORMABLE: False\n",
            "    USE_GCN_IN_MASK: False\n",
            "    USE_RELU: True\n",
            "    USE_SCALE: True\n",
            "    WHITEN: True\n",
            "  META_ARCHITECTURE: SOLOv2\n",
            "  MOBILENET: False\n",
            "  PANOPTIC_FPN:\n",
            "    COMBINE:\n",
            "      ENABLED: True\n",
            "      INSTANCES_CONFIDENCE_THRESH: 0.5\n",
            "      OVERLAP_THRESH: 0.5\n",
            "      STUFF_AREA_LIMIT: 4096\n",
            "    INSTANCE_LOSS_WEIGHT: 1.0\n",
            "  PIXEL_MEAN: [103.53, 116.28, 123.675]\n",
            "  PIXEL_STD: [1.0, 1.0, 1.0]\n",
            "  PROPOSAL_GENERATOR:\n",
            "    MIN_SIZE: 0\n",
            "    NAME: RPN\n",
            "  RESNETS:\n",
            "    DEFORM_INTERVAL: 1\n",
            "    DEFORM_MODULATED: False\n",
            "    DEFORM_NUM_GROUPS: 1\n",
            "    DEFORM_ON_PER_STAGE: [False, False, False, False]\n",
            "    DEPTH: 50\n",
            "    NORM: FrozenBN\n",
            "    NUM_GROUPS: 1\n",
            "    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']\n",
            "    RES2_OUT_CHANNELS: 256\n",
            "    RES5_DILATION: 1\n",
            "    STEM_OUT_CHANNELS: 64\n",
            "    STRIDE_IN_1X1: True\n",
            "    WIDTH_PER_GROUP: 64\n",
            "  RETINANET:\n",
            "    BBOX_REG_LOSS_TYPE: smooth_l1\n",
            "    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)\n",
            "    FOCAL_LOSS_ALPHA: 0.25\n",
            "    FOCAL_LOSS_GAMMA: 2.0\n",
            "    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']\n",
            "    IOU_LABELS: [0, -1, 1]\n",
            "    IOU_THRESHOLDS: [0.4, 0.5]\n",
            "    NMS_THRESH_TEST: 0.5\n",
            "    NORM: \n",
            "    NUM_CLASSES: 80\n",
            "    NUM_CONVS: 4\n",
            "    PRIOR_PROB: 0.01\n",
            "    SCORE_THRESH_TEST: 0.05\n",
            "    SMOOTH_L1_LOSS_BETA: 0.1\n",
            "    TOPK_CANDIDATES_TEST: 1000\n",
            "  ROI_BOX_CASCADE_HEAD:\n",
            "    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))\n",
            "    IOUS: (0.5, 0.6, 0.7)\n",
            "  ROI_BOX_HEAD:\n",
            "    BBOX_REG_LOSS_TYPE: smooth_l1\n",
            "    BBOX_REG_LOSS_WEIGHT: 1.0\n",
            "    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)\n",
            "    CLS_AGNOSTIC_BBOX_REG: False\n",
            "    CONV_DIM: 256\n",
            "    FC_DIM: 1024\n",
            "    FED_LOSS_FREQ_WEIGHT_POWER: 0.5\n",
            "    FED_LOSS_NUM_CLASSES: 50\n",
            "    NAME: \n",
            "    NORM: \n",
            "    NUM_CONV: 0\n",
            "    NUM_FC: 0\n",
            "    POOLER_RESOLUTION: 14\n",
            "    POOLER_SAMPLING_RATIO: 0\n",
            "    POOLER_TYPE: ROIAlignV2\n",
            "    SMOOTH_L1_BETA: 0.0\n",
            "    TRAIN_ON_PRED_BOXES: False\n",
            "    USE_FED_LOSS: False\n",
            "    USE_SIGMOID_CE: False\n",
            "  ROI_HEADS:\n",
            "    BATCH_SIZE_PER_IMAGE: 512\n",
            "    IN_FEATURES: ['res4']\n",
            "    IOU_LABELS: [0, 1]\n",
            "    IOU_THRESHOLDS: [0.5]\n",
            "    NAME: Res5ROIHeads\n",
            "    NMS_THRESH_TEST: 0.5\n",
            "    NUM_CLASSES: 80\n",
            "    POSITIVE_FRACTION: 0.25\n",
            "    PROPOSAL_APPEND_GT: True\n",
            "    SCORE_THRESH_TEST: 0.05\n",
            "  ROI_KEYPOINT_HEAD:\n",
            "    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)\n",
            "    LOSS_WEIGHT: 1.0\n",
            "    MIN_KEYPOINTS_PER_IMAGE: 1\n",
            "    NAME: KRCNNConvDeconvUpsampleHead\n",
            "    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True\n",
            "    NUM_KEYPOINTS: 17\n",
            "    POOLER_RESOLUTION: 14\n",
            "    POOLER_SAMPLING_RATIO: 0\n",
            "    POOLER_TYPE: ROIAlignV2\n",
            "  ROI_MASK_HEAD:\n",
            "    CLS_AGNOSTIC_MASK: False\n",
            "    CONV_DIM: 256\n",
            "    NAME: MaskRCNNConvUpsampleHead\n",
            "    NORM: \n",
            "    NUM_CONV: 0\n",
            "    POOLER_RESOLUTION: 14\n",
            "    POOLER_SAMPLING_RATIO: 0\n",
            "    POOLER_TYPE: ROIAlignV2\n",
            "  RPN:\n",
            "    BATCH_SIZE_PER_IMAGE: 256\n",
            "    BBOX_REG_LOSS_TYPE: smooth_l1\n",
            "    BBOX_REG_LOSS_WEIGHT: 1.0\n",
            "    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)\n",
            "    BOUNDARY_THRESH: -1\n",
            "    CONV_DIMS: [-1]\n",
            "    HEAD_NAME: StandardRPNHead\n",
            "    IN_FEATURES: ['res4']\n",
            "    IOU_LABELS: [0, -1, 1]\n",
            "    IOU_THRESHOLDS: [0.3, 0.7]\n",
            "    LOSS_WEIGHT: 1.0\n",
            "    NMS_THRESH: 0.7\n",
            "    POSITIVE_FRACTION: 0.5\n",
            "    POST_NMS_TOPK_TEST: 1000\n",
            "    POST_NMS_TOPK_TRAIN: 2000\n",
            "    PRE_NMS_TOPK_TEST: 6000\n",
            "    PRE_NMS_TOPK_TRAIN: 12000\n",
            "    SMOOTH_L1_BETA: 0.0\n",
            "  SEM_SEG_HEAD:\n",
            "    COMMON_STRIDE: 4\n",
            "    CONVS_DIM: 128\n",
            "    IGNORE_VALUE: 255\n",
            "    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']\n",
            "    LOSS_WEIGHT: 1.0\n",
            "    NAME: SemSegFPNHead\n",
            "    NORM: GN\n",
            "    NUM_CLASSES: 54\n",
            "  SOLOV2:\n",
            "    FPN_INSTANCE_STRIDES: [8, 8, 16, 32, 32]\n",
            "    FPN_SCALE_RANGES: ((1, 96), (48, 192), (96, 384), (192, 768), (384, 2048))\n",
            "    INSTANCE_CHANNELS: 512\n",
            "    INSTANCE_IN_CHANNELS: 256\n",
            "    INSTANCE_IN_FEATURES: ['p2', 'p3', 'p4', 'p5', 'p6']\n",
            "    LOSS:\n",
            "      DICE_WEIGHT: 3.0\n",
            "      FOCAL_ALPHA: 0.25\n",
            "      FOCAL_GAMMA: 2.0\n",
            "      FOCAL_USE_SIGMOID: True\n",
            "      FOCAL_WEIGHT: 1.0\n",
            "    MASK_CHANNELS: 128\n",
            "    MASK_IN_CHANNELS: 256\n",
            "    MASK_IN_FEATURES: ['p2', 'p3', 'p4', 'p5']\n",
            "    MASK_THR: 0.5\n",
            "    MAX_PER_IMG: 100\n",
            "    NMS_KERNEL: gaussian\n",
            "    NMS_PRE: 500\n",
            "    NMS_SIGMA: 2\n",
            "    NMS_TYPE: matrix\n",
            "    NORM: GN\n",
            "    NUM_CLASSES: 80\n",
            "    NUM_GRIDS: [40, 36, 24, 16, 12]\n",
            "    NUM_INSTANCE_CONVS: 4\n",
            "    NUM_KERNELS: 256\n",
            "    NUM_MASKS: 256\n",
            "    PRIOR_PROB: 0.01\n",
            "    SCORE_THR: 0.1\n",
            "    SIGMA: 0.2\n",
            "    TYPE_DCN: DCN\n",
            "    UPDATE_THR: 0.05\n",
            "    USE_COORD_CONV: True\n",
            "    USE_DCN_IN_INSTANCE: False\n",
            "  TOP_MODULE:\n",
            "    DIM: 16\n",
            "    NAME: conv\n",
            "  VOVNET:\n",
            "    BACKBONE_OUT_CHANNELS: 256\n",
            "    CONV_BODY: V-39-eSE\n",
            "    NORM: FrozenBN\n",
            "    OUT_CHANNELS: 256\n",
            "    OUT_FEATURES: ['stage2', 'stage3', 'stage4', 'stage5']\n",
            "  WEIGHTS: detectron2://ImageNetPretrained/MSRA/R-50.pkl\n",
            "OUTPUT_DIR: ./output\n",
            "SEED: -1\n",
            "SOLVER:\n",
            "  AMP:\n",
            "    ENABLED: False\n",
            "  BASE_LR: 0.01\n",
            "  BASE_LR_END: 0.0\n",
            "  BIAS_LR_FACTOR: 1.0\n",
            "  CHECKPOINT_PERIOD: 5000\n",
            "  CLIP_GRADIENTS:\n",
            "    CLIP_TYPE: value\n",
            "    CLIP_VALUE: 1.0\n",
            "    ENABLED: False\n",
            "    NORM_TYPE: 2.0\n",
            "  GAMMA: 0.1\n",
            "  IMS_PER_BATCH: 16\n",
            "  LR_SCHEDULER_NAME: WarmupMultiStepLR\n",
            "  MAX_ITER: 270000\n",
            "  MOMENTUM: 0.9\n",
            "  NESTEROV: False\n",
            "  REFERENCE_WORLD_SIZE: 0\n",
            "  STEPS: (210000, 250000)\n",
            "  WARMUP_FACTOR: 0.01\n",
            "  WARMUP_ITERS: 1000\n",
            "  WARMUP_METHOD: linear\n",
            "  WEIGHT_DECAY: 0.0001\n",
            "  WEIGHT_DECAY_BIAS: None\n",
            "  WEIGHT_DECAY_NORM: 0.0\n",
            "TEST:\n",
            "  AUG:\n",
            "    ENABLED: False\n",
            "    FLIP: True\n",
            "    MAX_SIZE: 4000\n",
            "    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)\n",
            "  DETECTIONS_PER_IMAGE: 100\n",
            "  EVAL_PERIOD: 0\n",
            "  EXPECTED_RESULTS: []\n",
            "  KEYPOINT_OKS_SIGMAS: []\n",
            "  PRECISE_BN:\n",
            "    ENABLED: False\n",
            "    NUM_ITER: 200\n",
            "VERSION: 2\n",
            "VIS_PERIOD: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from detectron2.modeling import build_model\n",
        "#the solov2 model is located at: /content/AdelaiDet/adet/modeling/solov2/solov2.py\n",
        "%cd /content/AdelaiDet/adet/modeling/solov2/\n",
        "from solov2 import SOLOv2\n",
        "\n",
        "model = build_model(cfg_solov2)\n",
        "num_trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(num_trainable_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WU8b_0sjT80T",
        "outputId": "b1fba4ca-b86b-49e0-87ea-39cb93d216c0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/AdelaiDet/adet/modeling/solov2\n",
            "46317392\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/TACO-expl\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "import os.path\n",
        "import json\n",
        "import argparse\n",
        "import numpy as np\n",
        "import random\n",
        "import datetime as dt\n",
        "import copy\n",
        "import torch.nn as nn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from pathlib import Path\n",
        "\n",
        "import torch\n",
        "import math\n",
        "import torch.utils.data\n",
        "from torch.utils.data import DataLoader\n",
        "from pycocotools import mask as coco_mask\n",
        "\n",
        "\n",
        "from torchvision.ops import RoIAlign\n",
        "from HDDETR.datasets.torchvision_datasets.coco import CocoDetection as TvCocoDetection # from torchvision.datasets import CocoDetection as TvCocoDetection\n",
        "                                                                                       # the right above import import does not work bc of attribute definitions\n",
        "import HDDETR.datasets.transforms as T #from torchvision import transforms as T # this import does not contain the randomselect method\n",
        "import HDDETR.util.misc as mutils"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oEpIySaFnprv",
        "outputId": "cb4054f7-7b22-41f3-e2b6-aa76d6bd26b2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/TACO-expl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DEFAULT_RANDOM_SEED = 42\n",
        "# basic random seed\n",
        "def seedBasic(seed=DEFAULT_RANDOM_SEED):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "# torch random seed\n",
        "def seedTorch(seed=DEFAULT_RANDOM_SEED):\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "# combine\n",
        "def seedEverything(seed=DEFAULT_RANDOM_SEED):\n",
        "    seedBasic(seed)\n",
        "    seedTorch(seed)\n",
        "\n",
        "seedEverything()"
      ],
      "metadata": {
        "id": "gHfxVrm3nrzg"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keep_categories = [\"Bottle\", \"Bottle cap\", \"Can\", \"Cigarette\", \"Cup\",\n",
        "                   \"Lid\", \"Plastic bag & wrapper\", \"Pop tab\", \"Straw\"]\n",
        "\n",
        "def create_map(original, keep_supercategories):\n",
        "  class_map = {}\n",
        "  for cat in original:\n",
        "    if cat[\"supercategory\"] in keep_supercategories:\n",
        "      class_map[cat[\"name\"]] = cat[\"supercategory\"]\n",
        "    else:\n",
        "      class_map[cat[\"name\"]] = \"Other\"\n",
        "  return class_map\n",
        "\n",
        "def replace_dataset_classes(dataset, class_map):\n",
        "      \"\"\" Replaces classes of dataset based on a dictionary\"\"\"\n",
        "      class_new_names = list(set(class_map.values()))\n",
        "      class_new_names.sort()\n",
        "      class_originals = copy.deepcopy(dataset['categories'])\n",
        "      dataset['categories'] = []\n",
        "      class_ids_map = {}  # map from old id to new id\n",
        "\n",
        "      # Assign background id 0\n",
        "      has_background = False\n",
        "      if 'Background' in class_new_names:\n",
        "          if class_new_names.index('Background') != 0:\n",
        "              class_new_names.remove('Background')\n",
        "              class_new_names.insert(0, 'Background')\n",
        "          has_background = True\n",
        "\n",
        "      # Replace categories\n",
        "      for id_new, class_new_name in enumerate(class_new_names):\n",
        "          # Make sure id:0 is reserved for background\n",
        "          id_rectified = id_new\n",
        "          if not has_background:\n",
        "              id_rectified += 1\n",
        "\n",
        "          category = {\n",
        "              'supercategory': '',\n",
        "              'id': id_rectified,  # Background has id=0\n",
        "              'name': class_new_name,\n",
        "          }\n",
        "          dataset['categories'].append(category)\n",
        "          # Map class names\n",
        "          for class_original in class_originals:\n",
        "              if class_map[class_original['name']] == class_new_name:\n",
        "                  class_ids_map[class_original['id']] = id_rectified\n",
        "\n",
        "      # Update annotations category id tag\n",
        "      for ann in dataset['annotations']:\n",
        "          ann['category_id'] = class_ids_map[ann['category_id']]"
      ],
      "metadata": {
        "id": "ZCws_VTInwr5"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/TACO-expl/data/annotations.json\", \"r\") as f: #\"/content/TACO/data/annotations.json\"\n",
        "    dataset = json.loads(f.read())\n",
        "\n",
        "class_map = create_map(dataset[\"categories\"], keep_categories)\n",
        "replace_dataset_classes(dataset, class_map)\n",
        "dataset[\"categories\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9QJNgK7anxnv",
        "outputId": "50819b05-e243-4004-dce2-ed0cf2c5180c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'supercategory': '', 'id': 1, 'name': 'Bottle'},\n",
              " {'supercategory': '', 'id': 2, 'name': 'Bottle cap'},\n",
              " {'supercategory': '', 'id': 3, 'name': 'Can'},\n",
              " {'supercategory': '', 'id': 4, 'name': 'Cigarette'},\n",
              " {'supercategory': '', 'id': 5, 'name': 'Cup'},\n",
              " {'supercategory': '', 'id': 6, 'name': 'Lid'},\n",
              " {'supercategory': '', 'id': 7, 'name': 'Other'},\n",
              " {'supercategory': '', 'id': 8, 'name': 'Plastic bag & wrapper'},\n",
              " {'supercategory': '', 'id': 9, 'name': 'Pop tab'},\n",
              " {'supercategory': '', 'id': 10, 'name': 'Straw'}]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classes = [elem[\"name\"] for elem in dataset[\"categories\"]]\n",
        "print(classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mz77Fd0Any8W",
        "outputId": "f05c0fb2-5f46-48ca-f2be-8f9290a837f6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Bottle', 'Bottle cap', 'Can', 'Cigarette', 'Cup', 'Lid', 'Other', 'Plastic bag & wrapper', 'Pop tab', 'Straw']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TACODataset(TvCocoDetection):\n",
        "    def __init__(\n",
        "        self,\n",
        "        img_folder,\n",
        "        ann_file,\n",
        "        classes,\n",
        "        transforms,\n",
        "        cache_mode=False,\n",
        "        local_rank=0,\n",
        "        local_size=1,\n",
        "        use_crowd=False,\n",
        "        return_unmodified=True # Needed for debugging purposes\n",
        "    ):\n",
        "        super(TACODataset, self).__init__(\n",
        "            img_folder,\n",
        "            ann_file,\n",
        "            cache_mode=cache_mode,\n",
        "            local_rank=local_rank,\n",
        "            local_size=local_size,\n",
        "        )\n",
        "        self._transforms = transforms\n",
        "        self.prepare = ConvertCocoPolysToMask(use_crowd)\n",
        "        self.return_unmodified = return_unmodified\n",
        "        self.image_dir = img_folder\n",
        "        self.annotation_file = ann_file\n",
        "        self.classes = classes\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img, target = super(TACODataset, self).__getitem__(idx)\n",
        "        unmodified_img = np.array(img.copy())\n",
        "        image_id = self.ids[idx]\n",
        "        target = {\"image_id\": image_id, \"annotations\": target}\n",
        "        img, target = self.prepare(img, target)\n",
        "        if self._transforms is not None:\n",
        "            img, target = self._transforms(img, target)\n",
        "        if self.return_unmodified:\n",
        "          return unmodified_img, img, target\n",
        "        return img, target\n",
        "\n",
        "\n",
        "\n",
        "class ConvertCocoPolysToMask(object):\n",
        "    def __init__(self, use_crowd):\n",
        "       self.use_crowd = use_crowd\n",
        "\n",
        "    def __call__(self, image, target):\n",
        "        w, h = image.size\n",
        "\n",
        "        image_id = target[\"image_id\"]\n",
        "        image_id = torch.tensor([image_id])\n",
        "\n",
        "        anno = target[\"annotations\"]\n",
        "\n",
        "        if not self.use_crowd:\n",
        "          anno = [obj for obj in anno if \"iscrowd\" not in obj or obj[\"iscrowd\"] == 0]\n",
        "\n",
        "        # condition as sanity check for empty segmentations\n",
        "        boxes = [obj[\"bbox\"] for obj in anno if obj[\"segmentation\"]]\n",
        "        # guard against no boxes via resizing\n",
        "        boxes = torch.as_tensor(boxes, dtype=torch.float32).reshape(-1, 4)\n",
        "        boxes[:, 2:] += boxes[:, :2]\n",
        "        boxes[:, 0::2].clamp_(min=0, max=w)\n",
        "        boxes[:, 1::2].clamp_(min=0, max=h)\n",
        "\n",
        "        classes = [obj[\"category_id\"] for obj in anno if obj[\"segmentation\"]]\n",
        "        classes = torch.tensor(classes, dtype=torch.int64) - 1 # for labels between 0 and 9\n",
        "\n",
        "        segmentations = [obj[\"segmentation\"] for obj in anno if obj[\"segmentation\"]]\n",
        "        masks = self.convert_coco_poly_to_mask(segmentations=segmentations, height=h, width=w) # this requires investigation\n",
        "                                                                                               # if sample 82 is not an isolated case\n",
        "        keep = (boxes[:, 3] > boxes[:, 1]) & (boxes[:, 2] > boxes[:, 0])\n",
        "\n",
        "        #print(keep)\n",
        "        #print(keep.shape)\n",
        "        #print(masks)\n",
        "\n",
        "        boxes = boxes[keep]\n",
        "        classes = classes[keep]\n",
        "        masks = masks#[keep] # some samples could not be loaded\n",
        "\n",
        "        target = {}\n",
        "        target[\"boxes\"] = boxes\n",
        "        target[\"labels\"] = classes\n",
        "        target[\"masks\"] = masks\n",
        "        target[\"image_id\"] = image_id\n",
        "\n",
        "        # for conversion to coco api\n",
        "        area = torch.tensor([obj[\"area\"] for obj in anno if obj[\"segmentation\"]])\n",
        "        iscrowd = torch.tensor(\n",
        "            [obj[\"iscrowd\"] if \"iscrowd\" in obj else 0 for obj in anno if obj[\"segmentation\"]]\n",
        "        )\n",
        "        target[\"area\"] = area[keep]\n",
        "        target[\"iscrowd\"] = iscrowd[keep]\n",
        "\n",
        "        target[\"orig_size\"] = torch.as_tensor([int(h), int(w)])\n",
        "        target[\"size\"] = torch.as_tensor([int(h), int(w)])\n",
        "\n",
        "        return image, target\n",
        "\n",
        "    def convert_coco_poly_to_mask(self, segmentations, height, width):\n",
        "      masks = []\n",
        "      for polygons in segmentations:\n",
        "          rles = coco_mask.frPyObjects(polygons, height, width)\n",
        "\n",
        "          mask = coco_mask.decode(rles)\n",
        "          if mask.max() < 1:\n",
        "            continue\n",
        "          if len(mask.shape) < 3:\n",
        "            mask = mask[..., None]\n",
        "          mask = torch.as_tensor(mask, dtype=torch.uint8)\n",
        "          mask = mask.any(dim=2)\n",
        "          masks.append(mask)\n",
        "      if masks:\n",
        "          masks = torch.stack(masks, dim=0)\n",
        "      else:\n",
        "          masks = torch.zeros((0, height, width), dtype=torch.uint8)\n",
        "      return masks\n",
        "\n",
        "\n",
        "def make_coco_transforms(image_set):\n",
        "\n",
        "    normalize = T.Compose(\n",
        "        [T.ToTensor(), T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]\n",
        "    )\n",
        "    #max_size = 1333\n",
        "    max_size = 1024\n",
        "    scales = [480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800]\n",
        "              # 832, 864, 896, 928, 960]\n",
        "\n",
        "    if image_set == \"train\":\n",
        "        return T.Compose(\n",
        "            [\n",
        "                T.RandomHorizontalFlip(),\n",
        "                T.RandomSelect(\n",
        "                    T.RandomResize(scales, max_size=max_size),\n",
        "                    T.Compose(\n",
        "                        [\n",
        "                            # T.RandomResize([400, 500, 600])\n",
        "                            T.RandomResize([2000, 2500, 3000]),\n",
        "                            #T.RandomSizeCrop(384, 600),\n",
        "                            T.RandomSizeCrop(1920, 3000),\n",
        "                            T.RandomResize(scales, max_size=max_size),\n",
        "                        ]\n",
        "                    ),\n",
        "                ),\n",
        "                normalize,\n",
        "            ]\n",
        "        )\n",
        "\n",
        "\n",
        "\n",
        "    if image_set == \"val\":\n",
        "        return T.Compose([T.RandomResize([800], max_size=max_size), normalize,])\n",
        "    if image_set == \"test\":\n",
        "        return None\n",
        "\n",
        "    raise ValueError(f\"unknown {image_set}\")\n",
        "\n",
        "def create_dataset(split):\n",
        "  ann_file = Path(\"/content/TACO-expl/data/annotations_off_0_\" + split +\".json\")\n",
        "  img_folder = Path(\"/content/MyDrive/MyDrive/official/\")\n",
        "\n",
        "  dataset = TACODataset(\n",
        "      img_folder,\n",
        "      ann_file,\n",
        "      classes=classes,\n",
        "      transforms=make_coco_transforms(split),\n",
        "      local_rank=mutils.get_local_rank(),\n",
        "      local_size=mutils.get_local_size(),\n",
        "  )\n",
        "  return dataset"
      ],
      "metadata": {
        "id": "YPRAHHPvn1zm"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = create_dataset('train')\n",
        "val_dataset = create_dataset('val')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R37IT3BMn2R3",
        "outputId": "946ec6e9-1fa3-4f5d-8ace-a2e05cfe5edd"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=0.05s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=0.01s)\n",
            "creating index...\n",
            "index created!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from detectron2.data.datasets import register_coco_instances\n",
        "from detectron2.data import MetadataCatalog\n",
        "\n",
        "register_coco_instances(\"TACO_train\", {}, train_dataset.annotation_file, train_dataset.image_dir)\n",
        "MetadataCatalog.get(\"TACO_train\").set(thing_classes=train_dataset.classes)\n",
        "dataset_dicts_train = DatasetCatalog.get(\"TACO_train\")\n",
        "\n",
        "register_coco_instances(\"TACO_val\", {}, val_dataset.annotation_file, val_dataset.image_dir)\n",
        "MetadataCatalog.get(\"TACO_val\").set(thing_classes=val_dataset.classes)\n",
        "dataset_dicts_val = DatasetCatalog.get(\"TACO_val\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LmR4YkANn3eG",
        "outputId": "5c136bd2-f213-4696-ebb7-22e15bafec6b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05/07 16:00:05 d2.data.datasets.coco]: Loaded 1200 images in COCO format from /content/TACO-expl/data/annotations_off_0_train.json\n",
            "[05/07 16:00:05 d2.data.datasets.coco]: Loaded 150 images in COCO format from /content/TACO-expl/data/annotations_off_0_val.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_cfg = cfg_solov2.clone()\n",
        "with open(\"/content/TACO-expl/taco_train_solov2.yaml\", \"w\") as f:\n",
        "  f.write(train_cfg.dump())"
      ],
      "metadata": {
        "id": "rhuvntPZn9Ar"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_cfg_loaded = get_cfg()\n",
        "train_cfg_loaded.set_new_allowed(True)\n",
        "train_cfg_loaded.merge_from_file(\"/content/TACO-expl/taco_train_solov2.yaml\")\n",
        "#print(train_cfg_loaded.MODEL.BACKBONE.FREEZE_AT)\n",
        "#print(train_cfg_loaded.SOLVER.IMS_PER_BATCH)\n",
        "#print(train_cfg_loaded.INPUT.MIN_SIZE_TRAIN)\n",
        "#print(train_cfg_loaded.DATASETS.PRECOMPUTED_PROPOSAL_TOPK_TRAIN)\n",
        "#print(train_cfg_loaded.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE)\n",
        "#print(train_cfg_loaded.MODEL.MaskDINO.BOX_LOSS)\n",
        "#print(train_cfg_loaded.MODEL.MaskDINO.NUM_OBJECT_QUERIES)"
      ],
      "metadata": {
        "id": "hDjfTaa9n9W8"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/AdelaiDet/tools/\n",
        "from train_net import Trainer\n",
        "!python -m pip install numpy==1.23.1\n",
        "import numpy as np\n",
        "np.bool = np.bool_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4MsfHBcWn_O1",
        "outputId": "a9ec0949-2f1f-491f-ce92-fcae202050ec"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/AdelaiDet/tools\n",
            "Requirement already satisfied: numpy==1.23.1 in /usr/local/lib/python3.10/dist-packages (1.23.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/AdelaiDet/adet/modeling/solov2/\n",
        "from solov2 import SOLOv2"
      ],
      "metadata": {
        "id": "5C5LFENYzK41",
        "outputId": "5d4716cb-bc96-4490-9160-15859668ce35",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/AdelaiDet/adet/modeling/solov2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(train_cfg_loaded)\n",
        "trainer.resume_or_load()  # load last checkpoint or MODEL.WEIGHTS\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "xvnHug9_oDE_",
        "outputId": "ef6d6573-cc6e-4e7f-c959-a9b03ada611e"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05/07 16:09:36 d2.engine.defaults]: Model:\n",
            "SOLOv2(\n",
            "  (backbone): FPN(\n",
            "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (top_block): LastLevelMaxPool()\n",
            "    (bottom_up): ResNet(\n",
            "      (stem): BasicStem(\n",
            "        (conv1): Conv2d(\n",
            "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (res2): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res3): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res4): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (4): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (5): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res5): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (ins_head): SOLOv2InsHead(\n",
            "    (cate_tower): Sequential(\n",
            "      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
            "      (2): ReLU(inplace=True)\n",
            "      (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (4): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
            "      (5): ReLU(inplace=True)\n",
            "      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (7): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
            "      (8): ReLU(inplace=True)\n",
            "      (9): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (10): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
            "      (11): ReLU(inplace=True)\n",
            "    )\n",
            "    (kernel_tower): Sequential(\n",
            "      (0): Conv2d(258, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
            "      (2): ReLU(inplace=True)\n",
            "      (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (4): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
            "      (5): ReLU(inplace=True)\n",
            "      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (7): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
            "      (8): ReLU(inplace=True)\n",
            "      (9): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (10): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
            "      (11): ReLU(inplace=True)\n",
            "    )\n",
            "    (cate_pred): Conv2d(512, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (kernel_pred): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  )\n",
            "  (mask_head): SOLOv2MaskHead(\n",
            "    (convs_all_levels): ModuleList(\n",
            "      (0): Sequential(\n",
            "        (conv0): Sequential(\n",
            "          (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
            "          (2): ReLU()\n",
            "        )\n",
            "      )\n",
            "      (1): Sequential(\n",
            "        (conv0): Sequential(\n",
            "          (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
            "          (2): ReLU()\n",
            "        )\n",
            "        (upsample0): Upsample(scale_factor=2.0, mode='bilinear')\n",
            "      )\n",
            "      (2): Sequential(\n",
            "        (conv0): Sequential(\n",
            "          (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
            "          (2): ReLU()\n",
            "        )\n",
            "        (upsample0): Upsample(scale_factor=2.0, mode='bilinear')\n",
            "        (conv1): Sequential(\n",
            "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
            "          (2): ReLU()\n",
            "        )\n",
            "        (upsample1): Upsample(scale_factor=2.0, mode='bilinear')\n",
            "      )\n",
            "      (3): Sequential(\n",
            "        (conv0): Sequential(\n",
            "          (0): Conv2d(258, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
            "          (2): ReLU()\n",
            "        )\n",
            "        (upsample0): Upsample(scale_factor=2.0, mode='bilinear')\n",
            "        (conv1): Sequential(\n",
            "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
            "          (2): ReLU()\n",
            "        )\n",
            "        (upsample1): Upsample(scale_factor=2.0, mode='bilinear')\n",
            "        (conv2): Sequential(\n",
            "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
            "          (2): ReLU()\n",
            "        )\n",
            "        (upsample2): Upsample(scale_factor=2.0, mode='bilinear')\n",
            "      )\n",
            "    )\n",
            "    (conv_pred): Sequential(\n",
            "      (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
            "      (2): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "[05/07 16:09:36 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
            "[05/07 16:09:37 d2.data.datasets.coco]: Loaded 1200 images in COCO format from /content/TACO-expl/data/annotations_off_0_train.json\n",
            "[05/07 16:09:37 d2.data.build]: Removed 0 images with no usable annotations. 1200 images left.\n",
            "[05/07 16:09:37 d2.data.build]: Using training sampler TrainingSampler\n",
            "[05/07 16:09:37 d2.data.common]: Serializing 1200 elements to byte tensors and concatenating them all ...\n",
            "[05/07 16:09:37 d2.data.common]: Serialized dataset takes 1.81 MiB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "R-50.pkl: 102MB [00:00, 158MB/s]                            "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05/07 16:09:43 d2.checkpoint.c2_model_loading]: Renaming Caffe2 weights ......\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05/07 16:09:43 d2.checkpoint.c2_model_loading]: Following weights matched with submodule backbone.bottom_up:\n",
            "| Names in Model    | Names in Checkpoint      | Shapes                                          |\n",
            "|:------------------|:-------------------------|:------------------------------------------------|\n",
            "| res2.0.conv1.*    | res2_0_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,1,1)             |\n",
            "| res2.0.conv2.*    | res2_0_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
            "| res2.0.conv3.*    | res2_0_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
            "| res2.0.shortcut.* | res2_0_branch1_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
            "| res2.1.conv1.*    | res2_1_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
            "| res2.1.conv2.*    | res2_1_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
            "| res2.1.conv3.*    | res2_1_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
            "| res2.2.conv1.*    | res2_2_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
            "| res2.2.conv2.*    | res2_2_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
            "| res2.2.conv3.*    | res2_2_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
            "| res3.0.conv1.*    | res3_0_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,256,1,1)       |\n",
            "| res3.0.conv2.*    | res3_0_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
            "| res3.0.conv3.*    | res3_0_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
            "| res3.0.shortcut.* | res3_0_branch1_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,256,1,1)       |\n",
            "| res3.1.conv1.*    | res3_1_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
            "| res3.1.conv2.*    | res3_1_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
            "| res3.1.conv3.*    | res3_1_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
            "| res3.2.conv1.*    | res3_2_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
            "| res3.2.conv2.*    | res3_2_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
            "| res3.2.conv3.*    | res3_2_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
            "| res3.3.conv1.*    | res3_3_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
            "| res3.3.conv2.*    | res3_3_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
            "| res3.3.conv3.*    | res3_3_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
            "| res4.0.conv1.*    | res4_0_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,512,1,1)       |\n",
            "| res4.0.conv2.*    | res4_0_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| res4.0.conv3.*    | res4_0_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| res4.0.shortcut.* | res4_0_branch1_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |\n",
            "| res4.1.conv1.*    | res4_1_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| res4.1.conv2.*    | res4_1_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| res4.1.conv3.*    | res4_1_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| res4.2.conv1.*    | res4_2_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| res4.2.conv2.*    | res4_2_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| res4.2.conv3.*    | res4_2_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| res4.3.conv1.*    | res4_3_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| res4.3.conv2.*    | res4_3_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| res4.3.conv3.*    | res4_3_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| res4.4.conv1.*    | res4_4_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| res4.4.conv2.*    | res4_4_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| res4.4.conv3.*    | res4_4_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| res4.5.conv1.*    | res4_5_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| res4.5.conv2.*    | res4_5_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| res4.5.conv3.*    | res4_5_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| res5.0.conv1.*    | res5_0_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,1024,1,1)      |\n",
            "| res5.0.conv2.*    | res5_0_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
            "| res5.0.conv3.*    | res5_0_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
            "| res5.0.shortcut.* | res5_0_branch1_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |\n",
            "| res5.1.conv1.*    | res5_1_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
            "| res5.1.conv2.*    | res5_1_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
            "| res5.1.conv3.*    | res5_1_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
            "| res5.2.conv1.*    | res5_2_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
            "| res5.2.conv2.*    | res5_2_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
            "| res5.2.conv3.*    | res5_2_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
            "| stem.conv1.norm.* | res_conv1_bn_*           | (64,) (64,) (64,) (64,)                         |\n",
            "| stem.conv1.weight | conv1_w                  | (64, 3, 7, 7)                                   |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:fvcore.common.checkpoint:Some model parameters or buffers are not found in the checkpoint:\n",
            "backbone.fpn_lateral2.{bias, weight}\n",
            "backbone.fpn_lateral3.{bias, weight}\n",
            "backbone.fpn_lateral4.{bias, weight}\n",
            "backbone.fpn_lateral5.{bias, weight}\n",
            "backbone.fpn_output2.{bias, weight}\n",
            "backbone.fpn_output3.{bias, weight}\n",
            "backbone.fpn_output4.{bias, weight}\n",
            "backbone.fpn_output5.{bias, weight}\n",
            "ins_head.cate_pred.{bias, weight}\n",
            "ins_head.cate_tower.0.weight\n",
            "ins_head.cate_tower.1.{bias, weight}\n",
            "ins_head.cate_tower.10.{bias, weight}\n",
            "ins_head.cate_tower.3.weight\n",
            "ins_head.cate_tower.4.{bias, weight}\n",
            "ins_head.cate_tower.6.weight\n",
            "ins_head.cate_tower.7.{bias, weight}\n",
            "ins_head.cate_tower.9.weight\n",
            "ins_head.kernel_pred.{bias, weight}\n",
            "ins_head.kernel_tower.0.weight\n",
            "ins_head.kernel_tower.1.{bias, weight}\n",
            "ins_head.kernel_tower.10.{bias, weight}\n",
            "ins_head.kernel_tower.3.weight\n",
            "ins_head.kernel_tower.4.{bias, weight}\n",
            "ins_head.kernel_tower.6.weight\n",
            "ins_head.kernel_tower.7.{bias, weight}\n",
            "ins_head.kernel_tower.9.weight\n",
            "mask_head.conv_pred.0.weight\n",
            "mask_head.conv_pred.1.{bias, weight}\n",
            "mask_head.convs_all_levels.0.conv0.0.weight\n",
            "mask_head.convs_all_levels.0.conv0.1.{bias, weight}\n",
            "mask_head.convs_all_levels.1.conv0.0.weight\n",
            "mask_head.convs_all_levels.1.conv0.1.{bias, weight}\n",
            "mask_head.convs_all_levels.2.conv0.0.weight\n",
            "mask_head.convs_all_levels.2.conv0.1.{bias, weight}\n",
            "mask_head.convs_all_levels.2.conv1.0.weight\n",
            "mask_head.convs_all_levels.2.conv1.1.{bias, weight}\n",
            "mask_head.convs_all_levels.3.conv0.0.weight\n",
            "mask_head.convs_all_levels.3.conv0.1.{bias, weight}\n",
            "mask_head.convs_all_levels.3.conv1.0.weight\n",
            "mask_head.convs_all_levels.3.conv1.1.{bias, weight}\n",
            "mask_head.convs_all_levels.3.conv2.0.weight\n",
            "mask_head.convs_all_levels.3.conv2.1.{bias, weight}\n",
            "WARNING:fvcore.common.checkpoint:The checkpoint state_dict contains keys that are not used by the model:\n",
            "  fc1000.{bias, weight}\n",
            "  stem.conv1.bias\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:507: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3549.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 526.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 385.06 MiB is free. Process 208452 has 14.37 GiB memory in use. Of the allocated memory 13.90 GiB is allocated by PyTorch, and 351.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-131f27d033ed>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_cfg_loaded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresume_or_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# load last checkpoint or MODEL.WEIGHTS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/AdelaiDet/tools/train_net.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0mOrderedDict\u001b[0m \u001b[0mof\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mevaluation\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0menabled\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mOtherwise\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \"\"\"\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_last_eval_results\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcomm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_main_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0mverify_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_last_eval_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/AdelaiDet/tools/train_net.py\u001b[0m in \u001b[0;36mtrain_loop\u001b[0;34m(self, start_iter, max_iter)\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbefore_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafter_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafter_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/detectron2/engine/defaults.py\u001b[0m in \u001b[0;36mrun_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    492\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 494\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/detectron2/engine/train_loop.py\u001b[0m in \u001b[0;36mrun_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0mIf\u001b[0m \u001b[0myou\u001b[0m \u001b[0mwant\u001b[0m \u001b[0mto\u001b[0m \u001b[0mdo\u001b[0m \u001b[0msomething\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myou\u001b[0m \u001b[0mcan\u001b[0m \u001b[0mwrap\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \"\"\"\n\u001b[0;32m--> 274\u001b[0;31m         \u001b[0mloss_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m             \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/AdelaiDet/adet/modeling/solov2/solov2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, batched_inputs)\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0;31m# mask branch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0mmask_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask_in_features\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0mmask_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask_head\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/AdelaiDet/adet/modeling/solov2/solov2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m    742\u001b[0m                 \u001b[0mmask_feat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask_feat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoord_feat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m             \u001b[0;31m# add for top features.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m             \u001b[0mfeature_add_all_level\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_add_all_level\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvs_all_levels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask_feat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    745\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m         \u001b[0mmask_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_pred\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_add_all_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/upsampling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m         return F.interpolate(input, self.size, self.scale_factor, self.mode, self.align_corners,\n\u001b[0m\u001b[1;32m    158\u001b[0m                              recompute_scale_factor=self.recompute_scale_factor)\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36minterpolate\u001b[0;34m(input, size, scale_factor, mode, align_corners, recompute_scale_factor, antialias)\u001b[0m\n\u001b[1;32m   4036\u001b[0m                 return importlib.import_module('torch._decomp.decompositions').upsample_bilinear2d_vec(\n\u001b[1;32m   4037\u001b[0m                     input, output_size, align_corners, scale_factors)\n\u001b[0;32m-> 4038\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupsample_bilinear2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malign_corners\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_factors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4039\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m5\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"trilinear\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4040\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0malign_corners\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 526.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 385.06 MiB is free. Process 208452 has 14.37 GiB memory in use. Of the allocated memory 13.90 GiB is allocated by PyTorch, and 351.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run this if you want to check how many trainable parameters we have"
      ],
      "metadata": {
        "id": "0JVZhhKDFYpo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from detectron2.modeling import build_model\n",
        "model = build_model(train_cfg_loaded)\n",
        "num_trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(num_trainable_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZljjMBcCFLtJ",
        "outputId": "52e790a5-9e9c-448d-9ecd-242ec3da4291"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "criterion.weight_dict  {'loss_ce': 4.0, 'loss_mask': 5.0, 'loss_dice': 5.0, 'loss_bbox': 5.0, 'loss_giou': 2.0, 'loss_ce_interm': 4.0, 'loss_mask_interm': 5.0, 'loss_dice_interm': 5.0, 'loss_bbox_interm': 5.0, 'loss_giou_interm': 2.0, 'loss_ce_dn': 4.0, 'loss_mask_dn': 5.0, 'loss_dice_dn': 5.0, 'loss_bbox_dn': 5.0, 'loss_giou_dn': 2.0, 'loss_ce_interm_dn': 4.0, 'loss_mask_interm_dn': 5.0, 'loss_dice_interm_dn': 5.0, 'loss_bbox_interm_dn': 5.0, 'loss_giou_interm_dn': 2.0, 'loss_ce_0': 4.0, 'loss_mask_0': 5.0, 'loss_dice_0': 5.0, 'loss_bbox_0': 5.0, 'loss_giou_0': 2.0, 'loss_ce_interm_0': 4.0, 'loss_mask_interm_0': 5.0, 'loss_dice_interm_0': 5.0, 'loss_bbox_interm_0': 5.0, 'loss_giou_interm_0': 2.0, 'loss_ce_dn_0': 4.0, 'loss_mask_dn_0': 5.0, 'loss_dice_dn_0': 5.0, 'loss_bbox_dn_0': 5.0, 'loss_giou_dn_0': 2.0, 'loss_ce_interm_dn_0': 4.0, 'loss_mask_interm_dn_0': 5.0, 'loss_dice_interm_dn_0': 5.0, 'loss_bbox_interm_dn_0': 5.0, 'loss_giou_interm_dn_0': 2.0, 'loss_ce_1': 4.0, 'loss_mask_1': 5.0, 'loss_dice_1': 5.0, 'loss_bbox_1': 5.0, 'loss_giou_1': 2.0, 'loss_ce_interm_1': 4.0, 'loss_mask_interm_1': 5.0, 'loss_dice_interm_1': 5.0, 'loss_bbox_interm_1': 5.0, 'loss_giou_interm_1': 2.0, 'loss_ce_dn_1': 4.0, 'loss_mask_dn_1': 5.0, 'loss_dice_dn_1': 5.0, 'loss_bbox_dn_1': 5.0, 'loss_giou_dn_1': 2.0, 'loss_ce_interm_dn_1': 4.0, 'loss_mask_interm_dn_1': 5.0, 'loss_dice_interm_dn_1': 5.0, 'loss_bbox_interm_dn_1': 5.0, 'loss_giou_interm_dn_1': 2.0, 'loss_ce_2': 4.0, 'loss_mask_2': 5.0, 'loss_dice_2': 5.0, 'loss_bbox_2': 5.0, 'loss_giou_2': 2.0, 'loss_ce_interm_2': 4.0, 'loss_mask_interm_2': 5.0, 'loss_dice_interm_2': 5.0, 'loss_bbox_interm_2': 5.0, 'loss_giou_interm_2': 2.0, 'loss_ce_dn_2': 4.0, 'loss_mask_dn_2': 5.0, 'loss_dice_dn_2': 5.0, 'loss_bbox_dn_2': 5.0, 'loss_giou_dn_2': 2.0, 'loss_ce_interm_dn_2': 4.0, 'loss_mask_interm_dn_2': 5.0, 'loss_dice_interm_dn_2': 5.0, 'loss_bbox_interm_dn_2': 5.0, 'loss_giou_interm_dn_2': 2.0, 'loss_ce_3': 4.0, 'loss_mask_3': 5.0, 'loss_dice_3': 5.0, 'loss_bbox_3': 5.0, 'loss_giou_3': 2.0, 'loss_ce_interm_3': 4.0, 'loss_mask_interm_3': 5.0, 'loss_dice_interm_3': 5.0, 'loss_bbox_interm_3': 5.0, 'loss_giou_interm_3': 2.0, 'loss_ce_dn_3': 4.0, 'loss_mask_dn_3': 5.0, 'loss_dice_dn_3': 5.0, 'loss_bbox_dn_3': 5.0, 'loss_giou_dn_3': 2.0, 'loss_ce_interm_dn_3': 4.0, 'loss_mask_interm_dn_3': 5.0, 'loss_dice_interm_dn_3': 5.0, 'loss_bbox_interm_dn_3': 5.0, 'loss_giou_interm_dn_3': 2.0, 'loss_ce_4': 4.0, 'loss_mask_4': 5.0, 'loss_dice_4': 5.0, 'loss_bbox_4': 5.0, 'loss_giou_4': 2.0, 'loss_ce_interm_4': 4.0, 'loss_mask_interm_4': 5.0, 'loss_dice_interm_4': 5.0, 'loss_bbox_interm_4': 5.0, 'loss_giou_interm_4': 2.0, 'loss_ce_dn_4': 4.0, 'loss_mask_dn_4': 5.0, 'loss_dice_dn_4': 5.0, 'loss_bbox_dn_4': 5.0, 'loss_giou_dn_4': 2.0, 'loss_ce_interm_dn_4': 4.0, 'loss_mask_interm_dn_4': 5.0, 'loss_dice_interm_dn_4': 5.0, 'loss_bbox_interm_dn_4': 5.0, 'loss_giou_interm_dn_4': 2.0, 'loss_ce_5': 4.0, 'loss_mask_5': 5.0, 'loss_dice_5': 5.0, 'loss_bbox_5': 5.0, 'loss_giou_5': 2.0, 'loss_ce_interm_5': 4.0, 'loss_mask_interm_5': 5.0, 'loss_dice_interm_5': 5.0, 'loss_bbox_interm_5': 5.0, 'loss_giou_interm_5': 2.0, 'loss_ce_dn_5': 4.0, 'loss_mask_dn_5': 5.0, 'loss_dice_dn_5': 5.0, 'loss_bbox_dn_5': 5.0, 'loss_giou_dn_5': 2.0, 'loss_ce_interm_dn_5': 4.0, 'loss_mask_interm_dn_5': 5.0, 'loss_dice_interm_dn_5': 5.0, 'loss_bbox_interm_dn_5': 5.0, 'loss_giou_interm_dn_5': 2.0, 'loss_ce_6': 4.0, 'loss_mask_6': 5.0, 'loss_dice_6': 5.0, 'loss_bbox_6': 5.0, 'loss_giou_6': 2.0, 'loss_ce_interm_6': 4.0, 'loss_mask_interm_6': 5.0, 'loss_dice_interm_6': 5.0, 'loss_bbox_interm_6': 5.0, 'loss_giou_interm_6': 2.0, 'loss_ce_dn_6': 4.0, 'loss_mask_dn_6': 5.0, 'loss_dice_dn_6': 5.0, 'loss_bbox_dn_6': 5.0, 'loss_giou_dn_6': 2.0, 'loss_ce_interm_dn_6': 4.0, 'loss_mask_interm_dn_6': 5.0, 'loss_dice_interm_dn_6': 5.0, 'loss_bbox_interm_dn_6': 5.0, 'loss_giou_interm_dn_6': 2.0, 'loss_ce_7': 4.0, 'loss_mask_7': 5.0, 'loss_dice_7': 5.0, 'loss_bbox_7': 5.0, 'loss_giou_7': 2.0, 'loss_ce_interm_7': 4.0, 'loss_mask_interm_7': 5.0, 'loss_dice_interm_7': 5.0, 'loss_bbox_interm_7': 5.0, 'loss_giou_interm_7': 2.0, 'loss_ce_dn_7': 4.0, 'loss_mask_dn_7': 5.0, 'loss_dice_dn_7': 5.0, 'loss_bbox_dn_7': 5.0, 'loss_giou_dn_7': 2.0, 'loss_ce_interm_dn_7': 4.0, 'loss_mask_interm_dn_7': 5.0, 'loss_dice_interm_dn_7': 5.0, 'loss_bbox_interm_dn_7': 5.0, 'loss_giou_interm_dn_7': 2.0, 'loss_ce_8': 4.0, 'loss_mask_8': 5.0, 'loss_dice_8': 5.0, 'loss_bbox_8': 5.0, 'loss_giou_8': 2.0, 'loss_ce_interm_8': 4.0, 'loss_mask_interm_8': 5.0, 'loss_dice_interm_8': 5.0, 'loss_bbox_interm_8': 5.0, 'loss_giou_interm_8': 2.0, 'loss_ce_dn_8': 4.0, 'loss_mask_dn_8': 5.0, 'loss_dice_dn_8': 5.0, 'loss_bbox_dn_8': 5.0, 'loss_giou_dn_8': 2.0, 'loss_ce_interm_dn_8': 4.0, 'loss_mask_interm_dn_8': 5.0, 'loss_dice_interm_dn_8': 5.0, 'loss_bbox_interm_dn_8': 5.0, 'loss_giou_interm_dn_8': 2.0}\n",
            "20361524\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "On training set: the maximum number of instances in a single image is 90.\n",
        "The average number of instances is 3.27\n",
        "On validation set: max is 16 mean is 2.59\n",
        "On test: max is 37 mean is 2.77"
      ],
      "metadata": {
        "id": "BblGWvwcsg_D"
      }
    }
  ]
}
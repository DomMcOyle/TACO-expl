{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "-2dI-mnxFBNC"
      ],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPFl4ojYBYp6+7CP3hpm762",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DomMcOyle/TACO-expl/blob/add_detr/Training%20notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "t = torch.randn(3,300,4)\n",
        "batchindexes = torch.arange(3).reshape(3,1,1).repeat(1,300,1)\n",
        "print(batchindexes.shape)\n",
        "#print(batchindexes)\n",
        "idx = torch.cat([batchindexes, t], -1)\n",
        "print(idx.shape)\n",
        "print(idx[0, 299, :])\n",
        "idx = idx.reshape(3*300, 5)\n",
        "print(idx.shape)\n",
        "print(idx[299,:])\n",
        "\n",
        "#print(t[-1, :, :].shape)\n",
        "#print(t.repeat(1,1,4))\n",
        "#t.view(t.shape[0], -1).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4oEkHKd2KLF4",
        "outputId": "af9264a9-e9ef-4cee-d51d-63bd5b9f17cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 300, 1])\n",
            "torch.Size([3, 300, 5])\n",
            "tensor([ 0.0000, -3.3577, -0.2601,  0.2991, -1.2073])\n",
            "torch.Size([900, 5])\n",
            "tensor([ 0.0000, -3.3577, -0.2601,  0.2991, -1.2073])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "uW0_gODeKIeQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5498ee0-117f-4a40-ed45-12d8ffb15e60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'TACO-expl' already exists and is not an empty directory.\n",
            "/content/TACO-expl\n",
            "M\tHDDETR/models/deformable_transformer.py\n",
            "Already on 'add_detr'\n",
            "Your branch is up to date with 'origin/add_detr'.\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/DomMcOyle/TACO-expl\n",
        "%cd /content/TACO-expl/\n",
        "!git checkout add_detr\n",
        "%cd /content/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/TACO-expl/HDDETR\n",
        "!pip install -r requirements.txt\n",
        "!pip install mmcv==2.1.0 -f https://download.openmmlab.com/mmcv/dist/cu118/torch2.1/index.html\n",
        "!pip install mmdet\n",
        "%cd /content/TACO-expl/HDDETR/models/ops\n",
        "!python setup.py build install\n",
        "# unit test (should see all checking is True)\n",
        "#!python test.py\n",
        "%cd /content/"
      ],
      "metadata": {
        "id": "UwcWEhm-wBCf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os.path\n",
        "import json\n",
        "import argparse\n",
        "import numpy as np\n",
        "import random\n",
        "import datetime as dt\n",
        "import copy\n",
        "import torch.nn as nn\n",
        "\n",
        "from google.colab import drive\n",
        "#drive.mount(\"/content/MyDrive/\")"
      ],
      "metadata": {
        "id": "XATP-Y3ZglE6"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#split"
      ],
      "metadata": {
        "id": "-2dI-mnxFBNC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "keep_categories = [\"Bottle\", \"Bottle cap\", \"Can\", \"Cigarette\", \"Cup\",\n",
        "                   \"Lid\", \"Plastic bag & wrapper\", \"Pop tab\", \"Straw\"]\n",
        "\n",
        "def create_map(original, keep_supercategories):\n",
        "  class_map = {}\n",
        "  for cat in original:\n",
        "    if cat[\"supercategory\"] in keep_supercategories:\n",
        "      class_map[cat[\"name\"]] = cat[\"supercategory\"]\n",
        "    else:\n",
        "      class_map[cat[\"name\"]] = \"Other\"\n",
        "  return class_map\n",
        "\n",
        "def replace_dataset_classes(dataset, class_map):\n",
        "      \"\"\" Replaces classes of dataset based on a dictionary\"\"\"\n",
        "      class_new_names = list(set(class_map.values()))\n",
        "      class_new_names.sort()\n",
        "      class_originals = copy.deepcopy(dataset['categories'])\n",
        "      dataset['categories'] = []\n",
        "      class_ids_map = {}  # map from old id to new id\n",
        "\n",
        "      # Assign background id 0\n",
        "      has_background = False\n",
        "      if 'Background' in class_new_names:\n",
        "          if class_new_names.index('Background') != 0:\n",
        "              class_new_names.remove('Background')\n",
        "              class_new_names.insert(0, 'Background')\n",
        "          has_background = True\n",
        "\n",
        "      # Replace categories\n",
        "      for id_new, class_new_name in enumerate(class_new_names):\n",
        "          # Make sure id:0 is reserved for background\n",
        "          id_rectified = id_new\n",
        "          if not has_background:\n",
        "              id_rectified += 1\n",
        "\n",
        "          category = {\n",
        "              'supercategory': '',\n",
        "              'id': id_rectified,  # Background has id=0\n",
        "              'name': class_new_name,\n",
        "          }\n",
        "          dataset['categories'].append(category)\n",
        "          # Map class names\n",
        "          for class_original in class_originals:\n",
        "              if class_map[class_original['name']] == class_new_name:\n",
        "                  class_ids_map[class_original['id']] = id_rectified\n",
        "\n",
        "      # Update annotations category id tag\n",
        "      for ann in dataset['annotations']:\n",
        "          ann['category_id'] = class_ids_map[ann['category_id']]\n"
      ],
      "metadata": {
        "id": "KutH3M6PmlFU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/TACO/data/annotations.json\", \"r\") as f:\n",
        "    dataset = json.loads(f.read())\n",
        "\n",
        "class_map = create_map(dataset[\"categories\"], keep_categories)\n",
        "replace_dataset_classes(dataset, class_map)\n",
        "dataset[\"categories\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RclP141dy5RU",
        "outputId": "66022aca-d855-436d-c343-77c8fa5b3e77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Aluminium foil': 'Other', 'Battery': 'Other', 'Aluminium blister pack': 'Other', 'Carded blister pack': 'Other', 'Other plastic bottle': 'Bottle', 'Clear plastic bottle': 'Bottle', 'Glass bottle': 'Bottle', 'Plastic bottle cap': 'Bottle cap', 'Metal bottle cap': 'Bottle cap', 'Broken glass': 'Other', 'Food Can': 'Can', 'Aerosol': 'Can', 'Drink can': 'Can', 'Toilet tube': 'Other', 'Other carton': 'Other', 'Egg carton': 'Other', 'Drink carton': 'Other', 'Corrugated carton': 'Other', 'Meal carton': 'Other', 'Pizza box': 'Other', 'Paper cup': 'Cup', 'Disposable plastic cup': 'Cup', 'Foam cup': 'Cup', 'Glass cup': 'Cup', 'Other plastic cup': 'Cup', 'Food waste': 'Other', 'Glass jar': 'Other', 'Plastic lid': 'Lid', 'Metal lid': 'Lid', 'Other plastic': 'Other', 'Magazine paper': 'Other', 'Tissues': 'Other', 'Wrapping paper': 'Other', 'Normal paper': 'Other', 'Paper bag': 'Other', 'Plastified paper bag': 'Other', 'Plastic film': 'Plastic bag & wrapper', 'Six pack rings': 'Plastic bag & wrapper', 'Garbage bag': 'Plastic bag & wrapper', 'Other plastic wrapper': 'Plastic bag & wrapper', 'Single-use carrier bag': 'Plastic bag & wrapper', 'Polypropylene bag': 'Plastic bag & wrapper', 'Crisp packet': 'Plastic bag & wrapper', 'Spread tub': 'Other', 'Tupperware': 'Other', 'Disposable food container': 'Other', 'Foam food container': 'Other', 'Other plastic container': 'Other', 'Plastic glooves': 'Other', 'Plastic utensils': 'Other', 'Pop tab': 'Pop tab', 'Rope & strings': 'Other', 'Scrap metal': 'Other', 'Shoe': 'Other', 'Squeezable tube': 'Other', 'Plastic straw': 'Straw', 'Paper straw': 'Straw', 'Styrofoam piece': 'Other', 'Unlabeled litter': 'Other', 'Cigarette': 'Cigarette'}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'supercategory': '', 'id': 1, 'name': 'Bottle'},\n",
              " {'supercategory': '', 'id': 2, 'name': 'Bottle cap'},\n",
              " {'supercategory': '', 'id': 3, 'name': 'Can'},\n",
              " {'supercategory': '', 'id': 4, 'name': 'Cigarette'},\n",
              " {'supercategory': '', 'id': 5, 'name': 'Cup'},\n",
              " {'supercategory': '', 'id': 6, 'name': 'Lid'},\n",
              " {'supercategory': '', 'id': 7, 'name': 'Other'},\n",
              " {'supercategory': '', 'id': 8, 'name': 'Plastic bag & wrapper'},\n",
              " {'supercategory': '', 'id': 9, 'name': 'Pop tab'},\n",
              " {'supercategory': '', 'id': 10, 'name': 'Straw'}]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os.path\n",
        "import json\n",
        "import argparse\n",
        "import numpy as np\n",
        "import random\n",
        "import datetime as dt\n",
        "import copy\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\"\"\"\n",
        "parser = argparse.ArgumentParser(description='User args')\n",
        "parser.add_argument('--dataset_dir', required=True, help='Path to dataset annotations')\n",
        "parser.add_argument('--test_percentage', type=int, default=10, required=False, help='Percentage of images used for the testing set')\n",
        "parser.add_argument('--val_percentage', type=int, default=10, required=False, help='Percentage of images used for the validation set')\n",
        "parser.add_argument('--nr_trials', type=int, default=10, required=False, help='Number of splits')\n",
        "\n",
        "args = parser.parse_args()\n",
        "\"\"\"\n",
        "args = {\n",
        "    \"nr_trials\":1,\n",
        "    \"test_percentage\":0.1,\n",
        "    \"val_percentage\":0.1,\n",
        "    \"dataset_dir\":'/content/TACO/data'\n",
        "}\n",
        "\n",
        "ann_input_path = args[\"dataset_dir\"] + '/annotations_unofficial.json'\n",
        "\n",
        "# Load annotations\n",
        "with open(ann_input_path, 'r') as f:\n",
        "    dataset = json.loads(f.read())\n",
        "\n",
        "keep_categories = [\"Bottle\", \"Bottle cap\", \"Can\", \"Cigarette\", \"Cup\",\n",
        "                   \"Lid\", \"Plastic bag & wrapper\", \"Pop tab\", \"Straw\"]\n",
        "if keep_categories is not None:\n",
        "  class_map = create_map(dataset[\"categories\"], keep_categories)\n",
        "  replace_dataset_classes(dataset, class_map)\n",
        "\n",
        "anns = dataset['annotations']\n",
        "scene_anns = dataset['scene_annotations']\n",
        "imgs = dataset['images']\n",
        "nr_images = len(imgs)\n",
        "\n",
        "for i in range(args[\"nr_trials\"]):\n",
        "    random.shuffle(imgs)\n",
        "\n",
        "    # Add new datasets\n",
        "    train_set = {\n",
        "        'info': None,\n",
        "        'images': [],\n",
        "        'annotations': [],\n",
        "        'scene_annotations': [],\n",
        "        'licenses': [],\n",
        "        'categories': [],\n",
        "        'scene_categories': [],\n",
        "    }\n",
        "    train_set['info'] =  dataset['info']\n",
        "    train_set['categories'] = dataset['categories']\n",
        "    train_set['scene_categories'] = dataset['scene_categories']\n",
        "\n",
        "    val_set = copy.deepcopy(train_set)\n",
        "    test_set = copy.deepcopy(train_set)\n",
        "\n",
        "    train_set['images'], partial = train_test_split(dataset['images'],\n",
        "                                                    random_state=42,\n",
        "                                                               test_size=args[\"test_percentage\"]+args[\"val_percentage\"])\n",
        "    val_set['images'], test_set[\"images\"] = train_test_split(partial,\n",
        "                                                             random_state=42,\n",
        "                                                             test_size=args[\"test_percentage\"]/(args[\"test_percentage\"]+args[\"val_percentage\"]))\n",
        "\n",
        "    # Aux Image Ids to split annotations\n",
        "    test_img_ids, val_img_ids, train_img_ids = [],[],[]\n",
        "    for img in test_set['images']:\n",
        "        test_img_ids.append(img['id'])\n",
        "\n",
        "    for img in val_set['images']:\n",
        "        val_img_ids.append(img['id'])\n",
        "\n",
        "    for img in train_set['images']:\n",
        "        train_img_ids.append(img['id'])\n",
        "\n",
        "    # Split instance annotations\n",
        "    for ann in anns:\n",
        "        if ann['image_id'] in test_img_ids:\n",
        "            test_set['annotations'].append(ann)\n",
        "        elif ann['image_id'] in val_img_ids:\n",
        "            val_set['annotations'].append(ann)\n",
        "        elif ann['image_id'] in train_img_ids:\n",
        "            train_set['annotations'].append(ann)\n",
        "\n",
        "    # Split scene tags\n",
        "    for ann in scene_anns:\n",
        "        if ann['image_id'] in test_img_ids:\n",
        "            test_set['scene_annotations'].append(ann)\n",
        "        elif ann['image_id'] in val_img_ids:\n",
        "            val_set['scene_annotations'].append(ann)\n",
        "        elif ann['image_id'] in train_img_ids:\n",
        "            train_set['scene_annotations'].append(ann)\n",
        "\n",
        "    # Write dataset splits\n",
        "    ann_train_out_path = args[\"dataset_dir\"] + '/' + 'annotations_' + str(i) +'_train.json'\n",
        "    ann_val_out_path   = args[\"dataset_dir\"] + '/' + 'annotations_' + str(i) + '_val.json'\n",
        "    ann_test_out_path  = args[\"dataset_dir\"] + '/' + 'annotations_' + str(i) + '_test.json'\n",
        "\n",
        "    with open(ann_train_out_path, 'w+') as f:\n",
        "        f.write(json.dumps(train_set))\n",
        "\n",
        "    with open(ann_val_out_path, 'w+') as f:\n",
        "        f.write(json.dumps(val_set))\n",
        "\n",
        "    with open(ann_test_out_path, 'w+') as f:\n",
        "        f.write(json.dumps(test_set))\n"
      ],
      "metadata": {
        "id": "EDh8FFzFhqut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#detr"
      ],
      "metadata": {
        "id": "8s9VTnF5FG-q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd TACO-expl\n",
        "import HDDETR.models\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W6-jdzdO88WS",
        "outputId": "67a6d67b-dc6a-4ed1-f63b-99e1a34349cd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/TACO-expl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/HDETR/H-Deformable-DETR/releases/download/v0.1/r50_hybrid_branch_lambda1_group6_t1500_dp0_mqs_lft_deformable_detr_plus_iterative_bbox_refinement_plus_plus_two_stage_36eps.pth\n",
        "!mv r50_hybrid_branch_lambda1_group6_t1500_dp0_mqs_lft_deformable_detr_plus_iterative_bbox_refinement_plus_plus_two_stage_36eps.pth r50.pth"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ERweJ8HTfm9",
        "outputId": "434dfd90-08fc-42fd-91e5-ebc7d8872bdd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-01-14 20:16:32--  https://github.com/HDETR/H-Deformable-DETR/releases/download/v0.1/r50_hybrid_branch_lambda1_group6_t1500_dp0_mqs_lft_deformable_detr_plus_iterative_bbox_refinement_plus_plus_two_stage_36eps.pth\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/517883062/ce62ee7a-43ec-4230-8bf1-348a1530d246?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240114%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240114T201633Z&X-Amz-Expires=300&X-Amz-Signature=5840f83ca0e4d81b9da992955462b32988c19c4e8ac19e49686f26d299ccb21a&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=517883062&response-content-disposition=attachment%3B%20filename%3Dr50_hybrid_branch_lambda1_group6_t1500_dp0_mqs_lft_deformable_detr_plus_iterative_bbox_refinement_plus_plus_two_stage_36eps.pth&response-content-type=application%2Foctet-stream [following]\n",
            "--2024-01-14 20:16:33--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/517883062/ce62ee7a-43ec-4230-8bf1-348a1530d246?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240114%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240114T201633Z&X-Amz-Expires=300&X-Amz-Signature=5840f83ca0e4d81b9da992955462b32988c19c4e8ac19e49686f26d299ccb21a&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=517883062&response-content-disposition=attachment%3B%20filename%3Dr50_hybrid_branch_lambda1_group6_t1500_dp0_mqs_lft_deformable_detr_plus_iterative_bbox_refinement_plus_plus_two_stage_36eps.pth&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 192422339 (184M) [application/octet-stream]\n",
            "Saving to: ‘r50_hybrid_branch_lambda1_group6_t1500_dp0_mqs_lft_deformable_detr_plus_iterative_bbox_refinement_plus_plus_two_stage_36eps.pth’\n",
            "\n",
            "r50_hybrid_branch_l 100%[===================>] 183.51M   145MB/s    in 1.3s    \n",
            "\n",
            "2024-01-14 20:16:34 (145 MB/s) - ‘r50_hybrid_branch_lambda1_group6_t1500_dp0_mqs_lft_deformable_detr_plus_iterative_bbox_refinement_plus_plus_two_stage_36eps.pth’ saved [192422339/192422339]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "model = torch.load(\"r50.pth\")"
      ],
      "metadata": {
        "id": "LYKL-11mT_sh"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "h8Eu-o-vUs6H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(model['model'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2kxDADFULrh",
        "outputId": "f7b8744e-6855-4932-a756-ea25c31ca880"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "collections.OrderedDict"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class AttrDict(dict):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super(AttrDict, self).__init__(*args, **kwargs)\n",
        "        self.__dict__ = self\n",
        "\n",
        "args = AttrDict()\n",
        "args.output_dir = './out/'\n",
        "args.with_box_refine = True\n",
        "args.two_stage = True\n",
        "args.dim_feedforward = 2048\n",
        "args.num_queries_one2one = 300\n",
        "args.num_queries_one2many = 1500\n",
        "args.k_one2many = 6\n",
        "args.lambda_one2many = 1.0\n",
        "args.mixed_selection = True\n",
        "args.look_forward_twice = True\n",
        "args.dataset_file = \"coco\"\n",
        "args.device = 'cuda'\n",
        "args.hidden_dim = 256\n",
        "args.position_embedding = 'sine'\n",
        "args.position_embedding_scale = np.pi *2\n",
        "#args.lr_backbone =2e-5\n",
        "args.lr_backbone = 0\n",
        "args.masks = False\n",
        "args.num_feature_levels = 4\n",
        "args.backbone = \"resnet50\"\n",
        "args.dilation = False\n",
        "args.nheads = 8\n",
        "args.enc_layers = 6\n",
        "args.dec_layers = 6\n",
        "args.dim_feedforwards = 2048\n",
        "args.dropout = 0\n",
        "args.dec_n_points = 4\n",
        "args.enc_n_points = 4\n",
        "args.use_checkpoint = True\n",
        "args.aux_loss = True\n",
        "args.cls_loss_coef=2\n",
        "args.giou_loss_coef=2\n",
        "args.focal_alpha=0.25\n",
        "args.topk=100\n",
        "args.bbox_loss_coef=5\n",
        "args.set_cost_class=2\n",
        "args.set_cost_bbox=5\n",
        "args.set_cost_giou=2"
      ],
      "metadata": {
        "id": "hcD6Qhp9AE7K"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model,crit, postproc = HDDETR.models.build(args)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "phzP-ZP3SKEW",
        "outputId": "fb47b74a-5c19-464d-e475-a4702d107066"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "topk for eval: 100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load(\"r50.pth\")[\"model\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tkc3mVUFqkaB",
        "outputId": "d6d7e790-174e-4b2b-ea9c-599130d4f464"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from HDDETR.util.misc import NestedTensor\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "\n",
        "dev = torch.device(\"cuda\")\n",
        "model.to(dev)\n",
        "to_t = transforms.ToTensor()\n",
        "img = Image.open(\"treno.jpg\")\n",
        "a = to_t(img).reshape((1,3,640,480))\n",
        "a = a.to(dev)\n",
        "mask = torch.zeros((1,640,480), dtype=torch.bool, device=dev)\n",
        "mask = mask.to(dev)\n",
        "nt = NestedTensor(a, mask)\n",
        "nt = nt.to(dev)"
      ],
      "metadata": {
        "id": "Aa-WuoDL55-M"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out = model(nt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KM8tSgljPTF-",
        "outputId": "98db9709-c4b6-4136-903d-429be608a0f4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([   0, 4800, 6000, 6300], device='cuda:0')\n",
            "tensor([[80, 60],\n",
            "        [40, 30],\n",
            "        [20, 15],\n",
            "        [10,  8]], device='cuda:0')\n",
            "tensor([[[1., 1.],\n",
            "         [1., 1.],\n",
            "         [1., 1.],\n",
            "         [1., 1.]]], device='cuda:0')\n",
            "tensor([[[ 0.1514,  1.0120,  0.0590,  ...,  0.3137,  1.3566,  0.1682],\n",
            "         [ 0.1514,  1.0120,  0.0590,  ...,  0.3137,  1.3566,  0.1682],\n",
            "         [ 0.1514,  1.0120,  0.0590,  ...,  0.3137,  1.3566,  0.1682],\n",
            "         ...,\n",
            "         [ 0.6646,  0.4375, -0.5388,  ..., -0.2039, -0.2458,  2.5909],\n",
            "         [ 0.6646,  0.4375, -0.5388,  ..., -0.2039, -0.2457,  2.5909],\n",
            "         [ 0.6646,  0.4375, -0.5388,  ..., -0.2039, -0.2456,  2.5909]]],\n",
            "       device='cuda:0', grad_fn=<CatBackward0>)\n",
            "tensor([   0, 4800, 6000, 6300], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([   0, 4800, 6000, 6300], device='cuda:0')\n",
            "tensor([   0, 4800, 6000, 6300], device='cuda:0')\n",
            "tensor([   0, 4800, 6000, 6300], device='cuda:0')\n",
            "tensor([   0, 4800, 6000, 6300], device='cuda:0')\n",
            "tensor([   0, 4800, 6000, 6300], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for k in out.keys():\n",
        "  print(k)\n",
        "  print(type(out[k]))\n",
        "\n",
        "  if type(out[k]) == torch.Tensor:\n",
        "    print(out[k].shape)\n",
        "  else:\n",
        "    print(out[k])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nmdiV03DXBER",
        "outputId": "7740298b-db7d-4527-8cb7-a9a5e45a48aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "decoder_out\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([6, 1, 1800, 256])\n",
            "pred_logits\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 300, 91])\n",
            "pred_boxes\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 300, 4])\n",
            "pred_logits_one2many\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 1500, 91])\n",
            "pred_boxes_one2many\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 1500, 4])\n",
            "backbone_out\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 256, 160, 120])\n",
            "intermediate_enc_out\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([1, 6380, 1024])\n",
            "aux_outputs\n",
            "<class 'list'>\n",
            "[{'pred_logits': tensor([[[-9.1464, -5.4714, -6.6855,  ..., -7.2224, -5.6382, -5.7590],\n",
            "         [-9.4401, -5.2760, -6.4668,  ..., -6.9920, -5.5224, -5.7362],\n",
            "         [-9.3116, -5.3722, -6.6665,  ..., -7.0782, -6.0493, -6.0677],\n",
            "         ...,\n",
            "         [-9.5011, -5.5192, -7.4980,  ..., -8.1119, -7.0149, -6.5823],\n",
            "         [-9.2461, -5.0731, -6.0116,  ..., -5.9315, -5.1204, -5.7667],\n",
            "         [-9.0631, -6.3629, -7.4295,  ..., -8.3089, -6.6256, -6.0667]]],\n",
            "       device='cuda:0', grad_fn=<UnbindBackward0>), 'pred_boxes': tensor([[[0.5958, 0.5342, 0.7726, 0.1303],\n",
            "         [0.5332, 0.5343, 0.6300, 0.1278],\n",
            "         [0.6524, 0.5328, 0.6413, 0.1324],\n",
            "         ...,\n",
            "         [0.4982, 0.7311, 0.9940, 0.5090],\n",
            "         [0.5233, 0.5248, 0.1824, 0.1085],\n",
            "         [0.4958, 0.4569, 0.9994, 0.0676]]], device='cuda:0',\n",
            "       grad_fn=<UnbindBackward0>)}, {'pred_logits': tensor([[[-8.9839, -5.3537, -6.1096,  ..., -6.4498, -5.2807, -5.3669],\n",
            "         [-8.5615, -5.0836, -5.8192,  ..., -6.0359, -4.4536, -4.7752],\n",
            "         [-8.7051, -5.0004, -6.2829,  ..., -6.0863, -5.3307, -5.2325],\n",
            "         ...,\n",
            "         [-9.0819, -5.5886, -7.3676,  ..., -7.3814, -6.6480, -6.2322],\n",
            "         [-8.7685, -5.3897, -6.3383,  ..., -5.8602, -5.3996, -5.5507],\n",
            "         [-8.4446, -5.3611, -7.4337,  ..., -7.5528, -6.0232, -5.2630]]],\n",
            "       device='cuda:0', grad_fn=<UnbindBackward0>), 'pred_boxes': tensor([[[0.5513, 0.5320, 0.8440, 0.1315],\n",
            "         [0.5233, 0.5322, 0.6561, 0.1274],\n",
            "         [0.6291, 0.5319, 0.6905, 0.1311],\n",
            "         ...,\n",
            "         [0.5001, 0.7351, 0.9966, 0.4991],\n",
            "         [0.5202, 0.5266, 0.1737, 0.1127],\n",
            "         [0.4974, 0.4627, 0.9994, 0.0764]]], device='cuda:0',\n",
            "       grad_fn=<UnbindBackward0>)}, {'pred_logits': tensor([[[-9.3076, -5.9032, -7.0668,  ..., -7.0332, -6.3691, -5.9612],\n",
            "         [-8.9808, -5.3084, -6.6296,  ..., -6.3844, -5.2739, -5.4630],\n",
            "         [-9.1728, -5.3358, -6.7557,  ..., -6.7137, -5.8399, -5.7662],\n",
            "         ...,\n",
            "         [-7.0762, -6.1367, -6.4410,  ..., -6.4030, -6.2287, -6.5342],\n",
            "         [-9.0209, -6.0317, -7.2598,  ..., -6.3561, -5.7358, -6.2400],\n",
            "         [-8.2293, -5.4590, -7.0555,  ..., -6.7459, -6.4194, -5.7968]]],\n",
            "       device='cuda:0', grad_fn=<UnbindBackward0>), 'pred_boxes': tensor([[[0.5560, 0.5338, 0.8593, 0.1290],\n",
            "         [0.5338, 0.5320, 0.6287, 0.1226],\n",
            "         [0.6312, 0.5297, 0.7035, 0.1271],\n",
            "         ...,\n",
            "         [0.5810, 0.8894, 0.9904, 0.0795],\n",
            "         [0.5218, 0.5209, 0.1733, 0.1007],\n",
            "         [0.4994, 0.4615, 0.9999, 0.0784]]], device='cuda:0',\n",
            "       grad_fn=<UnbindBackward0>)}, {'pred_logits': tensor([[[-8.9766, -5.6793, -6.3549,  ..., -6.3095, -6.3122, -6.2769],\n",
            "         [-8.8415, -5.1334, -6.0721,  ..., -5.4987, -5.8418, -5.5147],\n",
            "         [-8.9473, -5.1982, -6.0162,  ..., -5.7940, -5.9566, -5.8753],\n",
            "         ...,\n",
            "         [-8.4046, -5.7123, -6.6888,  ..., -6.4581, -7.7500, -6.6711],\n",
            "         [-8.4063, -5.6683, -6.4589,  ..., -6.0884, -6.8918, -6.2125],\n",
            "         [-8.9690, -5.1773, -6.4497,  ..., -6.7569, -6.4095, -6.0688]]],\n",
            "       device='cuda:0', grad_fn=<UnbindBackward0>), 'pred_boxes': tensor([[[0.5481, 0.5333, 0.8663, 0.1283],\n",
            "         [0.5398, 0.5336, 0.6183, 0.1237],\n",
            "         [0.6266, 0.5303, 0.7103, 0.1278],\n",
            "         ...,\n",
            "         [0.5952, 0.6161, 0.9880, 0.0248],\n",
            "         [0.5318, 0.1726, 0.1441, 0.0288],\n",
            "         [0.4995, 0.4636, 0.9999, 0.0802]]], device='cuda:0',\n",
            "       grad_fn=<UnbindBackward0>)}, {'pred_logits': tensor([[[-8.6739, -5.9056, -6.5313,  ..., -6.5802, -6.4772, -6.1854],\n",
            "         [-9.0635, -4.9194, -6.0888,  ..., -5.7897, -5.8840, -5.3623],\n",
            "         [-9.0340, -5.2086, -5.9033,  ..., -5.9945, -5.9465, -5.5769],\n",
            "         ...,\n",
            "         [-8.5341, -5.6703, -6.7822,  ..., -6.6434, -6.6095, -6.8442],\n",
            "         [-8.4740, -5.5879, -6.9138,  ..., -6.8244, -5.9254, -6.5917],\n",
            "         [-9.0406, -5.1653, -6.1672,  ..., -6.4978, -6.0374, -5.4645]]],\n",
            "       device='cuda:0', grad_fn=<UnbindBackward0>), 'pred_boxes': tensor([[[0.5481, 0.5333, 0.8662, 0.1283],\n",
            "         [0.5407, 0.5335, 0.6205, 0.1238],\n",
            "         [0.6269, 0.5309, 0.7115, 0.1270],\n",
            "         ...,\n",
            "         [0.5806, 0.6038, 0.9868, 0.0278],\n",
            "         [0.4885, 0.1924, 0.1196, 0.0358],\n",
            "         [0.4989, 0.4637, 0.9999, 0.0801]]], device='cuda:0',\n",
            "       grad_fn=<UnbindBackward0>)}]\n",
            "aux_outputs_one2many\n",
            "<class 'list'>\n",
            "[{'pred_logits': tensor([[[-9.4342, -5.4224, -7.4477,  ..., -7.3881, -7.6639, -6.4262],\n",
            "         [-9.3218, -4.6414, -7.1140,  ..., -6.9552, -6.3678, -6.5553],\n",
            "         [-8.7442, -5.6262, -6.4196,  ..., -7.6309, -5.5621, -5.9995],\n",
            "         ...,\n",
            "         [-8.9067, -5.0816, -6.2803,  ..., -6.5509, -5.8654, -6.0278],\n",
            "         [-9.1184, -4.4619, -6.8215,  ..., -7.3943, -6.6029, -6.3358],\n",
            "         [-9.0006, -5.2829, -7.4980,  ..., -7.3893, -7.1775, -6.5022]]],\n",
            "       device='cuda:0', grad_fn=<UnbindBackward0>), 'pred_boxes': tensor([[[3.0927e-01, 8.0648e-01, 5.8850e-01, 3.8141e-01],\n",
            "         [1.2019e-01, 5.0282e-01, 2.3565e-01, 2.2425e-01],\n",
            "         [4.9750e-01, 5.4245e-01, 9.9998e-01, 1.6708e-01],\n",
            "         ...,\n",
            "         [3.8728e-01, 1.7162e-04, 1.5341e-01, 4.9067e-04],\n",
            "         [4.7858e-01, 3.0559e-01, 9.2879e-01, 6.3704e-01],\n",
            "         [1.0242e-01, 7.6202e-01, 1.9286e-01, 4.5265e-01]]], device='cuda:0',\n",
            "       grad_fn=<UnbindBackward0>)}, {'pred_logits': tensor([[[-8.9845, -5.1789, -6.9711,  ..., -7.0799, -6.4810, -5.7990],\n",
            "         [-8.6339, -5.0844, -6.4991,  ..., -6.5847, -5.4649, -5.9503],\n",
            "         [-8.5644, -5.1265, -6.6520,  ..., -7.1195, -5.6218, -5.2057],\n",
            "         ...,\n",
            "         [-7.9008, -5.1634, -6.1989,  ..., -5.7972, -5.2090, -4.6111],\n",
            "         [-8.6110, -4.5708, -6.7903,  ..., -6.7730, -5.8111, -5.9863],\n",
            "         [-8.4927, -5.0133, -6.4924,  ..., -6.4634, -6.6644, -5.7257]]],\n",
            "       device='cuda:0', grad_fn=<UnbindBackward0>), 'pred_boxes': tensor([[[2.6403e-01, 7.9628e-01, 5.3627e-01, 3.9457e-01],\n",
            "         [1.4585e-01, 5.0907e-01, 2.8502e-01, 1.8643e-01],\n",
            "         [4.9864e-01, 5.3815e-01, 9.9998e-01, 1.4818e-01],\n",
            "         ...,\n",
            "         [4.0673e-01, 1.4914e-04, 1.3054e-01, 4.1053e-04],\n",
            "         [4.9530e-01, 3.0198e-01, 9.9630e-01, 6.0694e-01],\n",
            "         [1.0480e-01, 8.3865e-01, 2.0506e-01, 3.3535e-01]]], device='cuda:0',\n",
            "       grad_fn=<UnbindBackward0>)}, {'pred_logits': tensor([[[-9.2511, -5.5921, -6.7948,  ..., -6.9381, -7.1851, -6.5518],\n",
            "         [-9.3229, -5.4183, -6.4086,  ..., -6.8895, -5.6768, -6.2692],\n",
            "         [-7.9644, -4.9105, -6.2899,  ..., -6.6782, -6.1126, -5.0126],\n",
            "         ...,\n",
            "         [-7.8072, -5.2296, -6.0295,  ..., -5.8005, -5.2056, -5.4383],\n",
            "         [-8.7041, -5.2679, -6.8245,  ..., -7.0507, -6.1537, -7.0477],\n",
            "         [-8.8118, -5.5895, -6.6983,  ..., -6.7077, -7.0328, -6.4879]]],\n",
            "       device='cuda:0', grad_fn=<UnbindBackward0>), 'pred_boxes': tensor([[[2.8828e-01, 7.9097e-01, 5.6629e-01, 4.0103e-01],\n",
            "         [1.3936e-01, 5.1162e-01, 2.8095e-01, 1.7025e-01],\n",
            "         [5.0032e-01, 5.3438e-01, 9.9999e-01, 1.4091e-01],\n",
            "         ...,\n",
            "         [3.8232e-01, 1.1437e-04, 1.1463e-01, 4.1495e-04],\n",
            "         [4.9778e-01, 3.0984e-01, 9.9995e-01, 6.1339e-01],\n",
            "         [1.2884e-01, 8.4197e-01, 2.5646e-01, 3.0338e-01]]], device='cuda:0',\n",
            "       grad_fn=<UnbindBackward0>)}, {'pred_logits': tensor([[[-9.1730, -5.3791, -6.6004,  ..., -6.8685, -6.9900, -6.5145],\n",
            "         [-9.1855, -4.9885, -6.4339,  ..., -6.4798, -6.2588, -6.0279],\n",
            "         [-8.5151, -5.0058, -5.6830,  ..., -6.0606, -5.8857, -5.2733],\n",
            "         ...,\n",
            "         [-8.5570, -4.7840, -6.1424,  ..., -6.0426, -5.3798, -5.1242],\n",
            "         [-8.8108, -5.4372, -6.4895,  ..., -6.3590, -6.9444, -6.7728],\n",
            "         [-9.0296, -5.0699, -6.6191,  ..., -6.7555, -7.1096, -6.4080]]],\n",
            "       device='cuda:0', grad_fn=<UnbindBackward0>), 'pred_boxes': tensor([[[2.8773e-01, 7.9038e-01, 5.6801e-01, 3.9864e-01],\n",
            "         [1.4001e-01, 5.1206e-01, 2.7845e-01, 1.7068e-01],\n",
            "         [5.0033e-01, 5.3392e-01, 9.9999e-01, 1.4023e-01],\n",
            "         ...,\n",
            "         [3.8461e-01, 1.1113e-04, 1.1170e-01, 3.7173e-04],\n",
            "         [4.9835e-01, 1.9075e-01, 9.9995e-01, 4.1950e-01],\n",
            "         [1.2922e-01, 8.4154e-01, 2.5489e-01, 3.0196e-01]]], device='cuda:0',\n",
            "       grad_fn=<UnbindBackward0>)}, {'pred_logits': tensor([[[-8.8885, -5.2423, -6.6059,  ..., -6.8515, -6.6397, -6.2700],\n",
            "         [-9.0667, -4.6853, -6.4483,  ..., -6.3147, -5.7327, -5.6608],\n",
            "         [-8.9194, -5.0382, -5.6187,  ..., -6.0633, -5.8549, -5.0398],\n",
            "         ...,\n",
            "         [-8.7431, -4.8664, -6.5450,  ..., -6.1658, -5.5729, -5.1465],\n",
            "         [-8.5549, -5.6095, -6.9361,  ..., -6.8187, -6.6545, -6.7836],\n",
            "         [-8.9465, -5.0264, -6.5240,  ..., -6.7934, -6.8112, -6.0735]]],\n",
            "       device='cuda:0', grad_fn=<UnbindBackward0>), 'pred_boxes': tensor([[[2.9602e-01, 7.8682e-01, 5.7957e-01, 4.0633e-01],\n",
            "         [1.4019e-01, 5.1141e-01, 2.7925e-01, 1.7179e-01],\n",
            "         [4.9965e-01, 5.3392e-01, 9.9999e-01, 1.4025e-01],\n",
            "         ...,\n",
            "         [3.8245e-01, 1.1202e-04, 1.1034e-01, 3.6631e-04],\n",
            "         [4.9664e-01, 1.9995e-01, 9.9995e-01, 4.0454e-01],\n",
            "         [1.3005e-01, 8.3695e-01, 2.5774e-01, 3.1240e-01]]], device='cuda:0',\n",
            "       grad_fn=<UnbindBackward0>)}]\n",
            "enc_outputs\n",
            "<class 'dict'>\n",
            "{'pred_logits': tensor([[[ -6.5916, -10.6104, -10.2954,  ..., -10.3569, -10.3681, -10.4074],\n",
            "         [ -6.5916, -10.6104, -10.2954,  ..., -10.3569, -10.3681, -10.4074],\n",
            "         [ -6.5916, -10.6104, -10.2954,  ..., -10.3569, -10.3681, -10.4074],\n",
            "         ...,\n",
            "         [ -5.5594,  -9.6132,  -9.2637,  ...,  -9.4667,  -9.2935,  -9.2204],\n",
            "         [ -5.9165,  -9.3873,  -8.9957,  ...,  -9.2332,  -9.0688,  -8.9577],\n",
            "         [ -5.9886,  -8.8823,  -8.5054,  ...,  -8.7076,  -8.5924,  -8.4887]]],\n",
            "       device='cuda:0', grad_fn=<ViewBackward0>), 'pred_boxes': tensor([[[1.0000, 1.0000, 1.0000, 1.0000],\n",
            "         [1.0000, 1.0000, 1.0000, 1.0000],\n",
            "         [1.0000, 1.0000, 1.0000, 1.0000],\n",
            "         ...,\n",
            "         [0.6014, 0.9525, 0.7749, 0.0765],\n",
            "         [0.8924, 0.9188, 0.1700, 0.1212],\n",
            "         [0.9927, 0.8992, 0.0174, 0.1953]]], device='cuda:0',\n",
            "       grad_fn=<SigmoidBackward0>)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from HDDETR.models.deformable_transformer import DeformableTransformerEncoderLayer\n",
        "from torchvision.ops import ROIAlign\n",
        "from HDDETR.util.misc import interpolate\n",
        "class MaskFrozenDETR(nn.Module):\n",
        "  def __init__(self, detr, device):\n",
        "    super.__init__()\n",
        "    self.device = device\n",
        "    self.detr = detr\n",
        "    for param in detr.parameters():\n",
        "      param.requires_grad = False\n",
        "    # vedi deformable encoder block\n",
        "    self.feature_enc_1 = DeformableTransformerEncoderLayer(d_model=256,dropout=0, activation='gelu')\n",
        "    self.feature_enc_2 = DeformableTransformerEncoderLayer(d_model=256,dropout=0, activation='gelu')\n",
        "    self.box_enc_1 = DeformableTransformerEncoderLayer(d_model=128,dropout=0, activation='gelu')\n",
        "    self.box_enc_2 = DeformableTransformerEncoderLayer(d_model=128,dropout=0, activation='gelu')\n",
        "    self.channel_mapper = nn.Linear(256, 128)\n",
        "    self.query_channel_mapper = nn.Linear(256, 128)\n",
        "    self.roialign = ROIAlign(output_size=(32,32),spatial_scale=0.25 )\n",
        "    self.class_adapter1 = nn.linear(91, 10)\n",
        "    self.class_adapter2 = nn.linear(48, 10)\n",
        "    self.topk = 100\n",
        "  def forward(self, input, sizes):\n",
        "    bs, _, h, w = input.tensors.shape\n",
        "    detr_out = self.detr(input)\n",
        "\n",
        "    ref_points = self.detr.transformer.encoder.get_reference_points(detr_out[\"intermediate_enc_out\"][\"spatial_shapes\"],\n",
        "                                                                    detr_out[\"intermediate_enc_out\"][\"valid_ratios\"],\n",
        "                                                                    self.device)\n",
        "    enc_maps = self.feature_enc_1(**detr_out[\"intermediate_enc_out\"], reference_points=ref_points)\n",
        "    detr_out[\"intermediate_enc_out\"][\"src\"] = enc_maps\n",
        "    enc_maps = self.feature_enc_2(**detr_out[\"intermediate_enc_out\"], reference_points=ref_points).permute(0, 2, 1)\n",
        "    fe = interpolate(enc_maps, detr_out[\"backbone_out\"].shape, \"bilnear\")\n",
        "    f = detr_out[\"backbone_out\"].view((bs, 256, -1 )) + fe\n",
        "    mapped_f = self.channel_mapper(f)\n",
        "\n",
        "\n",
        "    logits = detr_out['pred_logits']\n",
        "    logits = self.class_adapter1(logits)\n",
        "    logits = self.class_adapter2(logits)\n",
        "    ci = logits.sigmoid()\n",
        "    topk_values, topk_indexes = torch.topk(\n",
        "            ci.view(logits.shape[0], -1), self.topk, dim=1\n",
        "    )\n",
        "    topk_boxes = topk_indexes // logits.shape[2]\n",
        "    boxes = box_ops.box_cxcywh_to_xyxy(detr_out[\"pred_boxes\"])\n",
        "    boxes = torch.gather(boxes, 1, topk_boxes.unsqueeze(-1).repeat(1, 1, 4))\n",
        "    img_h, img_w = sizes.unbind(1)\n",
        "    scale_fct = torch.stack([img_w, img_h, img_w, img_h], dim=1)\n",
        "    boxes = boxes * scale_fct[:, None, :]\n",
        "    object_queries = detr_out[\"decoder_out\"][-1, :, :self.detr.num_queries_one2one, :]\n",
        "    object_queries = torch.gather(object_queries, 1, topk_boxes.unsqueeze(-1).repeat(1,1,object_queries.shape[-1]))\n",
        "\n",
        "    batchindexes = torch.arange(bs).reshape(bs,1,1).repeat(1,self.topk,1)\n",
        "    boxes = torch.cat([batchindexes, boxes], -1).reshape(bs*self.topk, 5)\n",
        "    Ri = ROIAlign(mapped_f.reshape((bs, 128, h//4, w//4 )), boxes)\n",
        "    maskRi = ROIAlign(detr_out[\"intermediate_enc_out\"][\"padding_mask\"].reshape((bs,h//4, w//4 )), object_queries)\n",
        "    Ri = Ri.permute(0, 2, 3, 1).reshape(bs*self.topk,32*32, 128) # ?\n",
        "    valid_ratios_box = torch.stack([self.detr.transformer.get_valid_ratio(m) for m in maskRi], 1)\n",
        "    ref_point_box = self.detr.transformer.encoder.get_reference_points(torch.tensor([[32,32]]),\n",
        "                                                                    valid_ratios_box,\n",
        "                                                                    self.device)\n",
        "    Ri = self.box_enc_1(Ri, padding_mask=maskRi,\n",
        "                        level_start_index=torch.tensor([0]),\n",
        "                        pos=None,\n",
        "                        reference_points=ref_point_box,\n",
        "                        spatial_shapes=torch.tensor([[32,32]]))\n",
        "    Ri = self.box_enc_2(Ri, padding_mask=maskRi,\n",
        "                        level_start_index=torch.tensor([0]),\n",
        "                        pos=None,\n",
        "                        reference_points=ref_point_box,\n",
        "                        spatial_shapes=torch.tensor([[32,32]])))\n",
        "    object_queries = self.query_channel_mapper(objecy_queries).reshape(bs*self.topk, 128)\n",
        "    segmasks = torch.bmm(object_queries, torch.transpose(Ri, 1,2)).sigmoid().reshape(bs, 100, 32, 32)\n",
        "    segmasks = interpolate()\n",
        "    # prendere la maschera con i confidence score più alti ?\n",
        "    # vedere build_model + engine\n",
        "    # TODO: capire come selezionare le maschere\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vohh7Js-FMQa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "outputId": "d2cf8ba6-ec80-4e73-8186-3fe84429857e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-8-e8b73c1bea3e>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    class MaskFrozenDETR(nn.Module):\u001b[0m\n\u001b[0m                                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
          ]
        }
      ]
    }
  ]
}
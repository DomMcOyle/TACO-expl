{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DomMcOyle/TACO-expl/blob/add_detr/Training%20notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uW0_gODeKIeQ",
        "outputId": "0b0c198f-c95d-46d6-f447-4907a5a7faba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'TACO-expl'...\n",
            "remote: Enumerating objects: 986, done.\u001b[K\n",
            "remote: Counting objects: 100% (412/412), done.\u001b[K\n",
            "remote: Compressing objects: 100% (171/171), done.\u001b[K\n",
            "remote: Total 986 (delta 269), reused 378 (delta 239), pack-reused 574\u001b[K\n",
            "Receiving objects: 100% (986/986), 99.71 MiB | 26.27 MiB/s, done.\n",
            "Resolving deltas: 100% (642/642), done.\n",
            "/content/TACO-expl\n",
            "Branch 'add_detr' set up to track remote branch 'add_detr' from 'origin'.\n",
            "Switched to a new branch 'add_detr'\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/DomMcOyle/TACO-expl\n",
        "%cd /content/TACO-expl/\n",
        "!git checkout add_detr\n",
        "%cd /content/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pUv0ZCdoQwPv"
      },
      "source": [
        "After running the following cell, reset the environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UwcWEhm-wBCf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca7f1642-157e-44f1-87a1-fed90965f586"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/TACO-expl/HDDETR\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (2.0.7)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (4.66.1)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (3.0.8)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (1.11.4)\n",
            "Collecting wandb (from -r requirements.txt (line 5))\n",
            "  Downloading wandb-0.16.2-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting timm (from -r requirements.txt (line 6))\n",
            "  Downloading timm-0.9.12-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from pycocotools->-r requirements.txt (line 1)) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pycocotools->-r requirements.txt (line 1)) (1.23.5)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 5)) (8.1.7)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb->-r requirements.txt (line 5))\n",
            "  Downloading GitPython-3.1.41-py3-none-any.whl (196 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.4/196.4 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 5)) (2.31.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 5)) (5.9.5)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb->-r requirements.txt (line 5))\n",
            "  Downloading sentry_sdk-1.40.1-py2.py3-none-any.whl (257 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m257.8/257.8 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb->-r requirements.txt (line 5))\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 5)) (6.0.1)\n",
            "Collecting setproctitle (from wandb->-r requirements.txt (line 5))\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 5)) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 5)) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 5)) (3.20.3)\n",
            "Requirement already satisfied: torch>=1.7 in /usr/local/lib/python3.10/dist-packages (from timm->-r requirements.txt (line 6)) (2.1.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm->-r requirements.txt (line 6)) (0.16.0+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from timm->-r requirements.txt (line 6)) (0.20.3)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm->-r requirements.txt (line 6)) (0.4.2)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb->-r requirements.txt (line 5)) (1.16.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 5))\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools->-r requirements.txt (line 1)) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools->-r requirements.txt (line 1)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools->-r requirements.txt (line 1)) (4.47.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools->-r requirements.txt (line 1)) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools->-r requirements.txt (line 1)) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools->-r requirements.txt (line 1)) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools->-r requirements.txt (line 1)) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools->-r requirements.txt (line 1)) (2.8.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 5)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 5)) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 5)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 5)) (2024.2.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm->-r requirements.txt (line 6)) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm->-r requirements.txt (line 6)) (4.9.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm->-r requirements.txt (line 6)) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm->-r requirements.txt (line 6)) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm->-r requirements.txt (line 6)) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm->-r requirements.txt (line 6)) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm->-r requirements.txt (line 6)) (2.1.0)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 5))\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7->timm->-r requirements.txt (line 6)) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7->timm->-r requirements.txt (line 6)) (1.3.0)\n",
            "Installing collected packages: smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, GitPython, wandb, timm\n",
            "Successfully installed GitPython-3.1.41 docker-pycreds-0.4.0 gitdb-4.0.11 sentry-sdk-1.40.1 setproctitle-1.3.3 smmap-5.0.1 timm-0.9.12 wandb-0.16.2\n",
            "Looking in links: https://download.openmmlab.com/mmcv/dist/cu118/torch2.1/index.html\n",
            "Collecting mmcv==2.1.0\n",
            "  Downloading https://download.openmmlab.com/mmcv/dist/cu118/torch2.1.0/mmcv-2.1.0-cp310-cp310-manylinux1_x86_64.whl (99.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.3/99.3 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting addict (from mmcv==2.1.0)\n",
            "  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
            "Collecting mmengine>=0.3.0 (from mmcv==2.1.0)\n",
            "  Downloading mmengine-0.10.3-py3-none-any.whl (451 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m451.7/451.7 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mmcv==2.1.0) (1.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from mmcv==2.1.0) (23.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from mmcv==2.1.0) (9.4.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from mmcv==2.1.0) (6.0.1)\n",
            "Collecting yapf (from mmcv==2.1.0)\n",
            "  Downloading yapf-0.40.2-py3-none-any.whl (254 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m254.7/254.7 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opencv-python>=3 in /usr/local/lib/python3.10/dist-packages (from mmcv==2.1.0) (4.8.0.76)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mmengine>=0.3.0->mmcv==2.1.0) (3.7.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from mmengine>=0.3.0->mmcv==2.1.0) (13.7.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from mmengine>=0.3.0->mmcv==2.1.0) (2.4.0)\n",
            "Requirement already satisfied: importlib-metadata>=6.6.0 in /usr/local/lib/python3.10/dist-packages (from yapf->mmcv==2.1.0) (7.0.1)\n",
            "Requirement already satisfied: platformdirs>=3.5.1 in /usr/local/lib/python3.10/dist-packages (from yapf->mmcv==2.1.0) (4.2.0)\n",
            "Requirement already satisfied: tomli>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from yapf->mmcv==2.1.0) (2.0.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=6.6.0->yapf->mmcv==2.1.0) (3.17.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.3.0->mmcv==2.1.0) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.3.0->mmcv==2.1.0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.3.0->mmcv==2.1.0) (4.47.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.3.0->mmcv==2.1.0) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.3.0->mmcv==2.1.0) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.3.0->mmcv==2.1.0) (2.8.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->mmengine>=0.3.0->mmcv==2.1.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->mmengine>=0.3.0->mmcv==2.1.0) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->mmengine>=0.3.0->mmcv==2.1.0) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mmengine>=0.3.0->mmcv==2.1.0) (1.16.0)\n",
            "Installing collected packages: addict, yapf, mmengine, mmcv\n",
            "Successfully installed addict-2.4.0 mmcv-2.1.0 mmengine-0.10.3 yapf-0.40.2\n",
            "Collecting mmdet\n",
            "  Downloading mmdet-3.3.0-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mmdet) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mmdet) (1.23.5)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.10/dist-packages (from mmdet) (2.0.7)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from mmdet) (1.11.4)\n",
            "Requirement already satisfied: shapely in /usr/local/lib/python3.10/dist-packages (from mmdet) (2.0.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from mmdet) (1.16.0)\n",
            "Collecting terminaltables (from mmdet)\n",
            "  Downloading terminaltables-3.1.10-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from mmdet) (4.66.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmdet) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmdet) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmdet) (4.47.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmdet) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmdet) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmdet) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmdet) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmdet) (2.8.2)\n",
            "Installing collected packages: terminaltables, mmdet\n",
            "Successfully installed mmdet-3.3.0 terminaltables-3.1.10\n",
            "/content/TACO-expl/HDDETR/models/ops\n",
            "running build\n",
            "running build_py\n",
            "creating build\n",
            "creating build/lib.linux-x86_64-cpython-310\n",
            "creating build/lib.linux-x86_64-cpython-310/modules\n",
            "copying modules/__init__.py -> build/lib.linux-x86_64-cpython-310/modules\n",
            "copying modules/ms_deform_attn.py -> build/lib.linux-x86_64-cpython-310/modules\n",
            "creating build/lib.linux-x86_64-cpython-310/functions\n",
            "copying functions/__init__.py -> build/lib.linux-x86_64-cpython-310/functions\n",
            "copying functions/ms_deform_attn_func.py -> build/lib.linux-x86_64-cpython-310/functions\n",
            "running build_ext\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py:502: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n",
            "  warnings.warn(msg.format('we could not find ninja.'))\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py:414: UserWarning: The detected CUDA version (12.2) has a minor version mismatch with the version that was used to compile PyTorch (12.1). Most likely this shouldn't be a problem.\n",
            "  warnings.warn(CUDA_MISMATCH_WARN.format(cuda_str_version, torch.version.cuda))\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py:424: UserWarning: There are no x86_64-linux-gnu-g++ version bounds defined for CUDA version 12.2\n",
            "  warnings.warn(f'There are no {compiler_name} version bounds defined for CUDA version {cuda_str_version}')\n",
            "building 'MultiScaleDeformableAttention' extension\n",
            "creating build/temp.linux-x86_64-cpython-310\n",
            "creating build/temp.linux-x86_64-cpython-310/content\n",
            "creating build/temp.linux-x86_64-cpython-310/content/TACO-expl\n",
            "creating build/temp.linux-x86_64-cpython-310/content/TACO-expl/HDDETR\n",
            "creating build/temp.linux-x86_64-cpython-310/content/TACO-expl/HDDETR/models\n",
            "creating build/temp.linux-x86_64-cpython-310/content/TACO-expl/HDDETR/models/ops\n",
            "creating build/temp.linux-x86_64-cpython-310/content/TACO-expl/HDDETR/models/ops/src\n",
            "creating build/temp.linux-x86_64-cpython-310/content/TACO-expl/HDDETR/models/ops/src/cpu\n",
            "creating build/temp.linux-x86_64-cpython-310/content/TACO-expl/HDDETR/models/ops/src/cuda\n",
            "x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -DWITH_CUDA -I/content/TACO-expl/HDDETR/models/ops/src -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.10 -c /content/TACO-expl/HDDETR/models/ops/src/cpu/ms_deform_attn_cpu.cpp -o build/temp.linux-x86_64-cpython-310/content/TACO-expl/HDDETR/models/ops/src/cpu/ms_deform_attn_cpu.o -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=MultiScaleDeformableAttention -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
            "/usr/local/cuda/bin/nvcc -DWITH_CUDA -I/content/TACO-expl/HDDETR/models/ops/src -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.10 -c /content/TACO-expl/HDDETR/models/ops/src/cuda/ms_deform_attn_cuda.cu -o build/temp.linux-x86_64-cpython-310/content/TACO-expl/HDDETR/models/ops/src/cuda/ms_deform_attn_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -DCUDA_HAS_FP16=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=MultiScaleDeformableAttention -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++17\n",
            "\u001b[01m\u001b[0m\u001b[01m/content/TACO-expl/HDDETR/models/ops/src/cuda/ms_deform_im2col_cuda.cuh(261)\u001b[0m: \u001b[01;35mwarning\u001b[0m #177-D: variable \u001b[01m\"q_col\"\u001b[0m was declared but never referenced\n",
            "      const int q_col = _temp % num_query;\n",
            "                ^\n",
            "          detected during instantiation of \u001b[01m\"void ms_deformable_im2col_cuda(cudaStream_t, const scalar_t *, const int64_t *, const int64_t *, const scalar_t *, const scalar_t *, int, int, int, int, int, int, int, scalar_t *) [with scalar_t=double]\"\u001b[0m \u001b[32mat line 64 of /content/TACO-expl/HDDETR/models/ops/src/cuda/ms_deform_attn_cuda.cu\u001b[0m\n",
            "\n",
            "\u001b[01;36m\u001b[0m\u001b[01;36mRemark\u001b[0m: The warnings can be suppressed with \"-diag-suppress <warning-number>\"\n",
            "\n",
            "\u001b[01m\u001b[0m\u001b[01m/content/TACO-expl/HDDETR/models/ops/src/cuda/ms_deform_im2col_cuda.cuh(762)\u001b[0m: \u001b[01;35mwarning\u001b[0m #177-D: variable \u001b[01m\"q_col\"\u001b[0m was declared but never referenced\n",
            "      const int q_col = _temp % num_query;\n",
            "                ^\n",
            "          detected during instantiation of \u001b[01m\"void ms_deformable_col2im_cuda(cudaStream_t, const scalar_t *, const scalar_t *, const int64_t *, const int64_t *, const scalar_t *, const scalar_t *, int, int, int, int, int, int, int, scalar_t *, scalar_t *, scalar_t *) [with scalar_t=double]\"\u001b[0m \u001b[32mat line 134 of /content/TACO-expl/HDDETR/models/ops/src/cuda/ms_deform_attn_cuda.cu\u001b[0m\n",
            "\n",
            "\u001b[01m\u001b[0m\u001b[01m/content/TACO-expl/HDDETR/models/ops/src/cuda/ms_deform_im2col_cuda.cuh(872)\u001b[0m: \u001b[01;35mwarning\u001b[0m #177-D: variable \u001b[01m\"q_col\"\u001b[0m was declared but never referenced\n",
            "      const int q_col = _temp % num_query;\n",
            "                ^\n",
            "          detected during instantiation of \u001b[01m\"void ms_deformable_col2im_cuda(cudaStream_t, const scalar_t *, const scalar_t *, const int64_t *, const int64_t *, const scalar_t *, const scalar_t *, int, int, int, int, int, int, int, scalar_t *, scalar_t *, scalar_t *) [with scalar_t=double]\"\u001b[0m \u001b[32mat line 134 of /content/TACO-expl/HDDETR/models/ops/src/cuda/ms_deform_attn_cuda.cu\u001b[0m\n",
            "\n",
            "\u001b[01m\u001b[0m\u001b[01m/content/TACO-expl/HDDETR/models/ops/src/cuda/ms_deform_im2col_cuda.cuh(331)\u001b[0m: \u001b[01;35mwarning\u001b[0m #177-D: variable \u001b[01m\"q_col\"\u001b[0m was declared but never referenced\n",
            "      const int q_col = _temp % num_query;\n",
            "                ^\n",
            "          detected during instantiation of \u001b[01m\"void ms_deformable_col2im_cuda(cudaStream_t, const scalar_t *, const scalar_t *, const int64_t *, const int64_t *, const scalar_t *, const scalar_t *, int, int, int, int, int, int, int, scalar_t *, scalar_t *, scalar_t *) [with scalar_t=double]\"\u001b[0m \u001b[32mat line 134 of /content/TACO-expl/HDDETR/models/ops/src/cuda/ms_deform_attn_cuda.cu\u001b[0m\n",
            "\n",
            "\u001b[01m\u001b[0m\u001b[01m/content/TACO-expl/HDDETR/models/ops/src/cuda/ms_deform_im2col_cuda.cuh(436)\u001b[0m: \u001b[01;35mwarning\u001b[0m #177-D: variable \u001b[01m\"q_col\"\u001b[0m was declared but never referenced\n",
            "      const int q_col = _temp % num_query;\n",
            "                ^\n",
            "          detected during instantiation of \u001b[01m\"void ms_deformable_col2im_cuda(cudaStream_t, const scalar_t *, const scalar_t *, const int64_t *, const int64_t *, const scalar_t *, const scalar_t *, int, int, int, int, int, int, int, scalar_t *, scalar_t *, scalar_t *) [with scalar_t=double]\"\u001b[0m \u001b[32mat line 134 of /content/TACO-expl/HDDETR/models/ops/src/cuda/ms_deform_attn_cuda.cu\u001b[0m\n",
            "\n",
            "\u001b[01m\u001b[0m\u001b[01m/content/TACO-expl/HDDETR/models/ops/src/cuda/ms_deform_im2col_cuda.cuh(544)\u001b[0m: \u001b[01;35mwarning\u001b[0m #177-D: variable \u001b[01m\"q_col\"\u001b[0m was declared but never referenced\n",
            "      const int q_col = _temp % num_query;\n",
            "                ^\n",
            "          detected during instantiation of \u001b[01m\"void ms_deformable_col2im_cuda(cudaStream_t, const scalar_t *, const scalar_t *, const int64_t *, const int64_t *, const scalar_t *, const scalar_t *, int, int, int, int, int, int, int, scalar_t *, scalar_t *, scalar_t *) [with scalar_t=double]\"\u001b[0m \u001b[32mat line 134 of /content/TACO-expl/HDDETR/models/ops/src/cuda/ms_deform_attn_cuda.cu\u001b[0m\n",
            "\n",
            "\u001b[01m\u001b[0m\u001b[01m/content/TACO-expl/HDDETR/models/ops/src/cuda/ms_deform_im2col_cuda.cuh(649)\u001b[0m: \u001b[01;35mwarning\u001b[0m #177-D: variable \u001b[01m\"q_col\"\u001b[0m was declared but never referenced\n",
            "      const int q_col = _temp % num_query;\n",
            "                ^\n",
            "          detected during instantiation of \u001b[01m\"void ms_deformable_col2im_cuda(cudaStream_t, const scalar_t *, const scalar_t *, const int64_t *, const int64_t *, const scalar_t *, const scalar_t *, int, int, int, int, int, int, int, scalar_t *, scalar_t *, scalar_t *) [with scalar_t=double]\"\u001b[0m \u001b[32mat line 134 of /content/TACO-expl/HDDETR/models/ops/src/cuda/ms_deform_attn_cuda.cu\u001b[0m\n",
            "\n",
            "\u001b[01m\u001b[K/content/TACO-expl/HDDETR/models/ops/src/cuda/ms_deform_attn_cuda.cu:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kat::Tensor ms_deform_attn_cuda_forward(const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, int)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K/content/TACO-expl/HDDETR/models/ops/src/cuda/ms_deform_attn_cuda.cu:34:61:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   34 |     AT_ASSERTM(value.type().is_cuda(), \"value must\u001b[01;35m\u001b[K be a CUDA t\u001b[m\u001b[Kensor\");\n",
            "      |                                                   \u001b[01;35m\u001b[K~~~~~~~~~~^~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:225:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  225 | \u001b[01;36m\u001b[K  De\u001b[m\u001b[KprecatedTypeProperties & type() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/TACO-expl/HDDETR/models/ops/src/cuda/ms_deform_attn_cuda.cu:35:70:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   35 |     AT_ASSERTM(spatial_shapes.type().is_cuda(), \"s\u001b[01;35m\u001b[Kpatial_shapes must be\u001b[m\u001b[K a CUDA tensor\");\n",
            "      |                                                   \u001b[01;35m\u001b[K~~~~~~~~~~~~~~~~~~~^~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:225:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  225 | \u001b[01;36m\u001b[K  De\u001b[m\u001b[KprecatedTypeProperties & type() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/TACO-expl/HDDETR/models/ops/src/cuda/ms_deform_attn_cuda.cu:36:73:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   36 |     AT_ASSERTM(level_start_index.type().is_cuda(),\u001b[01;35m\u001b[K \"level_start_index must\u001b[m\u001b[K be a CUDA tensor\");\n",
            "      |                                                   \u001b[01;35m\u001b[K~~~~~~~~~~~~~~~~~~~~~~^~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:225:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  225 | \u001b[01;36m\u001b[K  De\u001b[m\u001b[KprecatedTypeProperties & type() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/TACO-expl/HDDETR/models/ops/src/cuda/ms_deform_attn_cuda.cu:37:68:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   37 |     AT_ASSERTM(sampling_loc.type().is_cuda(), \"sam\u001b[01;35m\u001b[Kpling_loc must be a\u001b[m\u001b[K CUDA tensor\");\n",
            "      |                                                   \u001b[01;35m\u001b[K~~~~~~~~~~~~~~~~~^~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:225:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  225 | \u001b[01;36m\u001b[K  De\u001b[m\u001b[KprecatedTypeProperties & type() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/TACO-expl/HDDETR/models/ops/src/cuda/ms_deform_attn_cuda.cu:38:67:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   38 |     AT_ASSERTM(attn_weight.type().is_cuda(), \"attn\u001b[01;35m\u001b[K_weight must be a \u001b[m\u001b[KCUDA tensor\");\n",
            "      |                                                   \u001b[01;35m\u001b[K~~~~~~~~~~~~~~~~^~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:225:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  225 | \u001b[01;36m\u001b[K  De\u001b[m\u001b[KprecatedTypeProperties & type() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/TACO-expl/HDDETR/models/ops/src/cuda/ms_deform_attn_cuda.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[K/content/TACO-expl/HDDETR/models/ops/src/cuda/ms_deform_attn_cuda.cu:64:42:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   64 |         AT_DISPATCH_FLOATING_\u001b[01;35m\u001b[KTYPES(value.ty\u001b[m\u001b[Kpe(), \"ms_deform_attn_forward_cuda\", ([&] {\n",
            "      |                              \u001b[01;35m\u001b[K~~~~~~~~~~~~^~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:225:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  225 | \u001b[01;36m\u001b[K  De\u001b[m\u001b[KprecatedTypeProperties & type() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/TACO-expl/HDDETR/models/ops/src/cuda/ms_deform_attn_cuda.cu:64:163:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kc10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)\u001b[m\u001b[K’ is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   64 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_forward_cuda\", ([&] {\n",
            "      |                                                                                                                                                                   \u001b[01;35m\u001b[K^\u001b[m\u001b[K         \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:109:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  109 | \u001b[01;36m\u001b[Kinline at::\u001b[m\u001b[KScalarType scalar_type(const at::DeprecatedTypeProperties& t) {\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/TACO-expl/HDDETR/models/ops/src/cuda/ms_deform_attn_cuda.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[K/content/TACO-expl/HDDETR/models/ops/src/cuda/ms_deform_attn_cuda.cu:64:1047:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   64 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_forward_cuda\", ([&] {\n",
            "      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:247:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  247 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/TACO-expl/HDDETR/models/ops/src/cuda/ms_deform_attn_cuda.cu:64:1133:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = long int]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   64 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_forward_cuda\", ([&] {\n",
            "      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:247:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  247 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/TACO-expl/HDDETR/models/ops/src/cuda/ms_deform_attn_cuda.cu:64:1176:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = long int]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   64 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_forward_cuda\", ([&] {\n",
            "      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:247:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  247 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/TACO-expl/HDDETR/models/ops/src/cuda/ms_deform_attn_cuda.cu:64:1209:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   64 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_forward_cuda\", ([&] {\n",
            "      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:247:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  247 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/TACO-expl/HDDETR/models/ops/src/cuda/ms_deform_attn_cuda.cu:64:1292:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   64 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_forward_cuda\", ([&] {\n",
            "      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:247:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  247 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/TACO-expl/HDDETR/models/ops/src/cuda/ms_deform_attn_cuda.cu:64:1450:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   64 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_forward_cuda\", ([&] {\n",
            "      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:247:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  247 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/TACO-expl/HDDETR/models/ops/src/cuda/ms_deform_attn_cuda.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[K/content/TACO-expl/HDDETR/models/ops/src/cuda/ms_deform_attn_cuda.cu:64:2314:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   64 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_forward_cuda\", ([&] {\n",
            "      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:247:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  247 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/TACO-expl/HDDETR/models/ops/src/cuda/ms_deform_attn_cuda.cu:64:2400:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = long int]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   64 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_forward_cuda\", ([&] {\n",
            "      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:247:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  247 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/TACO-expl/HDDETR/models/ops/src/cuda/ms_deform_attn_cuda.cu:64:2443:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = long int]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   64 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_forward_cuda\", ([&] {\n",
            "      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:247:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  247 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/TACO-expl/HDDETR/models/ops/src/cuda/ms_deform_attn_cuda.cu:64:2475:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   64 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_forward_cuda\", ([&] {\n",
            "      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:247:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  247 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/TACO-expl/HDDETR/models/ops/src/cuda/ms_deform_attn_cuda.cu:64:2557:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   64 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_forward_cuda\", ([&] {\n",
            "      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:247:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  247 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/TACO-expl/HDDETR/models/ops/src/cuda/ms_deform_attn_cuda.cu:64:2714:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   64 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_forward_cuda\", ([&] {\n",
            "      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:247:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  247 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/TACO-expl/HDDETR/models/ops/src/cuda/ms_deform_attn_cuda.cu:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kstd::vector<at::Tensor> ms_deform_attn_cuda_backward(const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, int)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K/content/TACO-expl/HDDETR/models/ops/src/cuda/ms_deform_attn_cuda.cu:100:61:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  100 |     AT_ASSERTM(value.type().is_cuda(), \"value must\u001b[01;35m\u001b[K be a CUDA t\u001b[m\u001b[Kensor\");\n",
            "      |                                                   \u001b[01;35m\u001b[K~~~~~~~~~~^~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:225:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  225 | \u001b[01;36m\u001b[K  De\u001b[m\u001b[KprecatedTypeProperties & type() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/TACO-expl/HDDETR/models/ops/src/cuda/ms_deform_attn_cuda.cu:101:70:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  101 |     AT_ASSERTM(spatial_shapes.type().is_cuda(), \"s\u001b[01;35m\u001b[Kpatial_shapes must be\u001b[m\u001b[K a CUDA tensor\");\n",
            "      |                                                   \u001b[01;35m\u001b[K~~~~~~~~~~~~~~~~~~~^~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:225:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  225 | \u001b[01;36m\u001b[K  De\u001b[m\u001b[KprecatedTypeProperties & type() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/TACO-expl/HDDETR/models/ops/src/cuda/ms_deform_attn_cuda.cu:102:73:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  102 |     AT_ASSERTM(level_start_index.type().is_cuda(),\u001b[01;35m\u001b[K \"level_start_index must\u001b[m\u001b[K be a CUDA tensor\");\n",
            "      |                                                   \u001b[01;35m\u001b[K~~~~~~~~~~~~~~~~~~~~~~^~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:225:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  225 | \u001b[01;36m\u001b[K  De\u001b[m\u001b[KprecatedTypeProperties & type() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/TACO-expl/HDDETR/models/ops/src/cuda/ms_deform_attn_cuda.cu:103:68:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  103 |     AT_ASSERTM(sampling_loc.type().is_cuda(), \"sam\u001b[01;35m\u001b[Kpling_loc must be a\u001b[m\u001b[K CUDA tensor\");\n",
            "      |                                                   \u001b[01;35m\u001b[K~~~~~~~~~~~~~~~~~^~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:225:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  225 | \u001b[01;36m\u001b[K  De\u001b[m\u001b[KprecatedTypeProperties & type() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/TACO-expl/HDDETR/models/ops/src/cuda/ms_deform_attn_cuda.cu:104:67:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  104 |     AT_ASSERTM(attn_weight.type().is_cuda(), \"attn\u001b[01;35m\u001b[K_weight must be a \u001b[m\u001b[KCUDA tensor\");\n",
            "      |                                                   \u001b[01;35m\u001b[K~~~~~~~~~~~~~~~~^~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:225:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  225 | \u001b[01;36m\u001b[K  De\u001b[m\u001b[KprecatedTypeProperties & type() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/TACO-expl/HDDETR/models/ops/src/cuda/ms_deform_attn_cuda.cu:105:67:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  105 |     AT_ASSERTM(grad_output.type().is_cuda(), \"grad\u001b[01;35m\u001b[K_output must be a \u001b[m\u001b[KCUDA tensor\");\n",
            "      |                                                   \u001b[01;35m\u001b[K~~~~~~~~~~~~~~~~^~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:225:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  225 | \u001b[01;36m\u001b[K  De\u001b[m\u001b[KprecatedTypeProperties & type() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/TACO-expl/HDDETR/models/ops/src/cuda/ms_deform_attn_cuda.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[K/content/TACO-expl/HDDETR/models/ops/src/cuda/ms_deform_attn_cuda.cu:134:42:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  134 |         AT_DISPATCH_FLOATING_\u001b[01;35m\u001b[KTYPES(value.ty\u001b[m\u001b[Kpe(), \"ms_deform_attn_backward_cuda\", ([&] {\n",
            "      |                              \u001b[01;35m\u001b[K~~~~~~~~~~~~^~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:225:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  225 | \u001b[01;36m\u001b[K  De\u001b[m\u001b[KprecatedTypeProperties & type() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/TACO-expl/HDDETR/models/ops/src/cuda/ms_deform_attn_cuda.cu:134:164:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kc10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)\u001b[m\u001b[K’ is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  134 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_backward_cuda\", ([&] {\n",
            "      |                                                                                                                                                                    \u001b[01;35m\u001b[K^\u001b[m\u001b[K         \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:109:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  109 | \u001b[01;36m\u001b[Kinline at::\u001b[m\u001b[KScalarType scalar_type(const at::DeprecatedTypeProperties& t) {\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/TACO-expl/HDDETR/models/ops/src/cuda/ms_deform_attn_cuda.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[K/content/TACO-expl/HDDETR/models/ops/src/cuda/ms_deform_attn_cuda.cu:134:1057:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  134 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_backward_cuda\", ([&] {\n",
            "      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:247:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  247 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/TACO-expl/HDDETR/models/ops/src/cuda/ms_deform_attn_cuda.cu:134:1083:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  134 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_backward_cuda\", ([&] {\n",
            "      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:247:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  247 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/TACO-expl/HDDETR/models/ops/src/cuda/ms_deform_attn_cuda.cu:134:1169:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = long int]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  134 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_backward_cuda\", ([&] {\n",
            "      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:247:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  247 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/TACO-expl/HDDETR/models/ops/src/cuda/ms_deform_attn_cuda.cu:134:1212:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = long int]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  134 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_backward_cuda\", ([&] {\n",
            "      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:247:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  247 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/TACO-expl/HDDETR/models/ops/src/cuda/ms_deform_attn_cuda.cu:134:1245:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  134 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_backward_cuda\", ([&] {\n",
            "      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:247:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  247 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/TACO-expl/HDDETR/models/ops/src/cuda/ms_deform_attn_cuda.cu:134:1328:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  134 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_backward_cuda\", ([&] {\n",
            "      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:247:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  247 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/TACO-expl/HDDETR/models/ops/src/cuda/ms_deform_attn_cuda.cu:134:1489:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  134 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_backward_cuda\", ([&] {\n",
            "      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:247:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  247 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/TACO-expl/HDDETR/models/ops/src/cuda/ms_deform_attn_cuda.cu:134:1573:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  134 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_backward_cuda\", ([&] {\n",
            "      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:247:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  247 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/TACO-expl/HDDETR/models/ops/src/cuda/ms_deform_attn_cuda.cu:134:1661:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  134 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_backward_cuda\", ([&] {\n",
            "      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:247:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  247 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/TACO-expl/HDDETR/models/ops/src/cuda/ms_deform_attn_cuda.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[K/content/TACO-expl/HDDETR/models/ops/src/cuda/ms_deform_attn_cuda.cu:134:2586:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  134 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_backward_cuda\", ([&] {\n",
            "      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:247:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  247 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/TACO-expl/HDDETR/models/ops/src/cuda/ms_deform_attn_cuda.cu:134:2611:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  134 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_backward_cuda\", ([&] {\n",
            "      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:247:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  247 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/TACO-expl/HDDETR/models/ops/src/cuda/ms_deform_attn_cuda.cu:134:2697:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = long int]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  134 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_backward_cuda\", ([&] {\n",
            "      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:247:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  247 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/TACO-expl/HDDETR/models/ops/src/cuda/ms_deform_attn_cuda.cu:134:2740:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = long int]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  134 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_backward_cuda\", ([&] {\n",
            "      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:247:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  247 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/TACO-expl/HDDETR/models/ops/src/cuda/ms_deform_attn_cuda.cu:134:2772:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  134 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_backward_cuda\", ([&] {\n",
            "      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:247:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  247 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/TACO-expl/HDDETR/models/ops/src/cuda/ms_deform_attn_cuda.cu:134:2854:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  134 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_backward_cuda\", ([&] {\n",
            "      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:247:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  247 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/TACO-expl/HDDETR/models/ops/src/cuda/ms_deform_attn_cuda.cu:134:3014:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  134 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_backward_cuda\", ([&] {\n",
            "      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:247:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  247 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/TACO-expl/HDDETR/models/ops/src/cuda/ms_deform_attn_cuda.cu:134:3097:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  134 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_backward_cuda\", ([&] {\n",
            "      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:247:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  247 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/TACO-expl/HDDETR/models/ops/src/cuda/ms_deform_attn_cuda.cu:134:3184:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  134 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_backward_cuda\", ([&] {\n",
            "      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:247:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  247 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -DWITH_CUDA -I/content/TACO-expl/HDDETR/models/ops/src -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.10 -c /content/TACO-expl/HDDETR/models/ops/src/vision.cpp -o build/temp.linux-x86_64-cpython-310/content/TACO-expl/HDDETR/models/ops/src/vision.o -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=MultiScaleDeformableAttention -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
            "In file included from \u001b[01m\u001b[K/content/TACO-expl/HDDETR/models/ops/src/vision.cpp:11\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/content/TACO-expl/HDDETR/models/ops/src/ms_deform_attn.h:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kat::Tensor ms_deform_attn_forward(const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, int)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K/content/TACO-expl/HDDETR/models/ops/src/ms_deform_attn.h:29:19:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   29 |     if (\u001b[01;35m\u001b[Kvalue.type()\u001b[m\u001b[K.is_cuda())\n",
            "      |         \u001b[01;35m\u001b[K~~~~~~~~~~^~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/extension.h:5\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/TACO-expl/HDDETR/models/ops/src/cpu/ms_deform_attn_cpu.h:12\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/TACO-expl/HDDETR/models/ops/src/ms_deform_attn.h:13\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/TACO-expl/HDDETR/models/ops/src/vision.cpp:11\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:225:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  225 |   DeprecatedTypeProperties & \u001b[01;36m\u001b[Ktype\u001b[m\u001b[K() const {\n",
            "      |                              \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/content/TACO-expl/HDDETR/models/ops/src/vision.cpp:11\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/content/TACO-expl/HDDETR/models/ops/src/ms_deform_attn.h:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kstd::vector<at::Tensor> ms_deform_attn_backward(const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, int)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K/content/TACO-expl/HDDETR/models/ops/src/ms_deform_attn.h:51:19:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   51 |     if (\u001b[01;35m\u001b[Kvalue.type()\u001b[m\u001b[K.is_cuda())\n",
            "      |         \u001b[01;35m\u001b[K~~~~~~~~~~^~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/extension.h:5\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/TACO-expl/HDDETR/models/ops/src/cpu/ms_deform_attn_cpu.h:12\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/TACO-expl/HDDETR/models/ops/src/ms_deform_attn.h:13\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/TACO-expl/HDDETR/models/ops/src/vision.cpp:11\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:225:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  225 |   DeprecatedTypeProperties & \u001b[01;36m\u001b[Ktype\u001b[m\u001b[K() const {\n",
            "      |                              \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "x86_64-linux-gnu-g++ -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 build/temp.linux-x86_64-cpython-310/content/TACO-expl/HDDETR/models/ops/src/cpu/ms_deform_attn_cpu.o build/temp.linux-x86_64-cpython-310/content/TACO-expl/HDDETR/models/ops/src/cuda/ms_deform_attn_cuda.o build/temp.linux-x86_64-cpython-310/content/TACO-expl/HDDETR/models/ops/src/vision.o -L/usr/local/lib/python3.10/dist-packages/torch/lib -L/usr/local/cuda/lib64 -L/usr/lib/x86_64-linux-gnu -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-cpython-310/MultiScaleDeformableAttention.cpython-310-x86_64-linux-gnu.so\n",
            "running install\n",
            "/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Please avoid running ``setup.py`` directly.\n",
            "        Instead, use pypa/build, pypa/installer, pypa/build or\n",
            "        other standards-based tools.\n",
            "\n",
            "        See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  self.initialize_options()\n",
            "/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/cmd.py:66: EasyInstallDeprecationWarning: easy_install command is deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Please avoid running ``setup.py`` and ``easy_install``.\n",
            "        Instead, use pypa/build, pypa/installer, pypa/build or\n",
            "        other standards-based tools.\n",
            "\n",
            "        See https://github.com/pypa/setuptools/issues/917 for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  self.initialize_options()\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "creating MultiScaleDeformableAttention.egg-info\n",
            "writing MultiScaleDeformableAttention.egg-info/PKG-INFO\n",
            "writing dependency_links to MultiScaleDeformableAttention.egg-info/dependency_links.txt\n",
            "writing top-level names to MultiScaleDeformableAttention.egg-info/top_level.txt\n",
            "writing manifest file 'MultiScaleDeformableAttention.egg-info/SOURCES.txt'\n",
            "reading manifest file 'MultiScaleDeformableAttention.egg-info/SOURCES.txt'\n",
            "writing manifest file 'MultiScaleDeformableAttention.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "creating build/bdist.linux-x86_64\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "copying build/lib.linux-x86_64-cpython-310/MultiScaleDeformableAttention.cpython-310-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg\n",
            "creating build/bdist.linux-x86_64/egg/modules\n",
            "copying build/lib.linux-x86_64-cpython-310/modules/__init__.py -> build/bdist.linux-x86_64/egg/modules\n",
            "copying build/lib.linux-x86_64-cpython-310/modules/ms_deform_attn.py -> build/bdist.linux-x86_64/egg/modules\n",
            "creating build/bdist.linux-x86_64/egg/functions\n",
            "copying build/lib.linux-x86_64-cpython-310/functions/__init__.py -> build/bdist.linux-x86_64/egg/functions\n",
            "copying build/lib.linux-x86_64-cpython-310/functions/ms_deform_attn_func.py -> build/bdist.linux-x86_64/egg/functions\n",
            "byte-compiling build/bdist.linux-x86_64/egg/modules/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/modules/ms_deform_attn.py to ms_deform_attn.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/functions/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/functions/ms_deform_attn_func.py to ms_deform_attn_func.cpython-310.pyc\n",
            "creating stub loader for MultiScaleDeformableAttention.cpython-310-x86_64-linux-gnu.so\n",
            "byte-compiling build/bdist.linux-x86_64/egg/MultiScaleDeformableAttention.py to MultiScaleDeformableAttention.cpython-310.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying MultiScaleDeformableAttention.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying MultiScaleDeformableAttention.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying MultiScaleDeformableAttention.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying MultiScaleDeformableAttention.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "writing build/bdist.linux-x86_64/egg/EGG-INFO/native_libs.txt\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "__pycache__.MultiScaleDeformableAttention.cpython-310: module references __file__\n",
            "creating dist\n",
            "creating 'dist/MultiScaleDeformableAttention-1.0-py3.10-linux-x86_64.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing MultiScaleDeformableAttention-1.0-py3.10-linux-x86_64.egg\n",
            "creating /usr/local/lib/python3.10/dist-packages/MultiScaleDeformableAttention-1.0-py3.10-linux-x86_64.egg\n",
            "Extracting MultiScaleDeformableAttention-1.0-py3.10-linux-x86_64.egg to /usr/local/lib/python3.10/dist-packages\n",
            "Adding MultiScaleDeformableAttention 1.0 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.10/dist-packages/MultiScaleDeformableAttention-1.0-py3.10-linux-x86_64.egg\n",
            "Processing dependencies for MultiScaleDeformableAttention==1.0\n",
            "Finished processing dependencies for MultiScaleDeformableAttention==1.0\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "%cd /content/TACO-expl/HDDETR\n",
        "!pip install -r requirements.txt\n",
        "!pip install mmcv==2.1.0 -f https://download.openmmlab.com/mmcv/dist/cu118/torch2.1/index.html\n",
        "!pip install mmdet\n",
        "%cd /content/TACO-expl/HDDETR/models/ops\n",
        "!python setup.py build install\n",
        "# unit test (should see all checking is True)\n",
        "#!python test.py\n",
        "%cd /content/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ODG94BFmYgl_",
        "outputId": "efcc6f9b-55f6-438d-8fd4-a1fbf87dbb02"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "remote: Enumerating objects: 9, done.\u001b[K\n",
            "remote: Counting objects:  11% (1/9)\u001b[K\rremote: Counting objects:  22% (2/9)\u001b[K\rremote: Counting objects:  33% (3/9)\u001b[K\rremote: Counting objects:  44% (4/9)\u001b[K\rremote: Counting objects:  55% (5/9)\u001b[K\rremote: Counting objects:  66% (6/9)\u001b[K\rremote: Counting objects:  77% (7/9)\u001b[K\rremote: Counting objects:  88% (8/9)\u001b[K\rremote: Counting objects: 100% (9/9)\u001b[K\rremote: Counting objects: 100% (9/9), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1/1)\u001b[K\rremote: Compressing objects: 100% (1/1), done.\u001b[K\n",
            "remote: Total 5 (delta 4), reused 5 (delta 4), pack-reused 0\u001b[K\n",
            "Unpacking objects:  20% (1/5)\rUnpacking objects:  40% (2/5)\rUnpacking objects:  60% (3/5)\rUnpacking objects:  80% (4/5)\rUnpacking objects: 100% (5/5)\rUnpacking objects: 100% (5/5), 444 bytes | 222.00 KiB/s, done.\n",
            "From https://github.com/DomMcOyle/TACO-expl\n",
            " * branch            add_detr   -> FETCH_HEAD\n",
            "   db83cde..9307f53  add_detr   -> origin/add_detr\n",
            "Updating db83cde..9307f53\n",
            "Fast-forward\n",
            " HDDETR/models/backbone.py | 6 \u001b[32m+++++\u001b[m\u001b[31m-\u001b[m\n",
            " 1 file changed, 5 insertions(+), 1 deletion(-)\n"
          ]
        }
      ],
      "source": [
        "!git pull origin add_detr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XATP-Y3ZglE6",
        "outputId": "1e32266e-5aa0-47ee-bf0e-84cde2ba9933"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/TACO-expl\n",
            "Mounted at /content/MyDrive/\n"
          ]
        }
      ],
      "source": [
        "%cd TACO-expl\n",
        "import os.path\n",
        "import json\n",
        "import argparse\n",
        "import numpy as np\n",
        "import random\n",
        "import datetime as dt\n",
        "import copy\n",
        "import torch.nn as nn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from pathlib import Path\n",
        "\n",
        "import torch\n",
        "import math\n",
        "import torch.utils.data\n",
        "from torch.utils.data import DataLoader\n",
        "from pycocotools import mask as coco_mask\n",
        "\n",
        "from HDDETR.datasets.torchvision_datasets.coco import CocoDetection as TvCocoDetection\n",
        "import HDDETR.datasets.transforms as T\n",
        "from HDDETR.datasets.data_prefetcher import data_prefetcher\n",
        "from HDDETR.datasets.coco_eval import CocoEvaluator\n",
        "from HDDETR.models.deformable_transformer import DeformableTransformerEncoderLayer\n",
        "from torchvision.ops import RoIAlign\n",
        "import HDDETR.util.misc as mutils\n",
        "from HDDETR.util import box_ops\n",
        "\n",
        "import HDDETR.models\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/MyDrive/\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2dI-mnxFBNC"
      },
      "source": [
        "#split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KutH3M6PmlFU"
      },
      "outputs": [],
      "source": [
        "keep_categories = [\"Bottle\", \"Bottle cap\", \"Can\", \"Cigarette\", \"Cup\",\n",
        "                   \"Lid\", \"Plastic bag & wrapper\", \"Pop tab\", \"Straw\"]\n",
        "\n",
        "def create_map(original, keep_supercategories):\n",
        "  class_map = {}\n",
        "  for cat in original:\n",
        "    if cat[\"supercategory\"] in keep_supercategories:\n",
        "      class_map[cat[\"name\"]] = cat[\"supercategory\"]\n",
        "    else:\n",
        "      class_map[cat[\"name\"]] = \"Other\"\n",
        "  return class_map\n",
        "\n",
        "def replace_dataset_classes(dataset, class_map):\n",
        "      \"\"\" Replaces classes of dataset based on a dictionary\"\"\"\n",
        "      class_new_names = list(set(class_map.values()))\n",
        "      class_new_names.sort()\n",
        "      class_originals = copy.deepcopy(dataset['categories'])\n",
        "      dataset['categories'] = []\n",
        "      class_ids_map = {}  # map from old id to new id\n",
        "\n",
        "      # Assign background id 0\n",
        "      has_background = False\n",
        "      if 'Background' in class_new_names:\n",
        "          if class_new_names.index('Background') != 0:\n",
        "              class_new_names.remove('Background')\n",
        "              class_new_names.insert(0, 'Background')\n",
        "          has_background = True\n",
        "\n",
        "      # Replace categories\n",
        "      for id_new, class_new_name in enumerate(class_new_names):\n",
        "          # Make sure id:0 is reserved for background\n",
        "          id_rectified = id_new\n",
        "          if not has_background:\n",
        "              id_rectified += 1\n",
        "\n",
        "          category = {\n",
        "              'supercategory': '',\n",
        "              'id': id_rectified,  # Background has id=0\n",
        "              'name': class_new_name,\n",
        "          }\n",
        "          dataset['categories'].append(category)\n",
        "          # Map class names\n",
        "          for class_original in class_originals:\n",
        "              if class_map[class_original['name']] == class_new_name:\n",
        "                  class_ids_map[class_original['id']] = id_rectified\n",
        "\n",
        "      # Update annotations category id tag\n",
        "      for ann in dataset['annotations']:\n",
        "          ann['category_id'] = class_ids_map[ann['category_id']]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RclP141dy5RU",
        "outputId": "66022aca-d855-436d-c343-77c8fa5b3e77"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Aluminium foil': 'Other', 'Battery': 'Other', 'Aluminium blister pack': 'Other', 'Carded blister pack': 'Other', 'Other plastic bottle': 'Bottle', 'Clear plastic bottle': 'Bottle', 'Glass bottle': 'Bottle', 'Plastic bottle cap': 'Bottle cap', 'Metal bottle cap': 'Bottle cap', 'Broken glass': 'Other', 'Food Can': 'Can', 'Aerosol': 'Can', 'Drink can': 'Can', 'Toilet tube': 'Other', 'Other carton': 'Other', 'Egg carton': 'Other', 'Drink carton': 'Other', 'Corrugated carton': 'Other', 'Meal carton': 'Other', 'Pizza box': 'Other', 'Paper cup': 'Cup', 'Disposable plastic cup': 'Cup', 'Foam cup': 'Cup', 'Glass cup': 'Cup', 'Other plastic cup': 'Cup', 'Food waste': 'Other', 'Glass jar': 'Other', 'Plastic lid': 'Lid', 'Metal lid': 'Lid', 'Other plastic': 'Other', 'Magazine paper': 'Other', 'Tissues': 'Other', 'Wrapping paper': 'Other', 'Normal paper': 'Other', 'Paper bag': 'Other', 'Plastified paper bag': 'Other', 'Plastic film': 'Plastic bag & wrapper', 'Six pack rings': 'Plastic bag & wrapper', 'Garbage bag': 'Plastic bag & wrapper', 'Other plastic wrapper': 'Plastic bag & wrapper', 'Single-use carrier bag': 'Plastic bag & wrapper', 'Polypropylene bag': 'Plastic bag & wrapper', 'Crisp packet': 'Plastic bag & wrapper', 'Spread tub': 'Other', 'Tupperware': 'Other', 'Disposable food container': 'Other', 'Foam food container': 'Other', 'Other plastic container': 'Other', 'Plastic glooves': 'Other', 'Plastic utensils': 'Other', 'Pop tab': 'Pop tab', 'Rope & strings': 'Other', 'Scrap metal': 'Other', 'Shoe': 'Other', 'Squeezable tube': 'Other', 'Plastic straw': 'Straw', 'Paper straw': 'Straw', 'Styrofoam piece': 'Other', 'Unlabeled litter': 'Other', 'Cigarette': 'Cigarette'}\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{'supercategory': '', 'id': 1, 'name': 'Bottle'},\n",
              " {'supercategory': '', 'id': 2, 'name': 'Bottle cap'},\n",
              " {'supercategory': '', 'id': 3, 'name': 'Can'},\n",
              " {'supercategory': '', 'id': 4, 'name': 'Cigarette'},\n",
              " {'supercategory': '', 'id': 5, 'name': 'Cup'},\n",
              " {'supercategory': '', 'id': 6, 'name': 'Lid'},\n",
              " {'supercategory': '', 'id': 7, 'name': 'Other'},\n",
              " {'supercategory': '', 'id': 8, 'name': 'Plastic bag & wrapper'},\n",
              " {'supercategory': '', 'id': 9, 'name': 'Pop tab'},\n",
              " {'supercategory': '', 'id': 10, 'name': 'Straw'}]"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "with open(\"/content/TACO/data/annotations.json\", \"r\") as f:\n",
        "    dataset = json.loads(f.read())\n",
        "\n",
        "class_map = create_map(dataset[\"categories\"], keep_categories)\n",
        "replace_dataset_classes(dataset, class_map)\n",
        "dataset[\"categories\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EDh8FFzFhqut"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\"\"\"\n",
        "parser = argparse.ArgumentParser(description='User args')\n",
        "parser.add_argument('--dataset_dir', required=True, help='Path to dataset annotations')\n",
        "parser.add_argument('--test_percentage', type=int, default=10, required=False, help='Percentage of images used for the testing set')\n",
        "parser.add_argument('--val_percentage', type=int, default=10, required=False, help='Percentage of images used for the validation set')\n",
        "parser.add_argument('--nr_trials', type=int, default=10, required=False, help='Number of splits')\n",
        "\n",
        "args = parser.parse_args()\n",
        "\"\"\"\n",
        "args = {\n",
        "    \"nr_trials\":1,\n",
        "    \"test_percentage\":0.1,\n",
        "    \"val_percentage\":0.1,\n",
        "    \"dataset_dir\":'/content/TACO/data'\n",
        "}\n",
        "\n",
        "ann_input_path = args[\"dataset_dir\"] + '/annotations_unofficial.json'\n",
        "\n",
        "# Load annotations\n",
        "with open(ann_input_path, 'r') as f:\n",
        "    dataset = json.loads(f.read())\n",
        "\n",
        "keep_categories = [\"Bottle\", \"Bottle cap\", \"Can\", \"Cigarette\", \"Cup\",\n",
        "                   \"Lid\", \"Plastic bag & wrapper\", \"Pop tab\", \"Straw\"]\n",
        "if keep_categories is not None:\n",
        "  class_map = create_map(dataset[\"categories\"], keep_categories)\n",
        "  replace_dataset_classes(dataset, class_map)\n",
        "\n",
        "anns = dataset['annotations']\n",
        "scene_anns = dataset['scene_annotations']\n",
        "imgs = dataset['images']\n",
        "nr_images = len(imgs)\n",
        "\n",
        "for i in range(args[\"nr_trials\"]):\n",
        "    random.shuffle(imgs)\n",
        "\n",
        "    # Add new datasets\n",
        "    train_set = {\n",
        "        'info': None,\n",
        "        'images': [],\n",
        "        'annotations': [],\n",
        "        'scene_annotations': [],\n",
        "        'licenses': [],\n",
        "        'categories': [],\n",
        "        'scene_categories': [],\n",
        "    }\n",
        "    train_set['info'] =  dataset['info']\n",
        "    train_set['categories'] = dataset['categories']\n",
        "    train_set['scene_categories'] = dataset['scene_categories']\n",
        "\n",
        "    val_set = copy.deepcopy(train_set)\n",
        "    test_set = copy.deepcopy(train_set)\n",
        "\n",
        "    train_set['images'], partial = train_test_split(dataset['images'],\n",
        "                                                    random_state=42,\n",
        "                                                               test_size=args[\"test_percentage\"]+args[\"val_percentage\"])\n",
        "    val_set['images'], test_set[\"images\"] = train_test_split(partial,\n",
        "                                                             random_state=42,\n",
        "                                                             test_size=args[\"test_percentage\"]/(args[\"test_percentage\"]+args[\"val_percentage\"]))\n",
        "\n",
        "    # Aux Image Ids to split annotations\n",
        "    test_img_ids, val_img_ids, train_img_ids = [],[],[]\n",
        "    for img in test_set['images']:\n",
        "        test_img_ids.append(img['id'])\n",
        "\n",
        "    for img in val_set['images']:\n",
        "        val_img_ids.append(img['id'])\n",
        "\n",
        "    for img in train_set['images']:\n",
        "        train_img_ids.append(img['id'])\n",
        "\n",
        "    # Split instance annotations\n",
        "    for ann in anns:\n",
        "        if ann['image_id'] in test_img_ids:\n",
        "            test_set['annotations'].append(ann)\n",
        "        elif ann['image_id'] in val_img_ids:\n",
        "            val_set['annotations'].append(ann)\n",
        "        elif ann['image_id'] in train_img_ids:\n",
        "            train_set['annotations'].append(ann)\n",
        "\n",
        "    # Split scene tags\n",
        "    for ann in scene_anns:\n",
        "        if ann['image_id'] in test_img_ids:\n",
        "            test_set['scene_annotations'].append(ann)\n",
        "        elif ann['image_id'] in val_img_ids:\n",
        "            val_set['scene_annotations'].append(ann)\n",
        "        elif ann['image_id'] in train_img_ids:\n",
        "            train_set['scene_annotations'].append(ann)\n",
        "\n",
        "    # Write dataset splits\n",
        "    ann_train_out_path = args[\"dataset_dir\"] + '/' + 'annotations_' + str(i) +'_train.json'\n",
        "    ann_val_out_path   = args[\"dataset_dir\"] + '/' + 'annotations_' + str(i) + '_val.json'\n",
        "    ann_test_out_path  = args[\"dataset_dir\"] + '/' + 'annotations_' + str(i) + '_test.json'\n",
        "\n",
        "    with open(ann_train_out_path, 'w+') as f:\n",
        "        f.write(json.dumps(train_set))\n",
        "\n",
        "    with open(ann_val_out_path, 'w+') as f:\n",
        "        f.write(json.dumps(val_set))\n",
        "\n",
        "    with open(ann_test_out_path, 'w+') as f:\n",
        "        f.write(json.dumps(test_set))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8s9VTnF5FG-q"
      },
      "source": [
        "#detr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SMqe-f0uqtjo"
      },
      "outputs": [],
      "source": [
        "class TACODataset(TvCocoDetection):\n",
        "    def __init__(\n",
        "        self,\n",
        "        img_folder,\n",
        "        ann_file,\n",
        "        transforms,\n",
        "        cache_mode=False,\n",
        "        local_rank=0,\n",
        "        local_size=1,\n",
        "        use_crowd=False,\n",
        "    ):\n",
        "        super(TACODataset, self).__init__(\n",
        "            img_folder,\n",
        "            ann_file,\n",
        "            cache_mode=cache_mode,\n",
        "            local_rank=local_rank,\n",
        "            local_size=local_size,\n",
        "        )\n",
        "        self._transforms = transforms\n",
        "        self.prepare = ConvertCocoPolysToMask(use_crowd)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img, target = super(TACODataset, self).__getitem__(idx)\n",
        "        image_id = self.ids[idx]\n",
        "        target = {\"image_id\": image_id, \"annotations\": target}\n",
        "        img, target = self.prepare(img, target)\n",
        "        if self._transforms is not None:\n",
        "            img, target = self._transforms(img, target)\n",
        "        return img, target\n",
        "\n",
        "\n",
        "class ConvertCocoPolysToMask(object):\n",
        "    def __init__(self, use_crowd):\n",
        "       self.use_crowd = use_crowd\n",
        "\n",
        "    def __call__(self, image, target):\n",
        "        w, h = image.size\n",
        "\n",
        "        image_id = target[\"image_id\"]\n",
        "        image_id = torch.tensor([image_id])\n",
        "\n",
        "        anno = target[\"annotations\"]\n",
        "\n",
        "        if not self.use_crowd:\n",
        "          anno = [obj for obj in anno if \"iscrowd\" not in obj or obj[\"iscrowd\"] == 0]\n",
        "\n",
        "        # condition as sanity check for empty segmentations\n",
        "        boxes = [obj[\"bbox\"] for obj in anno if obj[\"segmentation\"]]\n",
        "        # guard against no boxes via resizing\n",
        "        boxes = torch.as_tensor(boxes, dtype=torch.float32).reshape(-1, 4)\n",
        "        boxes[:, 2:] += boxes[:, :2]\n",
        "        boxes[:, 0::2].clamp_(min=0, max=w)\n",
        "        boxes[:, 1::2].clamp_(min=0, max=h)\n",
        "\n",
        "        classes = [obj[\"category_id\"] for obj in anno if obj[\"segmentation\"]]\n",
        "        classes = torch.tensor(classes, dtype=torch.int64) - 1 # for labels between 0 and 9\n",
        "\n",
        "        segmentations = [obj[\"segmentation\"] for obj in anno if obj[\"segmentation\"]]\n",
        "        masks = self.convert_coco_poly_to_mask(segmentations=segmentations, height=h, width=w)\n",
        "\n",
        "        keep = (boxes[:, 3] > boxes[:, 1]) & (boxes[:, 2] > boxes[:, 0])\n",
        "        boxes = boxes[keep]\n",
        "        classes = classes[keep]\n",
        "        masks = masks[keep]\n",
        "\n",
        "        target = {}\n",
        "        target[\"boxes\"] = boxes\n",
        "        target[\"labels\"] = classes\n",
        "        target[\"masks\"] = masks\n",
        "        target[\"image_id\"] = image_id\n",
        "\n",
        "        # for conversion to coco api\n",
        "        area = torch.tensor([obj[\"area\"] for obj in anno if obj[\"segmentation\"]])\n",
        "        iscrowd = torch.tensor(\n",
        "            [obj[\"iscrowd\"] if \"iscrowd\" in obj else 0 for obj in anno if obj[\"segmentation\"]]\n",
        "        )\n",
        "        target[\"area\"] = area[keep]\n",
        "        target[\"iscrowd\"] = iscrowd[keep]\n",
        "\n",
        "        target[\"orig_size\"] = torch.as_tensor([int(h), int(w)])\n",
        "        target[\"size\"] = torch.as_tensor([int(h), int(w)])\n",
        "\n",
        "        return image, target\n",
        "\n",
        "    def convert_coco_poly_to_mask(self, segmentations, height, width):\n",
        "      masks = []\n",
        "      for polygons in segmentations:\n",
        "          rles = coco_mask.frPyObjects(polygons, height, width)\n",
        "\n",
        "          mask = coco_mask.decode(rles)\n",
        "          if mask.max() < 1:\n",
        "            continue\n",
        "          if len(mask.shape) < 3:\n",
        "            mask = mask[..., None]\n",
        "          mask = torch.as_tensor(mask, dtype=torch.uint8)\n",
        "          mask = mask.any(dim=2)\n",
        "          masks.append(mask)\n",
        "      if masks:\n",
        "          masks = torch.stack(masks, dim=0)\n",
        "      else:\n",
        "          masks = torch.zeros((0, height, width), dtype=torch.uint8)\n",
        "      return masks\n",
        "\n",
        "\n",
        "def make_coco_transforms(image_set):\n",
        "\n",
        "    normalize = T.Compose(\n",
        "        [T.ToTensor(), T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]\n",
        "    )\n",
        "    #max_size = 1333\n",
        "    max_size = 1024\n",
        "    scales = [480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800]\n",
        "              # 832, 864, 896, 928, 960]\n",
        "\n",
        "    if image_set == \"train\":\n",
        "        return T.Compose(\n",
        "            [\n",
        "                T.RandomHorizontalFlip(),\n",
        "                T.RandomSelect(\n",
        "                    T.RandomResize(scales, max_size=max_size),\n",
        "                    T.Compose(\n",
        "                        [\n",
        "                            # T.RandomResize([400, 500, 600])\n",
        "                            T.RandomResize([2000, 2500, 3000]),\n",
        "                            #T.RandomSizeCrop(384, 600),\n",
        "                            T.RandomSizeCrop(1920, 3000),\n",
        "                            T.RandomResize(scales, max_size=max_size),\n",
        "                        ]\n",
        "                    ),\n",
        "                ),\n",
        "                normalize,\n",
        "            ]\n",
        "        )\n",
        "\n",
        "    if image_set == \"val\":\n",
        "        return T.Compose([T.RandomResize([800], max_size=max_size), normalize,])\n",
        "    if image_set == \"test\":\n",
        "        return None\n",
        "\n",
        "    raise ValueError(f\"unknown {image_set}\")\n",
        "\n",
        "def create_dataset(split):\n",
        "  ann_file = Path(\"/content/TACO-expl/data/annotations_0_\" + split +\".json\")\n",
        "  img_folder = Path(\"/content/MyDrive/MyDrive/\")\n",
        "\n",
        "  dataset = TACODataset(\n",
        "      img_folder,\n",
        "      ann_file,\n",
        "      transforms=make_coco_transforms(split),\n",
        "      local_rank=mutils.get_local_rank(),\n",
        "      local_size=mutils.get_local_size(),\n",
        "  )\n",
        "  return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ERweJ8HTfm9",
        "outputId": "69956d6a-51b2-4c98-99fb-cdc1bfebf3ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-02-06 18:25:59--  https://github.com/HDETR/H-Deformable-DETR/releases/download/v0.1/r50_hybrid_branch_lambda1_group6_t1500_dp0_mqs_lft_deformable_detr_plus_iterative_bbox_refinement_plus_plus_two_stage_36eps.pth\n",
            "Resolving github.com (github.com)... 192.30.255.112\n",
            "Connecting to github.com (github.com)|192.30.255.112|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/517883062/ce62ee7a-43ec-4230-8bf1-348a1530d246?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240206%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240206T182559Z&X-Amz-Expires=300&X-Amz-Signature=d66e8822fb7602e2894344290af7ea306a058d5cbf173c11c9804430e19a0705&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=517883062&response-content-disposition=attachment%3B%20filename%3Dr50_hybrid_branch_lambda1_group6_t1500_dp0_mqs_lft_deformable_detr_plus_iterative_bbox_refinement_plus_plus_two_stage_36eps.pth&response-content-type=application%2Foctet-stream [following]\n",
            "--2024-02-06 18:25:59--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/517883062/ce62ee7a-43ec-4230-8bf1-348a1530d246?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240206%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240206T182559Z&X-Amz-Expires=300&X-Amz-Signature=d66e8822fb7602e2894344290af7ea306a058d5cbf173c11c9804430e19a0705&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=517883062&response-content-disposition=attachment%3B%20filename%3Dr50_hybrid_branch_lambda1_group6_t1500_dp0_mqs_lft_deformable_detr_plus_iterative_bbox_refinement_plus_plus_two_stage_36eps.pth&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 192422339 (184M) [application/octet-stream]\n",
            "Saving to: ‘r50_hybrid_branch_lambda1_group6_t1500_dp0_mqs_lft_deformable_detr_plus_iterative_bbox_refinement_plus_plus_two_stage_36eps.pth’\n",
            "\n",
            "r50_hybrid_branch_l 100%[===================>] 183.51M  71.8MB/s    in 2.6s    \n",
            "\n",
            "2024-02-06 18:26:02 (71.8 MB/s) - ‘r50_hybrid_branch_lambda1_group6_t1500_dp0_mqs_lft_deformable_detr_plus_iterative_bbox_refinement_plus_plus_two_stage_36eps.pth’ saved [192422339/192422339]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://github.com/HDETR/H-Deformable-DETR/releases/download/v0.1/r50_hybrid_branch_lambda1_group6_t1500_dp0_mqs_lft_deformable_detr_plus_iterative_bbox_refinement_plus_plus_two_stage_36eps.pth\n",
        "!mv r50_hybrid_branch_lambda1_group6_t1500_dp0_mqs_lft_deformable_detr_plus_iterative_bbox_refinement_plus_plus_two_stage_36eps.pth r50.pth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hcD6Qhp9AE7K"
      },
      "outputs": [],
      "source": [
        "class AttrDict(dict):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super(AttrDict, self).__init__(*args, **kwargs)\n",
        "        self.__dict__ = self\n",
        "\n",
        "args = AttrDict()\n",
        "args.output_dir = './out/'\n",
        "args.with_box_refine = True\n",
        "args.two_stage = True\n",
        "args.dim_feedforward = 2048\n",
        "args.num_queries_one2one = 300\n",
        "args.num_queries_one2many = 1500\n",
        "args.k_one2many = 6\n",
        "args.lambda_one2many = 1.0\n",
        "args.mixed_selection = True\n",
        "args.look_forward_twice = True\n",
        "args.dataset_file = \"coco\"\n",
        "args.device = 'cuda'\n",
        "args.hidden_dim = 256\n",
        "args.position_embedding = 'sine'\n",
        "args.position_embedding_scale = np.pi *2\n",
        "#args.lr_backbone =2e-5\n",
        "args.lr_backbone = 0\n",
        "args.masks = False\n",
        "args.num_feature_levels = 4\n",
        "args.backbone = \"resnet50\"\n",
        "args.dilation = False\n",
        "args.nheads = 8\n",
        "args.enc_layers = 6\n",
        "args.dec_layers = 6\n",
        "args.dim_feedforwards = 2048\n",
        "args.dropout = 0\n",
        "args.dec_n_points = 4\n",
        "args.enc_n_points = 4\n",
        "args.use_checkpoint = True\n",
        "args.aux_loss = False\n",
        "args.cls_loss_coef=3\n",
        "args.giou_loss_coef=2\n",
        "args.focal_alpha=0.25\n",
        "args.topk=100\n",
        "args.bbox_loss_coef=0 #5\n",
        "args.set_cost_class=2\n",
        "args.set_cost_bbox=5\n",
        "args.set_cost_giou=2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jAq0eFHI2YUO"
      },
      "outputs": [],
      "source": [
        "def load_detr(args):\n",
        "  model,crit, postproc = HDDETR.models.build(args)\n",
        "  postproc.update({\"segm\": HDDETR.models.segmentation.PostProcessSegm()})\n",
        "  crit.losses.append(\"masks\")\n",
        "  crit.num_classes = 10\n",
        "  crit.weight_dict[\"loss_mask\"] = 5\n",
        "  crit.weight_dict[\"loss_dice\"] = 5\n",
        "  model.num_queries = 300\n",
        "  model.transformer.two_stage_num_proposals = 300\n",
        "  model.load_state_dict(torch.load(\"r50.pth\")[\"model\"])\n",
        "  return model, crit, postproc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "Aa-WuoDL55-M",
        "outputId": "60e85507-514b-4acc-a28f-f8415f3ef1fe"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nfrom HDDETR.util.misc import NestedTensor\\nfrom PIL import Image\\nimport torch\\nfrom torchvision import transforms\\n\\ndev = torch.device(\"cuda\")\\nmodel.to(dev)\\nto_t = transforms.ToTensor()\\nimg = Image.open(\"treno.jpg\")\\na = to_t(img).reshape((1,3,640,480))\\na = a.to(dev)\\nmask = torch.zeros((1,640,480), dtype=torch.bool, device=dev)\\nmask = mask.to(dev)\\nnt = NestedTensor(a, mask)\\nnt = nt.to(dev)\\n'"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"\n",
        "from HDDETR.util.misc import NestedTensor\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "\n",
        "dev = torch.device(\"cuda\")\n",
        "model.to(dev)\n",
        "to_t = transforms.ToTensor()\n",
        "img = Image.open(\"treno.jpg\")\n",
        "a = to_t(img).reshape((1,3,640,480))\n",
        "a = a.to(dev)\n",
        "mask = torch.zeros((1,640,480), dtype=torch.bool, device=dev)\n",
        "mask = mask.to(dev)\n",
        "nt = NestedTensor(a, mask)\n",
        "nt = nt.to(dev)\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vohh7Js-FMQa"
      },
      "outputs": [],
      "source": [
        "class MaskFrozenDETR(nn.Module):\n",
        "  def __init__(self, detr, device, num_classes):\n",
        "    super().__init__()\n",
        "    self.device = device\n",
        "    self.detr = detr\n",
        "    self.detr.num_queries = self.detr.num_queries_one2one\n",
        "    self.detr.transformer.two_stage_num_proposals = self.detr.num_queries_one2one\n",
        "    self.num_classes = num_classes\n",
        "    for param in detr.parameters():\n",
        "      param.requires_grad = False\n",
        "    # vedi deformable encoder block\n",
        "    self.feature_enc_1 = DeformableTransformerEncoderLayer(d_model=256,d_ffn=512,dropout=0, activation='gelu')\n",
        "    self.feature_enc_2 = DeformableTransformerEncoderLayer(d_model=256,d_ffn=512,dropout=0, activation='gelu')\n",
        "    self.box_enc_1 = DeformableTransformerEncoderLayer(d_model=128,d_ffn=512,dropout=0, activation='gelu')\n",
        "    self.box_enc_2 = DeformableTransformerEncoderLayer(d_model=128,d_ffn=512,dropout=0, activation='gelu')\n",
        "    self.channel_mapper = nn.Linear(256, 128)\n",
        "    self.query_channel_mapper = nn.Linear(256, 128)\n",
        "    self.roialign = RoIAlign(output_size=(32,32),spatial_scale=0.25, sampling_ratio=-1)\n",
        "    self.class_adapter = nn.Linear(256, num_classes)\n",
        "    self.topk = 96\n",
        "  def _paste(self, roi, empty_mask, flatboxes, index):\n",
        "      ox = int(round(flatboxes[index][0].item()))\n",
        "      oy = int(round(flatboxes[index][1].item()))\n",
        "      x1 = min(roi.shape[1], empty_mask[index].shape[1]-ox)\n",
        "      y1 = min(roi.shape[0], empty_mask[index].shape[0]-oy)\n",
        "\n",
        "      empty_mask[index][oy:oy+roi.shape[0],\n",
        "                        ox:ox+roi.shape[1]] = roi[:y1,:x1]\n",
        "      return empty_mask\n",
        "\n",
        "  def forward(self, input, sizes=None):\n",
        "    if isinstance(input, torch.Tensor):\n",
        "      input = mutils.nested_tensor_from_tensor_list(input)\n",
        "\n",
        "    bs, _, h, w = input.tensors.shape\n",
        "\n",
        "    # get output from the H-DETR\n",
        "    detr_out = self.detr(input)\n",
        "\n",
        "    # compute reference points for the following encoder layers\n",
        "    ref_points = self.detr.transformer.encoder.get_reference_points(detr_out[\"intermediate_enc_out\"][\"spatial_shapes\"],\n",
        "                                                                    detr_out[\"intermediate_enc_out\"][\"valid_ratios\"],\n",
        "                                                                    self.device)\n",
        "    # remove key not required by DeformableTransformerEncoderLayer.forward()\n",
        "    detr_out[\"intermediate_enc_out\"].pop(\"valid_ratios\")\n",
        "\n",
        "    # pass the multi-scale encoder maps to the two deformable layers\n",
        "    enc_maps = self.feature_enc_1(**detr_out[\"intermediate_enc_out\"], reference_points=ref_points)\n",
        "    detr_out[\"intermediate_enc_out\"][\"src\"] = enc_maps\n",
        "    enc_maps = self.feature_enc_2(**detr_out[\"intermediate_enc_out\"], reference_points=ref_points).permute(0, 2, 1)\n",
        "\n",
        "    # interpolate he maps to the backbone dimension\n",
        "    # detr_out[\"backbone_out\"].shape\n",
        "    backbone_h, backbone_w = detr_out[\"backbone_out\"].tensors.shape[-1], detr_out[\"backbone_out\"].tensors.shape[-2]\n",
        "    fe = mutils.interpolate(enc_maps, backbone_h*backbone_w, mode=\"linear\")\n",
        "\n",
        "    # sum the maps and reduce dimensionality\n",
        "    f = detr_out[\"backbone_out\"].tensors.view((bs, 256, -1 )) + fe\n",
        "\n",
        "    # map channel reduction\n",
        "    mapped_f = self.channel_mapper(f.permute(0, 2, 1))\n",
        "\n",
        "    # computing class for each proposal\n",
        "    logits = self.class_adapter(detr_out['decoder_out'][-1])\n",
        "\n",
        "    # computing top 100 proposals, boxes and queries\n",
        "    ci = logits.sigmoid()\n",
        "    topk_values, topk_indexes = torch.topk(\n",
        "            ci.view(logits.shape[0], -1), self.topk, dim=1\n",
        "    ) # takes top logits. may take a box more than once\n",
        "    topk_boxes = topk_indexes // logits.shape[2]\n",
        "    boxes = box_ops.box_cxcywh_to_xyxy(detr_out[\"pred_boxes\"])\n",
        "    boxes = torch.gather(boxes, 1, topk_boxes.unsqueeze(-1).repeat(1, 1, 4))\n",
        "    img_h, img_w = sizes.unbind(1)\n",
        "    scale_fct = torch.stack([img_w, img_h, img_w, img_h], dim=1)\n",
        "    boxes = boxes * scale_fct[:, None, :]\n",
        "    boxes = torch.clamp(boxes, min=0)\n",
        "    object_queries = detr_out[\"decoder_out\"][-1, :, :self.detr.num_queries_one2one, :]\n",
        "    object_queries = torch.gather(object_queries, 1, topk_boxes.unsqueeze(-1).repeat(1,1,object_queries.shape[-1]))\n",
        "    logits = torch.gather(logits, 1, topk_boxes.unsqueeze(-1).repeat(1,1, num_classes))\n",
        "\n",
        "\n",
        "    batchindexes = torch.arange(bs).reshape(bs,1,1).repeat(1,self.topk,1).to(self.device)\n",
        "    roiboxes = torch.cat([batchindexes, boxes], -1).reshape(bs*self.topk, 5)\n",
        "\n",
        "    Ri = self.roialign(mapped_f.reshape((bs, 128, backbone_h, backbone_w )), roiboxes)\n",
        "    maskRi = self.roialign(detr_out[\"backbone_out\"].mask.to(torch.float32).unsqueeze(1), roiboxes)\\\n",
        "                 .to(torch.bool)\\\n",
        "                 .permute(0,2,3,1).squeeze()\n",
        "\n",
        "    Ri = Ri.permute(0, 2, 3, 1).reshape(bs*self.topk,32*32, 128)\n",
        "     # ?\n",
        "\n",
        "    valid_ratios_box = torch.stack([self.detr.transformer.get_valid_ratio(m.unsqueeze(0)) for m in maskRi], 0)\n",
        "\n",
        "    ref_point_box = self.detr.transformer.encoder.get_reference_points(torch.tensor([[32,32]]),\n",
        "                                                                    valid_ratios_box,\n",
        "                                                                    self.device)\n",
        "\n",
        "    maskRi = maskRi.reshape(bs*self.topk,32*32)\n",
        "    Ri = self.box_enc_1(Ri, padding_mask=maskRi,\n",
        "                        level_start_index=torch.tensor([0]).to(self.device),\n",
        "                        pos=None,\n",
        "                        reference_points=ref_point_box,\n",
        "                        spatial_shapes=torch.tensor([[32,32]]).to(self.device))\n",
        "\n",
        "    Ri = self.box_enc_2(Ri, padding_mask=maskRi,\n",
        "                        level_start_index=torch.tensor([0]).to(self.device),\n",
        "                        pos=None,\n",
        "                        reference_points=ref_point_box,\n",
        "                        spatial_shapes=torch.tensor([[32,32]]).to(self.device))\n",
        "\n",
        "    object_queries = self.query_channel_mapper(object_queries).reshape(bs*self.topk, 128, 1)\n",
        "\n",
        "\n",
        "    segmasks = torch.bmm(Ri, object_queries).sigmoid().reshape(bs * self.topk, 32, 32)\n",
        "    emptym = torch.zeros(bs*self.topk, h, w)\n",
        "    flatboxes = boxes.view(bs * self.topk, 4)\n",
        "    for m in range(segmasks.shape[0]):\n",
        "      box_w = max(int(round((flatboxes[m][2] - flatboxes[m][0]).item())), 1)\n",
        "      box_h = max(int(round((flatboxes[m][3] - flatboxes[m][1]).item())), 1)\n",
        "      inter = mutils.interpolate(segmasks[m].expand(1,1,-1,-1),\n",
        "                                 (box_h, box_w),\n",
        "                                 mode=\"bilinear\").squeeze((0,1))\n",
        "      emptym = self._paste(inter, emptym, flatboxes, m)\n",
        "\n",
        "\n",
        "\n",
        "    segmasks = emptym.reshape(bs, self.topk, h, w)\n",
        "\n",
        "    return {\"pred_masks\": segmasks,\n",
        "            \"pred_logits\": logits,\n",
        "            \"pred_boxes\": boxes}\n",
        "\n",
        "def create_masks(boxes, segmasks):\n",
        "  pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6w0JOZXORcoX",
        "outputId": "6d087d6e-8c2d-43d5-cecb-2ea84568fa63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=0.26s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=0.01s)\n",
            "creating index...\n",
            "index created!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 144MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "topk for eval: 100\n"
          ]
        }
      ],
      "source": [
        "def set_seed(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "\n",
        "set_seed(42)\n",
        "batch_size = 2\n",
        "lr = 1.5e-4\n",
        "betas = (0.9, 0.999)\n",
        "weight_decay = 5e-5\n",
        "epochs = 6\n",
        "num_classes = 10\n",
        "\n",
        "device = torch.device(\"cuda\")\n",
        "\n",
        "dataset_train = create_dataset(\"train\")\n",
        "dataset_val = create_dataset(\"val\")\n",
        "sampler_train = torch.utils.data.RandomSampler(dataset_train)\n",
        "sampler_val = torch.utils.data.SequentialSampler(dataset_val)\n",
        "\n",
        "batch_sampler_train = torch.utils.data.BatchSampler(\n",
        "        sampler_train, batch_size, drop_last=True\n",
        ")\n",
        "\n",
        "data_loader_train = DataLoader(\n",
        "        dataset_train,\n",
        "        batch_sampler=batch_sampler_train,\n",
        "        collate_fn=mutils.collate_fn,\n",
        "        pin_memory=True,)\n",
        "\n",
        "data_loader_val = DataLoader(\n",
        "        dataset_val,\n",
        "        batch_size,\n",
        "        sampler=sampler_val,\n",
        "        drop_last=False,\n",
        "        collate_fn=mutils.collate_fn,\n",
        "        pin_memory=True,)\n",
        "\n",
        "detr, criterion, postprocessor = load_detr(args)\n",
        "\n",
        "mfdetr = MaskFrozenDETR(detr, device, num_classes)\n",
        "mfdetr.to(device)\n",
        "\n",
        "optimizer = torch.optim.AdamW([p for p in mfdetr.parameters() if p.requires_grad], lr=lr,\n",
        "                              betas=betas,\n",
        "                              weight_decay=weight_decay)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "-R_MuOnmBxrP"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "def train_MFDETR(model, criterion ,postprocessors, dl_train, dl_val, optimizer, epochs, device, save_path):\n",
        "\n",
        "  for e in range(epochs):\n",
        "    model.train()\n",
        "    prefetcher = data_prefetcher(dl_train, device, prefetch=True)\n",
        "    samples, targets = prefetcher.next()\n",
        "    criterion.train()\n",
        "    metric_logger = mutils.MetricLogger(delimiter=\"  \")\n",
        "    metric_logger.add_meter(\"lr\", mutils.SmoothedValue(window_size=1, fmt=\"{value:.6f}\"))\n",
        "    metric_logger.add_meter(\n",
        "        \"class_error\", mutils.SmoothedValue(window_size=1, fmt=\"{value:.2f}\")\n",
        "    )\n",
        "    header = \"Epoch: [{}]\".format(e)\n",
        "    print_freq = 10\n",
        "    batch_counter = 0\n",
        "    for b in metric_logger.log_every(range(len(dl_train)), print_freq, header):\n",
        "\n",
        "      sizes = torch.stack([t[\"size\"] for t in targets])\n",
        "      t = time.time()\n",
        "      outputs = model(samples, sizes)\n",
        "      print(outputs[\"pred_masks\"])\n",
        "      print(outputs[\"pred_masks\"].any())\n",
        "      t = time.time()\n",
        "      loss_dict = criterion(outputs, targets)\n",
        "      t = time.time()\n",
        "      weight_dict = criterion.weight_dict\n",
        "      losses = sum(loss_dict[k]*weight_dict[k] for k in loss_dict.keys() if k in weight_dict)\n",
        "      loss_dict_reduced = mutils.reduce_dict(loss_dict)\n",
        "      loss_dict_reduced_unscaled = {\n",
        "            f\"{k}_unscaled\": v for k, v in loss_dict_reduced.items()}\n",
        "      loss_dict_reduced_scaled = {\n",
        "            k: v * weight_dict[k]\n",
        "            for k, v in loss_dict_reduced.items()\n",
        "            if k in weight_dict}\n",
        "      losses_reduced_scaled = sum(loss_dict_reduced_scaled.values())\n",
        "\n",
        "      loss_value = losses_reduced_scaled.item()\n",
        "      if not math.isfinite(loss_value):\n",
        "            print(\"Loss is {}, stopping training\".format(loss_value))\n",
        "            print(loss_dict_reduced)\n",
        "            return model\n",
        "      print(f\"loss reduction: {losses}\")\n",
        "      print(f\"loss: {loss_dict_reduced_scaled}\")\n",
        "      t = time.time()\n",
        "      optimizer.zero_grad()\n",
        "      losses.backward()\n",
        "      optimizer.step()\n",
        "      print(f\"optimization: {time.time() - t}\")\n",
        "      metric_logger.update(\n",
        "            loss=loss_value, **loss_dict_reduced_scaled, **loss_dict_reduced_unscaled\n",
        "      )\n",
        "      metric_logger.update(class_error=loss_dict_reduced[\"class_error\"])\n",
        "      metric_logger.update(lr=optimizer.param_groups[0][\"lr\"])\n",
        "      #samples, targets = prefetcher.next()\n",
        "      batch_counter += 1\n",
        "      if batch_counter % 10:\n",
        "        torch.save({\n",
        "            \"epochs\":e,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': losses,\n",
        "            'batch':batch_counter\n",
        "        }, save_path + \"checkpoint.pth\")\n",
        "\n",
        "    val_evaluation(model, criterion, postprocessors, dl_val)\n",
        "  return model\n",
        "\n",
        "def val_evaluation(model, crterion, postprocessors, dl_val):\n",
        "  model.eval()\n",
        "  criterion.eval()\n",
        "  iou_types = tuple(k for k in (\"segm\", \"bbox\") if k in postprocessors.keys())\n",
        "  coco_evaluator = CocoEvaluator(dl_val.dataset.base_ds.coco, iou_types)\n",
        "  metric_logger = mutils.MetricLogger(delimiter=\"  \")\n",
        "  metric_logger.add_meter(\n",
        "        \"class_error\", mutils.SmoothedValue(window_size=1, fmt=\"{value:.2f}\"))\n",
        "  header = \"Validation:\"\n",
        "  for samples, targets in metric_logger.log_every(dl_val, 10, header):\n",
        "      samples = samples.to(device)\n",
        "      targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "\n",
        "      outputs = model(samples)\n",
        "      loss_dict = criterion(outputs, targets)\n",
        "      weight_dict = criterion.weight_dict\n",
        "\n",
        "      # reduce losses over all GPUs for logging purposes\n",
        "      loss_dict_reduced = mutils.reduce_dict(loss_dict)\n",
        "      loss_dict_reduced_scaled = {\n",
        "          k: v * weight_dict[k]\n",
        "          for k, v in loss_dict_reduced.items()\n",
        "          if k in weight_dict}\n",
        "      loss_dict_reduced_unscaled = {\n",
        "          f\"{k}_unscaled\": v for k, v in loss_dict_reduced.items()}\n",
        "      metric_logger.update(\n",
        "            loss=sum(loss_dict_reduced_scaled.values()),\n",
        "            **loss_dict_reduced_scaled,\n",
        "            **loss_dict_reduced_unscaled,)\n",
        "      metric_logger.update(class_error=loss_dict_reduced[\"class_error\"])\n",
        "\n",
        "      orig_target_sizes = torch.stack([t[\"orig_size\"] for t in targets], dim=0)\n",
        "      results = postprocessors[\"bbox\"](outputs, orig_target_sizes)\n",
        "      target_sizes = torch.stack([t[\"size\"] for t in targets], dim=0)\n",
        "      results = postprocessors[\"segm\"](\n",
        "                results, outputs, orig_target_sizes, target_sizes)\n",
        "      res = {target[\"image_id\"].item(): output\n",
        "            for target, output in zip(targets, results)}\n",
        "      if coco_evaluator is not None:\n",
        "          coco_evaluator.update(res)\n",
        "\n",
        "  # gather the stats from all processes\n",
        "  metric_logger.synchronize_between_processes()\n",
        "  print(\"Averaged stats:\", metric_logger)\n",
        "  if coco_evaluator is not None:\n",
        "      coco_evaluator.synchronize_between_processes()\n",
        "      # accumulate predictions from all images\n",
        "  if coco_evaluator is not None:\n",
        "      coco_evaluator.accumulate()\n",
        "      coco_evaluator.summarize()\n",
        "  stats = {k: meter.global_avg for k, meter in metric_logger.meters.items()}\n",
        "  if coco_evaluator is not None:\n",
        "      if \"bbox\" in postprocessors.keys():\n",
        "          stats[\"coco_eval_bbox\"] = coco_evaluator.coco_eval[\"bbox\"].stats.tolist()\n",
        "      if \"segm\" in postprocessors.keys():\n",
        "          stats[\"coco_eval_masks\"] = coco_evaluator.coco_eval[\"segm\"].stats.tolist()\n",
        "\n",
        "  return stats, coco_evaluator\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "YRkLkswfMkYT",
        "outputId": "2d0edd28-35d0-47c0-ddf7-bbbcc6ed967d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          ...,\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
            "\n",
            "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          ...,\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
            "\n",
            "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          ...,\n",
            "          [0.3319, 0.3319, 0.3319,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.3319, 0.3319, 0.3319,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.3319, 0.3319, 0.3319,  ..., 0.0000, 0.0000, 0.0000]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          ...,\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
            "\n",
            "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          ...,\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
            "\n",
            "         [[0.0000, 0.0000, 0.0000,  ..., 0.8867, 0.8867, 0.8867],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.8867, 0.8867, 0.8867],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.8867, 0.8867, 0.8867],\n",
            "          ...,\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
            "\n",
            "\n",
            "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          ...,\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
            "\n",
            "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          ...,\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
            "\n",
            "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          ...,\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          ...,\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
            "\n",
            "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          ...,\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
            "\n",
            "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          ...,\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor(True)\n",
            "loss reduction: 191.2110137939453\n",
            "loss: {'loss_ce': tensor(183.5504, device='cuda:0', grad_fn=<MulBackward0>), 'loss_bbox': tensor(0., device='cuda:0'), 'loss_giou': tensor(2.0339, device='cuda:0'), 'loss_mask': tensor(0.6580, grad_fn=<MulBackward0>), 'loss_dice': tensor(4.9687, grad_fn=<MulBackward0>)}\n",
            "optimization: 47.76753091812134\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-8c46db0202a4>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/MyDrive/MyDrive/ML4CV'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_MFDETR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmfdetr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_loader_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_loader_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-8-93ca9abe80e7>\u001b[0m in \u001b[0;36mtrain_MFDETR\u001b[0;34m(model, criterion, postprocessors, dl_train, dl_val, optimizer, epochs, device, save_path)\u001b[0m\n\u001b[1;32m     56\u001b[0m       \u001b[0mbatch_counter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mbatch_counter\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         torch.save({\n\u001b[0m\u001b[1;32m     59\u001b[0m             \u001b[0;34m\"epochs\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0;34m'model_state_dict'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_use_new_zipfile_serialization\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 618\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    619\u001b[0m             \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_disable_byteorder_record\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_zipfile_writer\u001b[0;34m(name_or_buffer)\u001b[0m\n\u001b[1;32m    490\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m         \u001b[0mcontainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_open_zipfile_writer_buffer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 492\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcontainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    461\u001b[0m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPyTorchFileWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_stream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPyTorchFileWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "path = '/content/MyDrive/MyDrive/ML4CV'\n",
        "train_MFDETR(mfdetr, criterion, postprocessor, data_loader_train, data_loader_val, optimizer, 1, device, path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R9NEtvq-e0E4",
        "outputId": "456b6c88-ba15-4632-e3b8-6fd544af4425"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "topk for eval: 100\n",
            "[{'boxes': tensor([[0.4073, 0.5974, 0.1229, 0.0812]], device='cuda:0'), 'labels': tensor([7], device='cuda:0'), 'masks': tensor([[[False, False, False,  ..., False, False, False],\n",
            "         [False, False, False,  ..., False, False, False],\n",
            "         [False, False, False,  ..., False, False, False],\n",
            "         ...,\n",
            "         [False, False, False,  ..., False, False, False],\n",
            "         [False, False, False,  ..., False, False, False],\n",
            "         [False, False, False,  ..., False, False, False]]], device='cuda:0'), 'image_id': tensor([2597], device='cuda:0'), 'area': tensor([2727.7170], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0'), 'orig_size': tensor([4000, 3000], device='cuda:0'), 'size': tensor([810, 608], device='cuda:0')}, {'boxes': tensor([[0.4258, 0.5101, 0.1553, 0.2129]], device='cuda:0'), 'labels': tensor([7], device='cuda:0'), 'masks': tensor([[[False, False, False,  ..., False, False, False],\n",
            "         [False, False, False,  ..., False, False, False],\n",
            "         [False, False, False,  ..., False, False, False],\n",
            "         ...,\n",
            "         [False, False, False,  ..., False, False, False],\n",
            "         [False, False, False,  ..., False, False, False],\n",
            "         [False, False, False,  ..., False, False, False]]], device='cuda:0'), 'image_id': tensor([1107], device='cuda:0'), 'area': tensor([1546.4883], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0'), 'orig_size': tensor([1536, 2048], device='cuda:0'), 'size': tensor([512, 682], device='cuda:0')}]\n"
          ]
        }
      ],
      "source": [
        "detr, criterion, postprocessor = load_detr(args)\n",
        "prefetcher = data_prefetcher(data_loader_train, device, prefetch=True)\n",
        "samples, targets = prefetcher.next()\n",
        "print(targets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwUPtYgZe-Gi",
        "outputId": "c43e688f-79e4-4297-a32f-16a24d9252dd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'boxes': tensor([[0.4073, 0.5974, 0.1229, 0.0812]], device='cuda:0'),\n",
              " 'labels': tensor([7], device='cuda:0'),\n",
              " 'masks': tensor([[[False, False, False,  ..., False, False, False],\n",
              "          [False, False, False,  ..., False, False, False],\n",
              "          [False, False, False,  ..., False, False, False],\n",
              "          ...,\n",
              "          [False, False, False,  ..., False, False, False],\n",
              "          [False, False, False,  ..., False, False, False],\n",
              "          [False, False, False,  ..., False, False, False]]], device='cuda:0'),\n",
              " 'image_id': tensor([2597], device='cuda:0'),\n",
              " 'area': tensor([2727.7170], device='cuda:0'),\n",
              " 'iscrowd': tensor([0], device='cuda:0'),\n",
              " 'orig_size': tensor([4000, 3000], device='cuda:0'),\n",
              " 'size': tensor([810, 608], device='cuda:0')}"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "targets[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nmdiV03DXBER",
        "outputId": "aaf88f05-b037-46cc-b9c0-83b53047f789"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "topk for eval: 100\n",
            "torch.Size([3, 3, 810, 682])\n",
            "4\n",
            "torch.Size([3, 102, 86])\n",
            "vrr\n",
            "torch.Size([3, 4, 2])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "decoder_out\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([6, 3, 300, 256])\n",
            "pred_logits\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([3, 300, 91])\n",
            "pred_boxes\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([3, 300, 4])\n",
            "pred_logits_one2many\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([3, 0, 91])\n",
            "pred_boxes_one2many\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([3, 0, 4])\n",
            "backbone_out\n",
            "<class 'HDDETR.util.misc.NestedTensor'>\n",
            "tensor([[[[0.0049, 0.0369, 0.0051,  ..., 0.0220, 0.0219, 0.0206],\n",
            "          [0.0048, 0.0052, 0.0342,  ..., 0.0053, 0.0047, 0.0188],\n",
            "          [0.0046, 0.0048, 0.0791,  ..., 0.0056, 0.0050, 0.0191],\n",
            "          ...,\n",
            "          [0.1141, 0.0891, 0.1674,  ..., 0.0054, 0.0049, 0.0188],\n",
            "          [0.1164, 0.1170, 0.1109,  ..., 0.0048, 0.0044, 0.0193],\n",
            "          [0.1293, 0.0303, 0.0901,  ..., 0.0183, 0.0197, 0.0287]],\n",
            "\n",
            "         [[0.0417, 0.1120, 0.1045,  ..., 0.1492, 0.1489, 0.1255],\n",
            "          [0.0504, 0.0879, 0.1362,  ..., 0.1457, 0.1457, 0.1119],\n",
            "          [0.1288, 0.1151, 0.1309,  ..., 0.1459, 0.1459, 0.1122],\n",
            "          ...,\n",
            "          [0.2525, 0.2837, 0.3458,  ..., 0.1457, 0.1457, 0.1127],\n",
            "          [0.2883, 0.2623, 0.2998,  ..., 0.1453, 0.1454, 0.1105],\n",
            "          [0.2336, 0.2009, 0.1915,  ..., 0.1028, 0.0985, 0.0777]],\n",
            "\n",
            "         [[0.1614, 0.0082, 0.1106,  ..., 0.0565, 0.1869, 0.2387],\n",
            "          [0.3053, 0.1502, 0.2526,  ..., 0.2896, 0.3948, 0.4863],\n",
            "          [0.2933, 0.0000, 0.1384,  ..., 0.2823, 0.2999, 0.3774],\n",
            "          ...,\n",
            "          [0.2061, 0.1298, 0.2783,  ..., 0.2858, 0.2755, 0.3995],\n",
            "          [0.2749, 0.0000, 0.7251,  ..., 0.3103, 0.4026, 0.3598],\n",
            "          [0.5070, 0.5971, 0.6663,  ..., 0.4549, 0.3153, 0.2133]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[0.0351, 0.1113, 0.1135,  ..., 0.0257, 0.0258, 0.0216],\n",
            "          [0.0187, 0.1049, 0.1545,  ..., 0.0257, 0.0257, 0.0204],\n",
            "          [0.0131, 0.0916, 0.1382,  ..., 0.0257, 0.0257, 0.0204],\n",
            "          ...,\n",
            "          [0.1251, 0.1132, 0.1475,  ..., 0.0257, 0.0257, 0.0203],\n",
            "          [0.1251, 0.1245, 0.1556,  ..., 0.0258, 0.0258, 0.0205],\n",
            "          [0.1050, 0.0739, 0.1345,  ..., 0.0262, 0.0266, 0.0222]],\n",
            "\n",
            "         [[0.5574, 0.7346, 0.5055,  ..., 0.4857, 0.5100, 0.5326],\n",
            "          [0.1273, 0.5021, 0.2049,  ..., 0.5225, 0.5491, 0.5957],\n",
            "          [0.0143, 0.3889, 0.2171,  ..., 0.5163, 0.5447, 0.5970],\n",
            "          ...,\n",
            "          [0.6167, 0.5973, 0.0448,  ..., 0.5157, 0.5451, 0.5962],\n",
            "          [0.6289, 0.8185, 0.0180,  ..., 0.5702, 0.5922, 0.6257],\n",
            "          [0.4864, 0.2445, 0.0576,  ..., 0.5180, 0.5259, 0.4898]],\n",
            "\n",
            "         [[1.0912, 0.0000, 0.0000,  ..., 0.1567, 0.0000, 0.0000],\n",
            "          [0.5752, 0.1070, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.7092, 0.5110, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          ...,\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0804,  ..., 0.3671, 0.2651, 0.0000]]],\n",
            "\n",
            "\n",
            "        [[[0.0068, 0.0041, 0.1117,  ..., 0.0042, 0.0052, 0.0052],\n",
            "          [0.0069, 0.0056, 0.0835,  ..., 0.0048, 0.0049, 0.0076],\n",
            "          [0.0056, 0.0056, 0.0626,  ..., 0.0050, 0.0058, 0.0091],\n",
            "          ...,\n",
            "          [0.0273, 0.0049, 0.0054,  ..., 0.0054, 0.0049, 0.0188],\n",
            "          [0.0277, 0.0046, 0.0048,  ..., 0.0048, 0.0044, 0.0193],\n",
            "          [0.0361, 0.0182, 0.0183,  ..., 0.0183, 0.0197, 0.0287]],\n",
            "\n",
            "         [[0.0808, 0.0439, 0.1327,  ..., 0.0122, 0.0232, 0.0722],\n",
            "          [0.0815, 0.0508, 0.0867,  ..., 0.0097, 0.0111, 0.0050],\n",
            "          [0.0710, 0.0881, 0.1040,  ..., 0.0104, 0.0095, 0.0319],\n",
            "          ...,\n",
            "          [0.1456, 0.1458, 0.1461,  ..., 0.1457, 0.1457, 0.1127],\n",
            "          [0.1432, 0.1455, 0.1459,  ..., 0.1453, 0.1454, 0.1105],\n",
            "          [0.1051, 0.1031, 0.1030,  ..., 0.1028, 0.0985, 0.0777]],\n",
            "\n",
            "         [[0.2107, 0.4565, 0.0110,  ..., 0.2444, 0.3677, 0.7809],\n",
            "          [0.8181, 0.5103, 0.3370,  ..., 0.0000, 0.4614, 0.7798],\n",
            "          [1.0747, 1.0217, 0.2350,  ..., 0.1447, 0.0000, 0.5733],\n",
            "          ...,\n",
            "          [0.1296, 0.3725, 0.2979,  ..., 0.2858, 0.2755, 0.3995],\n",
            "          [0.2718, 0.3149, 0.2991,  ..., 0.3103, 0.4026, 0.3598],\n",
            "          [0.0985, 0.4384, 0.3479,  ..., 0.4549, 0.3153, 0.2133]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[0.1472, 0.1851, 0.2606,  ..., 0.1519, 0.2352, 0.1774],\n",
            "          [0.1903, 0.2344, 0.2848,  ..., 0.2030, 0.2347, 0.1772],\n",
            "          [0.2471, 0.2309, 0.3005,  ..., 0.1811, 0.2067, 0.1314],\n",
            "          ...,\n",
            "          [0.0256, 0.0257, 0.0257,  ..., 0.0257, 0.0257, 0.0203],\n",
            "          [0.0258, 0.0258, 0.0258,  ..., 0.0258, 0.0258, 0.0205],\n",
            "          [0.0281, 0.0261, 0.0261,  ..., 0.0262, 0.0266, 0.0222]],\n",
            "\n",
            "         [[0.7375, 0.4006, 0.6861,  ..., 0.3637, 0.8192, 0.2677],\n",
            "          [0.5336, 0.4179, 1.0099,  ..., 0.6509, 0.6345, 0.5287],\n",
            "          [0.7894, 0.5741, 0.9564,  ..., 0.3602, 0.4665, 0.1855],\n",
            "          ...,\n",
            "          [0.5323, 0.5267, 0.5168,  ..., 0.5157, 0.5451, 0.5962],\n",
            "          [0.5656, 0.5707, 0.5698,  ..., 0.5702, 0.5922, 0.6257],\n",
            "          [0.4855, 0.5143, 0.5180,  ..., 0.5180, 0.5259, 0.4898]],\n",
            "\n",
            "         [[0.2127, 0.1598, 0.0000,  ..., 0.2160, 0.0458, 0.0000],\n",
            "          [0.0327, 0.0850, 0.0000,  ..., 0.3735, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          ...,\n",
            "          [0.0342, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.1890, 0.2809, 0.3667,  ..., 0.3671, 0.2651, 0.0000]]],\n",
            "\n",
            "\n",
            "        [[[0.1244, 0.1024, 0.1056,  ..., 0.0220, 0.0219, 0.0206],\n",
            "          [0.1001, 0.0816, 0.0766,  ..., 0.0053, 0.0047, 0.0188],\n",
            "          [0.1052, 0.0835, 0.0851,  ..., 0.0056, 0.0050, 0.0191],\n",
            "          ...,\n",
            "          [0.0273, 0.0049, 0.0054,  ..., 0.0054, 0.0049, 0.0188],\n",
            "          [0.0277, 0.0046, 0.0048,  ..., 0.0048, 0.0044, 0.0193],\n",
            "          [0.0361, 0.0182, 0.0183,  ..., 0.0183, 0.0197, 0.0287]],\n",
            "\n",
            "         [[0.2689, 0.2739, 0.2802,  ..., 0.1492, 0.1489, 0.1255],\n",
            "          [0.2584, 0.2601, 0.2606,  ..., 0.1457, 0.1457, 0.1119],\n",
            "          [0.2583, 0.2594, 0.2585,  ..., 0.1459, 0.1459, 0.1122],\n",
            "          ...,\n",
            "          [0.1456, 0.1458, 0.1461,  ..., 0.1457, 0.1457, 0.1127],\n",
            "          [0.1432, 0.1455, 0.1459,  ..., 0.1453, 0.1454, 0.1105],\n",
            "          [0.1051, 0.1031, 0.1030,  ..., 0.1028, 0.0985, 0.0777]],\n",
            "\n",
            "         [[0.1591, 0.1979, 0.2199,  ..., 0.0565, 0.1869, 0.2387],\n",
            "          [0.0326, 0.0890, 0.0485,  ..., 0.2896, 0.3948, 0.4863],\n",
            "          [0.0363, 0.1816, 0.0774,  ..., 0.2823, 0.2999, 0.3774],\n",
            "          ...,\n",
            "          [0.1296, 0.3725, 0.2979,  ..., 0.2858, 0.2755, 0.3995],\n",
            "          [0.2718, 0.3149, 0.2991,  ..., 0.3103, 0.4026, 0.3598],\n",
            "          [0.0985, 0.4384, 0.3479,  ..., 0.4549, 0.3153, 0.2133]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[0.0409, 0.0178, 0.0142,  ..., 0.0257, 0.0258, 0.0216],\n",
            "          [0.0117, 0.0117, 0.0117,  ..., 0.0257, 0.0257, 0.0204],\n",
            "          [0.0116, 0.0118, 0.0118,  ..., 0.0257, 0.0257, 0.0204],\n",
            "          ...,\n",
            "          [0.0256, 0.0257, 0.0257,  ..., 0.0257, 0.0257, 0.0203],\n",
            "          [0.0258, 0.0258, 0.0258,  ..., 0.0258, 0.0258, 0.0205],\n",
            "          [0.0281, 0.0261, 0.0261,  ..., 0.0262, 0.0266, 0.0222]],\n",
            "\n",
            "         [[0.3213, 0.3684, 0.4147,  ..., 0.4857, 0.5100, 0.5326],\n",
            "          [0.2976, 0.3877, 0.4208,  ..., 0.5225, 0.5491, 0.5957],\n",
            "          [0.2984, 0.4409, 0.4665,  ..., 0.5163, 0.5447, 0.5970],\n",
            "          ...,\n",
            "          [0.5323, 0.5267, 0.5168,  ..., 0.5157, 0.5451, 0.5962],\n",
            "          [0.5656, 0.5707, 0.5698,  ..., 0.5702, 0.5922, 0.6257],\n",
            "          [0.4855, 0.5143, 0.5180,  ..., 0.5180, 0.5259, 0.4898]],\n",
            "\n",
            "         [[0.1492, 0.0000, 0.0000,  ..., 0.1567, 0.0000, 0.0000],\n",
            "          [0.0080, 0.0000, 0.0180,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.2595, 0.0579, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          ...,\n",
            "          [0.0342, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.1890, 0.2809, 0.3667,  ..., 0.3671, 0.2651, 0.0000]]]],\n",
            "       device='cuda:0')\n",
            "intermediate_enc_out\n",
            "<class 'dict'>\n",
            "src\n",
            "torch.Size([3, 11680, 256])\n",
            "valid_ratios\n",
            "torch.Size([3, 4, 2])\n",
            "spatial_shapes\n",
            "torch.Size([4, 2])\n",
            "level_start_index\n",
            "torch.Size([4])\n",
            "pos\n",
            "torch.Size([3, 11680, 256])\n",
            "padding_mask\n",
            "torch.Size([3, 11680])\n",
            "enc_outputs\n",
            "<class 'dict'>\n",
            "pred_logits\n",
            "torch.Size([3, 11680, 91])\n",
            "pred_boxes\n",
            "torch.Size([3, 11680, 4])\n"
          ]
        }
      ],
      "source": [
        "detr, criterion, postprocessor = load_detr(args)\n",
        "prefetcher = data_prefetcher(data_loader_train, device, prefetch=True)\n",
        "samples, targets = prefetcher.next()\n",
        "print(samples.tensors.shape)\n",
        "detr = detr.to(torch.device(\"cuda\"))\n",
        "out = detr(samples)\n",
        "for k in out.keys():\n",
        "  print(k)\n",
        "  print(type(out[k]))\n",
        "\n",
        "  if type(out[k]) == torch.Tensor:\n",
        "    print(out[k].shape)\n",
        "  elif isinstance(out[k], dict):\n",
        "    for kk in out[k].keys():\n",
        "      print(kk)\n",
        "      if type(out[k][kk]) == torch.Tensor:\n",
        "        print(out[k][kk].shape)\n",
        "      else:\n",
        "        print(out[k][kk])\n",
        "  else:\n",
        "    print(out[k])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4kYxKUVsTQq",
        "outputId": "fe9adaaf-c8b1-4082-9103-d9b5c9eae177"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1., 0.])\n"
          ]
        }
      ],
      "source": [
        "a = torch.Tensor([True, False])\n",
        "print(a.to(torch.float32))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_train.ids[39]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YwbFsFbOohto",
        "outputId": "61d25068-8e7b-41ef-80aa-033dd16584e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "45"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
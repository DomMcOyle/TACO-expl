{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "7pzTIxbXnL6S",
        "outputId": "5640158f-3558-4680-8b9e-5bbaadeeadab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc fatal   : Unknown option '--version☻'\n",
            "Mon May 20 15:57:41 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   61C    P8              13W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.2.1+cu121'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "!nvcc --version☻\n",
        "!nvidia-smi\n",
        "import torch\n",
        "torch.__version__"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install 'git+https://github.com/facebookresearch/detectron2.git@5aeb252b194b93dc2879b4ac34bc51a31b5aee13'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "WGL4szW1o_UM",
        "outputId": "6a17c880-9d4c-49cd-c1ad-961dc428189e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/facebookresearch/detectron2.git@5aeb252b194b93dc2879b4ac34bc51a31b5aee13\n",
            "  Cloning https://github.com/facebookresearch/detectron2.git (to revision 5aeb252b194b93dc2879b4ac34bc51a31b5aee13) to /tmp/pip-req-build-5w1alkmw\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/detectron2.git /tmp/pip-req-build-5w1alkmw\n",
            "  Running command git rev-parse -q --verify 'sha^5aeb252b194b93dc2879b4ac34bc51a31b5aee13'\n",
            "  Running command git fetch -q https://github.com/facebookresearch/detectron2.git 5aeb252b194b93dc2879b4ac34bc51a31b5aee13\n",
            "  Running command git checkout -q 5aeb252b194b93dc2879b4ac34bc51a31b5aee13\n",
            "  Resolved https://github.com/facebookresearch/detectron2.git to commit 5aeb252b194b93dc2879b4ac34bc51a31b5aee13\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: Pillow>=7.1 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (9.4.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (3.7.1)\n",
            "Requirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (2.0.7)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (2.4.0)\n",
            "Collecting yacs>=0.1.8 (from detectron2==0.6)\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (0.9.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (2.2.1)\n",
            "Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (4.66.4)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (2.15.2)\n",
            "Collecting fvcore<0.1.6,>=0.1.5 (from detectron2==0.6)\n",
            "  Downloading fvcore-0.1.5.post20221221.tar.gz (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting iopath<0.1.10,>=0.1.7 (from detectron2==0.6)\n",
            "  Downloading iopath-0.1.9-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (0.18.3)\n",
            "Requirement already satisfied: pydot in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (1.4.2)\n",
            "Collecting omegaconf>=2.1 (from detectron2==0.6)\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting hydra-core>=1.1 (from detectron2==0.6)\n",
            "  Downloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting black==22.3.0 (from detectron2==0.6)\n",
            "  Downloading black-22.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m78.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting timm (from detectron2==0.6)\n",
            "  Downloading timm-1.0.3-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m88.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fairscale (from detectron2==0.6)\n",
            "  Downloading fairscale-0.4.13.tar.gz (266 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m266.3/266.3 kB\u001b[0m \u001b[31m37.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (24.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from black==22.3.0->detectron2==0.6) (8.1.7)\n",
            "Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.10/dist-packages (from black==22.3.0->detectron2==0.6) (4.2.1)\n",
            "Collecting pathspec>=0.9.0 (from black==22.3.0->detectron2==0.6)\n",
            "  Downloading pathspec-0.12.1-py3-none-any.whl (31 kB)\n",
            "Collecting mypy-extensions>=0.4.3 (from black==22.3.0->detectron2==0.6)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from black==22.3.0->detectron2==0.6) (2.0.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (1.25.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (6.0.1)\n",
            "Collecting antlr4-python3-runtime==4.9.* (from hydra-core>=1.1->detectron2==0.6)\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting portalocker (from iopath<0.1.10,>=0.1.7->detectron2==0.6)\n",
            "  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (2.8.2)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from fairscale->detectron2==0.6) (2.2.1+cu121)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (1.63.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (3.6)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (2.31.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (67.7.2)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (3.0.3)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm->detectron2==0.6) (0.17.1+cu121)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (from timm->detectron2==0.6) (0.20.3)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm->detectron2==0.6) (0.4.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard->detectron2==0.6) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (2024.2.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->fairscale->detectron2==0.6) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->fairscale->detectron2==0.6) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->fairscale->detectron2==0.6) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->fairscale->detectron2==0.6) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->fairscale->detectron2==0.6) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->fairscale->detectron2==0.6) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.8.0->fairscale->detectron2==0.6)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.8.0->fairscale->detectron2==0.6)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.8.0->fairscale->detectron2==0.6)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.8.0->fairscale->detectron2==0.6)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.8.0->fairscale->detectron2==0.6)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.8.0->fairscale->detectron2==0.6)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.8.0->fairscale->detectron2==0.6)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.8.0->fairscale->detectron2==0.6)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.8.0->fairscale->detectron2==0.6)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch>=1.8.0->fairscale->detectron2==0.6)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.8.0->fairscale->detectron2==0.6)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->fairscale->detectron2==0.6) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.0->fairscale->detectron2==0.6)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard->detectron2==0.6) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard->detectron2==0.6) (3.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->fairscale->detectron2==0.6) (1.3.0)\n",
            "Building wheels for collected packages: detectron2, fvcore, antlr4-python3-runtime, fairscale\n",
            "  Building wheel for detectron2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for detectron2: filename=detectron2-0.6-cp310-cp310-linux_x86_64.whl size=6172643 sha256=e18607ab2c5c9054bdaf562b76228fa8ed02f478cb79ff3c4284ae3e02d466d6\n",
            "  Stored in directory: /root/.cache/pip/wheels/93/68/da/76b0102912a9ea75cda929a4556a3eb0e5377b1d1ce0a79940\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fvcore: filename=fvcore-0.1.5.post20221221-py3-none-any.whl size=61400 sha256=a16f9d7f8093910cb59c1033be37b13a1f03b715185af14acffd640c1657ab27\n",
            "  Stored in directory: /root/.cache/pip/wheels/01/c0/af/77c1cf53a1be9e42a52b48e5af2169d40ec2e89f7362489dd0\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=f3a020922bce7ecfd72f5c4d50b3569929f8fac533b7ea35443fec1acf286d35\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n",
            "  Building wheel for fairscale (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fairscale: filename=fairscale-0.4.13-py3-none-any.whl size=332108 sha256=a16a66fed4408837407a7a4127b7fced0d2586af400157e107a91ab8c436fa6b\n",
            "  Stored in directory: /root/.cache/pip/wheels/78/a4/c0/fb0a7ef03cff161611c3fa40c6cf898f76e58ec421b88e8cb3\n",
            "Successfully built detectron2 fvcore antlr4-python3-runtime fairscale\n",
            "Installing collected packages: antlr4-python3-runtime, yacs, portalocker, pathspec, omegaconf, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, mypy-extensions, nvidia-cusparse-cu12, nvidia-cudnn-cu12, iopath, hydra-core, black, nvidia-cusolver-cu12, fvcore, fairscale, timm, detectron2\n",
            "Successfully installed antlr4-python3-runtime-4.9.3 black-22.3.0 detectron2-0.6 fairscale-0.4.13 fvcore-0.1.5.post20221221 hydra-core-1.3.2 iopath-0.1.9 mypy-extensions-1.0.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 omegaconf-2.3.0 pathspec-0.12.1 portalocker-2.8.2 timm-1.0.3 yacs-0.1.8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pydevd_plugins"
                ]
              },
              "id": "98de853d8de54b659b3a182f4f9809f9"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/\n",
        "!git clone https://github.com/DomMcOyle/TACO-expl.git\n",
        "%cd /content/TACO-expl\n",
        "!git checkout maskdino\n",
        "!git pull origin maskdino\n",
        "%cd /content/TACO-expl/MaskDINO\n",
        "!pip install -r requirements.txt\n",
        "%cd /content/TACO-expl/MaskDINO/maskdino/modeling/pixel_decoder/ops\n",
        "!sh make.sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X9P0HDTGnRDI",
        "outputId": "3469669d-65eb-422a-af84-9bf77d7cd718"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'TACO-expl'...\n",
            "remote: Enumerating objects: 2370, done.\u001b[K\n",
            "remote: Counting objects: 100% (2370/2370), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1143/1143), done.\u001b[K\n",
            "remote: Total 2370 (delta 1241), reused 2289 (delta 1188), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (2370/2370), 129.86 MiB | 13.71 MiB/s, done.\n",
            "Resolving deltas: 100% (1241/1241), done.\n",
            "/content/TACO-expl\n",
            "Branch 'maskdino' set up to track remote branch 'maskdino' from 'origin'.\n",
            "Switched to a new branch 'maskdino'\n",
            "From https://github.com/DomMcOyle/TACO-expl\n",
            " * branch            maskdino   -> FETCH_HEAD\n",
            "Already up to date.\n",
            "/content/TACO-expl/MaskDINO\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (3.0.10)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (1.11.4)\n",
            "Requirement already satisfied: shapely in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (2.0.4)\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (1.0.3)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (3.9.0)\n",
            "Collecting submitit (from -r requirements.txt (line 6))\n",
            "  Downloading submitit-1.5.1-py3-none-any.whl (74 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.7/74.7 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (0.19.3)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (4.8.0.76)\n",
            "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy->-r requirements.txt (line 2)) (1.25.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from timm->-r requirements.txt (line 4)) (2.2.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm->-r requirements.txt (line 4)) (0.17.1+cu121)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm->-r requirements.txt (line 4)) (6.0.1)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (from timm->-r requirements.txt (line 4)) (0.20.3)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm->-r requirements.txt (line 4)) (0.4.3)\n",
            "Requirement already satisfied: cloudpickle>=1.2.1 in /usr/local/lib/python3.10/dist-packages (from submitit->-r requirements.txt (line 6)) (2.2.1)\n",
            "Requirement already satisfied: typing_extensions>=3.7.4.2 in /usr/local/lib/python3.10/dist-packages (from submitit->-r requirements.txt (line 6)) (4.11.0)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image->-r requirements.txt (line 7)) (3.3)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->-r requirements.txt (line 7)) (9.4.0)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->-r requirements.txt (line 7)) (2.31.6)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->-r requirements.txt (line 7)) (2024.5.10)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->-r requirements.txt (line 7)) (1.6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->-r requirements.txt (line 7)) (24.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm->-r requirements.txt (line 4)) (3.14.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm->-r requirements.txt (line 4)) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm->-r requirements.txt (line 4)) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm->-r requirements.txt (line 4)) (4.66.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->timm->-r requirements.txt (line 4)) (1.12)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->timm->-r requirements.txt (line 4)) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->timm->-r requirements.txt (line 4)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->timm->-r requirements.txt (line 4)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->timm->-r requirements.txt (line 4)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->timm->-r requirements.txt (line 4)) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->timm->-r requirements.txt (line 4)) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->timm->-r requirements.txt (line 4)) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->timm->-r requirements.txt (line 4)) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->timm->-r requirements.txt (line 4)) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->timm->-r requirements.txt (line 4)) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch->timm->-r requirements.txt (line 4)) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->timm->-r requirements.txt (line 4)) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->timm->-r requirements.txt (line 4)) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->timm->-r requirements.txt (line 4)) (12.4.127)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->timm->-r requirements.txt (line 4)) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm->-r requirements.txt (line 4)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm->-r requirements.txt (line 4)) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm->-r requirements.txt (line 4)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm->-r requirements.txt (line 4)) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->timm->-r requirements.txt (line 4)) (1.3.0)\n",
            "Installing collected packages: submitit\n",
            "Successfully installed submitit-1.5.1\n",
            "/content/TACO-expl/MaskDINO/maskdino/modeling/pixel_decoder/ops\n",
            "running build\n",
            "running build_py\n",
            "creating build\n",
            "creating build/lib.linux-x86_64-cpython-310\n",
            "creating build/lib.linux-x86_64-cpython-310/functions\n",
            "copying functions/__init__.py -> build/lib.linux-x86_64-cpython-310/functions\n",
            "copying functions/ms_deform_attn_func.py -> build/lib.linux-x86_64-cpython-310/functions\n",
            "creating build/lib.linux-x86_64-cpython-310/modules\n",
            "copying modules/ms_deform_attn.py -> build/lib.linux-x86_64-cpython-310/modules\n",
            "copying modules/__init__.py -> build/lib.linux-x86_64-cpython-310/modules\n",
            "running build_ext\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py:500: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n",
            "  warnings.warn(msg.format('we could not find ninja.'))\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py:415: UserWarning: The detected CUDA version (12.2) has a minor version mismatch with the version that was used to compile PyTorch (12.1). Most likely this shouldn't be a problem.\n",
            "  warnings.warn(CUDA_MISMATCH_WARN.format(cuda_str_version, torch.version.cuda))\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py:425: UserWarning: There are no x86_64-linux-gnu-g++ version bounds defined for CUDA version 12.2\n",
            "  warnings.warn(f'There are no {compiler_name} version bounds defined for CUDA version {cuda_str_version}')\n",
            "building 'MultiScaleDeformableAttention' extension\n",
            "creating build/temp.linux-x86_64-cpython-310\n",
            "creating build/temp.linux-x86_64-cpython-310/content\n",
            "creating build/temp.linux-x86_64-cpython-310/content/TACO-expl\n",
            "creating build/temp.linux-x86_64-cpython-310/content/TACO-expl/MaskDINO\n",
            "creating build/temp.linux-x86_64-cpython-310/content/TACO-expl/MaskDINO/maskdino\n",
            "creating build/temp.linux-x86_64-cpython-310/content/TACO-expl/MaskDINO/maskdino/modeling\n",
            "creating build/temp.linux-x86_64-cpython-310/content/TACO-expl/MaskDINO/maskdino/modeling/pixel_decoder\n",
            "creating build/temp.linux-x86_64-cpython-310/content/TACO-expl/MaskDINO/maskdino/modeling/pixel_decoder/ops\n",
            "creating build/temp.linux-x86_64-cpython-310/content/TACO-expl/MaskDINO/maskdino/modeling/pixel_decoder/ops/src\n",
            "creating build/temp.linux-x86_64-cpython-310/content/TACO-expl/MaskDINO/maskdino/modeling/pixel_decoder/ops/src/cpu\n",
            "creating build/temp.linux-x86_64-cpython-310/content/TACO-expl/MaskDINO/maskdino/modeling/pixel_decoder/ops/src/cuda\n",
            "x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -DWITH_CUDA -I/content/TACO-expl/MaskDINO/maskdino/modeling/pixel_decoder/ops/src -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.10 -c /content/TACO-expl/MaskDINO/maskdino/modeling/pixel_decoder/ops/src/cpu/ms_deform_attn_cpu.cpp -o build/temp.linux-x86_64-cpython-310/content/TACO-expl/MaskDINO/maskdino/modeling/pixel_decoder/ops/src/cpu/ms_deform_attn_cpu.o -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=MultiScaleDeformableAttention -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
            "/usr/local/cuda/bin/nvcc -DWITH_CUDA -I/content/TACO-expl/MaskDINO/maskdino/modeling/pixel_decoder/ops/src -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.10 -c /content/TACO-expl/MaskDINO/maskdino/modeling/pixel_decoder/ops/src/cuda/ms_deform_attn_cuda.cu -o build/temp.linux-x86_64-cpython-310/content/TACO-expl/MaskDINO/maskdino/modeling/pixel_decoder/ops/src/cuda/ms_deform_attn_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -DCUDA_HAS_FP16=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=MultiScaleDeformableAttention -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++17\n",
            "\u001b[01m\u001b[0m\u001b[01m/content/TACO-expl/MaskDINO/maskdino/modeling/pixel_decoder/ops/src/cuda/ms_deform_im2col_cuda.cuh(266)\u001b[0m: \u001b[01;35mwarning\u001b[0m #177-D: variable \u001b[01m\"q_col\"\u001b[0m was declared but never referenced\n",
            "      const int q_col = _temp % num_query;\n",
            "                ^\n",
            "          detected during instantiation of \u001b[01m\"void ms_deformable_im2col_cuda(cudaStream_t, const scalar_t *, const int64_t *, const int64_t *, const scalar_t *, const scalar_t *, int, int, int, int, int, int, int, scalar_t *) [with scalar_t=double]\"\u001b[0m \u001b[32mat line 69 of /content/TACO-expl/MaskDINO/maskdino/modeling/pixel_decoder/ops/src/cuda/ms_deform_attn_cuda.cu\u001b[0m\n",
            "\n",
            "\u001b[01;36m\u001b[0m\u001b[01;36mRemark\u001b[0m: The warnings can be suppressed with \"-diag-suppress <warning-number>\"\n",
            "\n",
            "\u001b[01m\u001b[0m\u001b[01m/content/TACO-expl/MaskDINO/maskdino/modeling/pixel_decoder/ops/src/cuda/ms_deform_im2col_cuda.cuh(767)\u001b[0m: \u001b[01;35mwarning\u001b[0m #177-D: variable \u001b[01m\"q_col\"\u001b[0m was declared but never referenced\n",
            "      const int q_col = _temp % num_query;\n",
            "                ^\n",
            "          detected during instantiation of \u001b[01m\"void ms_deformable_col2im_cuda(cudaStream_t, const scalar_t *, const scalar_t *, const int64_t *, const int64_t *, const scalar_t *, const scalar_t *, int, int, int, int, int, int, int, scalar_t *, scalar_t *, scalar_t *) [with scalar_t=double]\"\u001b[0m \u001b[32mat line 139 of /content/TACO-expl/MaskDINO/maskdino/modeling/pixel_decoder/ops/src/cuda/ms_deform_attn_cuda.cu\u001b[0m\n",
            "\n",
            "\u001b[01m\u001b[0m\u001b[01m/content/TACO-expl/MaskDINO/maskdino/modeling/pixel_decoder/ops/src/cuda/ms_deform_im2col_cuda.cuh(877)\u001b[0m: \u001b[01;35mwarning\u001b[0m #177-D: variable \u001b[01m\"q_col\"\u001b[0m was declared but never referenced\n",
            "      const int q_col = _temp % num_query;\n",
            "                ^\n",
            "          detected during instantiation of \u001b[01m\"void ms_deformable_col2im_cuda(cudaStream_t, const scalar_t *, const scalar_t *, const int64_t *, const int64_t *, const scalar_t *, const scalar_t *, int, int, int, int, int, int, int, scalar_t *, scalar_t *, scalar_t *) [with scalar_t=double]\"\u001b[0m \u001b[32mat line 139 of /content/TACO-expl/MaskDINO/maskdino/modeling/pixel_decoder/ops/src/cuda/ms_deform_attn_cuda.cu\u001b[0m\n",
            "\n",
            "\u001b[01m\u001b[0m\u001b[01m/content/TACO-expl/MaskDINO/maskdino/modeling/pixel_decoder/ops/src/cuda/ms_deform_im2col_cuda.cuh(336)\u001b[0m: \u001b[01;35mwarning\u001b[0m #177-D: variable \u001b[01m\"q_col\"\u001b[0m was declared but never referenced\n",
            "      const int q_col = _temp % num_query;\n",
            "                ^\n",
            "          detected during instantiation of \u001b[01m\"void ms_deformable_col2im_cuda(cudaStream_t, const scalar_t *, const scalar_t *, const int64_t *, const int64_t *, const scalar_t *, const scalar_t *, int, int, int, int, int, int, int, scalar_t *, scalar_t *, scalar_t *) [with scalar_t=double]\"\u001b[0m \u001b[32mat line 139 of /content/TACO-expl/MaskDINO/maskdino/modeling/pixel_decoder/ops/src/cuda/ms_deform_attn_cuda.cu\u001b[0m\n",
            "\n",
            "\u001b[01m\u001b[0m\u001b[01m/content/TACO-expl/MaskDINO/maskdino/modeling/pixel_decoder/ops/src/cuda/ms_deform_im2col_cuda.cuh(441)\u001b[0m: \u001b[01;35mwarning\u001b[0m #177-D: variable \u001b[01m\"q_col\"\u001b[0m was declared but never referenced\n",
            "      const int q_col = _temp % num_query;\n",
            "                ^\n",
            "          detected during instantiation of \u001b[01m\"void ms_deformable_col2im_cuda(cudaStream_t, const scalar_t *, const scalar_t *, const int64_t *, const int64_t *, const scalar_t *, const scalar_t *, int, int, int, int, int, int, int, scalar_t *, scalar_t *, scalar_t *) [with scalar_t=double]\"\u001b[0m \u001b[32mat line 139 of /content/TACO-expl/MaskDINO/maskdino/modeling/pixel_decoder/ops/src/cuda/ms_deform_attn_cuda.cu\u001b[0m\n",
            "\n",
            "\u001b[01m\u001b[0m\u001b[01m/content/TACO-expl/MaskDINO/maskdino/modeling/pixel_decoder/ops/src/cuda/ms_deform_im2col_cuda.cuh(549)\u001b[0m: \u001b[01;35mwarning\u001b[0m #177-D: variable \u001b[01m\"q_col\"\u001b[0m was declared but never referenced\n",
            "      const int q_col = _temp % num_query;\n",
            "                ^\n",
            "          detected during instantiation of \u001b[01m\"void ms_deformable_col2im_cuda(cudaStream_t, const scalar_t *, const scalar_t *, const int64_t *, const int64_t *, const scalar_t *, const scalar_t *, int, int, int, int, int, int, int, scalar_t *, scalar_t *, scalar_t *) [with scalar_t=double]\"\u001b[0m \u001b[32mat line 139 of /content/TACO-expl/MaskDINO/maskdino/modeling/pixel_decoder/ops/src/cuda/ms_deform_attn_cuda.cu\u001b[0m\n",
            "\n",
            "\u001b[01m\u001b[0m\u001b[01m/content/TACO-expl/MaskDINO/maskdino/modeling/pixel_decoder/ops/src/cuda/ms_deform_im2col_cuda.cuh(654)\u001b[0m: \u001b[01;35mwarning\u001b[0m #177-D: variable \u001b[01m\"q_col\"\u001b[0m was declared but never referenced\n",
            "      const int q_col = _temp % num_query;\n",
            "                ^\n",
            "          detected during instantiation of \u001b[01m\"void ms_deformable_col2im_cuda(cudaStream_t, const scalar_t *, const scalar_t *, const int64_t *, const int64_t *, const scalar_t *, const scalar_t *, int, int, int, int, int, int, int, scalar_t *, scalar_t *, scalar_t *) [with scalar_t=double]\"\u001b[0m \u001b[32mat line 139 of /content/TACO-expl/MaskDINO/maskdino/modeling/pixel_decoder/ops/src/cuda/ms_deform_attn_cuda.cu\u001b[0m\n",
            "\n",
            "\u001b[01m\u001b[K/content/TACO-expl/MaskDINO/maskdino/modeling/pixel_decoder/ops/src/cuda/ms_deform_attn_cuda.cu:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kat::Tensor ms_deform_attn_cuda_forward(const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, int)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K/content/TACO-expl/MaskDINO/maskdino/modeling/pixel_decoder/ops/src/cuda/ms_deform_attn_cuda.cu:39:61:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   39 |     AT_ASSERTM(value.type().is_cuda(), \"value must\u001b[01;35m\u001b[K be a CUDA t\u001b[m\u001b[Kensor\");\n",
            "      |                                                   \u001b[01;35m\u001b[K~~~~~~~~~~^~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:225:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  225 | \u001b[01;36m\u001b[K  De\u001b[m\u001b[KprecatedTypeProperties & type() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/TACO-expl/MaskDINO/maskdino/modeling/pixel_decoder/ops/src/cuda/ms_deform_attn_cuda.cu:40:70:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   40 |     AT_ASSERTM(spatial_shapes.type().is_cuda(), \"s\u001b[01;35m\u001b[Kpatial_shapes must be\u001b[m\u001b[K a CUDA tensor\");\n",
            "      |                                                   \u001b[01;35m\u001b[K~~~~~~~~~~~~~~~~~~~^~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:225:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  225 | \u001b[01;36m\u001b[K  De\u001b[m\u001b[KprecatedTypeProperties & type() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/TACO-expl/MaskDINO/maskdino/modeling/pixel_decoder/ops/src/cuda/ms_deform_attn_cuda.cu:41:73:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   41 |     AT_ASSERTM(level_start_index.type().is_cuda(),\u001b[01;35m\u001b[K \"level_start_index must\u001b[m\u001b[K be a CUDA tensor\");\n",
            "      |                                                   \u001b[01;35m\u001b[K~~~~~~~~~~~~~~~~~~~~~~^~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:225:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  225 | \u001b[01;36m\u001b[K  De\u001b[m\u001b[KprecatedTypeProperties & type() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/TACO-expl/MaskDINO/maskdino/modeling/pixel_decoder/ops/src/cuda/ms_deform_attn_cuda.cu:42:68:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   42 |     AT_ASSERTM(sampling_loc.type().is_cuda(), \"sam\u001b[01;35m\u001b[Kpling_loc must be a\u001b[m\u001b[K CUDA tensor\");\n",
            "      |                                                   \u001b[01;35m\u001b[K~~~~~~~~~~~~~~~~~^~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:225:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  225 | \u001b[01;36m\u001b[K  De\u001b[m\u001b[KprecatedTypeProperties & type() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/TACO-expl/MaskDINO/maskdino/modeling/pixel_decoder/ops/src/cuda/ms_deform_attn_cuda.cu:43:67:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   43 |     AT_ASSERTM(attn_weight.type().is_cuda(), \"attn\u001b[01;35m\u001b[K_weight must be a \u001b[m\u001b[KCUDA tensor\");\n",
            "      |                                                   \u001b[01;35m\u001b[K~~~~~~~~~~~~~~~~^~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:225:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  225 | \u001b[01;36m\u001b[K  De\u001b[m\u001b[KprecatedTypeProperties & type() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/TACO-expl/MaskDINO/maskdino/modeling/pixel_decoder/ops/src/cuda/ms_deform_attn_cuda.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[K/content/TACO-expl/MaskDINO/maskdino/modeling/pixel_decoder/ops/src/cuda/ms_deform_attn_cuda.cu:69:42:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   69 |         AT_DISPATCH_FLOATING_\u001b[01;35m\u001b[KTYPES(value.ty\u001b[m\u001b[Kpe(), \"ms_deform_attn_forward_cuda\", ([&] {\n",
            "      |                              \u001b[01;35m\u001b[K~~~~~~~~~~~~^~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:225:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  225 | \u001b[01;36m\u001b[K  De\u001b[m\u001b[KprecatedTypeProperties & type() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/TACO-expl/MaskDINO/maskdino/modeling/pixel_decoder/ops/src/cuda/ms_deform_attn_cuda.cu:69:163:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kc10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)\u001b[m\u001b[K’ is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   69 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_forward_cuda\", ([&] {\n",
            "      |                                                                                                                                                                   \u001b[01;35m\u001b[K^\u001b[m\u001b[K         \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:109:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  109 | \u001b[01;36m\u001b[Kinline at::\u001b[m\u001b[KScalarType scalar_type(const at::DeprecatedTypeProperties& t) {\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/TACO-expl/MaskDINO/maskdino/modeling/pixel_decoder/ops/src/cuda/ms_deform_attn_cuda.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[K/content/TACO-expl/MaskDINO/maskdino/modeling/pixel_decoder/ops/src/cuda/ms_deform_attn_cuda.cu:69:1074:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   69 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_forward_cuda\", ([&] {\n",
            "      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:247:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  247 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/TACO-expl/MaskDINO/maskdino/modeling/pixel_decoder/ops/src/cuda/ms_deform_attn_cuda.cu:69:1160:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = long int]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   69 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_forward_cuda\", ([&] {\n",
            "      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:247:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  247 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/TACO-expl/MaskDINO/maskdino/modeling/pixel_decoder/ops/src/cuda/ms_deform_attn_cuda.cu:69:1203:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = long int]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   69 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_forward_cuda\", ([&] {\n",
            "      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:247:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  247 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/TACO-expl/MaskDINO/maskdino/modeling/pixel_decoder/ops/src/cuda/ms_deform_attn_cuda.cu:69:1236:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   69 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_forward_cuda\", ([&] {\n",
            "      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:247:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  247 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/TACO-expl/MaskDINO/maskdino/modeling/pixel_decoder/ops/src/cuda/ms_deform_attn_cuda.cu:69:1319:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   69 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_forward_cuda\", ([&] {\n",
            "      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:247:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  247 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/TACO-expl/MaskDINO/maskdino/modeling/pixel_decoder/ops/src/cuda/ms_deform_attn_cuda.cu:69:1477:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   69 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_forward_cuda\", ([&] {\n",
            "      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:247:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  247 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/TACO-expl/MaskDINO/maskdino/modeling/pixel_decoder/ops/src/cuda/ms_deform_attn_cuda.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[K/content/TACO-expl/MaskDINO/maskdino/modeling/pixel_decoder/ops/src/cuda/ms_deform_attn_cuda.cu:69:2368:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   69 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_forward_cuda\", ([&] {\n",
            "      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:247:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  247 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/TACO-expl/MaskDINO/maskdino/modeling/pixel_decoder/ops/src/cuda/ms_deform_attn_cuda.cu:69:2454:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = long int]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   69 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_forward_cuda\", ([&] {\n",
            "      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:247:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  247 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/TACO-expl/MaskDINO/maskdino/modeling/pixel_decoder/ops/src/cuda/ms_deform_attn_cuda.cu:69:2497:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = long int]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   69 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_forward_cuda\", ([&] {\n",
            "      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:247:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  247 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/TACO-expl/MaskDINO/maskdino/modeling/pixel_decoder/ops/src/cuda/ms_deform_attn_cuda.cu:69:2529:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   69 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_forward_cuda\", ([&] {\n",
            "      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:247:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  247 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/TACO-expl/MaskDINO/maskdino/modeling/pixel_decoder/ops/src/cuda/ms_deform_attn_cuda.cu:69:2611:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   69 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_forward_cuda\", ([&] {\n",
            "      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:247:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  247 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/TACO-expl/MaskDINO/maskdino/modeling/pixel_decoder/ops/src/cuda/ms_deform_attn_cuda.cu:69:2768:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   69 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_forward_cuda\", ([&] {\n",
            "      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:247:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  247 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/TACO-expl/MaskDINO/maskdino/modeling/pixel_decoder/ops/src/cuda/ms_deform_attn_cuda.cu:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kstd::vector<at::Tensor> ms_deform_attn_cuda_backward(const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, int)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K/content/TACO-expl/MaskDINO/maskdino/modeling/pixel_decoder/ops/src/cuda/ms_deform_attn_cuda.cu:105:61:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  105 |     AT_ASSERTM(value.type().is_cuda(), \"value must\u001b[01;35m\u001b[K be a CUDA t\u001b[m\u001b[Kensor\");\n",
            "      |                                                   \u001b[01;35m\u001b[K~~~~~~~~~~^~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:225:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  225 | \u001b[01;36m\u001b[K  De\u001b[m\u001b[KprecatedTypeProperties & type() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/TACO-expl/MaskDINO/maskdino/modeling/pixel_decoder/ops/src/cuda/ms_deform_attn_cuda.cu:106:70:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  106 |     AT_ASSERTM(spatial_shapes.type().is_cuda(), \"s\u001b[01;35m\u001b[Kpatial_shapes must be\u001b[m\u001b[K a CUDA tensor\");\n",
            "      |                                                   \u001b[01;35m\u001b[K~~~~~~~~~~~~~~~~~~~^~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:225:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  225 | \u001b[01;36m\u001b[K  De\u001b[m\u001b[KprecatedTypeProperties & type() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/TACO-expl/MaskDINO/maskdino/modeling/pixel_decoder/ops/src/cuda/ms_deform_attn_cuda.cu:107:73:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  107 |     AT_ASSERTM(level_start_index.type().is_cuda(),\u001b[01;35m\u001b[K \"level_start_index must\u001b[m\u001b[K be a CUDA tensor\");\n",
            "      |                                                   \u001b[01;35m\u001b[K~~~~~~~~~~~~~~~~~~~~~~^~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:225:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  225 | \u001b[01;36m\u001b[K  De\u001b[m\u001b[KprecatedTypeProperties & type() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/TACO-expl/MaskDINO/maskdino/modeling/pixel_decoder/ops/src/cuda/ms_deform_attn_cuda.cu:108:68:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  108 |     AT_ASSERTM(sampling_loc.type().is_cuda(), \"sam\u001b[01;35m\u001b[Kpling_loc must be a\u001b[m\u001b[K CUDA tensor\");\n",
            "      |                                                   \u001b[01;35m\u001b[K~~~~~~~~~~~~~~~~~^~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:225:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  225 | \u001b[01;36m\u001b[K  De\u001b[m\u001b[KprecatedTypeProperties & type() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/TACO-expl/MaskDINO/maskdino/modeling/pixel_decoder/ops/src/cuda/ms_deform_attn_cuda.cu:109:67:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  109 |     AT_ASSERTM(attn_weight.type().is_cuda(), \"attn\u001b[01;35m\u001b[K_weight must be a \u001b[m\u001b[KCUDA tensor\");\n",
            "      |                                                   \u001b[01;35m\u001b[K~~~~~~~~~~~~~~~~^~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:225:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  225 | \u001b[01;36m\u001b[K  De\u001b[m\u001b[KprecatedTypeProperties & type() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/TACO-expl/MaskDINO/maskdino/modeling/pixel_decoder/ops/src/cuda/ms_deform_attn_cuda.cu:110:67:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  110 |     AT_ASSERTM(grad_output.type().is_cuda(), \"grad\u001b[01;35m\u001b[K_output must be a \u001b[m\u001b[KCUDA tensor\");\n",
            "      |                                                   \u001b[01;35m\u001b[K~~~~~~~~~~~~~~~~^~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:225:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  225 | \u001b[01;36m\u001b[K  De\u001b[m\u001b[KprecatedTypeProperties & type() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/TACO-expl/MaskDINO/maskdino/modeling/pixel_decoder/ops/src/cuda/ms_deform_attn_cuda.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[K/content/TACO-expl/MaskDINO/maskdino/modeling/pixel_decoder/ops/src/cuda/ms_deform_attn_cuda.cu:139:42:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  139 |         AT_DISPATCH_FLOATING_\u001b[01;35m\u001b[KTYPES(value.ty\u001b[m\u001b[Kpe(), \"ms_deform_attn_backward_cuda\", ([&] {\n",
            "      |                              \u001b[01;35m\u001b[K~~~~~~~~~~~~^~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:225:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  225 | \u001b[01;36m\u001b[K  De\u001b[m\u001b[KprecatedTypeProperties & type() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/TACO-expl/MaskDINO/maskdino/modeling/pixel_decoder/ops/src/cuda/ms_deform_attn_cuda.cu:139:164:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kc10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)\u001b[m\u001b[K’ is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  139 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_backward_cuda\", ([&] {\n",
            "      |                                                                                                                                                                    \u001b[01;35m\u001b[K^\u001b[m\u001b[K         \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:109:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  109 | \u001b[01;36m\u001b[Kinline at::\u001b[m\u001b[KScalarType scalar_type(const at::DeprecatedTypeProperties& t) {\n",
            "      | \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/TACO-expl/MaskDINO/maskdino/modeling/pixel_decoder/ops/src/cuda/ms_deform_attn_cuda.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[K/content/TACO-expl/MaskDINO/maskdino/modeling/pixel_decoder/ops/src/cuda/ms_deform_attn_cuda.cu:139:1084:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  139 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_backward_cuda\", ([&] {\n",
            "      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:247:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  247 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/TACO-expl/MaskDINO/maskdino/modeling/pixel_decoder/ops/src/cuda/ms_deform_attn_cuda.cu:139:1110:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  139 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_backward_cuda\", ([&] {\n",
            "      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:247:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  247 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/TACO-expl/MaskDINO/maskdino/modeling/pixel_decoder/ops/src/cuda/ms_deform_attn_cuda.cu:139:1196:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = long int]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  139 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_backward_cuda\", ([&] {\n",
            "      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:247:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  247 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/TACO-expl/MaskDINO/maskdino/modeling/pixel_decoder/ops/src/cuda/ms_deform_attn_cuda.cu:139:1239:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = long int]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  139 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_backward_cuda\", ([&] {\n",
            "      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:247:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  247 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/TACO-expl/MaskDINO/maskdino/modeling/pixel_decoder/ops/src/cuda/ms_deform_attn_cuda.cu:139:1272:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  139 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_backward_cuda\", ([&] {\n",
            "      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:247:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  247 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/TACO-expl/MaskDINO/maskdino/modeling/pixel_decoder/ops/src/cuda/ms_deform_attn_cuda.cu:139:1355:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  139 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_backward_cuda\", ([&] {\n",
            "      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:247:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  247 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/TACO-expl/MaskDINO/maskdino/modeling/pixel_decoder/ops/src/cuda/ms_deform_attn_cuda.cu:139:1516:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  139 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_backward_cuda\", ([&] {\n",
            "      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:247:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  247 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/TACO-expl/MaskDINO/maskdino/modeling/pixel_decoder/ops/src/cuda/ms_deform_attn_cuda.cu:139:1600:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  139 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_backward_cuda\", ([&] {\n",
            "      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:247:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  247 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/TACO-expl/MaskDINO/maskdino/modeling/pixel_decoder/ops/src/cuda/ms_deform_attn_cuda.cu:139:1688:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  139 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_backward_cuda\", ([&] {\n",
            "      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:247:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  247 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/TACO-expl/MaskDINO/maskdino/modeling/pixel_decoder/ops/src/cuda/ms_deform_attn_cuda.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[K/content/TACO-expl/MaskDINO/maskdino/modeling/pixel_decoder/ops/src/cuda/ms_deform_attn_cuda.cu:139:2640:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  139 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_backward_cuda\", ([&] {\n",
            "      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:247:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  247 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/TACO-expl/MaskDINO/maskdino/modeling/pixel_decoder/ops/src/cuda/ms_deform_attn_cuda.cu:139:2665:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  139 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_backward_cuda\", ([&] {\n",
            "      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:247:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  247 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/TACO-expl/MaskDINO/maskdino/modeling/pixel_decoder/ops/src/cuda/ms_deform_attn_cuda.cu:139:2751:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = long int]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  139 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_backward_cuda\", ([&] {\n",
            "      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:247:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  247 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/TACO-expl/MaskDINO/maskdino/modeling/pixel_decoder/ops/src/cuda/ms_deform_attn_cuda.cu:139:2794:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = long int]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  139 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_backward_cuda\", ([&] {\n",
            "      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:247:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  247 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/TACO-expl/MaskDINO/maskdino/modeling/pixel_decoder/ops/src/cuda/ms_deform_attn_cuda.cu:139:2826:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  139 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_backward_cuda\", ([&] {\n",
            "      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:247:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  247 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/TACO-expl/MaskDINO/maskdino/modeling/pixel_decoder/ops/src/cuda/ms_deform_attn_cuda.cu:139:2908:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  139 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_backward_cuda\", ([&] {\n",
            "      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:247:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  247 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/TACO-expl/MaskDINO/maskdino/modeling/pixel_decoder/ops/src/cuda/ms_deform_attn_cuda.cu:139:3068:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  139 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_backward_cuda\", ([&] {\n",
            "      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:247:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  247 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/TACO-expl/MaskDINO/maskdino/modeling/pixel_decoder/ops/src/cuda/ms_deform_attn_cuda.cu:139:3151:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  139 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_backward_cuda\", ([&] {\n",
            "      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:247:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  247 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/content/TACO-expl/MaskDINO/maskdino/modeling/pixel_decoder/ops/src/cuda/ms_deform_attn_cuda.cu:139:3238:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[K’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  139 |         AT_DISPATCH_FLOATING_TYPES(value.type(), \"ms_deform_attn_backward_cuda\", ([&] {\n",
            "      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \u001b[01;35m\u001b[K^\u001b[m\u001b[K \n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:247:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  247 | \u001b[01;36m\u001b[K  T \u001b[m\u001b[K* data() const {\n",
            "      | \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n",
            "x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -DWITH_CUDA -I/content/TACO-expl/MaskDINO/maskdino/modeling/pixel_decoder/ops/src -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.10 -c /content/TACO-expl/MaskDINO/maskdino/modeling/pixel_decoder/ops/src/vision.cpp -o build/temp.linux-x86_64-cpython-310/content/TACO-expl/MaskDINO/maskdino/modeling/pixel_decoder/ops/src/vision.o -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=MultiScaleDeformableAttention -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
            "In file included from \u001b[01m\u001b[K/content/TACO-expl/MaskDINO/maskdino/modeling/pixel_decoder/ops/src/vision.cpp:16\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/content/TACO-expl/MaskDINO/maskdino/modeling/pixel_decoder/ops/src/ms_deform_attn.h:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kat::Tensor ms_deform_attn_forward(const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, int)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K/content/TACO-expl/MaskDINO/maskdino/modeling/pixel_decoder/ops/src/ms_deform_attn.h:34:19:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   34 |     if (\u001b[01;35m\u001b[Kvalue.type()\u001b[m\u001b[K.is_cuda())\n",
            "      |         \u001b[01;35m\u001b[K~~~~~~~~~~^~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/extension.h:5\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/TACO-expl/MaskDINO/maskdino/modeling/pixel_decoder/ops/src/cpu/ms_deform_attn_cpu.h:17\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/TACO-expl/MaskDINO/maskdino/modeling/pixel_decoder/ops/src/ms_deform_attn.h:18\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/TACO-expl/MaskDINO/maskdino/modeling/pixel_decoder/ops/src/vision.cpp:16\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:225:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  225 |   DeprecatedTypeProperties & \u001b[01;36m\u001b[Ktype\u001b[m\u001b[K() const {\n",
            "      |                              \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/content/TACO-expl/MaskDINO/maskdino/modeling/pixel_decoder/ops/src/vision.cpp:16\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/content/TACO-expl/MaskDINO/maskdino/modeling/pixel_decoder/ops/src/ms_deform_attn.h:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kstd::vector<at::Tensor> ms_deform_attn_backward(const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, const at::Tensor&, int)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K/content/TACO-expl/MaskDINO/maskdino/modeling/pixel_decoder/ops/src/ms_deform_attn.h:56:19:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[K’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   56 |     if (\u001b[01;35m\u001b[Kvalue.type()\u001b[m\u001b[K.is_cuda())\n",
            "      |         \u001b[01;35m\u001b[K~~~~~~~~~~^~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/torch/extension.h:5\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/TACO-expl/MaskDINO/maskdino/modeling/pixel_decoder/ops/src/cpu/ms_deform_attn_cpu.h:17\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/TACO-expl/MaskDINO/maskdino/modeling/pixel_decoder/ops/src/ms_deform_attn.h:18\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/TACO-expl/MaskDINO/maskdino/modeling/pixel_decoder/ops/src/vision.cpp:16\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:225:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  225 |   DeprecatedTypeProperties & \u001b[01;36m\u001b[Ktype\u001b[m\u001b[K() const {\n",
            "      |                              \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "x86_64-linux-gnu-g++ -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 build/temp.linux-x86_64-cpython-310/content/TACO-expl/MaskDINO/maskdino/modeling/pixel_decoder/ops/src/cpu/ms_deform_attn_cpu.o build/temp.linux-x86_64-cpython-310/content/TACO-expl/MaskDINO/maskdino/modeling/pixel_decoder/ops/src/cuda/ms_deform_attn_cuda.o build/temp.linux-x86_64-cpython-310/content/TACO-expl/MaskDINO/maskdino/modeling/pixel_decoder/ops/src/vision.o -L/usr/local/lib/python3.10/dist-packages/torch/lib -L/usr/local/cuda/lib64 -L/usr/lib/x86_64-linux-gnu -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-cpython-310/MultiScaleDeformableAttention.cpython-310-x86_64-linux-gnu.so\n",
            "running install\n",
            "/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Please avoid running ``setup.py`` directly.\n",
            "        Instead, use pypa/build, pypa/installer, pypa/build or\n",
            "        other standards-based tools.\n",
            "\n",
            "        See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  self.initialize_options()\n",
            "/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/cmd.py:66: EasyInstallDeprecationWarning: easy_install command is deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Please avoid running ``setup.py`` and ``easy_install``.\n",
            "        Instead, use pypa/build, pypa/installer, pypa/build or\n",
            "        other standards-based tools.\n",
            "\n",
            "        See https://github.com/pypa/setuptools/issues/917 for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  self.initialize_options()\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "creating MultiScaleDeformableAttention.egg-info\n",
            "writing MultiScaleDeformableAttention.egg-info/PKG-INFO\n",
            "writing dependency_links to MultiScaleDeformableAttention.egg-info/dependency_links.txt\n",
            "writing top-level names to MultiScaleDeformableAttention.egg-info/top_level.txt\n",
            "writing manifest file 'MultiScaleDeformableAttention.egg-info/SOURCES.txt'\n",
            "reading manifest file 'MultiScaleDeformableAttention.egg-info/SOURCES.txt'\n",
            "writing manifest file 'MultiScaleDeformableAttention.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "creating build/bdist.linux-x86_64\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "creating build/bdist.linux-x86_64/egg/functions\n",
            "copying build/lib.linux-x86_64-cpython-310/functions/__init__.py -> build/bdist.linux-x86_64/egg/functions\n",
            "copying build/lib.linux-x86_64-cpython-310/functions/ms_deform_attn_func.py -> build/bdist.linux-x86_64/egg/functions\n",
            "copying build/lib.linux-x86_64-cpython-310/MultiScaleDeformableAttention.cpython-310-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg\n",
            "creating build/bdist.linux-x86_64/egg/modules\n",
            "copying build/lib.linux-x86_64-cpython-310/modules/ms_deform_attn.py -> build/bdist.linux-x86_64/egg/modules\n",
            "copying build/lib.linux-x86_64-cpython-310/modules/__init__.py -> build/bdist.linux-x86_64/egg/modules\n",
            "byte-compiling build/bdist.linux-x86_64/egg/functions/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/functions/ms_deform_attn_func.py to ms_deform_attn_func.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/modules/ms_deform_attn.py to ms_deform_attn.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/modules/__init__.py to __init__.cpython-310.pyc\n",
            "creating stub loader for MultiScaleDeformableAttention.cpython-310-x86_64-linux-gnu.so\n",
            "byte-compiling build/bdist.linux-x86_64/egg/MultiScaleDeformableAttention.py to MultiScaleDeformableAttention.cpython-310.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying MultiScaleDeformableAttention.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying MultiScaleDeformableAttention.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying MultiScaleDeformableAttention.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying MultiScaleDeformableAttention.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "writing build/bdist.linux-x86_64/egg/EGG-INFO/native_libs.txt\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "__pycache__.MultiScaleDeformableAttention.cpython-310: module references __file__\n",
            "creating dist\n",
            "creating 'dist/MultiScaleDeformableAttention-1.0-py3.10-linux-x86_64.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing MultiScaleDeformableAttention-1.0-py3.10-linux-x86_64.egg\n",
            "creating /usr/local/lib/python3.10/dist-packages/MultiScaleDeformableAttention-1.0-py3.10-linux-x86_64.egg\n",
            "Extracting MultiScaleDeformableAttention-1.0-py3.10-linux-x86_64.egg to /usr/local/lib/python3.10/dist-packages\n",
            "Adding MultiScaleDeformableAttention 1.0 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.10/dist-packages/MultiScaleDeformableAttention-1.0-py3.10-linux-x86_64.egg\n",
            "Processing dependencies for MultiScaleDeformableAttention==1.0\n",
            "Finished processing dependencies for MultiScaleDeformableAttention==1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/MyDrive/\", force_remount = True)"
      ],
      "metadata": {
        "id": "yKG8tycQnkyb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89e1f827-1dee-442b-f055-2f7fd1757bff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/MyDrive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, detectron2\n",
        "!nvcc --version\n",
        "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
        "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
        "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
        "print(\"detectron2:\", detectron2.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJ444LmfnVe7",
        "outputId": "c3dc8756-260b-40eb-f3ee-93cebe68be66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2023 NVIDIA Corporation\n",
            "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
            "Cuda compilation tools, release 12.2, V12.2.140\n",
            "Build cuda_12.2.r12.2/compiler.33191640_0\n",
            "torch:  2.2 ; cuda:  cu121\n",
            "detectron2: 0.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/\n",
        "# Some basic setup:\n",
        "# Setup detectron2 logger\n",
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "\n",
        "# import some common libraries\n",
        "import sys\n",
        "import numpy as np\n",
        "import os, json, cv2, random\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# import some common detectron2 utilities\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
        "\n",
        "sys.path.append('/content/TACO-expl/MaskDINO/maskdino/')\n",
        "from config import add_maskdino_config\n",
        "%cd /content/TACO-expl/MaskDINO/maskdino/\n",
        "from detectron2.projects.deeplab import add_deeplab_config\n",
        "from maskdino import MaskDINO\n",
        "%cd /content/"
      ],
      "metadata": {
        "id": "LfdhgozHnZpe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d1e060e-958b-4cb8-ead7-5cbd792c4ad4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "/content/TACO-expl/MaskDINO/maskdino\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/TACO-expl/MaskDINO/maskdino/modeling/criterion.py:346: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
            "  if self.dn is not \"no\" and mask_dict is not None:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sys.path.append(\"/content/TACO-expl/MaskDINO\")\n",
        "!cd /content/TACO-expl/MaskDINO/\n",
        "cfg_biggest_path = '/content/TACO-expl/MaskDINO/configs/coco/instance-segmentation/swin/maskdino_R50_bs16_50ep_4s_dowsample1_2048.yaml'\n",
        "model_biggest_weights_url = 'https://github.com/IDEA-Research/detrex-storage/releases/download/maskdino-v0.1.0/maskdino_swinl_50ep_300q_hid2048_3sd1_instance_maskenhanced_mask52.3ap_box59.0ap.pth'\n",
        "\n",
        "cfg_smallest_path = '/content/TACO-expl/MaskDINO/configs/coco/instance-segmentation/maskdino_R50_bs16_50ep_3s.yaml'\n",
        "model_smallest_weight_url = 'https://github.com/IDEA-Research/detrex-storage/releases/download/maskdino-v0.1.0/maskdino_r50_50ep_300q_hid1024_3sd1_instance_maskenhanced_mask46.1ap_box51.5ap.pth'"
      ],
      "metadata": {
        "id": "tAagzHqSncrP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def setup_cfg(cfg_path, weights_url):\n",
        "    # load config from file and command-line arguments\n",
        "    cfg = get_cfg()\n",
        "    add_deeplab_config(cfg)\n",
        "    add_maskdino_config(cfg)\n",
        "    cfg.merge_from_file(cfg_path)\n",
        "    cfg.MODEL.WEIGHTS = weights_url\n",
        "    cfg.freeze()\n",
        "    return cfg\n",
        "\n",
        "cfg_alt_dino = setup_cfg(cfg_smallest_path, model_smallest_weight_url)\n",
        "cfg_modified = cfg_alt_dino.copy()\n",
        "#print(cfg_modified[\"MODEL\"])"
      ],
      "metadata": {
        "id": "xFqN2ogZngcc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/TACO-expl/\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "import os.path\n",
        "import json\n",
        "import argparse\n",
        "import numpy as np\n",
        "import random\n",
        "import datetime as dt\n",
        "import copy\n",
        "import torch.nn as nn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from pathlib import Path\n",
        "\n",
        "import torch\n",
        "import math\n",
        "import torch.utils.data\n",
        "from torch.utils.data import DataLoader\n",
        "from pycocotools import mask as coco_mask"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oEpIySaFnprv",
        "outputId": "fd525c2f-7454-470f-d26c-0224b2ae0395"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/TACO-expl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DEFAULT_RANDOM_SEED = 42\n",
        "# basic random seed\n",
        "def seedBasic(seed=DEFAULT_RANDOM_SEED):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "# torch random seed\n",
        "def seedTorch(seed=DEFAULT_RANDOM_SEED):\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "# combine\n",
        "def seedEverything(seed=DEFAULT_RANDOM_SEED):\n",
        "    seedBasic(seed)\n",
        "    seedTorch(seed)\n",
        "\n",
        "seedEverything()"
      ],
      "metadata": {
        "id": "gHfxVrm3nrzg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keep_categories = [\"Bottle\", \"Bottle cap\", \"Can\", \"Cigarette\", \"Cup\",\n",
        "                   \"Lid\", \"Plastic bag & wrapper\", \"Pop tab\", \"Straw\"]\n",
        "\n",
        "def create_map(original, keep_supercategories):\n",
        "  class_map = {}\n",
        "  for cat in original:\n",
        "    if cat[\"supercategory\"] in keep_supercategories:\n",
        "      class_map[cat[\"name\"]] = cat[\"supercategory\"]\n",
        "    else:\n",
        "      class_map[cat[\"name\"]] = \"Other\"\n",
        "  return class_map\n",
        "\n",
        "def replace_dataset_classes(dataset, class_map):\n",
        "      \"\"\" Replaces classes of dataset based on a dictionary\"\"\"\n",
        "      class_new_names = list(set(class_map.values()))\n",
        "      class_new_names.sort()\n",
        "      class_originals = copy.deepcopy(dataset['categories'])\n",
        "      dataset['categories'] = []\n",
        "      class_ids_map = {}  # map from old id to new id\n",
        "\n",
        "      # Assign background id 0\n",
        "      has_background = False\n",
        "      if 'Background' in class_new_names:\n",
        "          if class_new_names.index('Background') != 0:\n",
        "              class_new_names.remove('Background')\n",
        "              class_new_names.insert(0, 'Background')\n",
        "          has_background = True\n",
        "\n",
        "      # Replace categories\n",
        "      for id_new, class_new_name in enumerate(class_new_names):\n",
        "          # Make sure id:0 is reserved for background\n",
        "          id_rectified = id_new\n",
        "          if not has_background:\n",
        "              id_rectified += 1\n",
        "\n",
        "          category = {\n",
        "              'supercategory': '',\n",
        "              'id': id_rectified,  # Background has id=0\n",
        "              'name': class_new_name,\n",
        "          }\n",
        "          dataset['categories'].append(category)\n",
        "          # Map class names\n",
        "          for class_original in class_originals:\n",
        "              if class_map[class_original['name']] == class_new_name:\n",
        "                  class_ids_map[class_original['id']] = id_rectified\n",
        "\n",
        "      # Update annotations category id tag\n",
        "      for ann in dataset['annotations']:\n",
        "          ann['category_id'] = class_ids_map[ann['category_id']]"
      ],
      "metadata": {
        "id": "ZCws_VTInwr5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/TACO-expl/data/annotations.json\", \"r\") as f: #\"/content/TACO/data/annotations.json\"\n",
        "    dataset = json.loads(f.read())\n",
        "\n",
        "class_map = create_map(dataset[\"categories\"], keep_categories)\n",
        "replace_dataset_classes(dataset, class_map)\n",
        "dataset[\"categories\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9QJNgK7anxnv",
        "outputId": "7734189b-c27e-4cea-9a63-188cdc973141"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'supercategory': '', 'id': 1, 'name': 'Bottle'},\n",
              " {'supercategory': '', 'id': 2, 'name': 'Bottle cap'},\n",
              " {'supercategory': '', 'id': 3, 'name': 'Can'},\n",
              " {'supercategory': '', 'id': 4, 'name': 'Cigarette'},\n",
              " {'supercategory': '', 'id': 5, 'name': 'Cup'},\n",
              " {'supercategory': '', 'id': 6, 'name': 'Lid'},\n",
              " {'supercategory': '', 'id': 7, 'name': 'Other'},\n",
              " {'supercategory': '', 'id': 8, 'name': 'Plastic bag & wrapper'},\n",
              " {'supercategory': '', 'id': 9, 'name': 'Pop tab'},\n",
              " {'supercategory': '', 'id': 10, 'name': 'Straw'}]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classes = [elem[\"name\"] for elem in dataset[\"categories\"]]\n",
        "print(classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mz77Fd0Any8W",
        "outputId": "2c5c99b6-fbd1-41d3-e4d0-73c844849758"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Bottle', 'Bottle cap', 'Can', 'Cigarette', 'Cup', 'Lid', 'Other', 'Plastic bag & wrapper', 'Pop tab', 'Straw']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from detectron2.data.datasets import register_coco_instances\n",
        "from detectron2.data import MetadataCatalog\n",
        "\n",
        "help(register_coco_instances)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3-UgdxXOsei",
        "outputId": "f8650150-6165-4b4a-ab52-d43b3fd77b0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on function register_coco_instances in module detectron2.data.datasets.coco:\n",
            "\n",
            "register_coco_instances(name, metadata, json_file, image_root)\n",
            "    Register a dataset in COCO's json annotation format for\n",
            "    instance detection, instance segmentation and keypoint detection.\n",
            "    (i.e., Type 1 and 2 in http://cocodataset.org/#format-data.\n",
            "    `instances*.json` and `person_keypoints*.json` in the dataset).\n",
            "    \n",
            "    This is an example of how to register a new dataset.\n",
            "    You can do something similar to this function, to register new datasets.\n",
            "    \n",
            "    Args:\n",
            "        name (str): the name that identifies a dataset, e.g. \"coco_2014_train\".\n",
            "        metadata (dict): extra metadata associated with this dataset.  You can\n",
            "            leave it as an empty dict.\n",
            "        json_file (str): path to the json instance annotation file.\n",
            "        image_root (str or path-like): directory which contains all the images.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_annotation_file = '/content/TACO-expl/data/annotations_off_0_train.json'\n",
        "val_annotation_file = '/content/TACO-expl/data/annotations_off_0_resval.json'\n",
        "\n",
        "img_dir_train = '/content/MyDrive/MyDrive/res_official/rot_train/'\n",
        "img_dir_val = '/content/MyDrive/MyDrive/res_official/res_val/'\n",
        "\n",
        "register_coco_instances(\"TACO_train\", {}, train_annotation_file, img_dir_train)\n",
        "MetadataCatalog.get(\"TACO_train\").set(thing_classes = classes)\n",
        "dataset_dicts_train = DatasetCatalog.get(\"TACO_train\")\n",
        "\n",
        "register_coco_instances(\"TACO_val\", {}, val_annotation_file, img_dir_val)\n",
        "MetadataCatalog.get(\"TACO_val\").set(thing_classes = classes)\n",
        "dataset_dicts_val = DatasetCatalog.get(\"TACO_val\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LmR4YkANn3eG",
        "outputId": "ea7ead4f-af0a-438d-f6ea-6db99155e8a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05/20 16:07:28 d2.data.datasets.coco]: Loaded 1200 images in COCO format from /content/TACO-expl/data/annotations_off_0_train.json\n",
            "[05/20 16:07:28 d2.data.datasets.coco]: Loaded 150 images in COCO format from /content/TACO-expl/data/annotations_off_0_resval.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "with open(val_annotation_file, \"r\") as f:\n",
        "  val_annotations = json.load(f)\n",
        "\n",
        "print(val_annotations.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dTmEjMI4RWrM",
        "outputId": "83832c3d-5ccb-44bc-f015-e5d98de61edd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['info', 'scene_annotations', 'licenses', 'categories', 'scene_categories', 'images', 'annotations'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "first_img = val_annotations[\"images\"][0]\n",
        "first_ann = val_annotations[\"annotations\"][0]\n",
        "\n",
        "print(first_img)\n",
        "print(first_ann)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ixS2PmNZRf_0",
        "outputId": "5e6d77ee-2b9a-4322-c427-29bb16fe4063"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'id': 899, 'width': 1067, 'height': 800, 'file_name': 'batch_4/000023.JPG', 'license': None, 'flickr_url': 'https://farm66.staticflickr.com/65535/47803892332_5218b74150_o.png', 'coco_url': None, 'date_captured': None, 'flickr_640_url': 'https://farm66.staticflickr.com/65535/47803892332_f552fb65c7_z.jpg'}\n",
            "{'id': 2802, 'image_id': 899, 'category_id': 2, 'segmentation': {'counts': [541232, 2, 798, 7, 792, 10, 789, 12, 787, 13, 786, 15, 785, 15, 783, 18, 779, 22, 776, 24, 774, 27, 772, 28, 771, 29, 770, 31, 768, 32, 767, 33, 766, 34, 765, 36, 763, 37, 763, 37, 763, 37, 763, 37, 763, 37, 763, 37, 763, 38, 761, 39, 761, 39, 761, 39, 761, 39, 761, 39, 761, 39, 761, 39, 761, 39, 761, 39, 761, 39, 761, 39, 761, 39, 761, 39, 761, 39, 761, 39, 761, 39, 761, 39, 761, 39, 761, 39, 761, 39, 762, 38, 762, 38, 762, 38, 762, 37, 764, 36, 764, 36, 765, 35, 765, 34, 767, 33, 768, 32, 769, 30, 771, 29, 772, 28, 774, 25, 776, 5, 1, 18, 783, 17, 783, 16, 785, 15, 786, 13, 788, 11, 790, 9, 793, 6, 798, 1, 258761], 'size': [800, 1067]}, 'area': 2008.0, 'bbox': [676.0, 410.0, 68.0, 39.0], 'iscrowd': 0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# run this cell if you want a fresh config file to modify\n",
        "train_cfg = cfg_alt_dino.clone()\n",
        "with open(\"/content/TACO-expl/MaskDINO/configs/taco/taco_train.yaml\", \"w\") as f:\n",
        "  f.write(train_cfg.dump())"
      ],
      "metadata": {
        "id": "rhuvntPZn9Ar"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /content/TACO-expl/maskdino_config/\n",
        "!mkdir /content/output/\n",
        "!mkdir /content/output/chkpt/\n",
        "#!cp /content/MyDrive/MyDrive/maskdino_models/model_0000478.pth /content/output/chkpt/"
      ],
      "metadata": {
        "id": "l8MuJfQ0X20K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_cfg_loaded = get_cfg()\n",
        "train_cfg_loaded.set_new_allowed(True)\n",
        "train_cfg_loaded.merge_from_file(\"/content/TACO-expl/maskdino_config/taco_train_maskdino.yaml\")\n",
        "print(train_cfg_loaded.MODEL.BACKBONE.FREEZE_AT)\n",
        "print(train_cfg_loaded.SOLVER.IMS_PER_BATCH)\n",
        "print(train_cfg_loaded.INPUT.MIN_SIZE_TRAIN)\n",
        "print(train_cfg_loaded.DATASETS.PRECOMPUTED_PROPOSAL_TOPK_TRAIN)\n",
        "print(train_cfg_loaded.TEST.AUG.ENABLED)\n",
        "print(train_cfg_loaded.INPUT.MASK_FORMAT)\n",
        "print(train_cfg_loaded.Default_loading)"
      ],
      "metadata": {
        "id": "hDjfTaa9n9W8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "664b472f-78c4-4772-ddc2-3c041bf65f30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n",
            "2\n",
            "(480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)\n",
            "100\n",
            "False\n",
            "polygon\n",
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/TACO-expl/MaskDINO/\n",
        "from train_net import Trainer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4MsfHBcWn_O1",
        "outputId": "abdb0e06-7608-4007-feee-19af39ca0ccb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/TACO-expl/MaskDINO\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m pip install numpy==1.23.1\n",
        "import numpy as np\n",
        "np.bool = np.bool_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EfBMKcibmcuZ",
        "outputId": "7eb0f210-d7e5-45fd-a1b4-743e1ae1fd95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy==1.23.1\n",
            "  Downloading numpy-1.23.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.0/17.0 MB\u001b[0m \u001b[31m48.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.25.2\n",
            "    Uninstalling numpy-1.25.2:\n",
            "      Successfully uninstalled numpy-1.25.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "chex 0.1.86 requires numpy>=1.24.1, but you have numpy 1.23.1 which is incompatible.\n",
            "pandas-stubs 2.0.3.230814 requires numpy>=1.25.0; python_version >= \"3.9\", but you have numpy 1.23.1 which is incompatible.\n",
            "tensorflow 2.15.0 requires numpy<2.0.0,>=1.23.5, but you have numpy 1.23.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.23.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/output/chkpt/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SvuBSgJPaZXq",
        "outputId": "a8fa9eeb-d62c-4ca3-ab30-fdc6cc5ee986"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: '/content/output/chkpt/'\n",
            "/content/TACO-expl/MaskDINO\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(train_cfg_loaded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yXff5ODnne9w",
        "outputId": "e65593ae-9286-4975-8635-54e1dab12f11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "criterion.weight_dict  {'loss_ce': 4.0, 'loss_mask': 5.0, 'loss_dice': 5.0, 'loss_bbox': 5.0, 'loss_giou': 2.0, 'loss_ce_interm': 4.0, 'loss_mask_interm': 5.0, 'loss_dice_interm': 5.0, 'loss_bbox_interm': 5.0, 'loss_giou_interm': 2.0, 'loss_ce_dn': 4.0, 'loss_mask_dn': 5.0, 'loss_dice_dn': 5.0, 'loss_bbox_dn': 5.0, 'loss_giou_dn': 2.0, 'loss_ce_interm_dn': 4.0, 'loss_mask_interm_dn': 5.0, 'loss_dice_interm_dn': 5.0, 'loss_bbox_interm_dn': 5.0, 'loss_giou_interm_dn': 2.0, 'loss_ce_0': 4.0, 'loss_mask_0': 5.0, 'loss_dice_0': 5.0, 'loss_bbox_0': 5.0, 'loss_giou_0': 2.0, 'loss_ce_interm_0': 4.0, 'loss_mask_interm_0': 5.0, 'loss_dice_interm_0': 5.0, 'loss_bbox_interm_0': 5.0, 'loss_giou_interm_0': 2.0, 'loss_ce_dn_0': 4.0, 'loss_mask_dn_0': 5.0, 'loss_dice_dn_0': 5.0, 'loss_bbox_dn_0': 5.0, 'loss_giou_dn_0': 2.0, 'loss_ce_interm_dn_0': 4.0, 'loss_mask_interm_dn_0': 5.0, 'loss_dice_interm_dn_0': 5.0, 'loss_bbox_interm_dn_0': 5.0, 'loss_giou_interm_dn_0': 2.0, 'loss_ce_1': 4.0, 'loss_mask_1': 5.0, 'loss_dice_1': 5.0, 'loss_bbox_1': 5.0, 'loss_giou_1': 2.0, 'loss_ce_interm_1': 4.0, 'loss_mask_interm_1': 5.0, 'loss_dice_interm_1': 5.0, 'loss_bbox_interm_1': 5.0, 'loss_giou_interm_1': 2.0, 'loss_ce_dn_1': 4.0, 'loss_mask_dn_1': 5.0, 'loss_dice_dn_1': 5.0, 'loss_bbox_dn_1': 5.0, 'loss_giou_dn_1': 2.0, 'loss_ce_interm_dn_1': 4.0, 'loss_mask_interm_dn_1': 5.0, 'loss_dice_interm_dn_1': 5.0, 'loss_bbox_interm_dn_1': 5.0, 'loss_giou_interm_dn_1': 2.0, 'loss_ce_2': 4.0, 'loss_mask_2': 5.0, 'loss_dice_2': 5.0, 'loss_bbox_2': 5.0, 'loss_giou_2': 2.0, 'loss_ce_interm_2': 4.0, 'loss_mask_interm_2': 5.0, 'loss_dice_interm_2': 5.0, 'loss_bbox_interm_2': 5.0, 'loss_giou_interm_2': 2.0, 'loss_ce_dn_2': 4.0, 'loss_mask_dn_2': 5.0, 'loss_dice_dn_2': 5.0, 'loss_bbox_dn_2': 5.0, 'loss_giou_dn_2': 2.0, 'loss_ce_interm_dn_2': 4.0, 'loss_mask_interm_dn_2': 5.0, 'loss_dice_interm_dn_2': 5.0, 'loss_bbox_interm_dn_2': 5.0, 'loss_giou_interm_dn_2': 2.0, 'loss_ce_3': 4.0, 'loss_mask_3': 5.0, 'loss_dice_3': 5.0, 'loss_bbox_3': 5.0, 'loss_giou_3': 2.0, 'loss_ce_interm_3': 4.0, 'loss_mask_interm_3': 5.0, 'loss_dice_interm_3': 5.0, 'loss_bbox_interm_3': 5.0, 'loss_giou_interm_3': 2.0, 'loss_ce_dn_3': 4.0, 'loss_mask_dn_3': 5.0, 'loss_dice_dn_3': 5.0, 'loss_bbox_dn_3': 5.0, 'loss_giou_dn_3': 2.0, 'loss_ce_interm_dn_3': 4.0, 'loss_mask_interm_dn_3': 5.0, 'loss_dice_interm_dn_3': 5.0, 'loss_bbox_interm_dn_3': 5.0, 'loss_giou_interm_dn_3': 2.0, 'loss_ce_4': 4.0, 'loss_mask_4': 5.0, 'loss_dice_4': 5.0, 'loss_bbox_4': 5.0, 'loss_giou_4': 2.0, 'loss_ce_interm_4': 4.0, 'loss_mask_interm_4': 5.0, 'loss_dice_interm_4': 5.0, 'loss_bbox_interm_4': 5.0, 'loss_giou_interm_4': 2.0, 'loss_ce_dn_4': 4.0, 'loss_mask_dn_4': 5.0, 'loss_dice_dn_4': 5.0, 'loss_bbox_dn_4': 5.0, 'loss_giou_dn_4': 2.0, 'loss_ce_interm_dn_4': 4.0, 'loss_mask_interm_dn_4': 5.0, 'loss_dice_interm_dn_4': 5.0, 'loss_bbox_interm_dn_4': 5.0, 'loss_giou_interm_dn_4': 2.0, 'loss_ce_5': 4.0, 'loss_mask_5': 5.0, 'loss_dice_5': 5.0, 'loss_bbox_5': 5.0, 'loss_giou_5': 2.0, 'loss_ce_interm_5': 4.0, 'loss_mask_interm_5': 5.0, 'loss_dice_interm_5': 5.0, 'loss_bbox_interm_5': 5.0, 'loss_giou_interm_5': 2.0, 'loss_ce_dn_5': 4.0, 'loss_mask_dn_5': 5.0, 'loss_dice_dn_5': 5.0, 'loss_bbox_dn_5': 5.0, 'loss_giou_dn_5': 2.0, 'loss_ce_interm_dn_5': 4.0, 'loss_mask_interm_dn_5': 5.0, 'loss_dice_interm_dn_5': 5.0, 'loss_bbox_interm_dn_5': 5.0, 'loss_giou_interm_dn_5': 2.0, 'loss_ce_6': 4.0, 'loss_mask_6': 5.0, 'loss_dice_6': 5.0, 'loss_bbox_6': 5.0, 'loss_giou_6': 2.0, 'loss_ce_interm_6': 4.0, 'loss_mask_interm_6': 5.0, 'loss_dice_interm_6': 5.0, 'loss_bbox_interm_6': 5.0, 'loss_giou_interm_6': 2.0, 'loss_ce_dn_6': 4.0, 'loss_mask_dn_6': 5.0, 'loss_dice_dn_6': 5.0, 'loss_bbox_dn_6': 5.0, 'loss_giou_dn_6': 2.0, 'loss_ce_interm_dn_6': 4.0, 'loss_mask_interm_dn_6': 5.0, 'loss_dice_interm_dn_6': 5.0, 'loss_bbox_interm_dn_6': 5.0, 'loss_giou_interm_dn_6': 2.0, 'loss_ce_7': 4.0, 'loss_mask_7': 5.0, 'loss_dice_7': 5.0, 'loss_bbox_7': 5.0, 'loss_giou_7': 2.0, 'loss_ce_interm_7': 4.0, 'loss_mask_interm_7': 5.0, 'loss_dice_interm_7': 5.0, 'loss_bbox_interm_7': 5.0, 'loss_giou_interm_7': 2.0, 'loss_ce_dn_7': 4.0, 'loss_mask_dn_7': 5.0, 'loss_dice_dn_7': 5.0, 'loss_bbox_dn_7': 5.0, 'loss_giou_dn_7': 2.0, 'loss_ce_interm_dn_7': 4.0, 'loss_mask_interm_dn_7': 5.0, 'loss_dice_interm_dn_7': 5.0, 'loss_bbox_interm_dn_7': 5.0, 'loss_giou_interm_dn_7': 2.0, 'loss_ce_8': 4.0, 'loss_mask_8': 5.0, 'loss_dice_8': 5.0, 'loss_bbox_8': 5.0, 'loss_giou_8': 2.0, 'loss_ce_interm_8': 4.0, 'loss_mask_interm_8': 5.0, 'loss_dice_interm_8': 5.0, 'loss_bbox_interm_8': 5.0, 'loss_giou_interm_8': 2.0, 'loss_ce_dn_8': 4.0, 'loss_mask_dn_8': 5.0, 'loss_dice_dn_8': 5.0, 'loss_bbox_dn_8': 5.0, 'loss_giou_dn_8': 2.0, 'loss_ce_interm_dn_8': 4.0, 'loss_mask_interm_dn_8': 5.0, 'loss_dice_interm_dn_8': 5.0, 'loss_bbox_interm_dn_8': 5.0, 'loss_giou_interm_dn_8': 2.0}\n",
            "[05/20 16:07:59 d2.engine.defaults]: Model:\n",
            "MaskDINO(\n",
            "  (backbone): ResNet(\n",
            "    (stem): BasicStem(\n",
            "      (conv1): Conv2d(\n",
            "        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
            "        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "      )\n",
            "    )\n",
            "    (res2): Sequential(\n",
            "      (0): BottleneckBlock(\n",
            "        (shortcut): Conv2d(\n",
            "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv1): Conv2d(\n",
            "          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (1): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (2): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (res3): Sequential(\n",
            "      (0): BottleneckBlock(\n",
            "        (shortcut): Conv2d(\n",
            "          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "        (conv1): Conv2d(\n",
            "          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (1): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (2): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (3): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (res4): Sequential(\n",
            "      (0): BottleneckBlock(\n",
            "        (shortcut): Conv2d(\n",
            "          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "        )\n",
            "        (conv1): Conv2d(\n",
            "          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (1): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (2): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (3): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (4): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (5): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (res5): Sequential(\n",
            "      (0): BottleneckBlock(\n",
            "        (shortcut): Conv2d(\n",
            "          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "        )\n",
            "        (conv1): Conv2d(\n",
            "          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (1): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (2): BottleneckBlock(\n",
            "        (conv1): Conv2d(\n",
            "          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "        (conv2): Conv2d(\n",
            "          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "        )\n",
            "        (conv3): Conv2d(\n",
            "          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (sem_seg_head): MaskDINOHead(\n",
            "    (pixel_decoder): MaskDINOEncoder(\n",
            "      (input_proj): ModuleList(\n",
            "        (0): Sequential(\n",
            "          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
            "        )\n",
            "        (1): Sequential(\n",
            "          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
            "        )\n",
            "        (2): Sequential(\n",
            "          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
            "        )\n",
            "      )\n",
            "      (transformer): MSDeformAttnTransformerEncoderOnly(\n",
            "        (encoder): MSDeformAttnTransformerEncoder(\n",
            "          (layers): ModuleList(\n",
            "            (0-5): 6 x MSDeformAttnTransformerEncoderLayer(\n",
            "              (self_attn): MSDeformAttn(\n",
            "                (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)\n",
            "                (attention_weights): Linear(in_features=256, out_features=96, bias=True)\n",
            "                (value_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "                (output_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "              )\n",
            "              (dropout1): Dropout(p=0.0, inplace=False)\n",
            "              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "              (linear1): Linear(in_features=256, out_features=1024, bias=True)\n",
            "              (dropout2): Dropout(p=0.0, inplace=False)\n",
            "              (linear2): Linear(in_features=1024, out_features=256, bias=True)\n",
            "              (dropout3): Dropout(p=0.0, inplace=False)\n",
            "              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (pe_layer): Positional encoding PositionEmbeddingSine\n",
            "          num_pos_feats: 128\n",
            "          temperature: 10000\n",
            "          normalize: True\n",
            "          scale: 6.283185307179586\n",
            "      (mask_features): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (adapter_1): Conv2d(\n",
            "        256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
            "      )\n",
            "      (layer_1): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
            "      )\n",
            "    )\n",
            "    (predictor): MaskDINODecoder(\n",
            "      (enc_output): Linear(in_features=256, out_features=256, bias=True)\n",
            "      (enc_output_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "      (input_proj): ModuleList(\n",
            "        (0-2): 3 x Sequential()\n",
            "      )\n",
            "      (class_embed): Linear(in_features=256, out_features=10, bias=True)\n",
            "      (label_enc): Embedding(10, 256)\n",
            "      (mask_embed): MLP(\n",
            "        (layers): ModuleList(\n",
            "          (0-2): 3 x Linear(in_features=256, out_features=256, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (decoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "      (decoder): TransformerDecoder(\n",
            "        (layers): ModuleList(\n",
            "          (0-8): 9 x DeformableTransformerDecoderLayer(\n",
            "            (cross_attn): MSDeformAttn(\n",
            "              (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)\n",
            "              (attention_weights): Linear(in_features=256, out_features=96, bias=True)\n",
            "              (value_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "              (output_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "            )\n",
            "            (dropout1): Dropout(p=0.0, inplace=False)\n",
            "            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "            (self_attn): MultiheadAttention(\n",
            "              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
            "            )\n",
            "            (dropout2): Dropout(p=0.0, inplace=False)\n",
            "            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "            (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
            "            (dropout3): Dropout(p=0.0, inplace=False)\n",
            "            (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
            "            (dropout4): Dropout(p=0.0, inplace=False)\n",
            "            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "          )\n",
            "        )\n",
            "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "        (ref_point_head): MLP(\n",
            "          (layers): ModuleList(\n",
            "            (0): Linear(in_features=512, out_features=256, bias=True)\n",
            "            (1): Linear(in_features=256, out_features=256, bias=True)\n",
            "          )\n",
            "        )\n",
            "        (bbox_embed): ModuleList(\n",
            "          (0-8): 9 x MLP(\n",
            "            (layers): ModuleList(\n",
            "              (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)\n",
            "              (2): Linear(in_features=256, out_features=4, bias=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (_bbox_embed): MLP(\n",
            "        (layers): ModuleList(\n",
            "          (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)\n",
            "          (2): Linear(in_features=256, out_features=4, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (bbox_embed): ModuleList(\n",
            "        (0-8): 9 x MLP(\n",
            "          (layers): ModuleList(\n",
            "            (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)\n",
            "            (2): Linear(in_features=256, out_features=4, bias=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (criterion): Criterion SetCriterion\n",
            "      matcher: Matcher HungarianMatcher\n",
            "          cost_class: 4.0\n",
            "          cost_mask: 5.0\n",
            "          cost_dice: 5.0\n",
            "      losses: ['labels', 'masks', 'boxes']\n",
            "      weight_dict: {'loss_ce': 4.0, 'loss_mask': 5.0, 'loss_dice': 5.0, 'loss_bbox': 5.0, 'loss_giou': 2.0, 'loss_ce_interm': 4.0, 'loss_mask_interm': 5.0, 'loss_dice_interm': 5.0, 'loss_bbox_interm': 5.0, 'loss_giou_interm': 2.0, 'loss_ce_dn': 4.0, 'loss_mask_dn': 5.0, 'loss_dice_dn': 5.0, 'loss_bbox_dn': 5.0, 'loss_giou_dn': 2.0, 'loss_ce_interm_dn': 4.0, 'loss_mask_interm_dn': 5.0, 'loss_dice_interm_dn': 5.0, 'loss_bbox_interm_dn': 5.0, 'loss_giou_interm_dn': 2.0, 'loss_ce_0': 4.0, 'loss_mask_0': 5.0, 'loss_dice_0': 5.0, 'loss_bbox_0': 5.0, 'loss_giou_0': 2.0, 'loss_ce_interm_0': 4.0, 'loss_mask_interm_0': 5.0, 'loss_dice_interm_0': 5.0, 'loss_bbox_interm_0': 5.0, 'loss_giou_interm_0': 2.0, 'loss_ce_dn_0': 4.0, 'loss_mask_dn_0': 5.0, 'loss_dice_dn_0': 5.0, 'loss_bbox_dn_0': 5.0, 'loss_giou_dn_0': 2.0, 'loss_ce_interm_dn_0': 4.0, 'loss_mask_interm_dn_0': 5.0, 'loss_dice_interm_dn_0': 5.0, 'loss_bbox_interm_dn_0': 5.0, 'loss_giou_interm_dn_0': 2.0, 'loss_ce_1': 4.0, 'loss_mask_1': 5.0, 'loss_dice_1': 5.0, 'loss_bbox_1': 5.0, 'loss_giou_1': 2.0, 'loss_ce_interm_1': 4.0, 'loss_mask_interm_1': 5.0, 'loss_dice_interm_1': 5.0, 'loss_bbox_interm_1': 5.0, 'loss_giou_interm_1': 2.0, 'loss_ce_dn_1': 4.0, 'loss_mask_dn_1': 5.0, 'loss_dice_dn_1': 5.0, 'loss_bbox_dn_1': 5.0, 'loss_giou_dn_1': 2.0, 'loss_ce_interm_dn_1': 4.0, 'loss_mask_interm_dn_1': 5.0, 'loss_dice_interm_dn_1': 5.0, 'loss_bbox_interm_dn_1': 5.0, 'loss_giou_interm_dn_1': 2.0, 'loss_ce_2': 4.0, 'loss_mask_2': 5.0, 'loss_dice_2': 5.0, 'loss_bbox_2': 5.0, 'loss_giou_2': 2.0, 'loss_ce_interm_2': 4.0, 'loss_mask_interm_2': 5.0, 'loss_dice_interm_2': 5.0, 'loss_bbox_interm_2': 5.0, 'loss_giou_interm_2': 2.0, 'loss_ce_dn_2': 4.0, 'loss_mask_dn_2': 5.0, 'loss_dice_dn_2': 5.0, 'loss_bbox_dn_2': 5.0, 'loss_giou_dn_2': 2.0, 'loss_ce_interm_dn_2': 4.0, 'loss_mask_interm_dn_2': 5.0, 'loss_dice_interm_dn_2': 5.0, 'loss_bbox_interm_dn_2': 5.0, 'loss_giou_interm_dn_2': 2.0, 'loss_ce_3': 4.0, 'loss_mask_3': 5.0, 'loss_dice_3': 5.0, 'loss_bbox_3': 5.0, 'loss_giou_3': 2.0, 'loss_ce_interm_3': 4.0, 'loss_mask_interm_3': 5.0, 'loss_dice_interm_3': 5.0, 'loss_bbox_interm_3': 5.0, 'loss_giou_interm_3': 2.0, 'loss_ce_dn_3': 4.0, 'loss_mask_dn_3': 5.0, 'loss_dice_dn_3': 5.0, 'loss_bbox_dn_3': 5.0, 'loss_giou_dn_3': 2.0, 'loss_ce_interm_dn_3': 4.0, 'loss_mask_interm_dn_3': 5.0, 'loss_dice_interm_dn_3': 5.0, 'loss_bbox_interm_dn_3': 5.0, 'loss_giou_interm_dn_3': 2.0, 'loss_ce_4': 4.0, 'loss_mask_4': 5.0, 'loss_dice_4': 5.0, 'loss_bbox_4': 5.0, 'loss_giou_4': 2.0, 'loss_ce_interm_4': 4.0, 'loss_mask_interm_4': 5.0, 'loss_dice_interm_4': 5.0, 'loss_bbox_interm_4': 5.0, 'loss_giou_interm_4': 2.0, 'loss_ce_dn_4': 4.0, 'loss_mask_dn_4': 5.0, 'loss_dice_dn_4': 5.0, 'loss_bbox_dn_4': 5.0, 'loss_giou_dn_4': 2.0, 'loss_ce_interm_dn_4': 4.0, 'loss_mask_interm_dn_4': 5.0, 'loss_dice_interm_dn_4': 5.0, 'loss_bbox_interm_dn_4': 5.0, 'loss_giou_interm_dn_4': 2.0, 'loss_ce_5': 4.0, 'loss_mask_5': 5.0, 'loss_dice_5': 5.0, 'loss_bbox_5': 5.0, 'loss_giou_5': 2.0, 'loss_ce_interm_5': 4.0, 'loss_mask_interm_5': 5.0, 'loss_dice_interm_5': 5.0, 'loss_bbox_interm_5': 5.0, 'loss_giou_interm_5': 2.0, 'loss_ce_dn_5': 4.0, 'loss_mask_dn_5': 5.0, 'loss_dice_dn_5': 5.0, 'loss_bbox_dn_5': 5.0, 'loss_giou_dn_5': 2.0, 'loss_ce_interm_dn_5': 4.0, 'loss_mask_interm_dn_5': 5.0, 'loss_dice_interm_dn_5': 5.0, 'loss_bbox_interm_dn_5': 5.0, 'loss_giou_interm_dn_5': 2.0, 'loss_ce_6': 4.0, 'loss_mask_6': 5.0, 'loss_dice_6': 5.0, 'loss_bbox_6': 5.0, 'loss_giou_6': 2.0, 'loss_ce_interm_6': 4.0, 'loss_mask_interm_6': 5.0, 'loss_dice_interm_6': 5.0, 'loss_bbox_interm_6': 5.0, 'loss_giou_interm_6': 2.0, 'loss_ce_dn_6': 4.0, 'loss_mask_dn_6': 5.0, 'loss_dice_dn_6': 5.0, 'loss_bbox_dn_6': 5.0, 'loss_giou_dn_6': 2.0, 'loss_ce_interm_dn_6': 4.0, 'loss_mask_interm_dn_6': 5.0, 'loss_dice_interm_dn_6': 5.0, 'loss_bbox_interm_dn_6': 5.0, 'loss_giou_interm_dn_6': 2.0, 'loss_ce_7': 4.0, 'loss_mask_7': 5.0, 'loss_dice_7': 5.0, 'loss_bbox_7': 5.0, 'loss_giou_7': 2.0, 'loss_ce_interm_7': 4.0, 'loss_mask_interm_7': 5.0, 'loss_dice_interm_7': 5.0, 'loss_bbox_interm_7': 5.0, 'loss_giou_interm_7': 2.0, 'loss_ce_dn_7': 4.0, 'loss_mask_dn_7': 5.0, 'loss_dice_dn_7': 5.0, 'loss_bbox_dn_7': 5.0, 'loss_giou_dn_7': 2.0, 'loss_ce_interm_dn_7': 4.0, 'loss_mask_interm_dn_7': 5.0, 'loss_dice_interm_dn_7': 5.0, 'loss_bbox_interm_dn_7': 5.0, 'loss_giou_interm_dn_7': 2.0, 'loss_ce_8': 4.0, 'loss_mask_8': 5.0, 'loss_dice_8': 5.0, 'loss_bbox_8': 5.0, 'loss_giou_8': 2.0, 'loss_ce_interm_8': 4.0, 'loss_mask_interm_8': 5.0, 'loss_dice_interm_8': 5.0, 'loss_bbox_interm_8': 5.0, 'loss_giou_interm_8': 2.0, 'loss_ce_dn_8': 4.0, 'loss_mask_dn_8': 5.0, 'loss_dice_dn_8': 5.0, 'loss_bbox_dn_8': 5.0, 'loss_giou_dn_8': 2.0, 'loss_ce_interm_dn_8': 4.0, 'loss_mask_interm_dn_8': 5.0, 'loss_dice_interm_dn_8': 5.0, 'loss_bbox_interm_dn_8': 5.0, 'loss_giou_interm_dn_8': 2.0}\n",
            "      num_classes: 10\n",
            "      eos_coef: 0.1\n",
            "      num_points: 12544\n",
            "      oversample_ratio: 3.0\n",
            "      importance_sample_ratio: 0.75\n",
            ")\n",
            "[05/20 16:07:59 d2.data.datasets.coco]: Loaded 1200 images in COCO format from /content/TACO-expl/data/annotations_off_0_train.json\n",
            "[05/20 16:07:59 d2.data.build]: Removed 0 images with no usable annotations. 1200 images left.\n",
            "[05/20 16:07:59 d2.data.build]: Using training sampler TrainingSampler\n",
            "[05/20 16:07:59 d2.data.common]: Serializing 1200 elements to byte tensors and concatenating them all ...\n",
            "[05/20 16:07:59 d2.data.common]: Serialized dataset takes 1.82 MiB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#trainer.build_hooks()\n",
        "trainer.resume_or_load(resume = True)  # load last checkpoint or MODEL.WEIGHTS\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xvnHug9_oDE_",
        "outputId": "7c1024d4-fdb4-48bf-9b96-bcc52fa5db7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "maskdino_r50_50ep_300q_hid1024_3sd1_instance_maskenhanced_mask46.1ap_box51.5ap.pth: 527MB [00:52, 9.96MB/s]                           \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING [05/20 16:09:01 d2.checkpoint.c2_model_loading]: Shape of criterion.empty_weight in checkpoint is torch.Size([81]), while shape of criterion.empty_weight in model is torch.Size([11]).\n",
            "WARNING [05/20 16:09:01 d2.checkpoint.c2_model_loading]: criterion.empty_weight will not be loaded. Please double check and see if this is desired.\n",
            "WARNING [05/20 16:09:01 d2.checkpoint.c2_model_loading]: Shape of sem_seg_head.predictor.class_embed.bias in checkpoint is torch.Size([80]), while shape of sem_seg_head.predictor.class_embed.bias in model is torch.Size([10]).\n",
            "WARNING [05/20 16:09:01 d2.checkpoint.c2_model_loading]: sem_seg_head.predictor.class_embed.bias will not be loaded. Please double check and see if this is desired.\n",
            "WARNING [05/20 16:09:01 d2.checkpoint.c2_model_loading]: Shape of sem_seg_head.predictor.class_embed.weight in checkpoint is torch.Size([80, 256]), while shape of sem_seg_head.predictor.class_embed.weight in model is torch.Size([10, 256]).\n",
            "WARNING [05/20 16:09:01 d2.checkpoint.c2_model_loading]: sem_seg_head.predictor.class_embed.weight will not be loaded. Please double check and see if this is desired.\n",
            "WARNING [05/20 16:09:01 d2.checkpoint.c2_model_loading]: Shape of sem_seg_head.predictor.label_enc.weight in checkpoint is torch.Size([80, 256]), while shape of sem_seg_head.predictor.label_enc.weight in model is torch.Size([10, 256]).\n",
            "WARNING [05/20 16:09:01 d2.checkpoint.c2_model_loading]: sem_seg_head.predictor.label_enc.weight will not be loaded. Please double check and see if this is desired.\n",
            "[05/20 16:09:01 d2.checkpoint.c2_model_loading]: Following weights matched with model:\n",
            "| Names in Model                                                         | Names in Checkpoint                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          | Shapes                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |\n",
            "|:-----------------------------------------------------------------------|:-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
            "| backbone.res2.0.conv1.*                                                | backbone.res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | (64,) (64,) (64,) (64,) (64,64,1,1)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |\n",
            "| backbone.res2.0.conv2.*                                                | backbone.res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | (64,) (64,) (64,) (64,) (64,64,3,3)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |\n",
            "| backbone.res2.0.conv3.*                                                | backbone.res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | (256,) (256,) (256,) (256,) (256,64,1,1)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |\n",
            "| backbone.res2.0.shortcut.*                                             | backbone.res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   | (256,) (256,) (256,) (256,) (256,64,1,1)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |\n",
            "| backbone.res2.1.conv1.*                                                | backbone.res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | (64,) (64,) (64,) (64,) (64,256,1,1)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |\n",
            "| backbone.res2.1.conv2.*                                                | backbone.res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | (64,) (64,) (64,) (64,) (64,64,3,3)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |\n",
            "| backbone.res2.1.conv3.*                                                | backbone.res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | (256,) (256,) (256,) (256,) (256,64,1,1)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |\n",
            "| backbone.res2.2.conv1.*                                                | backbone.res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | (64,) (64,) (64,) (64,) (64,256,1,1)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |\n",
            "| backbone.res2.2.conv2.*                                                | backbone.res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | (64,) (64,) (64,) (64,) (64,64,3,3)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |\n",
            "| backbone.res2.2.conv3.*                                                | backbone.res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | (256,) (256,) (256,) (256,) (256,64,1,1)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |\n",
            "| backbone.res3.0.conv1.*                                                | backbone.res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | (128,) (128,) (128,) (128,) (128,256,1,1)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |\n",
            "| backbone.res3.0.conv2.*                                                | backbone.res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | (128,) (128,) (128,) (128,) (128,128,3,3)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |\n",
            "| backbone.res3.0.conv3.*                                                | backbone.res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | (512,) (512,) (512,) (512,) (512,128,1,1)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |\n",
            "| backbone.res3.0.shortcut.*                                             | backbone.res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   | (512,) (512,) (512,) (512,) (512,256,1,1)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |\n",
            "| backbone.res3.1.conv1.*                                                | backbone.res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | (128,) (128,) (128,) (128,) (128,512,1,1)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |\n",
            "| backbone.res3.1.conv2.*                                                | backbone.res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | (128,) (128,) (128,) (128,) (128,128,3,3)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |\n",
            "| backbone.res3.1.conv3.*                                                | backbone.res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | (512,) (512,) (512,) (512,) (512,128,1,1)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |\n",
            "| backbone.res3.2.conv1.*                                                | backbone.res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | (128,) (128,) (128,) (128,) (128,512,1,1)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |\n",
            "| backbone.res3.2.conv2.*                                                | backbone.res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | (128,) (128,) (128,) (128,) (128,128,3,3)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |\n",
            "| backbone.res3.2.conv3.*                                                | backbone.res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | (512,) (512,) (512,) (512,) (512,128,1,1)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |\n",
            "| backbone.res3.3.conv1.*                                                | backbone.res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | (128,) (128,) (128,) (128,) (128,512,1,1)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |\n",
            "| backbone.res3.3.conv2.*                                                | backbone.res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | (128,) (128,) (128,) (128,) (128,128,3,3)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |\n",
            "| backbone.res3.3.conv3.*                                                | backbone.res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | (512,) (512,) (512,) (512,) (512,128,1,1)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |\n",
            "| backbone.res4.0.conv1.*                                                | backbone.res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | (256,) (256,) (256,) (256,) (256,512,1,1)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |\n",
            "| backbone.res4.0.conv2.*                                                | backbone.res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | (256,) (256,) (256,) (256,) (256,256,3,3)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |\n",
            "| backbone.res4.0.conv3.*                                                | backbone.res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |\n",
            "| backbone.res4.0.shortcut.*                                             | backbone.res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |\n",
            "| backbone.res4.1.conv1.*                                                | backbone.res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | (256,) (256,) (256,) (256,) (256,1024,1,1)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |\n",
            "| backbone.res4.1.conv2.*                                                | backbone.res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | (256,) (256,) (256,) (256,) (256,256,3,3)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |\n",
            "| backbone.res4.1.conv3.*                                                | backbone.res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |\n",
            "| backbone.res4.2.conv1.*                                                | backbone.res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | (256,) (256,) (256,) (256,) (256,1024,1,1)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |\n",
            "| backbone.res4.2.conv2.*                                                | backbone.res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | (256,) (256,) (256,) (256,) (256,256,3,3)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |\n",
            "| backbone.res4.2.conv3.*                                                | backbone.res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |\n",
            "| backbone.res4.3.conv1.*                                                | backbone.res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | (256,) (256,) (256,) (256,) (256,1024,1,1)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |\n",
            "| backbone.res4.3.conv2.*                                                | backbone.res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | (256,) (256,) (256,) (256,) (256,256,3,3)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |\n",
            "| backbone.res4.3.conv3.*                                                | backbone.res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |\n",
            "| backbone.res4.4.conv1.*                                                | backbone.res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | (256,) (256,) (256,) (256,) (256,1024,1,1)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |\n",
            "| backbone.res4.4.conv2.*                                                | backbone.res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | (256,) (256,) (256,) (256,) (256,256,3,3)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |\n",
            "| backbone.res4.4.conv3.*                                                | backbone.res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |\n",
            "| backbone.res4.5.conv1.*                                                | backbone.res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | (256,) (256,) (256,) (256,) (256,1024,1,1)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |\n",
            "| backbone.res4.5.conv2.*                                                | backbone.res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | (256,) (256,) (256,) (256,) (256,256,3,3)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |\n",
            "| backbone.res4.5.conv3.*                                                | backbone.res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |\n",
            "| backbone.res5.0.conv1.*                                                | backbone.res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | (512,) (512,) (512,) (512,) (512,1024,1,1)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |\n",
            "| backbone.res5.0.conv2.*                                                | backbone.res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | (512,) (512,) (512,) (512,) (512,512,3,3)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |\n",
            "| backbone.res5.0.conv3.*                                                | backbone.res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |\n",
            "| backbone.res5.0.shortcut.*                                             | backbone.res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |\n",
            "| backbone.res5.1.conv1.*                                                | backbone.res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | (512,) (512,) (512,) (512,) (512,2048,1,1)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |\n",
            "| backbone.res5.1.conv2.*                                                | backbone.res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | (512,) (512,) (512,) (512,) (512,512,3,3)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |\n",
            "| backbone.res5.1.conv3.*                                                | backbone.res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |\n",
            "| backbone.res5.2.conv1.*                                                | backbone.res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | (512,) (512,) (512,) (512,) (512,2048,1,1)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |\n",
            "| backbone.res5.2.conv2.*                                                | backbone.res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | (512,) (512,) (512,) (512,) (512,512,3,3)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |\n",
            "| backbone.res5.2.conv3.*                                                | backbone.res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |\n",
            "| backbone.stem.conv1.*                                                  | backbone.stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        | (64,) (64,) (64,) (64,) (64,3,7,7)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |\n",
            "| sem_seg_head.pixel_decoder.adapter_1.*                                 | sem_seg_head.pixel_decoder.adapter_1.{norm.bias,norm.weight,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          | (256,) (256,) (256,256,1,1)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |\n",
            "| sem_seg_head.pixel_decoder.input_proj.0.0.*                            | sem_seg_head.pixel_decoder.input_proj.0.0.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | (256,) (256,2048,1,1)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |\n",
            "| sem_seg_head.pixel_decoder.input_proj.0.1.*                            | sem_seg_head.pixel_decoder.input_proj.0.1.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | (256,) (256,)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |\n",
            "| sem_seg_head.pixel_decoder.input_proj.1.0.*                            | sem_seg_head.pixel_decoder.input_proj.1.0.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | (256,) (256,1024,1,1)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |\n",
            "| sem_seg_head.pixel_decoder.input_proj.1.1.*                            | sem_seg_head.pixel_decoder.input_proj.1.1.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | (256,) (256,)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |\n",
            "| sem_seg_head.pixel_decoder.input_proj.2.0.*                            | sem_seg_head.pixel_decoder.input_proj.2.0.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | (256,) (256,512,1,1)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |\n",
            "| sem_seg_head.pixel_decoder.input_proj.2.1.*                            | sem_seg_head.pixel_decoder.input_proj.2.1.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | (256,) (256,)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |\n",
            "| sem_seg_head.pixel_decoder.layer_1.*                                   | sem_seg_head.pixel_decoder.layer_1.{norm.bias,norm.weight,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            | (256,) (256,) (256,256,3,3)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |\n",
            "| sem_seg_head.pixel_decoder.mask_features.*                             | sem_seg_head.pixel_decoder.mask_features.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       | (256,) (256,256,1,1)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |\n",
            "| sem_seg_head.pixel_decoder.transformer.*                               | sem_seg_head.pixel_decoder.transformer.{encoder.layers.0.linear1.bias,encoder.layers.0.linear1.weight,encoder.layers.0.linear2.bias,encoder.layers.0.linear2.weight,encoder.layers.0.norm1.bias,encoder.layers.0.norm1.weight,encoder.layers.0.norm2.bias,encoder.layers.0.norm2.weight,encoder.layers.0.self_attn.attention_weights.bias,encoder.layers.0.self_attn.attention_weights.weight,encoder.layers.0.self_attn.output_proj.bias,encoder.layers.0.self_attn.output_proj.weight,encoder.layers.0.self_attn.sampling_offsets.bias,encoder.layers.0.self_attn.sampling_offsets.weight,encoder.layers.0.self_attn.value_proj.bias,encoder.layers.0.self_attn.value_proj.weight,encoder.layers.1.linear1.bias,encoder.layers.1.linear1.weight,encoder.layers.1.linear2.bias,encoder.layers.1.linear2.weight,encoder.layers.1.norm1.bias,encoder.layers.1.norm1.weight,encoder.layers.1.norm2.bias,encoder.layers.1.norm2.weight,encoder.layers.1.self_attn.attention_weights.bias,encoder.layers.1.self_attn.attention_weights.weight,encoder.layers.1.self_attn.output_proj.bias,encoder.layers.1.self_attn.output_proj.weight,encoder.layers.1.self_attn.sampling_offsets.bias,encoder.layers.1.self_attn.sampling_offsets.weight,encoder.layers.1.self_attn.value_proj.bias,encoder.layers.1.self_attn.value_proj.weight,encoder.layers.2.linear1.bias,encoder.layers.2.linear1.weight,encoder.layers.2.linear2.bias,encoder.layers.2.linear2.weight,encoder.layers.2.norm1.bias,encoder.layers.2.norm1.weight,encoder.layers.2.norm2.bias,encoder.layers.2.norm2.weight,encoder.layers.2.self_attn.attention_weights.bias,encoder.layers.2.self_attn.attention_weights.weight,encoder.layers.2.self_attn.output_proj.bias,encoder.layers.2.self_attn.output_proj.weight,encoder.layers.2.self_attn.sampling_offsets.bias,encoder.layers.2.self_attn.sampling_offsets.weight,encoder.layers.2.self_attn.value_proj.bias,encoder.layers.2.self_attn.value_proj.weight,encoder.layers.3.linear1.bias,encoder.layers.3.linear1.weight,encoder.layers.3.linear2.bias,encoder.layers.3.linear2.weight,encoder.layers.3.norm1.bias,encoder.layers.3.norm1.weight,encoder.layers.3.norm2.bias,encoder.layers.3.norm2.weight,encoder.layers.3.self_attn.attention_weights.bias,encoder.layers.3.self_attn.attention_weights.weight,encoder.layers.3.self_attn.output_proj.bias,encoder.layers.3.self_attn.output_proj.weight,encoder.layers.3.self_attn.sampling_offsets.bias,encoder.layers.3.self_attn.sampling_offsets.weight,encoder.layers.3.self_attn.value_proj.bias,encoder.layers.3.self_attn.value_proj.weight,encoder.layers.4.linear1.bias,encoder.layers.4.linear1.weight,encoder.layers.4.linear2.bias,encoder.layers.4.linear2.weight,encoder.layers.4.norm1.bias,encoder.layers.4.norm1.weight,encoder.layers.4.norm2.bias,encoder.layers.4.norm2.weight,encoder.layers.4.self_attn.attention_weights.bias,encoder.layers.4.self_attn.attention_weights.weight,encoder.layers.4.self_attn.output_proj.bias,encoder.layers.4.self_attn.output_proj.weight,encoder.layers.4.self_attn.sampling_offsets.bias,encoder.layers.4.self_attn.sampling_offsets.weight,encoder.layers.4.self_attn.value_proj.bias,encoder.layers.4.self_attn.value_proj.weight,encoder.layers.5.linear1.bias,encoder.layers.5.linear1.weight,encoder.layers.5.linear2.bias,encoder.layers.5.linear2.weight,encoder.layers.5.norm1.bias,encoder.layers.5.norm1.weight,encoder.layers.5.norm2.bias,encoder.layers.5.norm2.weight,encoder.layers.5.self_attn.attention_weights.bias,encoder.layers.5.self_attn.attention_weights.weight,encoder.layers.5.self_attn.output_proj.bias,encoder.layers.5.self_attn.output_proj.weight,encoder.layers.5.self_attn.sampling_offsets.bias,encoder.layers.5.self_attn.sampling_offsets.weight,encoder.layers.5.self_attn.value_proj.bias,encoder.layers.5.self_attn.value_proj.weight,level_embed} | (1024,) (1024,256) (256,) (256,1024) (256,) (256,) (256,) (256,) (96,) (96,256) (256,) (256,256) (192,) (192,256) (256,) (256,256) (1024,) (1024,256) (256,) (256,1024) (256,) (256,) (256,) (256,) (96,) (96,256) (256,) (256,256) (192,) (192,256) (256,) (256,256) (1024,) (1024,256) (256,) (256,1024) (256,) (256,) (256,) (256,) (96,) (96,256) (256,) (256,256) (192,) (192,256) (256,) (256,256) (1024,) (1024,256) (256,) (256,1024) (256,) (256,) (256,) (256,) (96,) (96,256) (256,) (256,256) (192,) (192,256) (256,) (256,256) (1024,) (1024,256) (256,) (256,1024) (256,) (256,) (256,) (256,) (96,) (96,256) (256,) (256,256) (192,) (192,256) (256,) (256,256) (1024,) (1024,256) (256,) (256,1024) (256,) (256,) (256,) (256,) (96,) (96,256) (256,) (256,256) (192,) (192,256) (256,) (256,256) (3,256) |\n",
            "| sem_seg_head.predictor._bbox_embed.layers.0.*                          | sem_seg_head.predictor._bbox_embed.layers.0.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    | (256,) (256,256)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |\n",
            "| sem_seg_head.predictor._bbox_embed.layers.1.*                          | sem_seg_head.predictor._bbox_embed.layers.1.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    | (256,) (256,256)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |\n",
            "| sem_seg_head.predictor._bbox_embed.layers.2.*                          | sem_seg_head.predictor._bbox_embed.layers.2.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    | (4,) (4,256)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |\n",
            "| sem_seg_head.predictor.bbox_embed.0.layers.0.*                         | sem_seg_head.predictor.bbox_embed.0.layers.0.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   | (256,) (256,256)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |\n",
            "| sem_seg_head.predictor.bbox_embed.0.layers.1.*                         | sem_seg_head.predictor.bbox_embed.0.layers.1.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   | (256,) (256,256)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |\n",
            "| sem_seg_head.predictor.bbox_embed.0.layers.2.*                         | sem_seg_head.predictor.bbox_embed.0.layers.2.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   | (4,) (4,256)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |\n",
            "| sem_seg_head.predictor.bbox_embed.1.layers.0.*                         | sem_seg_head.predictor.bbox_embed.1.layers.0.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   | (256,) (256,256)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |\n",
            "| sem_seg_head.predictor.bbox_embed.1.layers.1.*                         | sem_seg_head.predictor.bbox_embed.1.layers.1.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   | (256,) (256,256)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |\n",
            "| sem_seg_head.predictor.bbox_embed.1.layers.2.*                         | sem_seg_head.predictor.bbox_embed.1.layers.2.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   | (4,) (4,256)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |\n",
            "| sem_seg_head.predictor.bbox_embed.2.layers.0.*                         | sem_seg_head.predictor.bbox_embed.2.layers.0.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   | (256,) (256,256)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |\n",
            "| sem_seg_head.predictor.bbox_embed.2.layers.1.*                         | sem_seg_head.predictor.bbox_embed.2.layers.1.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   | (256,) (256,256)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |\n",
            "| sem_seg_head.predictor.bbox_embed.2.layers.2.*                         | sem_seg_head.predictor.bbox_embed.2.layers.2.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   | (4,) (4,256)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |\n",
            "| sem_seg_head.predictor.bbox_embed.3.layers.0.*                         | sem_seg_head.predictor.bbox_embed.3.layers.0.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   | (256,) (256,256)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |\n",
            "| sem_seg_head.predictor.bbox_embed.3.layers.1.*                         | sem_seg_head.predictor.bbox_embed.3.layers.1.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   | (256,) (256,256)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |\n",
            "| sem_seg_head.predictor.bbox_embed.3.layers.2.*                         | sem_seg_head.predictor.bbox_embed.3.layers.2.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   | (4,) (4,256)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |\n",
            "| sem_seg_head.predictor.bbox_embed.4.layers.0.*                         | sem_seg_head.predictor.bbox_embed.4.layers.0.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   | (256,) (256,256)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |\n",
            "| sem_seg_head.predictor.bbox_embed.4.layers.1.*                         | sem_seg_head.predictor.bbox_embed.4.layers.1.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   | (256,) (256,256)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |\n",
            "| sem_seg_head.predictor.bbox_embed.4.layers.2.*                         | sem_seg_head.predictor.bbox_embed.4.layers.2.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   | (4,) (4,256)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |\n",
            "| sem_seg_head.predictor.bbox_embed.5.layers.0.*                         | sem_seg_head.predictor.bbox_embed.5.layers.0.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   | (256,) (256,256)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |\n",
            "| sem_seg_head.predictor.bbox_embed.5.layers.1.*                         | sem_seg_head.predictor.bbox_embed.5.layers.1.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   | (256,) (256,256)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |\n",
            "| sem_seg_head.predictor.bbox_embed.5.layers.2.*                         | sem_seg_head.predictor.bbox_embed.5.layers.2.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   | (4,) (4,256)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |\n",
            "| sem_seg_head.predictor.bbox_embed.6.layers.0.*                         | sem_seg_head.predictor.bbox_embed.6.layers.0.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   | (256,) (256,256)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |\n",
            "| sem_seg_head.predictor.bbox_embed.6.layers.1.*                         | sem_seg_head.predictor.bbox_embed.6.layers.1.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   | (256,) (256,256)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |\n",
            "| sem_seg_head.predictor.bbox_embed.6.layers.2.*                         | sem_seg_head.predictor.bbox_embed.6.layers.2.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   | (4,) (4,256)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |\n",
            "| sem_seg_head.predictor.bbox_embed.7.layers.0.*                         | sem_seg_head.predictor.bbox_embed.7.layers.0.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   | (256,) (256,256)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |\n",
            "| sem_seg_head.predictor.bbox_embed.7.layers.1.*                         | sem_seg_head.predictor.bbox_embed.7.layers.1.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   | (256,) (256,256)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |\n",
            "| sem_seg_head.predictor.bbox_embed.7.layers.2.*                         | sem_seg_head.predictor.bbox_embed.7.layers.2.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   | (4,) (4,256)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |\n",
            "| sem_seg_head.predictor.bbox_embed.8.layers.0.*                         | sem_seg_head.predictor.bbox_embed.8.layers.0.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   | (256,) (256,256)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |\n",
            "| sem_seg_head.predictor.bbox_embed.8.layers.1.*                         | sem_seg_head.predictor.bbox_embed.8.layers.1.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   | (256,) (256,256)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |\n",
            "| sem_seg_head.predictor.bbox_embed.8.layers.2.*                         | sem_seg_head.predictor.bbox_embed.8.layers.2.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   | (4,) (4,256)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |\n",
            "| sem_seg_head.predictor.decoder.bbox_embed.0.layers.0.*                 | sem_seg_head.predictor.decoder.bbox_embed.0.layers.0.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           | (256,) (256,256)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |\n",
            "| sem_seg_head.predictor.decoder.bbox_embed.0.layers.1.*                 | sem_seg_head.predictor.decoder.bbox_embed.0.layers.1.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           | (256,) (256,256)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |\n",
            "| sem_seg_head.predictor.decoder.bbox_embed.0.layers.2.*                 | sem_seg_head.predictor.decoder.bbox_embed.0.layers.2.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           | (4,) (4,256)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |\n",
            "| sem_seg_head.predictor.decoder.bbox_embed.1.layers.0.*                 | sem_seg_head.predictor.decoder.bbox_embed.1.layers.0.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           | (256,) (256,256)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |\n",
            "| sem_seg_head.predictor.decoder.bbox_embed.1.layers.1.*                 | sem_seg_head.predictor.decoder.bbox_embed.1.layers.1.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           | (256,) (256,256)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |\n",
            "| sem_seg_head.predictor.decoder.bbox_embed.1.layers.2.*                 | sem_seg_head.predictor.decoder.bbox_embed.1.layers.2.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           | (4,) (4,256)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |\n",
            "| sem_seg_head.predictor.decoder.bbox_embed.2.layers.0.*                 | sem_seg_head.predictor.decoder.bbox_embed.2.layers.0.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           | (256,) (256,256)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |\n",
            "| sem_seg_head.predictor.decoder.bbox_embed.2.layers.1.*                 | sem_seg_head.predictor.decoder.bbox_embed.2.layers.1.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           | (256,) (256,256)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |\n",
            "| sem_seg_head.predictor.decoder.bbox_embed.2.layers.2.*                 | sem_seg_head.predictor.decoder.bbox_embed.2.layers.2.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           | (4,) (4,256)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |\n",
            "| sem_seg_head.predictor.decoder.bbox_embed.3.layers.0.*                 | sem_seg_head.predictor.decoder.bbox_embed.3.layers.0.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           | (256,) (256,256)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |\n",
            "| sem_seg_head.predictor.decoder.bbox_embed.3.layers.1.*                 | sem_seg_head.predictor.decoder.bbox_embed.3.layers.1.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           | (256,) (256,256)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |\n",
            "| sem_seg_head.predictor.decoder.bbox_embed.3.layers.2.*                 | sem_seg_head.predictor.decoder.bbox_embed.3.layers.2.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           | (4,) (4,256)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |\n",
            "| sem_seg_head.predictor.decoder.bbox_embed.4.layers.0.*                 | sem_seg_head.predictor.decoder.bbox_embed.4.layers.0.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           | (256,) (256,256)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |\n",
            "| sem_seg_head.predictor.decoder.bbox_embed.4.layers.1.*                 | sem_seg_head.predictor.decoder.bbox_embed.4.layers.1.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           | (256,) (256,256)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |\n",
            "| sem_seg_head.predictor.decoder.bbox_embed.4.layers.2.*                 | sem_seg_head.predictor.decoder.bbox_embed.4.layers.2.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           | (4,) (4,256)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |\n",
            "| sem_seg_head.predictor.decoder.bbox_embed.5.layers.0.*                 | sem_seg_head.predictor.decoder.bbox_embed.5.layers.0.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           | (256,) (256,256)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |\n",
            "| sem_seg_head.predictor.decoder.bbox_embed.5.layers.1.*                 | sem_seg_head.predictor.decoder.bbox_embed.5.layers.1.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           | (256,) (256,256)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |\n",
            "| sem_seg_head.predictor.decoder.bbox_embed.5.layers.2.*                 | sem_seg_head.predictor.decoder.bbox_embed.5.layers.2.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           | (4,) (4,256)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |\n",
            "| sem_seg_head.predictor.decoder.bbox_embed.6.layers.0.*                 | sem_seg_head.predictor.decoder.bbox_embed.6.layers.0.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           | (256,) (256,256)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |\n",
            "| sem_seg_head.predictor.decoder.bbox_embed.6.layers.1.*                 | sem_seg_head.predictor.decoder.bbox_embed.6.layers.1.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           | (256,) (256,256)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |\n",
            "| sem_seg_head.predictor.decoder.bbox_embed.6.layers.2.*                 | sem_seg_head.predictor.decoder.bbox_embed.6.layers.2.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           | (4,) (4,256)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |\n",
            "| sem_seg_head.predictor.decoder.bbox_embed.7.layers.0.*                 | sem_seg_head.predictor.decoder.bbox_embed.7.layers.0.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           | (256,) (256,256)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |\n",
            "| sem_seg_head.predictor.decoder.bbox_embed.7.layers.1.*                 | sem_seg_head.predictor.decoder.bbox_embed.7.layers.1.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           | (256,) (256,256)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |\n",
            "| sem_seg_head.predictor.decoder.bbox_embed.7.layers.2.*                 | sem_seg_head.predictor.decoder.bbox_embed.7.layers.2.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           | (4,) (4,256)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |\n",
            "| sem_seg_head.predictor.decoder.bbox_embed.8.layers.0.*                 | sem_seg_head.predictor.decoder.bbox_embed.8.layers.0.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           | (256,) (256,256)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |\n",
            "| sem_seg_head.predictor.decoder.bbox_embed.8.layers.1.*                 | sem_seg_head.predictor.decoder.bbox_embed.8.layers.1.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           | (256,) (256,256)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |\n",
            "| sem_seg_head.predictor.decoder.bbox_embed.8.layers.2.*                 | sem_seg_head.predictor.decoder.bbox_embed.8.layers.2.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           | (4,) (4,256)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |\n",
            "| sem_seg_head.predictor.decoder.layers.0.cross_attn.attention_weights.* | sem_seg_head.predictor.decoder.layers.0.cross_attn.attention_weights.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           | (96,) (96,256)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |\n",
            "| sem_seg_head.predictor.decoder.layers.0.cross_attn.output_proj.*       | sem_seg_head.predictor.decoder.layers.0.cross_attn.output_proj.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 | (256,) (256,256)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |\n",
            "| sem_seg_head.predictor.decoder.layers.0.cross_attn.sampling_offsets.*  | sem_seg_head.predictor.decoder.layers.0.cross_attn.sampling_offsets.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            | (192,) (192,256)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |\n",
            "| sem_seg_head.predictor.decoder.layers.0.cross_attn.value_proj.*        | sem_seg_head.predictor.decoder.layers.0.cross_attn.value_proj.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  | (256,) (256,256)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |\n",
            "| sem_seg_head.predictor.decoder.layers.0.linear1.*                      | sem_seg_head.predictor.decoder.layers.0.linear1.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                | (2048,) (2048,256)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |\n",
            "| sem_seg_head.predictor.decoder.layers.0.linear2.*                      | sem_seg_head.predictor.decoder.layers.0.linear2.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                | (256,) (256,2048)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |\n",
            "| sem_seg_head.predictor.decoder.layers.0.norm1.*                        | sem_seg_head.predictor.decoder.layers.0.norm1.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  | (256,) (256,)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |\n",
            "| sem_seg_head.predictor.decoder.layers.0.norm2.*                        | sem_seg_head.predictor.decoder.layers.0.norm2.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  | (256,) (256,)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |\n",
            "| sem_seg_head.predictor.decoder.layers.0.norm3.*                        | sem_seg_head.predictor.decoder.layers.0.norm3.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  | (256,) (256,)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |\n",
            "| sem_seg_head.predictor.decoder.layers.0.self_attn.*                    | sem_seg_head.predictor.decoder.layers.0.self_attn.{in_proj_bias,in_proj_weight,out_proj.bias,out_proj.weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                | (768,) (768,256) (256,) (256,256)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |\n",
            "| sem_seg_head.predictor.decoder.layers.1.cross_attn.attention_weights.* | sem_seg_head.predictor.decoder.layers.1.cross_attn.attention_weights.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           | (96,) (96,256)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |\n",
            "| sem_seg_head.predictor.decoder.layers.1.cross_attn.output_proj.*       | sem_seg_head.predictor.decoder.layers.1.cross_attn.output_proj.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 | (256,) (256,256)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |\n",
            "| sem_seg_head.predictor.decoder.layers.1.cross_attn.sampling_offsets.*  | sem_seg_head.predictor.decoder.layers.1.cross_attn.sampling_offsets.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            | (192,) (192,256)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |\n",
            "| sem_seg_head.predictor.decoder.layers.1.cross_attn.value_proj.*        | sem_seg_head.predictor.decoder.layers.1.cross_attn.value_proj.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  | (256,) (256,256)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |\n",
            "| sem_seg_head.predictor.decoder.layers.1.linear1.*                      | sem_seg_head.predictor.decoder.layers.1.linear1.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                | (2048,) (2048,256)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |\n",
            "| sem_seg_head.predictor.decoder.layers.1.linear2.*                      | sem_seg_head.predictor.decoder.layers.1.linear2.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                | (256,) (256,2048)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |\n",
            "| sem_seg_head.predictor.decoder.layers.1.norm1.*                        | sem_seg_head.predictor.decoder.layers.1.norm1.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  | (256,) (256,)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |\n",
            "| sem_seg_head.predictor.decoder.layers.1.norm2.*                        | sem_seg_head.predictor.decoder.layers.1.norm2.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  | (256,) (256,)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |\n",
            "| sem_seg_head.predictor.decoder.layers.1.norm3.*                        | sem_seg_head.predictor.decoder.layers.1.norm3.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  | (256,) (256,)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |\n",
            "| sem_seg_head.predictor.decoder.layers.1.self_attn.*                    | sem_seg_head.predictor.decoder.layers.1.self_attn.{in_proj_bias,in_proj_weight,out_proj.bias,out_proj.weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                | (768,) (768,256) (256,) (256,256)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |\n",
            "| sem_seg_head.predictor.decoder.layers.2.cross_attn.attention_weights.* | sem_seg_head.predictor.decoder.layers.2.cross_attn.attention_weights.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           | (96,) (96,256)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |\n",
            "| sem_seg_head.predictor.decoder.layers.2.cross_attn.output_proj.*       | sem_seg_head.predictor.decoder.layers.2.cross_attn.output_proj.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 | (256,) (256,256)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |\n",
            "| sem_seg_head.predictor.decoder.layers.2.cross_attn.sampling_offsets.*  | sem_seg_head.predictor.decoder.layers.2.cross_attn.sampling_offsets.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            | (192,) (192,256)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |\n",
            "| sem_seg_head.predictor.decoder.layers.2.cross_attn.value_proj.*        | sem_seg_head.predictor.decoder.layers.2.cross_attn.value_proj.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  | (256,) (256,256)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |\n",
            "| sem_seg_head.predictor.decoder.layers.2.linear1.*                      | sem_seg_head.predictor.decoder.layers.2.linear1.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                | (2048,) (2048,256)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |\n",
            "| sem_seg_head.predictor.decoder.layers.2.linear2.*                      | sem_seg_head.predictor.decoder.layers.2.linear2.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                | (256,) (256,2048)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |\n",
            "| sem_seg_head.predictor.decoder.layers.2.norm1.*                        | sem_seg_head.predictor.decoder.layers.2.norm1.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  | (256,) (256,)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |\n",
            "| sem_seg_head.predictor.decoder.layers.2.norm2.*                        | sem_seg_head.predictor.decoder.layers.2.norm2.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  | (256,) (256,)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |\n",
            "| sem_seg_head.predictor.decoder.layers.2.norm3.*                        | sem_seg_head.predictor.decoder.layers.2.norm3.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  | (256,) (256,)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |\n",
            "| sem_seg_head.predictor.decoder.layers.2.self_attn.*                    | sem_seg_head.predictor.decoder.layers.2.self_attn.{in_proj_bias,in_proj_weight,out_proj.bias,out_proj.weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                | (768,) (768,256) (256,) (256,256)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |\n",
            "| sem_seg_head.predictor.decoder.layers.3.cross_attn.attention_weights.* | sem_seg_head.predictor.decoder.layers.3.cross_attn.attention_weights.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           | (96,) (96,256)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |\n",
            "| sem_seg_head.predictor.decoder.layers.3.cross_attn.output_proj.*       | sem_seg_head.predictor.decoder.layers.3.cross_attn.output_proj.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 | (256,) (256,256)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |\n",
            "| sem_seg_head.predictor.decoder.layers.3.cross_attn.sampling_offsets.*  | sem_seg_head.predictor.decoder.layers.3.cross_attn.sampling_offsets.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            | (192,) (192,256)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |\n",
            "| sem_seg_head.predictor.decoder.layers.3.cross_attn.value_proj.*        | sem_seg_head.predictor.decoder.layers.3.cross_attn.value_proj.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  | (256,) (256,256)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |\n",
            "| sem_seg_head.predictor.decoder.layers.3.linear1.*                      | sem_seg_head.predictor.decoder.layers.3.linear1.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                | (2048,) (2048,256)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |\n",
            "| sem_seg_head.predictor.decoder.layers.3.linear2.*                      | sem_seg_head.predictor.decoder.layers.3.linear2.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                | (256,) (256,2048)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |\n",
            "| sem_seg_head.predictor.decoder.layers.3.norm1.*                        | sem_seg_head.predictor.decoder.layers.3.norm1.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  | (256,) (256,)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |\n",
            "| sem_seg_head.predictor.decoder.layers.3.norm2.*                        | sem_seg_head.predictor.decoder.layers.3.norm2.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  | (256,) (256,)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |\n",
            "| sem_seg_head.predictor.decoder.layers.3.norm3.*                        | sem_seg_head.predictor.decoder.layers.3.norm3.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  | (256,) (256,)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |\n",
            "| sem_seg_head.predictor.decoder.layers.3.self_attn.*                    | sem_seg_head.predictor.decoder.layers.3.self_attn.{in_proj_bias,in_proj_weight,out_proj.bias,out_proj.weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                | (768,) (768,256) (256,) (256,256)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |\n",
            "| sem_seg_head.predictor.decoder.layers.4.cross_attn.attention_weights.* | sem_seg_head.predictor.decoder.layers.4.cross_attn.attention_weights.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           | (96,) (96,256)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |\n",
            "| sem_seg_head.predictor.decoder.layers.4.cross_attn.output_proj.*       | sem_seg_head.predictor.decoder.layers.4.cross_attn.output_proj.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 | (256,) (256,256)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |\n",
            "| sem_seg_head.predictor.decoder.layers.4.cross_attn.sampling_offsets.*  | sem_seg_head.predictor.decoder.layers.4.cross_attn.sampling_offsets.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            | (192,) (192,256)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |\n",
            "| sem_seg_head.predictor.decoder.layers.4.cross_attn.value_proj.*        | sem_seg_head.predictor.decoder.layers.4.cross_attn.value_proj.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  | (256,) (256,256)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |\n",
            "| sem_seg_head.predictor.decoder.layers.4.linear1.*                      | sem_seg_head.predictor.decoder.layers.4.linear1.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                | (2048,) (2048,256)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |\n",
            "| sem_seg_head.predictor.decoder.layers.4.linear2.*                      | sem_seg_head.predictor.decoder.layers.4.linear2.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                | (256,) (256,2048)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |\n",
            "| sem_seg_head.predictor.decoder.layers.4.norm1.*                        | sem_seg_head.predictor.decoder.layers.4.norm1.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  | (256,) (256,)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |\n",
            "| sem_seg_head.predictor.decoder.layers.4.norm2.*                        | sem_seg_head.predictor.decoder.layers.4.norm2.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  | (256,) (256,)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |\n",
            "| sem_seg_head.predictor.decoder.layers.4.norm3.*                        | sem_seg_head.predictor.decoder.layers.4.norm3.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  | (256,) (256,)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |\n",
            "| sem_seg_head.predictor.decoder.layers.4.self_attn.*                    | sem_seg_head.predictor.decoder.layers.4.self_attn.{in_proj_bias,in_proj_weight,out_proj.bias,out_proj.weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                | (768,) (768,256) (256,) (256,256)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |\n",
            "| sem_seg_head.predictor.decoder.layers.5.cross_attn.attention_weights.* | sem_seg_head.predictor.decoder.layers.5.cross_attn.attention_weights.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           | (96,) (96,256)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |\n",
            "| sem_seg_head.predictor.decoder.layers.5.cross_attn.output_proj.*       | sem_seg_head.predictor.decoder.layers.5.cross_attn.output_proj.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 | (256,) (256,256)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |\n",
            "| sem_seg_head.predictor.decoder.layers.5.cross_attn.sampling_offsets.*  | sem_seg_head.predictor.decoder.layers.5.cross_attn.sampling_offsets.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            | (192,) (192,256)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |\n",
            "| sem_seg_head.predictor.decoder.layers.5.cross_attn.value_proj.*        | sem_seg_head.predictor.decoder.layers.5.cross_attn.value_proj.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  | (256,) (256,256)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |\n",
            "| sem_seg_head.predictor.decoder.layers.5.linear1.*                      | sem_seg_head.predictor.decoder.layers.5.linear1.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                | (2048,) (2048,256)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |\n",
            "| sem_seg_head.predictor.decoder.layers.5.linear2.*                      | sem_seg_head.predictor.decoder.layers.5.linear2.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                | (256,) (256,2048)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |\n",
            "| sem_seg_head.predictor.decoder.layers.5.norm1.*                        | sem_seg_head.predictor.decoder.layers.5.norm1.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  | (256,) (256,)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |\n",
            "| sem_seg_head.predictor.decoder.layers.5.norm2.*                        | sem_seg_head.predictor.decoder.layers.5.norm2.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  | (256,) (256,)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |\n",
            "| sem_seg_head.predictor.decoder.layers.5.norm3.*                        | sem_seg_head.predictor.decoder.layers.5.norm3.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  | (256,) (256,)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |\n",
            "| sem_seg_head.predictor.decoder.layers.5.self_attn.*                    | sem_seg_head.predictor.decoder.layers.5.self_attn.{in_proj_bias,in_proj_weight,out_proj.bias,out_proj.weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                | (768,) (768,256) (256,) (256,256)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |\n",
            "| sem_seg_head.predictor.decoder.layers.6.cross_attn.attention_weights.* | sem_seg_head.predictor.decoder.layers.6.cross_attn.attention_weights.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           | (96,) (96,256)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |\n",
            "| sem_seg_head.predictor.decoder.layers.6.cross_attn.output_proj.*       | sem_seg_head.predictor.decoder.layers.6.cross_attn.output_proj.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 | (256,) (256,256)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |\n",
            "| sem_seg_head.predictor.decoder.layers.6.cross_attn.sampling_offsets.*  | sem_seg_head.predictor.decoder.layers.6.cross_attn.sampling_offsets.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            | (192,) (192,256)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |\n",
            "| sem_seg_head.predictor.decoder.layers.6.cross_attn.value_proj.*        | sem_seg_head.predictor.decoder.layers.6.cross_attn.value_proj.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  | (256,) (256,256)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |\n",
            "| sem_seg_head.predictor.decoder.layers.6.linear1.*                      | sem_seg_head.predictor.decoder.layers.6.linear1.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                | (2048,) (2048,256)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |\n",
            "| sem_seg_head.predictor.decoder.layers.6.linear2.*                      | sem_seg_head.predictor.decoder.layers.6.linear2.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                | (256,) (256,2048)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |\n",
            "| sem_seg_head.predictor.decoder.layers.6.norm1.*                        | sem_seg_head.predictor.decoder.layers.6.norm1.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  | (256,) (256,)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |\n",
            "| sem_seg_head.predictor.decoder.layers.6.norm2.*                        | sem_seg_head.predictor.decoder.layers.6.norm2.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  | (256,) (256,)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |\n",
            "| sem_seg_head.predictor.decoder.layers.6.norm3.*                        | sem_seg_head.predictor.decoder.layers.6.norm3.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  | (256,) (256,)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |\n",
            "| sem_seg_head.predictor.decoder.layers.6.self_attn.*                    | sem_seg_head.predictor.decoder.layers.6.self_attn.{in_proj_bias,in_proj_weight,out_proj.bias,out_proj.weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                | (768,) (768,256) (256,) (256,256)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |\n",
            "| sem_seg_head.predictor.decoder.layers.7.cross_attn.attention_weights.* | sem_seg_head.predictor.decoder.layers.7.cross_attn.attention_weights.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           | (96,) (96,256)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |\n",
            "| sem_seg_head.predictor.decoder.layers.7.cross_attn.output_proj.*       | sem_seg_head.predictor.decoder.layers.7.cross_attn.output_proj.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 | (256,) (256,256)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |\n",
            "| sem_seg_head.predictor.decoder.layers.7.cross_attn.sampling_offsets.*  | sem_seg_head.predictor.decoder.layers.7.cross_attn.sampling_offsets.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            | (192,) (192,256)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |\n",
            "| sem_seg_head.predictor.decoder.layers.7.cross_attn.value_proj.*        | sem_seg_head.predictor.decoder.layers.7.cross_attn.value_proj.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  | (256,) (256,256)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |\n",
            "| sem_seg_head.predictor.decoder.layers.7.linear1.*                      | sem_seg_head.predictor.decoder.layers.7.linear1.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                | (2048,) (2048,256)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |\n",
            "| sem_seg_head.predictor.decoder.layers.7.linear2.*                      | sem_seg_head.predictor.decoder.layers.7.linear2.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                | (256,) (256,2048)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |\n",
            "| sem_seg_head.predictor.decoder.layers.7.norm1.*                        | sem_seg_head.predictor.decoder.layers.7.norm1.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  | (256,) (256,)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |\n",
            "| sem_seg_head.predictor.decoder.layers.7.norm2.*                        | sem_seg_head.predictor.decoder.layers.7.norm2.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  | (256,) (256,)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |\n",
            "| sem_seg_head.predictor.decoder.layers.7.norm3.*                        | sem_seg_head.predictor.decoder.layers.7.norm3.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  | (256,) (256,)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |\n",
            "| sem_seg_head.predictor.decoder.layers.7.self_attn.*                    | sem_seg_head.predictor.decoder.layers.7.self_attn.{in_proj_bias,in_proj_weight,out_proj.bias,out_proj.weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                | (768,) (768,256) (256,) (256,256)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |\n",
            "| sem_seg_head.predictor.decoder.layers.8.cross_attn.attention_weights.* | sem_seg_head.predictor.decoder.layers.8.cross_attn.attention_weights.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           | (96,) (96,256)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |\n",
            "| sem_seg_head.predictor.decoder.layers.8.cross_attn.output_proj.*       | sem_seg_head.predictor.decoder.layers.8.cross_attn.output_proj.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 | (256,) (256,256)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |\n",
            "| sem_seg_head.predictor.decoder.layers.8.cross_attn.sampling_offsets.*  | sem_seg_head.predictor.decoder.layers.8.cross_attn.sampling_offsets.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            | (192,) (192,256)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |\n",
            "| sem_seg_head.predictor.decoder.layers.8.cross_attn.value_proj.*        | sem_seg_head.predictor.decoder.layers.8.cross_attn.value_proj.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  | (256,) (256,256)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |\n",
            "| sem_seg_head.predictor.decoder.layers.8.linear1.*                      | sem_seg_head.predictor.decoder.layers.8.linear1.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                | (2048,) (2048,256)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |\n",
            "| sem_seg_head.predictor.decoder.layers.8.linear2.*                      | sem_seg_head.predictor.decoder.layers.8.linear2.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                | (256,) (256,2048)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |\n",
            "| sem_seg_head.predictor.decoder.layers.8.norm1.*                        | sem_seg_head.predictor.decoder.layers.8.norm1.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  | (256,) (256,)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |\n",
            "| sem_seg_head.predictor.decoder.layers.8.norm2.*                        | sem_seg_head.predictor.decoder.layers.8.norm2.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  | (256,) (256,)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |\n",
            "| sem_seg_head.predictor.decoder.layers.8.norm3.*                        | sem_seg_head.predictor.decoder.layers.8.norm3.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  | (256,) (256,)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |\n",
            "| sem_seg_head.predictor.decoder.layers.8.self_attn.*                    | sem_seg_head.predictor.decoder.layers.8.self_attn.{in_proj_bias,in_proj_weight,out_proj.bias,out_proj.weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                | (768,) (768,256) (256,) (256,256)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |\n",
            "| sem_seg_head.predictor.decoder.norm.*                                  | sem_seg_head.predictor.decoder.norm.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            | (256,) (256,)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |\n",
            "| sem_seg_head.predictor.decoder.ref_point_head.layers.0.*               | sem_seg_head.predictor.decoder.ref_point_head.layers.0.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         | (256,) (256,512)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |\n",
            "| sem_seg_head.predictor.decoder.ref_point_head.layers.1.*               | sem_seg_head.predictor.decoder.ref_point_head.layers.1.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         | (256,) (256,256)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |\n",
            "| sem_seg_head.predictor.decoder_norm.*                                  | sem_seg_head.predictor.decoder_norm.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            | (256,) (256,)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |\n",
            "| sem_seg_head.predictor.enc_output.*                                    | sem_seg_head.predictor.enc_output.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              | (256,) (256,256)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |\n",
            "| sem_seg_head.predictor.enc_output_norm.*                               | sem_seg_head.predictor.enc_output_norm.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         | (256,) (256,)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |\n",
            "| sem_seg_head.predictor.mask_embed.layers.0.*                           | sem_seg_head.predictor.mask_embed.layers.0.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     | (256,) (256,256)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |\n",
            "| sem_seg_head.predictor.mask_embed.layers.1.*                           | sem_seg_head.predictor.mask_embed.layers.1.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     | (256,) (256,256)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |\n",
            "| sem_seg_head.predictor.mask_embed.layers.2.*                           | sem_seg_head.predictor.mask_embed.layers.2.{bias,weight}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     | (256,) (256,256)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:fvcore.common.checkpoint:Skip loading parameter 'criterion.empty_weight' to the model due to incompatible shapes: (81,) in the checkpoint but (11,) in the model! You might want to double check if this is expected.\n",
            "WARNING:fvcore.common.checkpoint:Skip loading parameter 'sem_seg_head.predictor.class_embed.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (10,) in the model! You might want to double check if this is expected.\n",
            "WARNING:fvcore.common.checkpoint:Skip loading parameter 'sem_seg_head.predictor.class_embed.weight' to the model due to incompatible shapes: (80, 256) in the checkpoint but (10, 256) in the model! You might want to double check if this is expected.\n",
            "WARNING:fvcore.common.checkpoint:Skip loading parameter 'sem_seg_head.predictor.label_enc.weight' to the model due to incompatible shapes: (80, 256) in the checkpoint but (10, 256) in the model! You might want to double check if this is expected.\n",
            "WARNING:fvcore.common.checkpoint:Some model parameters or buffers are not found in the checkpoint:\n",
            "criterion.empty_weight\n",
            "sem_seg_head.predictor.class_embed.{bias, weight}\n",
            "sem_seg_head.predictor.label_enc.weight\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[05/20 16:09:02 d2.engine.train_loop]: Starting training from iteration 0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:507: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3549.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:143: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[05/20 16:10:16 d2.utils.events]:  eta: 4:02:34  iter: 19  total_loss: 2.106e+04  loss_ce: 1888  loss_mask: 0.1383  loss_dice: 2.078  loss_bbox: 0.6054  loss_giou: 1.595  loss_ce_dn: 14.29  loss_mask_dn: 0.1453  loss_dice_dn: 1.676  loss_bbox_dn: 0.2191  loss_giou_dn: 0.7858  loss_ce_0: 1991  loss_mask_0: 0.4599  loss_dice_0: 2.863  loss_bbox_0: 0.761  loss_giou_0: 1.993  loss_ce_dn_0: 10.1  loss_mask_dn_0: 0.7581  loss_dice_dn_0: 4.405  loss_bbox_dn_0: 0.2388  loss_giou_dn_0: 0.854  loss_ce_1: 2219  loss_mask_1: 0.3709  loss_dice_1: 2.423  loss_bbox_1: 0.7104  loss_giou_1: 1.822  loss_ce_dn_1: 13.89  loss_mask_dn_1: 0.09837  loss_dice_dn_1: 1.635  loss_bbox_dn_1: 0.2564  loss_giou_dn_1: 0.9162  loss_ce_2: 1957  loss_mask_2: 0.2876  loss_dice_2: 2.156  loss_bbox_2: 0.7366  loss_giou_2: 1.846  loss_ce_dn_2: 13.79  loss_mask_dn_2: 0.08483  loss_dice_dn_2: 1.407  loss_bbox_dn_2: 0.2142  loss_giou_dn_2: 0.7684  loss_ce_3: 1959  loss_mask_3: 0.2084  loss_dice_3: 2.381  loss_bbox_3: 0.648  loss_giou_3: 1.791  loss_ce_dn_3: 14.53  loss_mask_dn_3: 0.08791  loss_dice_dn_3: 1.451  loss_bbox_dn_3: 0.2303  loss_giou_dn_3: 0.7332  loss_ce_4: 1868  loss_mask_4: 0.1471  loss_dice_4: 2.368  loss_bbox_4: 0.6489  loss_giou_4: 1.743  loss_ce_dn_4: 14.08  loss_mask_dn_4: 0.1079  loss_dice_dn_4: 1.493  loss_bbox_dn_4: 0.2088  loss_giou_dn_4: 0.7283  loss_ce_5: 1870  loss_mask_5: 0.1493  loss_dice_5: 2.231  loss_bbox_5: 0.531  loss_giou_5: 1.605  loss_ce_dn_5: 14.57  loss_mask_dn_5: 0.1059  loss_dice_dn_5: 1.779  loss_bbox_dn_5: 0.2244  loss_giou_dn_5: 0.7753  loss_ce_6: 1932  loss_mask_6: 0.1328  loss_dice_6: 2.108  loss_bbox_6: 0.5738  loss_giou_6: 1.621  loss_ce_dn_6: 14.27  loss_mask_dn_6: 0.1215  loss_dice_dn_6: 1.762  loss_bbox_dn_6: 0.226  loss_giou_dn_6: 0.8047  loss_ce_7: 1941  loss_mask_7: 0.1276  loss_dice_7: 1.862  loss_bbox_7: 0.6369  loss_giou_7: 1.532  loss_ce_dn_7: 14.22  loss_mask_dn_7: 0.1294  loss_dice_dn_7: 1.77  loss_bbox_dn_7: 0.2242  loss_giou_dn_7: 0.8073  loss_ce_8: 1911  loss_mask_8: 0.1488  loss_dice_8: 2.039  loss_bbox_8: 0.4876  loss_giou_8: 1.503  loss_ce_dn_8: 14.17  loss_mask_dn_8: 0.1355  loss_dice_dn_8: 1.789  loss_bbox_dn_8: 0.2222  loss_giou_dn_8: 0.8029  loss_ce_interm: 1991  loss_mask_interm: 0.4697  loss_dice_interm: 2.892  loss_bbox_interm: 0.8545  loss_giou_interm: 2.169  time: 2.6460  data_time: 1.7557  lr: 0.0001  max_mem: 6575M\n",
            "[05/20 16:11:16 d2.utils.events]:  eta: 4:00:07  iter: 39  total_loss: 1946  loss_ce: 5.959  loss_mask: 0.4724  loss_dice: 3.824  loss_bbox: 2.033  loss_giou: 2.552  loss_ce_dn: 2.216  loss_mask_dn: 0.295  loss_dice_dn: 2.255  loss_bbox_dn: 0.2343  loss_giou_dn: 0.7828  loss_ce_0: 753.6  loss_mask_0: 0.2604  loss_dice_0: 3.932  loss_bbox_0: 2.131  loss_giou_0: 2.556  loss_ce_dn_0: 8.983  loss_mask_dn_0: 0.4204  loss_dice_dn_0: 4.344  loss_bbox_dn_0: 0.3016  loss_giou_dn_0: 0.8498  loss_ce_1: 47.09  loss_mask_1: 0.4813  loss_dice_1: 3.808  loss_bbox_1: 1.871  loss_giou_1: 2.539  loss_ce_dn_1: 2.274  loss_mask_dn_1: 0.2212  loss_dice_dn_1: 2.395  loss_bbox_dn_1: 0.2455  loss_giou_dn_1: 0.825  loss_ce_2: 12.6  loss_mask_2: 0.518  loss_dice_2: 3.924  loss_bbox_2: 1.909  loss_giou_2: 2.569  loss_ce_dn_2: 2.158  loss_mask_dn_2: 0.1733  loss_dice_dn_2: 2.086  loss_bbox_dn_2: 0.236  loss_giou_dn_2: 0.8363  loss_ce_3: 9.594  loss_mask_3: 0.57  loss_dice_3: 3.727  loss_bbox_3: 1.907  loss_giou_3: 2.598  loss_ce_dn_3: 2.186  loss_mask_dn_3: 0.2491  loss_dice_dn_3: 2.068  loss_bbox_dn_3: 0.2399  loss_giou_dn_3: 0.8138  loss_ce_4: 8.555  loss_mask_4: 0.6135  loss_dice_4: 3.616  loss_bbox_4: 1.995  loss_giou_4: 2.61  loss_ce_dn_4: 2.262  loss_mask_dn_4: 0.2405  loss_dice_dn_4: 1.95  loss_bbox_dn_4: 0.2355  loss_giou_dn_4: 0.7773  loss_ce_5: 6.968  loss_mask_5: 0.5973  loss_dice_5: 3.78  loss_bbox_5: 1.971  loss_giou_5: 2.57  loss_ce_dn_5: 2.182  loss_mask_dn_5: 0.264  loss_dice_dn_5: 2.021  loss_bbox_dn_5: 0.2432  loss_giou_dn_5: 0.833  loss_ce_6: 6.969  loss_mask_6: 0.6081  loss_dice_6: 3.732  loss_bbox_6: 2.003  loss_giou_6: 2.535  loss_ce_dn_6: 2.239  loss_mask_dn_6: 0.2902  loss_dice_dn_6: 2.072  loss_bbox_dn_6: 0.2553  loss_giou_dn_6: 0.7764  loss_ce_7: 6.376  loss_mask_7: 0.6286  loss_dice_7: 3.819  loss_bbox_7: 2.002  loss_giou_7: 2.56  loss_ce_dn_7: 2.196  loss_mask_dn_7: 0.2897  loss_dice_dn_7: 2.141  loss_bbox_dn_7: 0.251  loss_giou_dn_7: 0.8142  loss_ce_8: 6.416  loss_mask_8: 0.4929  loss_dice_8: 3.763  loss_bbox_8: 2.05  loss_giou_8: 2.578  loss_ce_dn_8: 2.175  loss_mask_dn_8: 0.3092  loss_dice_dn_8: 2.216  loss_bbox_dn_8: 0.2484  loss_giou_dn_8: 0.8303  loss_ce_interm: 753.7  loss_mask_interm: 0.3839  loss_dice_interm: 4.017  loss_bbox_interm: 13.34  loss_giou_interm: 2.467  time: 2.8432  data_time: 1.3356  lr: 0.0001  max_mem: 6591M\n",
            "[05/20 16:12:29 d2.utils.events]:  eta: 3:54:42  iter: 59  total_loss: 511.8  loss_ce: 3.281  loss_mask: 0.2784  loss_dice: 3.081  loss_bbox: 1.846  loss_giou: 2.297  loss_ce_dn: 2.279  loss_mask_dn: 0.2625  loss_dice_dn: 2.353  loss_bbox_dn: 0.1738  loss_giou_dn: 0.6986  loss_ce_0: 159.1  loss_mask_0: 0.2998  loss_dice_0: 3.711  loss_bbox_0: 2.212  loss_giou_0: 2.112  loss_ce_dn_0: 7.815  loss_mask_dn_0: 0.4026  loss_dice_dn_0: 4.084  loss_bbox_dn_0: 0.2269  loss_giou_dn_0: 0.8571  loss_ce_1: 5.707  loss_mask_1: 0.3012  loss_dice_1: 3.54  loss_bbox_1: 1.793  loss_giou_1: 2.358  loss_ce_dn_1: 2.291  loss_mask_dn_1: 0.1714  loss_dice_dn_1: 2.649  loss_bbox_dn_1: 0.1914  loss_giou_dn_1: 0.8105  loss_ce_2: 3.714  loss_mask_2: 0.3136  loss_dice_2: 2.943  loss_bbox_2: 1.782  loss_giou_2: 2.383  loss_ce_dn_2: 2.195  loss_mask_dn_2: 0.1486  loss_dice_dn_2: 2.318  loss_bbox_dn_2: 0.1845  loss_giou_dn_2: 0.759  loss_ce_3: 3.611  loss_mask_3: 0.3297  loss_dice_3: 3.204  loss_bbox_3: 1.831  loss_giou_3: 2.362  loss_ce_dn_3: 2.25  loss_mask_dn_3: 0.208  loss_dice_dn_3: 2.1  loss_bbox_dn_3: 0.1809  loss_giou_dn_3: 0.7556  loss_ce_4: 3.415  loss_mask_4: 0.36  loss_dice_4: 3.369  loss_bbox_4: 1.972  loss_giou_4: 2.28  loss_ce_dn_4: 2.261  loss_mask_dn_4: 0.2383  loss_dice_dn_4: 2.188  loss_bbox_dn_4: 0.1769  loss_giou_dn_4: 0.7087  loss_ce_5: 3.638  loss_mask_5: 0.3889  loss_dice_5: 3.145  loss_bbox_5: 1.962  loss_giou_5: 2.339  loss_ce_dn_5: 2.265  loss_mask_dn_5: 0.2668  loss_dice_dn_5: 2.393  loss_bbox_dn_5: 0.1769  loss_giou_dn_5: 0.7375  loss_ce_6: 3.431  loss_mask_6: 0.2834  loss_dice_6: 3.468  loss_bbox_6: 1.952  loss_giou_6: 2.262  loss_ce_dn_6: 2.237  loss_mask_dn_6: 0.2207  loss_dice_dn_6: 2.27  loss_bbox_dn_6: 0.1863  loss_giou_dn_6: 0.7085  loss_ce_7: 3.533  loss_mask_7: 0.2991  loss_dice_7: 3.007  loss_bbox_7: 1.904  loss_giou_7: 2.253  loss_ce_dn_7: 2.193  loss_mask_dn_7: 0.2419  loss_dice_dn_7: 2.298  loss_bbox_dn_7: 0.178  loss_giou_dn_7: 0.7144  loss_ce_8: 3.336  loss_mask_8: 0.299  loss_dice_8: 3.563  loss_bbox_8: 1.917  loss_giou_8: 2.259  loss_ce_dn_8: 2.208  loss_mask_dn_8: 0.2684  loss_dice_dn_8: 2.316  loss_bbox_dn_8: 0.1745  loss_giou_dn_8: 0.7083  loss_ce_interm: 159.2  loss_mask_interm: 0.3307  loss_dice_interm: 3.748  loss_bbox_interm: 13.23  loss_giou_interm: 2.676  time: 3.1068  data_time: 1.9759  lr: 0.0001  max_mem: 6614M\n",
            "[05/20 16:13:22 d2.utils.events]:  eta: 3:48:18  iter: 79  total_loss: 190.6  loss_ce: 3.541  loss_mask: 0.1616  loss_dice: 1.806  loss_bbox: 0.5874  loss_giou: 1.305  loss_ce_dn: 2.214  loss_mask_dn: 0.09419  loss_dice_dn: 1.638  loss_bbox_dn: 0.1138  loss_giou_dn: 0.6194  loss_ce_0: 22.45  loss_mask_0: 0.1508  loss_dice_0: 1.852  loss_bbox_0: 1.006  loss_giou_0: 1.268  loss_ce_dn_0: 5.806  loss_mask_dn_0: 0.2662  loss_dice_dn_0: 3.792  loss_bbox_dn_0: 0.2333  loss_giou_dn_0: 0.8644  loss_ce_1: 3.872  loss_mask_1: 0.1632  loss_dice_1: 2.016  loss_bbox_1: 0.6985  loss_giou_1: 1.363  loss_ce_dn_1: 2.203  loss_mask_dn_1: 0.1095  loss_dice_dn_1: 1.666  loss_bbox_dn_1: 0.1739  loss_giou_dn_1: 0.7017  loss_ce_2: 3.357  loss_mask_2: 0.2349  loss_dice_2: 2.065  loss_bbox_2: 0.7381  loss_giou_2: 1.425  loss_ce_dn_2: 1.924  loss_mask_dn_2: 0.09592  loss_dice_dn_2: 1.586  loss_bbox_dn_2: 0.1483  loss_giou_dn_2: 0.6441  loss_ce_3: 3.342  loss_mask_3: 0.1261  loss_dice_3: 1.814  loss_bbox_3: 0.6536  loss_giou_3: 1.406  loss_ce_dn_3: 2.069  loss_mask_dn_3: 0.07994  loss_dice_dn_3: 1.461  loss_bbox_dn_3: 0.1306  loss_giou_dn_3: 0.6032  loss_ce_4: 3.218  loss_mask_4: 0.159  loss_dice_4: 1.835  loss_bbox_4: 0.5788  loss_giou_4: 1.375  loss_ce_dn_4: 2.088  loss_mask_dn_4: 0.0742  loss_dice_dn_4: 1.462  loss_bbox_dn_4: 0.1293  loss_giou_dn_4: 0.6188  loss_ce_5: 3.251  loss_mask_5: 0.1469  loss_dice_5: 1.654  loss_bbox_5: 0.6105  loss_giou_5: 1.392  loss_ce_dn_5: 2.125  loss_mask_dn_5: 0.07774  loss_dice_dn_5: 1.376  loss_bbox_dn_5: 0.1182  loss_giou_dn_5: 0.6165  loss_ce_6: 3.358  loss_mask_6: 0.135  loss_dice_6: 1.851  loss_bbox_6: 0.6033  loss_giou_6: 1.298  loss_ce_dn_6: 2.061  loss_mask_dn_6: 0.08698  loss_dice_dn_6: 1.539  loss_bbox_dn_6: 0.1204  loss_giou_dn_6: 0.6308  loss_ce_7: 3.477  loss_mask_7: 0.1421  loss_dice_7: 1.937  loss_bbox_7: 0.5786  loss_giou_7: 1.314  loss_ce_dn_7: 2.118  loss_mask_dn_7: 0.08309  loss_dice_dn_7: 1.495  loss_bbox_dn_7: 0.1139  loss_giou_dn_7: 0.6175  loss_ce_8: 3.526  loss_mask_8: 0.158  loss_dice_8: 1.978  loss_bbox_8: 0.5756  loss_giou_8: 1.335  loss_ce_dn_8: 2.19  loss_mask_dn_8: 0.09249  loss_dice_dn_8: 1.617  loss_bbox_dn_8: 0.1153  loss_giou_dn_8: 0.6212  loss_ce_interm: 22.43  loss_mask_interm: 0.2093  loss_dice_interm: 1.882  loss_bbox_interm: 0.8321  loss_giou_interm: 1.778  time: 2.9912  data_time: 1.0226  lr: 0.0001  max_mem: 6614M\n",
            "[05/20 16:14:11 d2.utils.events]:  eta: 3:45:26  iter: 99  total_loss: 128.8  loss_ce: 2.411  loss_mask: 0.1138  loss_dice: 1.873  loss_bbox: 0.5298  loss_giou: 1.468  loss_ce_dn: 1.391  loss_mask_dn: 0.09665  loss_dice_dn: 1.525  loss_bbox_dn: 0.1185  loss_giou_dn: 0.4795  loss_ce_0: 7.25  loss_mask_0: 0.08556  loss_dice_0: 1.982  loss_bbox_0: 0.4331  loss_giou_0: 1.414  loss_ce_dn_0: 5.134  loss_mask_dn_0: 0.3579  loss_dice_dn_0: 3.648  loss_bbox_dn_0: 0.2587  loss_giou_dn_0: 0.8532  loss_ce_1: 3.078  loss_mask_1: 0.08064  loss_dice_1: 1.543  loss_bbox_1: 0.4122  loss_giou_1: 1.487  loss_ce_dn_1: 1.878  loss_mask_dn_1: 0.104  loss_dice_dn_1: 1.719  loss_bbox_dn_1: 0.1359  loss_giou_dn_1: 0.641  loss_ce_2: 2.59  loss_mask_2: 0.07811  loss_dice_2: 1.794  loss_bbox_2: 0.5862  loss_giou_2: 1.516  loss_ce_dn_2: 1.569  loss_mask_dn_2: 0.08963  loss_dice_dn_2: 1.502  loss_bbox_dn_2: 0.1208  loss_giou_dn_2: 0.5422  loss_ce_3: 2.534  loss_mask_3: 0.09829  loss_dice_3: 1.571  loss_bbox_3: 0.4894  loss_giou_3: 1.476  loss_ce_dn_3: 1.427  loss_mask_dn_3: 0.08672  loss_dice_dn_3: 1.496  loss_bbox_dn_3: 0.1168  loss_giou_dn_3: 0.5114  loss_ce_4: 2.471  loss_mask_4: 0.1119  loss_dice_4: 1.954  loss_bbox_4: 0.4481  loss_giou_4: 1.268  loss_ce_dn_4: 1.43  loss_mask_dn_4: 0.07854  loss_dice_dn_4: 1.527  loss_bbox_dn_4: 0.1158  loss_giou_dn_4: 0.4909  loss_ce_5: 2.398  loss_mask_5: 0.1421  loss_dice_5: 1.955  loss_bbox_5: 0.4413  loss_giou_5: 1.394  loss_ce_dn_5: 1.304  loss_mask_dn_5: 0.08264  loss_dice_dn_5: 1.489  loss_bbox_dn_5: 0.118  loss_giou_dn_5: 0.4825  loss_ce_6: 2.453  loss_mask_6: 0.1423  loss_dice_6: 1.796  loss_bbox_6: 0.4417  loss_giou_6: 1.388  loss_ce_dn_6: 1.311  loss_mask_dn_6: 0.08593  loss_dice_dn_6: 1.518  loss_bbox_dn_6: 0.1174  loss_giou_dn_6: 0.4852  loss_ce_7: 2.346  loss_mask_7: 0.135  loss_dice_7: 1.736  loss_bbox_7: 0.479  loss_giou_7: 1.464  loss_ce_dn_7: 1.356  loss_mask_dn_7: 0.08719  loss_dice_dn_7: 1.471  loss_bbox_dn_7: 0.1178  loss_giou_dn_7: 0.4783  loss_ce_8: 2.284  loss_mask_8: 0.1189  loss_dice_8: 1.883  loss_bbox_8: 0.5356  loss_giou_8: 1.376  loss_ce_dn_8: 1.386  loss_mask_dn_8: 0.08636  loss_dice_dn_8: 1.542  loss_bbox_dn_8: 0.1176  loss_giou_dn_8: 0.4964  loss_ce_interm: 7.304  loss_mask_interm: 0.08798  loss_dice_interm: 1.883  loss_bbox_interm: 0.6603  loss_giou_interm: 1.422  time: 2.8784  data_time: 0.7860  lr: 0.0001  max_mem: 6614M\n",
            "[05/20 16:15:19 d2.utils.events]:  eta: 3:46:41  iter: 119  total_loss: 87.71  loss_ce: 2.261  loss_mask: 0.08276  loss_dice: 0.8137  loss_bbox: 0.1639  loss_giou: 0.6998  loss_ce_dn: 1.192  loss_mask_dn: 0.07349  loss_dice_dn: 0.8892  loss_bbox_dn: 0.08273  loss_giou_dn: 0.4754  loss_ce_0: 3.416  loss_mask_0: 0.05859  loss_dice_0: 1.094  loss_bbox_0: 0.2582  loss_giou_0: 0.6859  loss_ce_dn_0: 4.279  loss_mask_dn_0: 0.2085  loss_dice_dn_0: 3.392  loss_bbox_dn_0: 0.211  loss_giou_dn_0: 0.8556  loss_ce_1: 2.608  loss_mask_1: 0.07754  loss_dice_1: 1.056  loss_bbox_1: 0.222  loss_giou_1: 0.6819  loss_ce_dn_1: 1.118  loss_mask_dn_1: 0.0635  loss_dice_dn_1: 0.8782  loss_bbox_dn_1: 0.1202  loss_giou_dn_1: 0.5998  loss_ce_2: 2.333  loss_mask_2: 0.08162  loss_dice_2: 0.9525  loss_bbox_2: 0.2441  loss_giou_2: 0.657  loss_ce_dn_2: 1.054  loss_mask_dn_2: 0.06223  loss_dice_dn_2: 0.9352  loss_bbox_dn_2: 0.1037  loss_giou_dn_2: 0.5246  loss_ce_3: 2.203  loss_mask_3: 0.07343  loss_dice_3: 1.111  loss_bbox_3: 0.2307  loss_giou_3: 0.7144  loss_ce_dn_3: 0.9854  loss_mask_dn_3: 0.06123  loss_dice_dn_3: 0.8474  loss_bbox_dn_3: 0.09377  loss_giou_dn_3: 0.4827  loss_ce_4: 2.197  loss_mask_4: 0.06509  loss_dice_4: 1.078  loss_bbox_4: 0.2233  loss_giou_4: 0.7145  loss_ce_dn_4: 1.089  loss_mask_dn_4: 0.05533  loss_dice_dn_4: 0.8526  loss_bbox_dn_4: 0.08793  loss_giou_dn_4: 0.4656  loss_ce_5: 2.161  loss_mask_5: 0.07207  loss_dice_5: 1.136  loss_bbox_5: 0.226  loss_giou_5: 0.7078  loss_ce_dn_5: 1.1  loss_mask_dn_5: 0.06344  loss_dice_dn_5: 0.8409  loss_bbox_dn_5: 0.0827  loss_giou_dn_5: 0.4668  loss_ce_6: 2.114  loss_mask_6: 0.07956  loss_dice_6: 1.08  loss_bbox_6: 0.2411  loss_giou_6: 0.7104  loss_ce_dn_6: 1.137  loss_mask_dn_6: 0.05749  loss_dice_dn_6: 0.8793  loss_bbox_dn_6: 0.08216  loss_giou_dn_6: 0.4682  loss_ce_7: 2.159  loss_mask_7: 0.07628  loss_dice_7: 1.009  loss_bbox_7: 0.1806  loss_giou_7: 0.6563  loss_ce_dn_7: 1.191  loss_mask_dn_7: 0.07695  loss_dice_dn_7: 0.8587  loss_bbox_dn_7: 0.08073  loss_giou_dn_7: 0.4655  loss_ce_8: 2.238  loss_mask_8: 0.08414  loss_dice_8: 1.163  loss_bbox_8: 0.1694  loss_giou_8: 0.7008  loss_ce_dn_8: 1.2  loss_mask_dn_8: 0.0791  loss_dice_dn_8: 0.9044  loss_bbox_dn_8: 0.08118  loss_giou_dn_8: 0.4697  loss_ce_interm: 3.464  loss_mask_interm: 0.05907  loss_dice_interm: 1.199  loss_bbox_interm: 0.2575  loss_giou_interm: 0.6968  time: 2.9672  data_time: 1.7385  lr: 0.0001  max_mem: 6614M\n",
            "[05/20 16:16:10 d2.utils.events]:  eta: 3:46:40  iter: 139  total_loss: 80.66  loss_ce: 2.049  loss_mask: 0.06426  loss_dice: 1.138  loss_bbox: 0.1384  loss_giou: 0.5633  loss_ce_dn: 0.9447  loss_mask_dn: 0.06013  loss_dice_dn: 1.102  loss_bbox_dn: 0.08976  loss_giou_dn: 0.3586  loss_ce_0: 3.513  loss_mask_0: 0.05744  loss_dice_0: 1.182  loss_bbox_0: 0.1527  loss_giou_0: 0.6485  loss_ce_dn_0: 4.035  loss_mask_dn_0: 0.2854  loss_dice_dn_0: 3.163  loss_bbox_dn_0: 0.2375  loss_giou_dn_0: 0.8492  loss_ce_1: 2.33  loss_mask_1: 0.06711  loss_dice_1: 1.308  loss_bbox_1: 0.1614  loss_giou_1: 0.7007  loss_ce_dn_1: 0.8937  loss_mask_dn_1: 0.05566  loss_dice_dn_1: 1.217  loss_bbox_dn_1: 0.1339  loss_giou_dn_1: 0.5567  loss_ce_2: 1.983  loss_mask_2: 0.06583  loss_dice_2: 1.388  loss_bbox_2: 0.1492  loss_giou_2: 0.6248  loss_ce_dn_2: 0.8275  loss_mask_dn_2: 0.05908  loss_dice_dn_2: 1.131  loss_bbox_dn_2: 0.1112  loss_giou_dn_2: 0.439  loss_ce_3: 2.075  loss_mask_3: 0.06234  loss_dice_3: 1.273  loss_bbox_3: 0.1282  loss_giou_3: 0.6063  loss_ce_dn_3: 0.8731  loss_mask_dn_3: 0.06173  loss_dice_dn_3: 1.024  loss_bbox_dn_3: 0.08763  loss_giou_dn_3: 0.3896  loss_ce_4: 1.972  loss_mask_4: 0.05348  loss_dice_4: 1.171  loss_bbox_4: 0.1511  loss_giou_4: 0.639  loss_ce_dn_4: 0.8364  loss_mask_dn_4: 0.06516  loss_dice_dn_4: 0.9518  loss_bbox_dn_4: 0.09175  loss_giou_dn_4: 0.3771  loss_ce_5: 1.985  loss_mask_5: 0.06375  loss_dice_5: 1.217  loss_bbox_5: 0.133  loss_giou_5: 0.5814  loss_ce_dn_5: 0.8824  loss_mask_dn_5: 0.05993  loss_dice_dn_5: 0.9626  loss_bbox_dn_5: 0.08341  loss_giou_dn_5: 0.3651  loss_ce_6: 2.022  loss_mask_6: 0.06661  loss_dice_6: 1.108  loss_bbox_6: 0.1321  loss_giou_6: 0.5364  loss_ce_dn_6: 0.8826  loss_mask_dn_6: 0.06182  loss_dice_dn_6: 1.038  loss_bbox_dn_6: 0.09055  loss_giou_dn_6: 0.369  loss_ce_7: 2.029  loss_mask_7: 0.05941  loss_dice_7: 1.325  loss_bbox_7: 0.1423  loss_giou_7: 0.5684  loss_ce_dn_7: 0.9177  loss_mask_dn_7: 0.05669  loss_dice_dn_7: 0.9768  loss_bbox_dn_7: 0.0888  loss_giou_dn_7: 0.3715  loss_ce_8: 2.015  loss_mask_8: 0.06679  loss_dice_8: 1.253  loss_bbox_8: 0.1264  loss_giou_8: 0.5087  loss_ce_dn_8: 0.9035  loss_mask_dn_8: 0.05775  loss_dice_dn_8: 1.075  loss_bbox_dn_8: 0.08809  loss_giou_dn_8: 0.3638  loss_ce_interm: 3.437  loss_mask_interm: 0.04939  loss_dice_interm: 1.251  loss_bbox_interm: 0.163  loss_giou_interm: 0.6934  time: 2.9073  data_time: 0.9370  lr: 0.0001  max_mem: 6614M\n",
            "[05/20 16:16:57 d2.utils.events]:  eta: 3:44:01  iter: 159  total_loss: 75.4  loss_ce: 1.973  loss_mask: 0.06122  loss_dice: 0.628  loss_bbox: 0.135  loss_giou: 0.4365  loss_ce_dn: 1.079  loss_mask_dn: 0.05788  loss_dice_dn: 0.6383  loss_bbox_dn: 0.07439  loss_giou_dn: 0.3121  loss_ce_0: 2.725  loss_mask_0: 0.07317  loss_dice_0: 0.7714  loss_bbox_0: 0.1354  loss_giou_0: 0.4363  loss_ce_dn_0: 3.557  loss_mask_dn_0: 0.2684  loss_dice_dn_0: 2.559  loss_bbox_dn_0: 0.3096  loss_giou_dn_0: 0.8559  loss_ce_1: 2.2  loss_mask_1: 0.07628  loss_dice_1: 0.8079  loss_bbox_1: 0.1569  loss_giou_1: 0.3833  loss_ce_dn_1: 0.7581  loss_mask_dn_1: 0.08644  loss_dice_dn_1: 0.8407  loss_bbox_dn_1: 0.1366  loss_giou_dn_1: 0.4691  loss_ce_2: 2.212  loss_mask_2: 0.04751  loss_dice_2: 0.6573  loss_bbox_2: 0.1167  loss_giou_2: 0.337  loss_ce_dn_2: 0.7428  loss_mask_dn_2: 0.06502  loss_dice_dn_2: 0.6414  loss_bbox_dn_2: 0.09754  loss_giou_dn_2: 0.3934  loss_ce_3: 2.215  loss_mask_3: 0.0728  loss_dice_3: 0.9472  loss_bbox_3: 0.1156  loss_giou_3: 0.3755  loss_ce_dn_3: 0.8367  loss_mask_dn_3: 0.0684  loss_dice_dn_3: 0.6459  loss_bbox_dn_3: 0.07596  loss_giou_dn_3: 0.3327  loss_ce_4: 2.039  loss_mask_4: 0.06918  loss_dice_4: 0.883  loss_bbox_4: 0.1212  loss_giou_4: 0.5067  loss_ce_dn_4: 0.881  loss_mask_dn_4: 0.05879  loss_dice_dn_4: 0.6368  loss_bbox_dn_4: 0.08047  loss_giou_dn_4: 0.3346  loss_ce_5: 1.981  loss_mask_5: 0.05872  loss_dice_5: 0.6829  loss_bbox_5: 0.1104  loss_giou_5: 0.402  loss_ce_dn_5: 0.9763  loss_mask_dn_5: 0.05153  loss_dice_dn_5: 0.6488  loss_bbox_dn_5: 0.08137  loss_giou_dn_5: 0.3178  loss_ce_6: 2.003  loss_mask_6: 0.06413  loss_dice_6: 0.8603  loss_bbox_6: 0.1135  loss_giou_6: 0.4071  loss_ce_dn_6: 1.059  loss_mask_dn_6: 0.05921  loss_dice_dn_6: 0.6626  loss_bbox_dn_6: 0.07908  loss_giou_dn_6: 0.3159  loss_ce_7: 1.932  loss_mask_7: 0.05269  loss_dice_7: 0.8904  loss_bbox_7: 0.1139  loss_giou_7: 0.4122  loss_ce_dn_7: 1.073  loss_mask_dn_7: 0.04981  loss_dice_dn_7: 0.6501  loss_bbox_dn_7: 0.07765  loss_giou_dn_7: 0.3129  loss_ce_8: 1.909  loss_mask_8: 0.04756  loss_dice_8: 0.6357  loss_bbox_8: 0.1151  loss_giou_8: 0.4193  loss_ce_dn_8: 1.076  loss_mask_dn_8: 0.05111  loss_dice_dn_8: 0.6456  loss_bbox_dn_8: 0.0741  loss_giou_dn_8: 0.3127  loss_ce_interm: 2.645  loss_mask_interm: 0.07572  loss_dice_interm: 0.719  loss_bbox_interm: 0.1217  loss_giou_interm: 0.4944  time: 2.8359  data_time: 0.6973  lr: 0.0001  max_mem: 6614M\n",
            "[05/20 16:17:48 d2.utils.events]:  eta: 3:43:13  iter: 179  total_loss: 76.23  loss_ce: 2.186  loss_mask: 0.08286  loss_dice: 1.13  loss_bbox: 0.1436  loss_giou: 0.695  loss_ce_dn: 0.7917  loss_mask_dn: 0.07516  loss_dice_dn: 1.044  loss_bbox_dn: 0.09443  loss_giou_dn: 0.4533  loss_ce_0: 2.633  loss_mask_0: 0.06569  loss_dice_0: 1.247  loss_bbox_0: 0.1584  loss_giou_0: 0.8319  loss_ce_dn_0: 3.141  loss_mask_dn_0: 0.3752  loss_dice_dn_0: 3.683  loss_bbox_dn_0: 0.2611  loss_giou_dn_0: 0.8554  loss_ce_1: 2.331  loss_mask_1: 0.1015  loss_dice_1: 1.108  loss_bbox_1: 0.1582  loss_giou_1: 0.7571  loss_ce_dn_1: 0.6399  loss_mask_dn_1: 0.1037  loss_dice_dn_1: 1.215  loss_bbox_dn_1: 0.1379  loss_giou_dn_1: 0.5771  loss_ce_2: 2.28  loss_mask_2: 0.1031  loss_dice_2: 1.217  loss_bbox_2: 0.1686  loss_giou_2: 0.8399  loss_ce_dn_2: 0.6369  loss_mask_dn_2: 0.08655  loss_dice_dn_2: 1.079  loss_bbox_dn_2: 0.103  loss_giou_dn_2: 0.5246  loss_ce_3: 2.304  loss_mask_3: 0.08461  loss_dice_3: 1.058  loss_bbox_3: 0.1443  loss_giou_3: 0.7802  loss_ce_dn_3: 0.6068  loss_mask_dn_3: 0.0886  loss_dice_dn_3: 0.9891  loss_bbox_dn_3: 0.09905  loss_giou_dn_3: 0.4804  loss_ce_4: 2.281  loss_mask_4: 0.07906  loss_dice_4: 1.061  loss_bbox_4: 0.1325  loss_giou_4: 0.7606  loss_ce_dn_4: 0.6019  loss_mask_dn_4: 0.08239  loss_dice_dn_4: 0.9828  loss_bbox_dn_4: 0.09899  loss_giou_dn_4: 0.4725  loss_ce_5: 2.19  loss_mask_5: 0.08633  loss_dice_5: 1.219  loss_bbox_5: 0.1355  loss_giou_5: 0.7588  loss_ce_dn_5: 0.6404  loss_mask_dn_5: 0.08044  loss_dice_dn_5: 1.008  loss_bbox_dn_5: 0.09634  loss_giou_dn_5: 0.4609  loss_ce_6: 2.312  loss_mask_6: 0.075  loss_dice_6: 1.192  loss_bbox_6: 0.1469  loss_giou_6: 0.7228  loss_ce_dn_6: 0.7003  loss_mask_dn_6: 0.07817  loss_dice_dn_6: 0.9972  loss_bbox_dn_6: 0.09531  loss_giou_dn_6: 0.4549  loss_ce_7: 2.275  loss_mask_7: 0.07666  loss_dice_7: 1.26  loss_bbox_7: 0.143  loss_giou_7: 0.7786  loss_ce_dn_7: 0.7245  loss_mask_dn_7: 0.07617  loss_dice_dn_7: 0.9895  loss_bbox_dn_7: 0.09517  loss_giou_dn_7: 0.4544  loss_ce_8: 2.197  loss_mask_8: 0.07831  loss_dice_8: 1.171  loss_bbox_8: 0.1431  loss_giou_8: 0.6798  loss_ce_dn_8: 0.7642  loss_mask_dn_8: 0.07509  loss_dice_dn_8: 0.9936  loss_bbox_dn_8: 0.09411  loss_giou_dn_8: 0.4545  loss_ce_interm: 2.579  loss_mask_interm: 0.09476  loss_dice_interm: 1.065  loss_bbox_interm: 0.1955  loss_giou_interm: 0.7466  time: 2.8038  data_time: 0.9458  lr: 0.0001  max_mem: 6614M\n",
            "[05/20 16:18:34 d2.utils.events]:  eta: 3:39:03  iter: 199  total_loss: 62.5  loss_ce: 1.71  loss_mask: 0.06701  loss_dice: 0.4984  loss_bbox: 0.138  loss_giou: 0.4608  loss_ce_dn: 0.899  loss_mask_dn: 0.05165  loss_dice_dn: 0.4626  loss_bbox_dn: 0.07809  loss_giou_dn: 0.3166  loss_ce_0: 2.439  loss_mask_0: 0.06191  loss_dice_0: 0.5301  loss_bbox_0: 0.1122  loss_giou_0: 0.3989  loss_ce_dn_0: 2.832  loss_mask_dn_0: 0.2601  loss_dice_dn_0: 3.036  loss_bbox_dn_0: 0.2957  loss_giou_dn_0: 0.8611  loss_ce_1: 2.144  loss_mask_1: 0.07403  loss_dice_1: 0.6051  loss_bbox_1: 0.1295  loss_giou_1: 0.3885  loss_ce_dn_1: 0.7126  loss_mask_dn_1: 0.07091  loss_dice_dn_1: 0.6128  loss_bbox_dn_1: 0.12  loss_giou_dn_1: 0.4927  loss_ce_2: 2.068  loss_mask_2: 0.07264  loss_dice_2: 0.5812  loss_bbox_2: 0.1415  loss_giou_2: 0.4482  loss_ce_dn_2: 0.7098  loss_mask_dn_2: 0.06002  loss_dice_dn_2: 0.4947  loss_bbox_dn_2: 0.09626  loss_giou_dn_2: 0.368  loss_ce_3: 1.887  loss_mask_3: 0.06426  loss_dice_3: 0.6742  loss_bbox_3: 0.1227  loss_giou_3: 0.4313  loss_ce_dn_3: 0.7225  loss_mask_dn_3: 0.05493  loss_dice_dn_3: 0.5179  loss_bbox_dn_3: 0.08242  loss_giou_dn_3: 0.3298  loss_ce_4: 1.818  loss_mask_4: 0.06865  loss_dice_4: 0.5638  loss_bbox_4: 0.1341  loss_giou_4: 0.4379  loss_ce_dn_4: 0.7435  loss_mask_dn_4: 0.05473  loss_dice_dn_4: 0.4962  loss_bbox_dn_4: 0.08133  loss_giou_dn_4: 0.32  loss_ce_5: 1.841  loss_mask_5: 0.07474  loss_dice_5: 0.5273  loss_bbox_5: 0.1404  loss_giou_5: 0.4838  loss_ce_dn_5: 0.8211  loss_mask_dn_5: 0.05054  loss_dice_dn_5: 0.4702  loss_bbox_dn_5: 0.07366  loss_giou_dn_5: 0.3138  loss_ce_6: 1.864  loss_mask_6: 0.06514  loss_dice_6: 0.4921  loss_bbox_6: 0.1374  loss_giou_6: 0.4396  loss_ce_dn_6: 0.8694  loss_mask_dn_6: 0.05068  loss_dice_dn_6: 0.5044  loss_bbox_dn_6: 0.07656  loss_giou_dn_6: 0.3151  loss_ce_7: 1.756  loss_mask_7: 0.06648  loss_dice_7: 0.5301  loss_bbox_7: 0.1422  loss_giou_7: 0.4684  loss_ce_dn_7: 0.88  loss_mask_dn_7: 0.05019  loss_dice_dn_7: 0.4692  loss_bbox_dn_7: 0.07587  loss_giou_dn_7: 0.3177  loss_ce_8: 1.779  loss_mask_8: 0.07159  loss_dice_8: 0.7119  loss_bbox_8: 0.1397  loss_giou_8: 0.4643  loss_ce_dn_8: 0.8885  loss_mask_dn_8: 0.05214  loss_dice_dn_8: 0.4772  loss_bbox_dn_8: 0.07621  loss_giou_dn_8: 0.3155  loss_ce_interm: 2.45  loss_mask_interm: 0.06238  loss_dice_interm: 0.4982  loss_bbox_interm: 0.1784  loss_giou_interm: 0.4947  time: 2.7532  data_time: 0.7063  lr: 0.0001  max_mem: 6614M\n",
            "[05/20 16:19:22 d2.utils.events]:  eta: 3:38:16  iter: 219  total_loss: 71.86  loss_ce: 1.968  loss_mask: 0.06699  loss_dice: 0.8262  loss_bbox: 0.1511  loss_giou: 0.5835  loss_ce_dn: 0.6796  loss_mask_dn: 0.05551  loss_dice_dn: 0.7816  loss_bbox_dn: 0.07845  loss_giou_dn: 0.3576  loss_ce_0: 2.19  loss_mask_0: 0.07232  loss_dice_0: 0.7586  loss_bbox_0: 0.1469  loss_giou_0: 0.6368  loss_ce_dn_0: 3.079  loss_mask_dn_0: 0.1865  loss_dice_dn_0: 3.081  loss_bbox_dn_0: 0.2882  loss_giou_dn_0: 0.8569  loss_ce_1: 2.097  loss_mask_1: 0.086  loss_dice_1: 0.9987  loss_bbox_1: 0.1569  loss_giou_1: 0.6243  loss_ce_dn_1: 0.5317  loss_mask_dn_1: 0.0499  loss_dice_dn_1: 0.9964  loss_bbox_dn_1: 0.1593  loss_giou_dn_1: 0.5454  loss_ce_2: 2.101  loss_mask_2: 0.092  loss_dice_2: 0.9059  loss_bbox_2: 0.138  loss_giou_2: 0.651  loss_ce_dn_2: 0.5305  loss_mask_dn_2: 0.07181  loss_dice_dn_2: 0.8022  loss_bbox_dn_2: 0.1086  loss_giou_dn_2: 0.4452  loss_ce_3: 2.073  loss_mask_3: 0.07364  loss_dice_3: 0.9381  loss_bbox_3: 0.1467  loss_giou_3: 0.6099  loss_ce_dn_3: 0.4846  loss_mask_dn_3: 0.06863  loss_dice_dn_3: 0.7983  loss_bbox_dn_3: 0.09234  loss_giou_dn_3: 0.3935  loss_ce_4: 1.968  loss_mask_4: 0.07422  loss_dice_4: 0.9451  loss_bbox_4: 0.1427  loss_giou_4: 0.5967  loss_ce_dn_4: 0.4822  loss_mask_dn_4: 0.06751  loss_dice_dn_4: 0.757  loss_bbox_dn_4: 0.08041  loss_giou_dn_4: 0.3788  loss_ce_5: 1.981  loss_mask_5: 0.07855  loss_dice_5: 0.8329  loss_bbox_5: 0.1535  loss_giou_5: 0.6056  loss_ce_dn_5: 0.528  loss_mask_dn_5: 0.06189  loss_dice_dn_5: 0.7334  loss_bbox_dn_5: 0.07713  loss_giou_dn_5: 0.36  loss_ce_6: 1.946  loss_mask_6: 0.05086  loss_dice_6: 0.8618  loss_bbox_6: 0.1858  loss_giou_6: 0.5927  loss_ce_dn_6: 0.5385  loss_mask_dn_6: 0.05735  loss_dice_dn_6: 0.7488  loss_bbox_dn_6: 0.07659  loss_giou_dn_6: 0.3629  loss_ce_7: 1.964  loss_mask_7: 0.07014  loss_dice_7: 0.7673  loss_bbox_7: 0.1743  loss_giou_7: 0.6022  loss_ce_dn_7: 0.6286  loss_mask_dn_7: 0.0567  loss_dice_dn_7: 0.7725  loss_bbox_dn_7: 0.0759  loss_giou_dn_7: 0.3501  loss_ce_8: 2.033  loss_mask_8: 0.05534  loss_dice_8: 0.8298  loss_bbox_8: 0.1633  loss_giou_8: 0.6006  loss_ce_dn_8: 0.6498  loss_mask_dn_8: 0.05513  loss_dice_dn_8: 0.7954  loss_bbox_dn_8: 0.07752  loss_giou_dn_8: 0.3579  loss_ce_interm: 2.303  loss_mask_interm: 0.1139  loss_dice_interm: 0.8302  loss_bbox_interm: 0.1724  loss_giou_interm: 0.6291  time: 2.7201  data_time: 0.7853  lr: 0.0001  max_mem: 6614M\n",
            "[05/20 16:20:12 d2.utils.events]:  eta: 3:35:19  iter: 239  total_loss: 69.83  loss_ce: 1.859  loss_mask: 0.07041  loss_dice: 1.008  loss_bbox: 0.1335  loss_giou: 0.5066  loss_ce_dn: 0.5815  loss_mask_dn: 0.04991  loss_dice_dn: 0.8795  loss_bbox_dn: 0.08666  loss_giou_dn: 0.4248  loss_ce_0: 2.103  loss_mask_0: 0.06791  loss_dice_0: 1.04  loss_bbox_0: 0.2218  loss_giou_0: 0.5991  loss_ce_dn_0: 2.902  loss_mask_dn_0: 0.3813  loss_dice_dn_0: 3.314  loss_bbox_dn_0: 0.2214  loss_giou_dn_0: 0.8476  loss_ce_1: 2.021  loss_mask_1: 0.07028  loss_dice_1: 0.9982  loss_bbox_1: 0.1938  loss_giou_1: 0.5756  loss_ce_dn_1: 0.4804  loss_mask_dn_1: 0.07001  loss_dice_dn_1: 1.161  loss_bbox_dn_1: 0.1288  loss_giou_dn_1: 0.5468  loss_ce_2: 1.989  loss_mask_2: 0.06252  loss_dice_2: 0.9839  loss_bbox_2: 0.1787  loss_giou_2: 0.5691  loss_ce_dn_2: 0.4644  loss_mask_dn_2: 0.05487  loss_dice_dn_2: 0.9806  loss_bbox_dn_2: 0.1045  loss_giou_dn_2: 0.47  loss_ce_3: 1.969  loss_mask_3: 0.0654  loss_dice_3: 1.041  loss_bbox_3: 0.1889  loss_giou_3: 0.5573  loss_ce_dn_3: 0.4997  loss_mask_dn_3: 0.05437  loss_dice_dn_3: 0.907  loss_bbox_dn_3: 0.09496  loss_giou_dn_3: 0.441  loss_ce_4: 1.913  loss_mask_4: 0.05964  loss_dice_4: 0.9992  loss_bbox_4: 0.1807  loss_giou_4: 0.6005  loss_ce_dn_4: 0.4338  loss_mask_dn_4: 0.0529  loss_dice_dn_4: 0.8837  loss_bbox_dn_4: 0.08855  loss_giou_dn_4: 0.428  loss_ce_5: 1.957  loss_mask_5: 0.06167  loss_dice_5: 0.8471  loss_bbox_5: 0.1512  loss_giou_5: 0.6229  loss_ce_dn_5: 0.4661  loss_mask_dn_5: 0.04948  loss_dice_dn_5: 0.9206  loss_bbox_dn_5: 0.08649  loss_giou_dn_5: 0.4277  loss_ce_6: 1.97  loss_mask_6: 0.06434  loss_dice_6: 1.013  loss_bbox_6: 0.1572  loss_giou_6: 0.5148  loss_ce_dn_6: 0.4924  loss_mask_dn_6: 0.05131  loss_dice_dn_6: 0.8976  loss_bbox_dn_6: 0.08619  loss_giou_dn_6: 0.427  loss_ce_7: 1.927  loss_mask_7: 0.06516  loss_dice_7: 1.051  loss_bbox_7: 0.1538  loss_giou_7: 0.5545  loss_ce_dn_7: 0.5387  loss_mask_dn_7: 0.05037  loss_dice_dn_7: 0.8598  loss_bbox_dn_7: 0.0856  loss_giou_dn_7: 0.426  loss_ce_8: 1.912  loss_mask_8: 0.07234  loss_dice_8: 0.9868  loss_bbox_8: 0.131  loss_giou_8: 0.511  loss_ce_dn_8: 0.5583  loss_mask_dn_8: 0.05115  loss_dice_dn_8: 0.8777  loss_bbox_dn_8: 0.08664  loss_giou_dn_8: 0.4269  loss_ce_interm: 2.075  loss_mask_interm: 0.07022  loss_dice_interm: 0.9446  loss_bbox_interm: 0.1415  loss_giou_interm: 0.6197  time: 2.7005  data_time: 0.8607  lr: 0.0001  max_mem: 6614M\n",
            "[05/20 16:21:08 d2.utils.events]:  eta: 3:35:03  iter: 259  total_loss: 69.93  loss_ce: 1.644  loss_mask: 0.0415  loss_dice: 0.5477  loss_bbox: 0.0883  loss_giou: 0.3466  loss_ce_dn: 0.5171  loss_mask_dn: 0.04767  loss_dice_dn: 0.7952  loss_bbox_dn: 0.04508  loss_giou_dn: 0.344  loss_ce_0: 1.988  loss_mask_0: 0.04873  loss_dice_0: 0.5983  loss_bbox_0: 0.1043  loss_giou_0: 0.3789  loss_ce_dn_0: 2.545  loss_mask_dn_0: 0.143  loss_dice_dn_0: 2.632  loss_bbox_dn_0: 0.2924  loss_giou_dn_0: 0.858  loss_ce_1: 1.817  loss_mask_1: 0.04743  loss_dice_1: 0.5319  loss_bbox_1: 0.108  loss_giou_1: 0.3215  loss_ce_dn_1: 0.4726  loss_mask_dn_1: 0.05102  loss_dice_dn_1: 0.7884  loss_bbox_dn_1: 0.09673  loss_giou_dn_1: 0.4841  loss_ce_2: 1.81  loss_mask_2: 0.05463  loss_dice_2: 0.6749  loss_bbox_2: 0.1081  loss_giou_2: 0.3919  loss_ce_dn_2: 0.5284  loss_mask_dn_2: 0.05127  loss_dice_dn_2: 0.6722  loss_bbox_dn_2: 0.06556  loss_giou_dn_2: 0.4096  loss_ce_3: 1.809  loss_mask_3: 0.03671  loss_dice_3: 0.588  loss_bbox_3: 0.1015  loss_giou_3: 0.385  loss_ce_dn_3: 0.4566  loss_mask_dn_3: 0.04869  loss_dice_dn_3: 0.6847  loss_bbox_dn_3: 0.05472  loss_giou_dn_3: 0.3726  loss_ce_4: 1.762  loss_mask_4: 0.04057  loss_dice_4: 0.641  loss_bbox_4: 0.1031  loss_giou_4: 0.3493  loss_ce_dn_4: 0.4408  loss_mask_dn_4: 0.04742  loss_dice_dn_4: 0.733  loss_bbox_dn_4: 0.04923  loss_giou_dn_4: 0.3546  loss_ce_5: 1.746  loss_mask_5: 0.04064  loss_dice_5: 0.5635  loss_bbox_5: 0.111  loss_giou_5: 0.3437  loss_ce_dn_5: 0.4622  loss_mask_dn_5: 0.04682  loss_dice_dn_5: 0.6907  loss_bbox_dn_5: 0.04572  loss_giou_dn_5: 0.3542  loss_ce_6: 1.792  loss_mask_6: 0.04203  loss_dice_6: 0.563  loss_bbox_6: 0.1131  loss_giou_6: 0.3503  loss_ce_dn_6: 0.4918  loss_mask_dn_6: 0.04439  loss_dice_dn_6: 0.7846  loss_bbox_dn_6: 0.04626  loss_giou_dn_6: 0.347  loss_ce_7: 1.696  loss_mask_7: 0.04019  loss_dice_7: 0.5293  loss_bbox_7: 0.1069  loss_giou_7: 0.3453  loss_ce_dn_7: 0.49  loss_mask_dn_7: 0.04418  loss_dice_dn_7: 0.7666  loss_bbox_dn_7: 0.04405  loss_giou_dn_7: 0.3456  loss_ce_8: 1.678  loss_mask_8: 0.0352  loss_dice_8: 0.6906  loss_bbox_8: 0.1096  loss_giou_8: 0.3365  loss_ce_dn_8: 0.4938  loss_mask_dn_8: 0.04816  loss_dice_dn_8: 0.7407  loss_bbox_dn_8: 0.04459  loss_giou_dn_8: 0.3453  loss_ce_interm: 2.056  loss_mask_interm: 0.05565  loss_dice_interm: 0.6712  loss_bbox_interm: 0.1415  loss_giou_interm: 0.5165  time: 2.7064  data_time: 1.1408  lr: 0.0001  max_mem: 6614M\n",
            "[05/20 16:21:58 d2.utils.events]:  eta: 3:34:16  iter: 279  total_loss: 56.08  loss_ce: 1.719  loss_mask: 0.03683  loss_dice: 0.6416  loss_bbox: 0.06539  loss_giou: 0.3854  loss_ce_dn: 0.5729  loss_mask_dn: 0.04701  loss_dice_dn: 0.5824  loss_bbox_dn: 0.0489  loss_giou_dn: 0.367  loss_ce_0: 1.906  loss_mask_0: 0.03463  loss_dice_0: 0.6002  loss_bbox_0: 0.08303  loss_giou_0: 0.4351  loss_ce_dn_0: 2.551  loss_mask_dn_0: 0.4057  loss_dice_dn_0: 2.999  loss_bbox_dn_0: 0.2454  loss_giou_dn_0: 0.8573  loss_ce_1: 1.899  loss_mask_1: 0.04855  loss_dice_1: 0.5441  loss_bbox_1: 0.09141  loss_giou_1: 0.4528  loss_ce_dn_1: 0.5377  loss_mask_dn_1: 0.04047  loss_dice_dn_1: 0.6091  loss_bbox_dn_1: 0.08455  loss_giou_dn_1: 0.4701  loss_ce_2: 1.848  loss_mask_2: 0.04063  loss_dice_2: 0.519  loss_bbox_2: 0.0684  loss_giou_2: 0.4049  loss_ce_dn_2: 0.5384  loss_mask_dn_2: 0.04056  loss_dice_dn_2: 0.5712  loss_bbox_dn_2: 0.06648  loss_giou_dn_2: 0.3902  loss_ce_3: 1.736  loss_mask_3: 0.0426  loss_dice_3: 0.5507  loss_bbox_3: 0.06546  loss_giou_3: 0.402  loss_ce_dn_3: 0.5348  loss_mask_dn_3: 0.0474  loss_dice_dn_3: 0.595  loss_bbox_dn_3: 0.05432  loss_giou_dn_3: 0.372  loss_ce_4: 1.808  loss_mask_4: 0.03624  loss_dice_4: 0.5904  loss_bbox_4: 0.0672  loss_giou_4: 0.4029  loss_ce_dn_4: 0.4766  loss_mask_dn_4: 0.04745  loss_dice_dn_4: 0.5537  loss_bbox_dn_4: 0.05172  loss_giou_dn_4: 0.3728  loss_ce_5: 1.69  loss_mask_5: 0.03982  loss_dice_5: 0.5205  loss_bbox_5: 0.06588  loss_giou_5: 0.4096  loss_ce_dn_5: 0.4848  loss_mask_dn_5: 0.04709  loss_dice_dn_5: 0.5374  loss_bbox_dn_5: 0.04902  loss_giou_dn_5: 0.3683  loss_ce_6: 1.735  loss_mask_6: 0.03373  loss_dice_6: 0.5309  loss_bbox_6: 0.08552  loss_giou_6: 0.409  loss_ce_dn_6: 0.5353  loss_mask_dn_6: 0.0453  loss_dice_dn_6: 0.5598  loss_bbox_dn_6: 0.04852  loss_giou_dn_6: 0.3676  loss_ce_7: 1.706  loss_mask_7: 0.03566  loss_dice_7: 0.5944  loss_bbox_7: 0.06653  loss_giou_7: 0.3928  loss_ce_dn_7: 0.5546  loss_mask_dn_7: 0.04533  loss_dice_dn_7: 0.5857  loss_bbox_dn_7: 0.04882  loss_giou_dn_7: 0.3639  loss_ce_8: 1.654  loss_mask_8: 0.03505  loss_dice_8: 0.6609  loss_bbox_8: 0.06426  loss_giou_8: 0.4011  loss_ce_dn_8: 0.5625  loss_mask_dn_8: 0.04596  loss_dice_dn_8: 0.5624  loss_bbox_dn_8: 0.04814  loss_giou_dn_8: 0.3624  loss_ce_interm: 1.837  loss_mask_interm: 0.04475  loss_dice_interm: 0.5844  loss_bbox_interm: 0.1433  loss_giou_interm: 0.5519  time: 2.6923  data_time: 0.8688  lr: 0.0001  max_mem: 6614M\n",
            "[05/20 16:22:56 d2.utils.events]:  eta: 3:32:58  iter: 299  total_loss: 60.73  loss_ce: 1.872  loss_mask: 0.08728  loss_dice: 0.9023  loss_bbox: 0.1037  loss_giou: 0.4242  loss_ce_dn: 0.5609  loss_mask_dn: 0.06078  loss_dice_dn: 0.6896  loss_bbox_dn: 0.08326  loss_giou_dn: 0.331  loss_ce_0: 2.073  loss_mask_0: 0.0704  loss_dice_0: 0.8192  loss_bbox_0: 0.1364  loss_giou_0: 0.511  loss_ce_dn_0: 2.2  loss_mask_dn_0: 0.4309  loss_dice_dn_0: 2.873  loss_bbox_dn_0: 0.3242  loss_giou_dn_0: 0.8511  loss_ce_1: 1.779  loss_mask_1: 0.06749  loss_dice_1: 0.8914  loss_bbox_1: 0.142  loss_giou_1: 0.5465  loss_ce_dn_1: 0.4729  loss_mask_dn_1: 0.06088  loss_dice_dn_1: 0.7742  loss_bbox_dn_1: 0.1239  loss_giou_dn_1: 0.4936  loss_ce_2: 1.863  loss_mask_2: 0.09163  loss_dice_2: 0.8633  loss_bbox_2: 0.1443  loss_giou_2: 0.6024  loss_ce_dn_2: 0.4872  loss_mask_dn_2: 0.05643  loss_dice_dn_2: 0.7888  loss_bbox_dn_2: 0.1006  loss_giou_dn_2: 0.4031  loss_ce_3: 1.842  loss_mask_3: 0.09292  loss_dice_3: 0.9372  loss_bbox_3: 0.166  loss_giou_3: 0.5867  loss_ce_dn_3: 0.4877  loss_mask_dn_3: 0.06482  loss_dice_dn_3: 0.7579  loss_bbox_dn_3: 0.09317  loss_giou_dn_3: 0.3728  loss_ce_4: 2.094  loss_mask_4: 0.08901  loss_dice_4: 0.7833  loss_bbox_4: 0.09538  loss_giou_4: 0.5404  loss_ce_dn_4: 0.4753  loss_mask_dn_4: 0.06543  loss_dice_dn_4: 0.757  loss_bbox_dn_4: 0.08769  loss_giou_dn_4: 0.3525  loss_ce_5: 2.08  loss_mask_5: 0.08516  loss_dice_5: 0.6519  loss_bbox_5: 0.1153  loss_giou_5: 0.5538  loss_ce_dn_5: 0.4979  loss_mask_dn_5: 0.07224  loss_dice_dn_5: 0.7159  loss_bbox_dn_5: 0.08668  loss_giou_dn_5: 0.3293  loss_ce_6: 1.921  loss_mask_6: 0.09017  loss_dice_6: 0.862  loss_bbox_6: 0.1116  loss_giou_6: 0.447  loss_ce_dn_6: 0.5063  loss_mask_dn_6: 0.06411  loss_dice_dn_6: 0.6951  loss_bbox_dn_6: 0.08642  loss_giou_dn_6: 0.3291  loss_ce_7: 1.928  loss_mask_7: 0.08105  loss_dice_7: 0.8424  loss_bbox_7: 0.1259  loss_giou_7: 0.551  loss_ce_dn_7: 0.4967  loss_mask_dn_7: 0.06209  loss_dice_dn_7: 0.7  loss_bbox_dn_7: 0.08392  loss_giou_dn_7: 0.3282  loss_ce_8: 1.867  loss_mask_8: 0.09772  loss_dice_8: 0.7421  loss_bbox_8: 0.1031  loss_giou_8: 0.4294  loss_ce_dn_8: 0.5263  loss_mask_dn_8: 0.06214  loss_dice_dn_8: 0.7014  loss_bbox_dn_8: 0.08325  loss_giou_dn_8: 0.3302  loss_ce_interm: 2.079  loss_mask_interm: 0.06921  loss_dice_interm: 0.7647  loss_bbox_interm: 0.1584  loss_giou_interm: 0.6807  time: 2.7049  data_time: 1.2280  lr: 0.0001  max_mem: 6614M\n",
            "[05/20 16:23:45 d2.utils.events]:  eta: 3:30:54  iter: 319  total_loss: 68.53  loss_ce: 1.805  loss_mask: 0.03188  loss_dice: 0.8105  loss_bbox: 0.1261  loss_giou: 0.621  loss_ce_dn: 0.4517  loss_mask_dn: 0.03087  loss_dice_dn: 0.8903  loss_bbox_dn: 0.04693  loss_giou_dn: 0.4206  loss_ce_0: 1.81  loss_mask_0: 0.0333  loss_dice_0: 0.8497  loss_bbox_0: 0.1643  loss_giou_0: 0.7389  loss_ce_dn_0: 2.373  loss_mask_dn_0: 0.2457  loss_dice_dn_0: 3.663  loss_bbox_dn_0: 0.2344  loss_giou_dn_0: 0.8616  loss_ce_1: 1.89  loss_mask_1: 0.0339  loss_dice_1: 1.085  loss_bbox_1: 0.2084  loss_giou_1: 0.632  loss_ce_dn_1: 0.4423  loss_mask_dn_1: 0.03148  loss_dice_dn_1: 1.014  loss_bbox_dn_1: 0.08262  loss_giou_dn_1: 0.5126  loss_ce_2: 1.707  loss_mask_2: 0.03476  loss_dice_2: 0.8246  loss_bbox_2: 0.1734  loss_giou_2: 0.6754  loss_ce_dn_2: 0.4019  loss_mask_dn_2: 0.03127  loss_dice_dn_2: 0.9276  loss_bbox_dn_2: 0.0638  loss_giou_dn_2: 0.4492  loss_ce_3: 1.794  loss_mask_3: 0.03029  loss_dice_3: 0.775  loss_bbox_3: 0.1581  loss_giou_3: 0.6364  loss_ce_dn_3: 0.3983  loss_mask_dn_3: 0.0308  loss_dice_dn_3: 0.9062  loss_bbox_dn_3: 0.05  loss_giou_dn_3: 0.4237  loss_ce_4: 1.775  loss_mask_4: 0.04025  loss_dice_4: 0.9104  loss_bbox_4: 0.1485  loss_giou_4: 0.5446  loss_ce_dn_4: 0.399  loss_mask_dn_4: 0.03145  loss_dice_dn_4: 0.9161  loss_bbox_dn_4: 0.04797  loss_giou_dn_4: 0.423  loss_ce_5: 1.857  loss_mask_5: 0.03317  loss_dice_5: 0.8371  loss_bbox_5: 0.1445  loss_giou_5: 0.5074  loss_ce_dn_5: 0.3979  loss_mask_dn_5: 0.03123  loss_dice_dn_5: 0.9257  loss_bbox_dn_5: 0.04572  loss_giou_dn_5: 0.4067  loss_ce_6: 1.835  loss_mask_6: 0.03265  loss_dice_6: 0.8598  loss_bbox_6: 0.1274  loss_giou_6: 0.5223  loss_ce_dn_6: 0.3961  loss_mask_dn_6: 0.03058  loss_dice_dn_6: 0.9004  loss_bbox_dn_6: 0.0464  loss_giou_dn_6: 0.4131  loss_ce_7: 1.915  loss_mask_7: 0.03906  loss_dice_7: 0.7053  loss_bbox_7: 0.1394  loss_giou_7: 0.5899  loss_ce_dn_7: 0.4384  loss_mask_dn_7: 0.03095  loss_dice_dn_7: 0.8874  loss_bbox_dn_7: 0.04702  loss_giou_dn_7: 0.4245  loss_ce_8: 1.853  loss_mask_8: 0.03319  loss_dice_8: 0.8239  loss_bbox_8: 0.1234  loss_giou_8: 0.5814  loss_ce_dn_8: 0.4348  loss_mask_dn_8: 0.03091  loss_dice_dn_8: 0.8979  loss_bbox_dn_8: 0.04663  loss_giou_dn_8: 0.4248  loss_ce_interm: 1.925  loss_mask_interm: 0.03149  loss_dice_interm: 0.8047  loss_bbox_interm: 0.1597  loss_giou_interm: 0.6798  time: 2.6912  data_time: 0.8879  lr: 0.0001  max_mem: 6614M\n",
            "[05/20 16:24:43 d2.utils.events]:  eta: 3:30:07  iter: 339  total_loss: 67.72  loss_ce: 1.723  loss_mask: 0.08112  loss_dice: 1.05  loss_bbox: 0.1132  loss_giou: 0.4616  loss_ce_dn: 0.5034  loss_mask_dn: 0.07859  loss_dice_dn: 0.7449  loss_bbox_dn: 0.08514  loss_giou_dn: 0.3314  loss_ce_0: 2.035  loss_mask_0: 0.076  loss_dice_0: 0.7923  loss_bbox_0: 0.08747  loss_giou_0: 0.5554  loss_ce_dn_0: 2.208  loss_mask_dn_0: 0.3378  loss_dice_dn_0: 3.132  loss_bbox_dn_0: 0.3386  loss_giou_dn_0: 0.8547  loss_ce_1: 2.034  loss_mask_1: 0.08643  loss_dice_1: 0.8788  loss_bbox_1: 0.08291  loss_giou_1: 0.5071  loss_ce_dn_1: 0.4662  loss_mask_dn_1: 0.1207  loss_dice_dn_1: 0.9591  loss_bbox_dn_1: 0.1487  loss_giou_dn_1: 0.4622  loss_ce_2: 2.154  loss_mask_2: 0.07298  loss_dice_2: 1.012  loss_bbox_2: 0.06868  loss_giou_2: 0.4758  loss_ce_dn_2: 0.4592  loss_mask_dn_2: 0.09594  loss_dice_dn_2: 0.7794  loss_bbox_dn_2: 0.1184  loss_giou_dn_2: 0.3863  loss_ce_3: 1.92  loss_mask_3: 0.06834  loss_dice_3: 0.873  loss_bbox_3: 0.07128  loss_giou_3: 0.4435  loss_ce_dn_3: 0.4243  loss_mask_dn_3: 0.08923  loss_dice_dn_3: 0.7775  loss_bbox_dn_3: 0.1018  loss_giou_dn_3: 0.3421  loss_ce_4: 1.794  loss_mask_4: 0.08527  loss_dice_4: 0.8055  loss_bbox_4: 0.09978  loss_giou_4: 0.4648  loss_ce_dn_4: 0.4158  loss_mask_dn_4: 0.08987  loss_dice_dn_4: 0.7358  loss_bbox_dn_4: 0.1025  loss_giou_dn_4: 0.3286  loss_ce_5: 1.74  loss_mask_5: 0.08102  loss_dice_5: 0.9025  loss_bbox_5: 0.1072  loss_giou_5: 0.4754  loss_ce_dn_5: 0.4319  loss_mask_dn_5: 0.07954  loss_dice_dn_5: 0.7451  loss_bbox_dn_5: 0.09732  loss_giou_dn_5: 0.3323  loss_ce_6: 1.665  loss_mask_6: 0.08662  loss_dice_6: 0.7918  loss_bbox_6: 0.1049  loss_giou_6: 0.4675  loss_ce_dn_6: 0.4067  loss_mask_dn_6: 0.07982  loss_dice_dn_6: 0.7398  loss_bbox_dn_6: 0.09134  loss_giou_dn_6: 0.3347  loss_ce_7: 1.729  loss_mask_7: 0.1006  loss_dice_7: 0.7787  loss_bbox_7: 0.1061  loss_giou_7: 0.4819  loss_ce_dn_7: 0.4338  loss_mask_dn_7: 0.08527  loss_dice_dn_7: 0.7483  loss_bbox_dn_7: 0.08723  loss_giou_dn_7: 0.33  loss_ce_8: 1.722  loss_mask_8: 0.08087  loss_dice_8: 0.8149  loss_bbox_8: 0.108  loss_giou_8: 0.4627  loss_ce_dn_8: 0.4802  loss_mask_dn_8: 0.07943  loss_dice_dn_8: 0.7435  loss_bbox_dn_8: 0.09245  loss_giou_dn_8: 0.3302  loss_ce_interm: 2.035  loss_mask_interm: 0.08026  loss_dice_interm: 0.8528  loss_bbox_interm: 0.1444  loss_giou_interm: 0.5604  time: 2.7020  data_time: 1.1984  lr: 0.0001  max_mem: 6620M\n",
            "[05/20 16:25:30 d2.utils.events]:  eta: 3:29:20  iter: 359  total_loss: 68.27  loss_ce: 1.825  loss_mask: 0.03792  loss_dice: 1.015  loss_bbox: 0.07246  loss_giou: 0.5947  loss_ce_dn: 0.3872  loss_mask_dn: 0.04076  loss_dice_dn: 0.7775  loss_bbox_dn: 0.04899  loss_giou_dn: 0.3955  loss_ce_0: 1.973  loss_mask_0: 0.04329  loss_dice_0: 1.252  loss_bbox_0: 0.136  loss_giou_0: 0.7748  loss_ce_dn_0: 2.053  loss_mask_dn_0: 0.2043  loss_dice_dn_0: 3.065  loss_bbox_dn_0: 0.1952  loss_giou_dn_0: 0.8547  loss_ce_1: 1.914  loss_mask_1: 0.03848  loss_dice_1: 0.9966  loss_bbox_1: 0.08871  loss_giou_1: 0.6714  loss_ce_dn_1: 0.5126  loss_mask_dn_1: 0.04448  loss_dice_dn_1: 0.9358  loss_bbox_dn_1: 0.08383  loss_giou_dn_1: 0.5135  loss_ce_2: 1.977  loss_mask_2: 0.04571  loss_dice_2: 0.9035  loss_bbox_2: 0.09786  loss_giou_2: 0.6445  loss_ce_dn_2: 0.4403  loss_mask_dn_2: 0.05003  loss_dice_dn_2: 0.7913  loss_bbox_dn_2: 0.06023  loss_giou_dn_2: 0.459  loss_ce_3: 1.973  loss_mask_3: 0.03826  loss_dice_3: 1.03  loss_bbox_3: 0.1162  loss_giou_3: 0.6613  loss_ce_dn_3: 0.4177  loss_mask_dn_3: 0.04143  loss_dice_dn_3: 0.7822  loss_bbox_dn_3: 0.05017  loss_giou_dn_3: 0.4111  loss_ce_4: 1.866  loss_mask_4: 0.03684  loss_dice_4: 1.079  loss_bbox_4: 0.1097  loss_giou_4: 0.6428  loss_ce_dn_4: 0.4052  loss_mask_dn_4: 0.0416  loss_dice_dn_4: 0.8182  loss_bbox_dn_4: 0.05096  loss_giou_dn_4: 0.4153  loss_ce_5: 2.001  loss_mask_5: 0.0352  loss_dice_5: 1.169  loss_bbox_5: 0.09021  loss_giou_5: 0.6017  loss_ce_dn_5: 0.4006  loss_mask_dn_5: 0.03929  loss_dice_dn_5: 0.7602  loss_bbox_dn_5: 0.04835  loss_giou_dn_5: 0.399  loss_ce_6: 1.905  loss_mask_6: 0.03078  loss_dice_6: 0.9388  loss_bbox_6: 0.08586  loss_giou_6: 0.6435  loss_ce_dn_6: 0.3958  loss_mask_dn_6: 0.03717  loss_dice_dn_6: 0.7899  loss_bbox_dn_6: 0.04929  loss_giou_dn_6: 0.3988  loss_ce_7: 1.941  loss_mask_7: 0.03202  loss_dice_7: 0.9004  loss_bbox_7: 0.08509  loss_giou_7: 0.6081  loss_ce_dn_7: 0.3854  loss_mask_dn_7: 0.038  loss_dice_dn_7: 0.7714  loss_bbox_dn_7: 0.04877  loss_giou_dn_7: 0.395  loss_ce_8: 1.848  loss_mask_8: 0.03846  loss_dice_8: 0.8237  loss_bbox_8: 0.08329  loss_giou_8: 0.6245  loss_ce_dn_8: 0.3907  loss_mask_dn_8: 0.03946  loss_dice_dn_8: 0.7667  loss_bbox_dn_8: 0.04917  loss_giou_dn_8: 0.3939  loss_ce_interm: 1.968  loss_mask_interm: 0.04193  loss_dice_interm: 1.024  loss_bbox_interm: 0.09931  loss_giou_interm: 0.5714  time: 2.6832  data_time: 0.7742  lr: 0.0001  max_mem: 6620M\n",
            "[05/20 16:26:23 d2.utils.events]:  eta: 3:28:33  iter: 379  total_loss: 65.29  loss_ce: 1.717  loss_mask: 0.0456  loss_dice: 0.6345  loss_bbox: 0.1086  loss_giou: 0.4224  loss_ce_dn: 0.5638  loss_mask_dn: 0.04787  loss_dice_dn: 0.7767  loss_bbox_dn: 0.05464  loss_giou_dn: 0.3556  loss_ce_0: 2.166  loss_mask_0: 0.04483  loss_dice_0: 1.032  loss_bbox_0: 0.07744  loss_giou_0: 0.5707  loss_ce_dn_0: 2.15  loss_mask_dn_0: 0.2201  loss_dice_dn_0: 3.341  loss_bbox_dn_0: 0.3297  loss_giou_dn_0: 0.8623  loss_ce_1: 2.157  loss_mask_1: 0.04498  loss_dice_1: 0.7244  loss_bbox_1: 0.08821  loss_giou_1: 0.5286  loss_ce_dn_1: 0.5088  loss_mask_dn_1: 0.0574  loss_dice_dn_1: 1.015  loss_bbox_dn_1: 0.1101  loss_giou_dn_1: 0.4793  loss_ce_2: 1.867  loss_mask_2: 0.0421  loss_dice_2: 0.6517  loss_bbox_2: 0.09458  loss_giou_2: 0.4914  loss_ce_dn_2: 0.4919  loss_mask_dn_2: 0.04625  loss_dice_dn_2: 0.8379  loss_bbox_dn_2: 0.08279  loss_giou_dn_2: 0.4109  loss_ce_3: 1.828  loss_mask_3: 0.0476  loss_dice_3: 0.9706  loss_bbox_3: 0.08887  loss_giou_3: 0.5074  loss_ce_dn_3: 0.4941  loss_mask_dn_3: 0.04539  loss_dice_dn_3: 0.7933  loss_bbox_dn_3: 0.0572  loss_giou_dn_3: 0.3765  loss_ce_4: 1.801  loss_mask_4: 0.03869  loss_dice_4: 0.8573  loss_bbox_4: 0.1078  loss_giou_4: 0.5149  loss_ce_dn_4: 0.5172  loss_mask_dn_4: 0.04498  loss_dice_dn_4: 0.8299  loss_bbox_dn_4: 0.05611  loss_giou_dn_4: 0.3594  loss_ce_5: 1.816  loss_mask_5: 0.04462  loss_dice_5: 0.8116  loss_bbox_5: 0.1068  loss_giou_5: 0.4967  loss_ce_dn_5: 0.5582  loss_mask_dn_5: 0.04549  loss_dice_dn_5: 0.7941  loss_bbox_dn_5: 0.05437  loss_giou_dn_5: 0.365  loss_ce_6: 1.733  loss_mask_6: 0.04214  loss_dice_6: 0.8845  loss_bbox_6: 0.1136  loss_giou_6: 0.4432  loss_ce_dn_6: 0.5421  loss_mask_dn_6: 0.04294  loss_dice_dn_6: 0.7707  loss_bbox_dn_6: 0.05201  loss_giou_dn_6: 0.3601  loss_ce_7: 1.739  loss_mask_7: 0.0356  loss_dice_7: 0.8197  loss_bbox_7: 0.1231  loss_giou_7: 0.427  loss_ce_dn_7: 0.5631  loss_mask_dn_7: 0.04443  loss_dice_dn_7: 0.7905  loss_bbox_dn_7: 0.05543  loss_giou_dn_7: 0.3577  loss_ce_8: 1.718  loss_mask_8: 0.04189  loss_dice_8: 0.839  loss_bbox_8: 0.1117  loss_giou_8: 0.4224  loss_ce_dn_8: 0.5569  loss_mask_dn_8: 0.04805  loss_dice_dn_8: 0.7958  loss_bbox_dn_8: 0.05632  loss_giou_dn_8: 0.3593  loss_ce_interm: 2.155  loss_mask_interm: 0.03658  loss_dice_interm: 0.7863  loss_bbox_interm: 0.144  loss_giou_interm: 0.5889  time: 2.6791  data_time: 0.9677  lr: 0.0001  max_mem: 6620M\n",
            "[05/20 16:27:16 d2.utils.events]:  eta: 3:28:07  iter: 399  total_loss: 53.19  loss_ce: 1.602  loss_mask: 0.08745  loss_dice: 0.6796  loss_bbox: 0.08157  loss_giou: 0.3455  loss_ce_dn: 0.5257  loss_mask_dn: 0.0773  loss_dice_dn: 0.6405  loss_bbox_dn: 0.06594  loss_giou_dn: 0.2961  loss_ce_0: 1.934  loss_mask_0: 0.08781  loss_dice_0: 0.6158  loss_bbox_0: 0.08356  loss_giou_0: 0.4111  loss_ce_dn_0: 1.944  loss_mask_dn_0: 0.2766  loss_dice_dn_0: 2.095  loss_bbox_dn_0: 0.39  loss_giou_dn_0: 0.8603  loss_ce_1: 1.828  loss_mask_1: 0.08365  loss_dice_1: 0.6986  loss_bbox_1: 0.08749  loss_giou_1: 0.3175  loss_ce_dn_1: 0.5237  loss_mask_dn_1: 0.06307  loss_dice_dn_1: 0.7328  loss_bbox_dn_1: 0.1286  loss_giou_dn_1: 0.4208  loss_ce_2: 1.602  loss_mask_2: 0.07155  loss_dice_2: 0.5578  loss_bbox_2: 0.09511  loss_giou_2: 0.3141  loss_ce_dn_2: 0.4707  loss_mask_dn_2: 0.07542  loss_dice_dn_2: 0.6319  loss_bbox_dn_2: 0.1104  loss_giou_dn_2: 0.3388  loss_ce_3: 1.572  loss_mask_3: 0.07874  loss_dice_3: 0.6373  loss_bbox_3: 0.08334  loss_giou_3: 0.3335  loss_ce_dn_3: 0.4539  loss_mask_dn_3: 0.06542  loss_dice_dn_3: 0.6364  loss_bbox_dn_3: 0.08793  loss_giou_dn_3: 0.3044  loss_ce_4: 1.527  loss_mask_4: 0.07535  loss_dice_4: 0.6434  loss_bbox_4: 0.08138  loss_giou_4: 0.3082  loss_ce_dn_4: 0.4434  loss_mask_dn_4: 0.06878  loss_dice_dn_4: 0.6256  loss_bbox_dn_4: 0.07739  loss_giou_dn_4: 0.2971  loss_ce_5: 1.597  loss_mask_5: 0.08538  loss_dice_5: 0.6249  loss_bbox_5: 0.08041  loss_giou_5: 0.3618  loss_ce_dn_5: 0.5033  loss_mask_dn_5: 0.07261  loss_dice_dn_5: 0.5965  loss_bbox_dn_5: 0.07112  loss_giou_dn_5: 0.2994  loss_ce_6: 1.627  loss_mask_6: 0.085  loss_dice_6: 0.6776  loss_bbox_6: 0.0817  loss_giou_6: 0.3231  loss_ce_dn_6: 0.4697  loss_mask_dn_6: 0.07224  loss_dice_dn_6: 0.6353  loss_bbox_dn_6: 0.07496  loss_giou_dn_6: 0.2995  loss_ce_7: 1.609  loss_mask_7: 0.09011  loss_dice_7: 0.6389  loss_bbox_7: 0.08105  loss_giou_7: 0.3343  loss_ce_dn_7: 0.5007  loss_mask_dn_7: 0.07611  loss_dice_dn_7: 0.6678  loss_bbox_dn_7: 0.07263  loss_giou_dn_7: 0.2927  loss_ce_8: 1.601  loss_mask_8: 0.0867  loss_dice_8: 0.5734  loss_bbox_8: 0.08147  loss_giou_8: 0.3549  loss_ce_dn_8: 0.5113  loss_mask_dn_8: 0.07936  loss_dice_dn_8: 0.6295  loss_bbox_dn_8: 0.07012  loss_giou_dn_8: 0.295  loss_ce_interm: 1.891  loss_mask_interm: 0.1019  loss_dice_interm: 0.6241  loss_bbox_interm: 0.1181  loss_giou_interm: 0.4172  time: 2.6774  data_time: 0.9987  lr: 0.0001  max_mem: 6620M\n",
            "[05/20 16:28:37 d2.utils.events]:  eta: 3:27:55  iter: 419  total_loss: 73.73  loss_ce: 1.967  loss_mask: 0.04559  loss_dice: 1.398  loss_bbox: 0.1468  loss_giou: 0.7966  loss_ce_dn: 0.52  loss_mask_dn: 0.02949  loss_dice_dn: 1.04  loss_bbox_dn: 0.04709  loss_giou_dn: 0.474  loss_ce_0: 2.151  loss_mask_0: 0.03146  loss_dice_0: 1.266  loss_bbox_0: 0.1464  loss_giou_0: 0.9136  loss_ce_dn_0: 1.91  loss_mask_dn_0: 0.1884  loss_dice_dn_0: 3.153  loss_bbox_dn_0: 0.142  loss_giou_dn_0: 0.8524  loss_ce_1: 2.215  loss_mask_1: 0.04403  loss_dice_1: 1.45  loss_bbox_1: 0.1789  loss_giou_1: 0.861  loss_ce_dn_1: 0.4633  loss_mask_dn_1: 0.03383  loss_dice_dn_1: 1.189  loss_bbox_dn_1: 0.06537  loss_giou_dn_1: 0.5476  loss_ce_2: 2.218  loss_mask_2: 0.04298  loss_dice_2: 1.161  loss_bbox_2: 0.1496  loss_giou_2: 0.841  loss_ce_dn_2: 0.4224  loss_mask_dn_2: 0.03248  loss_dice_dn_2: 1.131  loss_bbox_dn_2: 0.05122  loss_giou_dn_2: 0.4914  loss_ce_3: 2.236  loss_mask_3: 0.03917  loss_dice_3: 1.031  loss_bbox_3: 0.1673  loss_giou_3: 0.8176  loss_ce_dn_3: 0.444  loss_mask_dn_3: 0.02936  loss_dice_dn_3: 1.097  loss_bbox_dn_3: 0.04878  loss_giou_dn_3: 0.4772  loss_ce_4: 2.22  loss_mask_4: 0.03682  loss_dice_4: 1.283  loss_bbox_4: 0.1395  loss_giou_4: 0.7437  loss_ce_dn_4: 0.4463  loss_mask_dn_4: 0.02948  loss_dice_dn_4: 1.089  loss_bbox_dn_4: 0.04466  loss_giou_dn_4: 0.4694  loss_ce_5: 2.124  loss_mask_5: 0.06061  loss_dice_5: 1.065  loss_bbox_5: 0.1321  loss_giou_5: 0.7893  loss_ce_dn_5: 0.4538  loss_mask_dn_5: 0.02913  loss_dice_dn_5: 1.042  loss_bbox_dn_5: 0.04659  loss_giou_dn_5: 0.469  loss_ce_6: 2.049  loss_mask_6: 0.03974  loss_dice_6: 1.241  loss_bbox_6: 0.1331  loss_giou_6: 0.7708  loss_ce_dn_6: 0.4907  loss_mask_dn_6: 0.0299  loss_dice_dn_6: 1.067  loss_bbox_dn_6: 0.04671  loss_giou_dn_6: 0.4699  loss_ce_7: 2.005  loss_mask_7: 0.03695  loss_dice_7: 0.8792  loss_bbox_7: 0.1151  loss_giou_7: 0.7356  loss_ce_dn_7: 0.5044  loss_mask_dn_7: 0.0303  loss_dice_dn_7: 1.028  loss_bbox_dn_7: 0.04973  loss_giou_dn_7: 0.467  loss_ce_8: 1.904  loss_mask_8: 0.04402  loss_dice_8: 1.235  loss_bbox_8: 0.1454  loss_giou_8: 0.78  loss_ce_dn_8: 0.5073  loss_mask_dn_8: 0.02888  loss_dice_dn_8: 1.037  loss_bbox_dn_8: 0.04913  loss_giou_dn_8: 0.4741  loss_ce_interm: 2.103  loss_mask_interm: 0.03877  loss_dice_interm: 1.417  loss_bbox_interm: 0.1347  loss_giou_interm: 0.8353  time: 2.7432  data_time: 2.4606  lr: 0.0001  max_mem: 6620M\n",
            "[05/20 16:29:33 d2.utils.events]:  eta: 3:27:36  iter: 439  total_loss: 63.67  loss_ce: 1.604  loss_mask: 0.04529  loss_dice: 0.7978  loss_bbox: 0.1164  loss_giou: 0.5051  loss_ce_dn: 0.4464  loss_mask_dn: 0.03843  loss_dice_dn: 0.8769  loss_bbox_dn: 0.05183  loss_giou_dn: 0.4074  loss_ce_0: 1.753  loss_mask_0: 0.03825  loss_dice_0: 0.8912  loss_bbox_0: 0.1403  loss_giou_0: 0.5838  loss_ce_dn_0: 1.971  loss_mask_dn_0: 0.1555  loss_dice_dn_0: 3.015  loss_bbox_dn_0: 0.2027  loss_giou_dn_0: 0.8527  loss_ce_1: 1.888  loss_mask_1: 0.05145  loss_dice_1: 0.8166  loss_bbox_1: 0.1566  loss_giou_1: 0.5818  loss_ce_dn_1: 0.4398  loss_mask_dn_1: 0.03886  loss_dice_dn_1: 0.9625  loss_bbox_dn_1: 0.08474  loss_giou_dn_1: 0.5181  loss_ce_2: 1.802  loss_mask_2: 0.03593  loss_dice_2: 0.8112  loss_bbox_2: 0.1229  loss_giou_2: 0.5501  loss_ce_dn_2: 0.4125  loss_mask_dn_2: 0.03579  loss_dice_dn_2: 1.008  loss_bbox_dn_2: 0.06514  loss_giou_dn_2: 0.4597  loss_ce_3: 1.853  loss_mask_3: 0.04488  loss_dice_3: 0.7604  loss_bbox_3: 0.1053  loss_giou_3: 0.5665  loss_ce_dn_3: 0.4365  loss_mask_dn_3: 0.03561  loss_dice_dn_3: 1.002  loss_bbox_dn_3: 0.05503  loss_giou_dn_3: 0.4312  loss_ce_4: 1.692  loss_mask_4: 0.03651  loss_dice_4: 0.7565  loss_bbox_4: 0.08554  loss_giou_4: 0.5404  loss_ce_dn_4: 0.428  loss_mask_dn_4: 0.03511  loss_dice_dn_4: 0.9141  loss_bbox_dn_4: 0.05474  loss_giou_dn_4: 0.4309  loss_ce_5: 1.67  loss_mask_5: 0.04362  loss_dice_5: 0.7782  loss_bbox_5: 0.1133  loss_giou_5: 0.5563  loss_ce_dn_5: 0.419  loss_mask_dn_5: 0.03722  loss_dice_dn_5: 0.937  loss_bbox_dn_5: 0.05298  loss_giou_dn_5: 0.411  loss_ce_6: 1.688  loss_mask_6: 0.05141  loss_dice_6: 0.9005  loss_bbox_6: 0.09826  loss_giou_6: 0.5098  loss_ce_dn_6: 0.4143  loss_mask_dn_6: 0.03658  loss_dice_dn_6: 0.9063  loss_bbox_dn_6: 0.05251  loss_giou_dn_6: 0.4079  loss_ce_7: 1.623  loss_mask_7: 0.03555  loss_dice_7: 0.6103  loss_bbox_7: 0.1316  loss_giou_7: 0.5463  loss_ce_dn_7: 0.4395  loss_mask_dn_7: 0.03794  loss_dice_dn_7: 0.9264  loss_bbox_dn_7: 0.05206  loss_giou_dn_7: 0.4112  loss_ce_8: 1.635  loss_mask_8: 0.03607  loss_dice_8: 0.7235  loss_bbox_8: 0.1394  loss_giou_8: 0.542  loss_ce_dn_8: 0.45  loss_mask_dn_8: 0.03816  loss_dice_dn_8: 0.9257  loss_bbox_dn_8: 0.05203  loss_giou_dn_8: 0.4099  loss_ce_interm: 1.994  loss_mask_interm: 0.04956  loss_dice_interm: 1.048  loss_bbox_interm: 0.1218  loss_giou_interm: 0.7297  time: 2.7454  data_time: 1.1912  lr: 0.0001  max_mem: 6620M\n",
            "[05/20 16:30:42 d2.utils.events]:  eta: 3:26:59  iter: 459  total_loss: 66.85  loss_ce: 1.892  loss_mask: 0.05407  loss_dice: 0.9153  loss_bbox: 0.07429  loss_giou: 0.497  loss_ce_dn: 0.4821  loss_mask_dn: 0.04508  loss_dice_dn: 0.8012  loss_bbox_dn: 0.07595  loss_giou_dn: 0.3547  loss_ce_0: 1.982  loss_mask_0: 0.05207  loss_dice_0: 0.8215  loss_bbox_0: 0.07959  loss_giou_0: 0.4485  loss_ce_dn_0: 1.83  loss_mask_dn_0: 0.3704  loss_dice_dn_0: 2.705  loss_bbox_dn_0: 0.3337  loss_giou_dn_0: 0.853  loss_ce_1: 1.911  loss_mask_1: 0.05941  loss_dice_1: 0.7501  loss_bbox_1: 0.07984  loss_giou_1: 0.488  loss_ce_dn_1: 0.4649  loss_mask_dn_1: 0.0555  loss_dice_dn_1: 0.9327  loss_bbox_dn_1: 0.1067  loss_giou_dn_1: 0.5124  loss_ce_2: 1.938  loss_mask_2: 0.05145  loss_dice_2: 0.7867  loss_bbox_2: 0.08466  loss_giou_2: 0.4677  loss_ce_dn_2: 0.4473  loss_mask_dn_2: 0.05034  loss_dice_dn_2: 0.8532  loss_bbox_dn_2: 0.09404  loss_giou_dn_2: 0.4185  loss_ce_3: 1.86  loss_mask_3: 0.0726  loss_dice_3: 0.8562  loss_bbox_3: 0.1011  loss_giou_3: 0.468  loss_ce_dn_3: 0.4366  loss_mask_dn_3: 0.04828  loss_dice_dn_3: 0.8265  loss_bbox_dn_3: 0.08379  loss_giou_dn_3: 0.376  loss_ce_4: 1.956  loss_mask_4: 0.05711  loss_dice_4: 0.9852  loss_bbox_4: 0.09818  loss_giou_4: 0.4685  loss_ce_dn_4: 0.4322  loss_mask_dn_4: 0.04816  loss_dice_dn_4: 0.7762  loss_bbox_dn_4: 0.07938  loss_giou_dn_4: 0.3689  loss_ce_5: 1.909  loss_mask_5: 0.07741  loss_dice_5: 0.8622  loss_bbox_5: 0.09587  loss_giou_5: 0.4769  loss_ce_dn_5: 0.4225  loss_mask_dn_5: 0.04591  loss_dice_dn_5: 0.7846  loss_bbox_dn_5: 0.07598  loss_giou_dn_5: 0.3596  loss_ce_6: 1.79  loss_mask_6: 0.05634  loss_dice_6: 0.8614  loss_bbox_6: 0.08564  loss_giou_6: 0.5131  loss_ce_dn_6: 0.4345  loss_mask_dn_6: 0.04548  loss_dice_dn_6: 0.7648  loss_bbox_dn_6: 0.07812  loss_giou_dn_6: 0.3598  loss_ce_7: 1.86  loss_mask_7: 0.0767  loss_dice_7: 0.9989  loss_bbox_7: 0.1005  loss_giou_7: 0.5183  loss_ce_dn_7: 0.4587  loss_mask_dn_7: 0.04454  loss_dice_dn_7: 0.7826  loss_bbox_dn_7: 0.07609  loss_giou_dn_7: 0.357  loss_ce_8: 1.857  loss_mask_8: 0.06598  loss_dice_8: 0.8864  loss_bbox_8: 0.0849  loss_giou_8: 0.5126  loss_ce_dn_8: 0.4681  loss_mask_dn_8: 0.04619  loss_dice_dn_8: 0.756  loss_bbox_dn_8: 0.07728  loss_giou_dn_8: 0.3578  loss_ce_interm: 1.952  loss_mask_interm: 0.06449  loss_dice_interm: 0.8715  loss_bbox_interm: 0.1303  loss_giou_interm: 0.5096  time: 2.7772  data_time: 1.8584  lr: 0.0001  max_mem: 6620M\n",
            "[05/20 16:31:29 d2.utils.events]:  eta: 3:24:41  iter: 479  total_loss: 69.71  loss_ce: 1.702  loss_mask: 0.03501  loss_dice: 1.023  loss_bbox: 0.1176  loss_giou: 0.6233  loss_ce_dn: 0.4113  loss_mask_dn: 0.03481  loss_dice_dn: 0.9604  loss_bbox_dn: 0.06177  loss_giou_dn: 0.4069  loss_ce_0: 1.824  loss_mask_0: 0.04529  loss_dice_0: 1.096  loss_bbox_0: 0.151  loss_giou_0: 0.6817  loss_ce_dn_0: 1.926  loss_mask_dn_0: 0.1866  loss_dice_dn_0: 2.669  loss_bbox_dn_0: 0.2035  loss_giou_dn_0: 0.8593  loss_ce_1: 1.886  loss_mask_1: 0.04045  loss_dice_1: 1.038  loss_bbox_1: 0.1191  loss_giou_1: 0.6889  loss_ce_dn_1: 0.4344  loss_mask_dn_1: 0.03787  loss_dice_dn_1: 1.021  loss_bbox_dn_1: 0.08683  loss_giou_dn_1: 0.4887  loss_ce_2: 1.754  loss_mask_2: 0.04704  loss_dice_2: 0.8946  loss_bbox_2: 0.1248  loss_giou_2: 0.6458  loss_ce_dn_2: 0.3977  loss_mask_dn_2: 0.03885  loss_dice_dn_2: 0.9559  loss_bbox_dn_2: 0.07257  loss_giou_dn_2: 0.4255  loss_ce_3: 1.76  loss_mask_3: 0.04423  loss_dice_3: 1.105  loss_bbox_3: 0.1188  loss_giou_3: 0.622  loss_ce_dn_3: 0.3592  loss_mask_dn_3: 0.03687  loss_dice_dn_3: 0.9918  loss_bbox_dn_3: 0.06484  loss_giou_dn_3: 0.4356  loss_ce_4: 1.704  loss_mask_4: 0.04021  loss_dice_4: 0.9877  loss_bbox_4: 0.1105  loss_giou_4: 0.6283  loss_ce_dn_4: 0.3726  loss_mask_dn_4: 0.03768  loss_dice_dn_4: 0.9938  loss_bbox_dn_4: 0.06604  loss_giou_dn_4: 0.4285  loss_ce_5: 1.771  loss_mask_5: 0.03794  loss_dice_5: 0.9851  loss_bbox_5: 0.1182  loss_giou_5: 0.6156  loss_ce_dn_5: 0.3605  loss_mask_dn_5: 0.03748  loss_dice_dn_5: 0.9901  loss_bbox_dn_5: 0.06366  loss_giou_dn_5: 0.4035  loss_ce_6: 1.682  loss_mask_6: 0.03573  loss_dice_6: 0.947  loss_bbox_6: 0.1107  loss_giou_6: 0.627  loss_ce_dn_6: 0.3726  loss_mask_dn_6: 0.03536  loss_dice_dn_6: 0.9911  loss_bbox_dn_6: 0.06233  loss_giou_dn_6: 0.4112  loss_ce_7: 1.763  loss_mask_7: 0.03827  loss_dice_7: 1.151  loss_bbox_7: 0.1164  loss_giou_7: 0.5558  loss_ce_dn_7: 0.3721  loss_mask_dn_7: 0.03526  loss_dice_dn_7: 0.9697  loss_bbox_dn_7: 0.06156  loss_giou_dn_7: 0.41  loss_ce_8: 1.686  loss_mask_8: 0.04128  loss_dice_8: 1.033  loss_bbox_8: 0.112  loss_giou_8: 0.5958  loss_ce_dn_8: 0.3973  loss_mask_dn_8: 0.03522  loss_dice_dn_8: 0.9755  loss_bbox_dn_8: 0.06202  loss_giou_dn_8: 0.4075  loss_ce_interm: 1.905  loss_mask_interm: 0.04094  loss_dice_interm: 0.9814  loss_bbox_interm: 0.1186  loss_giou_interm: 0.7199  time: 2.7551  data_time: 0.6906  lr: 0.0001  max_mem: 6620M\n",
            "[05/20 16:32:21 d2.data.datasets.coco]: Loaded 150 images in COCO format from /content/TACO-expl/data/annotations_off_0_resval.json\n",
            "[05/20 16:32:21 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "[05/20 16:32:21 d2.data.common]: Serializing 150 elements to byte tensors and concatenating them all ...\n",
            "[05/20 16:32:21 d2.data.common]: Serialized dataset takes 0.21 MiB\n",
            "WARNING [05/20 16:32:21 d2.evaluation.coco_evaluation]: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
            "[05/20 16:32:21 d2.evaluation.evaluator]: Start inference on 150 batches\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1066, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1066, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1066, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1066])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 16:32:37 d2.evaluation.evaluator]: Inference done 11/150. Dataloading: 0.0254 s/iter. Inference: 0.2940 s/iter. Eval: 0.4772 s/iter. Total: 0.7965 s/iter. ETA=0:01:50\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 608])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 608])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 608])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1200])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 750])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 16:32:43 d2.evaluation.evaluator]: Inference done 16/150. Dataloading: 0.0644 s/iter. Inference: 0.3540 s/iter. Eval: 0.5815 s/iter. Total: 1.0001 s/iter. ETA=0:02:14\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 750])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 16:32:50 d2.evaluation.evaluator]: Inference done 23/150. Dataloading: 0.0587 s/iter. Inference: 0.3401 s/iter. Eval: 0.5568 s/iter. Total: 0.9561 s/iter. ETA=0:02:01\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([750, 1333])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 750])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([750, 1333])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 16:32:55 d2.evaluation.evaluator]: Inference done 29/150. Dataloading: 0.0446 s/iter. Inference: 0.3344 s/iter. Eval: 0.5492 s/iter. Total: 0.9287 s/iter. ETA=0:01:52\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 750])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 16:33:00 d2.evaluation.evaluator]: Inference done 34/150. Dataloading: 0.0374 s/iter. Inference: 0.3397 s/iter. Eval: 0.5738 s/iter. Total: 0.9514 s/iter. ETA=0:01:50\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 750])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 16:33:05 d2.evaluation.evaluator]: Inference done 40/150. Dataloading: 0.0315 s/iter. Inference: 0.3411 s/iter. Eval: 0.5711 s/iter. Total: 0.9444 s/iter. ETA=0:01:43\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 16:33:11 d2.evaluation.evaluator]: Inference done 47/150. Dataloading: 0.0266 s/iter. Inference: 0.3341 s/iter. Eval: 0.5567 s/iter. Total: 0.9180 s/iter. ETA=0:01:34\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 16:33:17 d2.evaluation.evaluator]: Inference done 53/150. Dataloading: 0.0297 s/iter. Inference: 0.3335 s/iter. Eval: 0.5656 s/iter. Total: 0.9293 s/iter. ETA=0:01:30\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 16:33:22 d2.evaluation.evaluator]: Inference done 59/150. Dataloading: 0.0267 s/iter. Inference: 0.3325 s/iter. Eval: 0.5650 s/iter. Total: 0.9248 s/iter. ETA=0:01:24\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 16:33:28 d2.evaluation.evaluator]: Inference done 65/150. Dataloading: 0.0380 s/iter. Inference: 0.3291 s/iter. Eval: 0.5561 s/iter. Total: 0.9238 s/iter. ETA=0:01:18\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 16:33:33 d2.evaluation.evaluator]: Inference done 70/150. Dataloading: 0.0421 s/iter. Inference: 0.3285 s/iter. Eval: 0.5599 s/iter. Total: 0.9311 s/iter. ETA=0:01:14\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 16:33:38 d2.evaluation.evaluator]: Inference done 75/150. Dataloading: 0.0395 s/iter. Inference: 0.3300 s/iter. Eval: 0.5664 s/iter. Total: 0.9365 s/iter. ETA=0:01:10\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([852, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 16:33:43 d2.evaluation.evaluator]: Inference done 82/150. Dataloading: 0.0384 s/iter. Inference: 0.3268 s/iter. Eval: 0.5574 s/iter. Total: 0.9232 s/iter. ETA=0:01:02\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 16:33:49 d2.evaluation.evaluator]: Inference done 88/150. Dataloading: 0.0433 s/iter. Inference: 0.3261 s/iter. Eval: 0.5567 s/iter. Total: 0.9267 s/iter. ETA=0:00:57\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 16:33:55 d2.evaluation.evaluator]: Inference done 93/150. Dataloading: 0.0410 s/iter. Inference: 0.3278 s/iter. Eval: 0.5637 s/iter. Total: 0.9332 s/iter. ETA=0:00:53\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 16:34:00 d2.evaluation.evaluator]: Inference done 99/150. Dataloading: 0.0407 s/iter. Inference: 0.3268 s/iter. Eval: 0.5601 s/iter. Total: 0.9282 s/iter. ETA=0:00:47\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 16:34:05 d2.evaluation.evaluator]: Inference done 105/150. Dataloading: 0.0442 s/iter. Inference: 0.3252 s/iter. Eval: 0.5550 s/iter. Total: 0.9251 s/iter. ETA=0:00:41\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 16:34:10 d2.evaluation.evaluator]: Inference done 110/150. Dataloading: 0.0438 s/iter. Inference: 0.3257 s/iter. Eval: 0.5608 s/iter. Total: 0.9310 s/iter. ETA=0:00:37\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 16:34:16 d2.evaluation.evaluator]: Inference done 116/150. Dataloading: 0.0416 s/iter. Inference: 0.3272 s/iter. Eval: 0.5620 s/iter. Total: 0.9314 s/iter. ETA=0:00:31\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 16:34:21 d2.evaluation.evaluator]: Inference done 122/150. Dataloading: 0.0423 s/iter. Inference: 0.3259 s/iter. Eval: 0.5577 s/iter. Total: 0.9265 s/iter. ETA=0:00:25\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 16:34:27 d2.evaluation.evaluator]: Inference done 128/150. Dataloading: 0.0443 s/iter. Inference: 0.3252 s/iter. Eval: 0.5584 s/iter. Total: 0.9284 s/iter. ETA=0:00:20\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 16:34:32 d2.evaluation.evaluator]: Inference done 133/150. Dataloading: 0.0430 s/iter. Inference: 0.3268 s/iter. Eval: 0.5620 s/iter. Total: 0.9323 s/iter. ETA=0:00:15\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 750])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 750])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 750])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 16:34:37 d2.evaluation.evaluator]: Inference done 139/150. Dataloading: 0.0421 s/iter. Inference: 0.3264 s/iter. Eval: 0.5601 s/iter. Total: 0.9292 s/iter. ETA=0:00:10\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 16:34:42 d2.evaluation.evaluator]: Inference done 145/150. Dataloading: 0.0432 s/iter. Inference: 0.3257 s/iter. Eval: 0.5582 s/iter. Total: 0.9277 s/iter. ETA=0:00:04\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 608])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 608])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 608])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 608])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 16:34:47 d2.evaluation.evaluator]: Inference done 150/150. Dataloading: 0.0418 s/iter. Inference: 0.3264 s/iter. Eval: 0.5620 s/iter. Total: 0.9308 s/iter. ETA=0:00:00\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[05/20 16:34:47 d2.evaluation.evaluator]: Total inference time: 0:02:15.055759 (0.931419 s / iter per device, on 1 devices)\n",
            "[05/20 16:34:47 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:47 (0.326387 s / iter per device, on 1 devices)\n",
            "[05/20 16:34:48 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...\n",
            "[05/20 16:34:48 d2.evaluation.coco_evaluation]: Saving results to /content/output/chkpt/inference/coco_instances_results.json\n",
            "[05/20 16:34:48 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "[05/20 16:34:48 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*\n",
            "[05/20 16:34:48 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.22 seconds.\n",
            "[05/20 16:34:48 d2.evaluation.fast_eval_api]: Accumulating evaluation results...\n",
            "[05/20 16:34:48 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.07 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.174\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.287\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.185\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.037\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.164\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.374\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.260\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.382\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.387\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.078\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.421\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.675\n",
            "[05/20 16:34:48 d2.evaluation.coco_evaluation]: Evaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
            "| 17.356 | 28.710 | 18.515 | 3.716 | 16.416 | 37.353 |\n",
            "[05/20 16:34:48 d2.evaluation.coco_evaluation]: Per-category bbox AP: \n",
            "| category   | AP     | category              | AP     | category   | AP     |\n",
            "|:-----------|:-------|:----------------------|:-------|:-----------|:-------|\n",
            "| Bottle     | 43.566 | Bottle cap            | 7.729  | Can        | 17.453 |\n",
            "| Cigarette  | 0.279  | Cup                   | 20.097 | Lid        | 30.041 |\n",
            "| Other      | 15.724 | Plastic bag & wrapper | 15.226 | Pop tab    | 7.928  |\n",
            "| Straw      | 15.512 |                       |        |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.17s)\n",
            "creating index...\n",
            "index created!\n",
            "[05/20 16:34:49 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*\n",
            "[05/20 16:34:49 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.29 seconds.\n",
            "[05/20 16:34:49 d2.evaluation.fast_eval_api]: Accumulating evaluation results...\n",
            "[05/20 16:34:49 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.07 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.255\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.322\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.257\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.171\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.269\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.436\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.378\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.575\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.587\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.358\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.663\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.776\n",
            "[05/20 16:34:49 d2.evaluation.coco_evaluation]: Evaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 25.507 | 32.241 | 25.720 | 17.108 | 26.877 | 43.577 |\n",
            "[05/20 16:34:49 d2.evaluation.coco_evaluation]: Per-category segm AP: \n",
            "| category   | AP     | category              | AP     | category   | AP     |\n",
            "|:-----------|:-------|:----------------------|:-------|:-----------|:-------|\n",
            "| Bottle     | 59.983 | Bottle cap            | 22.928 | Can        | 24.913 |\n",
            "| Cigarette  | 7.736  | Cup                   | 30.407 | Lid        | 37.601 |\n",
            "| Other      | 23.467 | Plastic bag & wrapper | 23.719 | Pop tab    | 10.531 |\n",
            "| Straw      | 13.788 |                       |        |            |        |\n",
            "[05/20 16:34:49 d2.engine.defaults]: Evaluation results for TACO_val in csv format:\n",
            "[05/20 16:34:49 d2.evaluation.testing]: copypaste: Task: bbox\n",
            "[05/20 16:34:49 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl\n",
            "[05/20 16:34:49 d2.evaluation.testing]: copypaste: 17.3555,28.7098,18.5152,3.7164,16.4156,37.3527\n",
            "[05/20 16:34:49 d2.evaluation.testing]: copypaste: Task: segm\n",
            "[05/20 16:34:49 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl\n",
            "[05/20 16:34:49 d2.evaluation.testing]: copypaste: 25.5072,32.2414,25.7196,17.1085,26.8769,43.5772\n",
            "[05/20 16:34:49 d2.utils.events]:  eta: 3:24:14  iter: 499  total_loss: 56.54  loss_ce: 1.621  loss_mask: 0.03343  loss_dice: 0.6569  loss_bbox: 0.07086  loss_giou: 0.4052  loss_ce_dn: 0.4082  loss_mask_dn: 0.03087  loss_dice_dn: 0.6732  loss_bbox_dn: 0.05233  loss_giou_dn: 0.33  loss_ce_0: 1.804  loss_mask_0: 0.04319  loss_dice_0: 0.5685  loss_bbox_0: 0.0645  loss_giou_0: 0.4288  loss_ce_dn_0: 1.622  loss_mask_dn_0: 0.1865  loss_dice_dn_0: 2.253  loss_bbox_dn_0: 0.337  loss_giou_dn_0: 0.8572  loss_ce_1: 1.732  loss_mask_1: 0.03153  loss_dice_1: 0.6383  loss_bbox_1: 0.06413  loss_giou_1: 0.4214  loss_ce_dn_1: 0.3972  loss_mask_dn_1: 0.03657  loss_dice_dn_1: 0.8191  loss_bbox_dn_1: 0.0903  loss_giou_dn_1: 0.4459  loss_ce_2: 1.764  loss_mask_2: 0.02772  loss_dice_2: 0.7079  loss_bbox_2: 0.07242  loss_giou_2: 0.4158  loss_ce_dn_2: 0.4029  loss_mask_dn_2: 0.03115  loss_dice_dn_2: 0.6929  loss_bbox_dn_2: 0.06397  loss_giou_dn_2: 0.3824  loss_ce_3: 1.57  loss_mask_3: 0.03804  loss_dice_3: 0.7187  loss_bbox_3: 0.06872  loss_giou_3: 0.4091  loss_ce_dn_3: 0.355  loss_mask_dn_3: 0.03139  loss_dice_dn_3: 0.7064  loss_bbox_dn_3: 0.05266  loss_giou_dn_3: 0.3483  loss_ce_4: 1.602  loss_mask_4: 0.03705  loss_dice_4: 0.7582  loss_bbox_4: 0.06976  loss_giou_4: 0.3929  loss_ce_dn_4: 0.3737  loss_mask_dn_4: 0.03969  loss_dice_dn_4: 0.6736  loss_bbox_dn_4: 0.05241  loss_giou_dn_4: 0.3337  loss_ce_5: 1.598  loss_mask_5: 0.03481  loss_dice_5: 0.5155  loss_bbox_5: 0.07013  loss_giou_5: 0.3969  loss_ce_dn_5: 0.3749  loss_mask_dn_5: 0.03439  loss_dice_dn_5: 0.6062  loss_bbox_dn_5: 0.05314  loss_giou_dn_5: 0.3294  loss_ce_6: 1.534  loss_mask_6: 0.03652  loss_dice_6: 0.6825  loss_bbox_6: 0.07164  loss_giou_6: 0.3818  loss_ce_dn_6: 0.3769  loss_mask_dn_6: 0.03066  loss_dice_dn_6: 0.649  loss_bbox_dn_6: 0.05397  loss_giou_dn_6: 0.3301  loss_ce_7: 1.562  loss_mask_7: 0.03834  loss_dice_7: 0.5179  loss_bbox_7: 0.0731  loss_giou_7: 0.404  loss_ce_dn_7: 0.3856  loss_mask_dn_7: 0.03011  loss_dice_dn_7: 0.6257  loss_bbox_dn_7: 0.05526  loss_giou_dn_7: 0.3296  loss_ce_8: 1.631  loss_mask_8: 0.03419  loss_dice_8: 0.582  loss_bbox_8: 0.07123  loss_giou_8: 0.3874  loss_ce_dn_8: 0.397  loss_mask_dn_8: 0.0305  loss_dice_dn_8: 0.6519  loss_bbox_dn_8: 0.05399  loss_giou_dn_8: 0.3305  loss_ce_interm: 1.762  loss_mask_interm: 0.04227  loss_dice_interm: 0.7282  loss_bbox_interm: 0.1087  loss_giou_interm: 0.5248  time: 2.7474  data_time: 0.9132  lr: 0.0001  max_mem: 6620M\n",
            "[05/20 16:35:37 d2.utils.events]:  eta: 3:23:08  iter: 519  total_loss: 53.09  loss_ce: 1.364  loss_mask: 0.02925  loss_dice: 0.6992  loss_bbox: 0.06858  loss_giou: 0.388  loss_ce_dn: 0.2759  loss_mask_dn: 0.03491  loss_dice_dn: 0.7842  loss_bbox_dn: 0.04112  loss_giou_dn: 0.3195  loss_ce_0: 1.585  loss_mask_0: 0.03402  loss_dice_0: 0.8477  loss_bbox_0: 0.06857  loss_giou_0: 0.4667  loss_ce_dn_0: 1.539  loss_mask_dn_0: 0.178  loss_dice_dn_0: 2.316  loss_bbox_dn_0: 0.2603  loss_giou_dn_0: 0.8609  loss_ce_1: 1.45  loss_mask_1: 0.03795  loss_dice_1: 0.692  loss_bbox_1: 0.07198  loss_giou_1: 0.4144  loss_ce_dn_1: 0.3361  loss_mask_dn_1: 0.03869  loss_dice_dn_1: 0.7799  loss_bbox_dn_1: 0.07285  loss_giou_dn_1: 0.4349  loss_ce_2: 1.555  loss_mask_2: 0.0329  loss_dice_2: 0.813  loss_bbox_2: 0.07029  loss_giou_2: 0.4003  loss_ce_dn_2: 0.3265  loss_mask_dn_2: 0.03138  loss_dice_dn_2: 0.7434  loss_bbox_dn_2: 0.05914  loss_giou_dn_2: 0.3756  loss_ce_3: 1.426  loss_mask_3: 0.03671  loss_dice_3: 0.6492  loss_bbox_3: 0.07051  loss_giou_3: 0.4276  loss_ce_dn_3: 0.316  loss_mask_dn_3: 0.03672  loss_dice_dn_3: 0.7478  loss_bbox_dn_3: 0.04488  loss_giou_dn_3: 0.3295  loss_ce_4: 1.428  loss_mask_4: 0.03435  loss_dice_4: 0.6819  loss_bbox_4: 0.06744  loss_giou_4: 0.4082  loss_ce_dn_4: 0.301  loss_mask_dn_4: 0.0352  loss_dice_dn_4: 0.7536  loss_bbox_dn_4: 0.04769  loss_giou_dn_4: 0.3312  loss_ce_5: 1.434  loss_mask_5: 0.03255  loss_dice_5: 0.7336  loss_bbox_5: 0.07001  loss_giou_5: 0.3878  loss_ce_dn_5: 0.2825  loss_mask_dn_5: 0.03191  loss_dice_dn_5: 0.7481  loss_bbox_dn_5: 0.04358  loss_giou_dn_5: 0.3187  loss_ce_6: 1.438  loss_mask_6: 0.0266  loss_dice_6: 0.7599  loss_bbox_6: 0.07165  loss_giou_6: 0.4159  loss_ce_dn_6: 0.2794  loss_mask_dn_6: 0.03352  loss_dice_dn_6: 0.7797  loss_bbox_dn_6: 0.04435  loss_giou_dn_6: 0.3155  loss_ce_7: 1.372  loss_mask_7: 0.02881  loss_dice_7: 0.7959  loss_bbox_7: 0.07272  loss_giou_7: 0.3894  loss_ce_dn_7: 0.2776  loss_mask_dn_7: 0.03554  loss_dice_dn_7: 0.761  loss_bbox_dn_7: 0.04179  loss_giou_dn_7: 0.315  loss_ce_8: 1.404  loss_mask_8: 0.02687  loss_dice_8: 0.6245  loss_bbox_8: 0.07145  loss_giou_8: 0.3816  loss_ce_dn_8: 0.2796  loss_mask_dn_8: 0.03423  loss_dice_dn_8: 0.7264  loss_bbox_dn_8: 0.04236  loss_giou_dn_8: 0.318  loss_ce_interm: 1.546  loss_mask_interm: 0.03368  loss_dice_interm: 0.8065  loss_bbox_interm: 0.09932  loss_giou_interm: 0.4532  time: 2.7325  data_time: 0.7319  lr: 0.0001  max_mem: 6620M\n",
            "[05/20 16:36:26 d2.utils.events]:  eta: 3:22:20  iter: 539  total_loss: 69.48  loss_ce: 1.797  loss_mask: 0.06288  loss_dice: 1.054  loss_bbox: 0.1317  loss_giou: 0.5509  loss_ce_dn: 0.4385  loss_mask_dn: 0.05517  loss_dice_dn: 0.9126  loss_bbox_dn: 0.08445  loss_giou_dn: 0.4117  loss_ce_0: 2.05  loss_mask_0: 0.06283  loss_dice_0: 1.089  loss_bbox_0: 0.139  loss_giou_0: 0.666  loss_ce_dn_0: 1.705  loss_mask_dn_0: 0.375  loss_dice_dn_0: 3.153  loss_bbox_dn_0: 0.3519  loss_giou_dn_0: 0.8594  loss_ce_1: 2.067  loss_mask_1: 0.0718  loss_dice_1: 1.071  loss_bbox_1: 0.1198  loss_giou_1: 0.6019  loss_ce_dn_1: 0.4725  loss_mask_dn_1: 0.09568  loss_dice_dn_1: 1.17  loss_bbox_dn_1: 0.142  loss_giou_dn_1: 0.5426  loss_ce_2: 1.973  loss_mask_2: 0.07683  loss_dice_2: 1.122  loss_bbox_2: 0.1254  loss_giou_2: 0.6138  loss_ce_dn_2: 0.4093  loss_mask_dn_2: 0.0737  loss_dice_dn_2: 1.051  loss_bbox_dn_2: 0.101  loss_giou_dn_2: 0.4996  loss_ce_3: 1.95  loss_mask_3: 0.06874  loss_dice_3: 1.066  loss_bbox_3: 0.09686  loss_giou_3: 0.5984  loss_ce_dn_3: 0.4056  loss_mask_dn_3: 0.06621  loss_dice_dn_3: 0.978  loss_bbox_dn_3: 0.09321  loss_giou_dn_3: 0.461  loss_ce_4: 1.854  loss_mask_4: 0.06842  loss_dice_4: 0.9863  loss_bbox_4: 0.1325  loss_giou_4: 0.5623  loss_ce_dn_4: 0.424  loss_mask_dn_4: 0.0625  loss_dice_dn_4: 0.9474  loss_bbox_dn_4: 0.08524  loss_giou_dn_4: 0.4443  loss_ce_5: 1.876  loss_mask_5: 0.0692  loss_dice_5: 0.9905  loss_bbox_5: 0.1302  loss_giou_5: 0.5677  loss_ce_dn_5: 0.4323  loss_mask_dn_5: 0.0597  loss_dice_dn_5: 0.9442  loss_bbox_dn_5: 0.0868  loss_giou_dn_5: 0.4296  loss_ce_6: 1.822  loss_mask_6: 0.06123  loss_dice_6: 1.166  loss_bbox_6: 0.1272  loss_giou_6: 0.5795  loss_ce_dn_6: 0.4299  loss_mask_dn_6: 0.05681  loss_dice_dn_6: 0.9191  loss_bbox_dn_6: 0.0852  loss_giou_dn_6: 0.4226  loss_ce_7: 1.801  loss_mask_7: 0.06711  loss_dice_7: 1.022  loss_bbox_7: 0.1398  loss_giou_7: 0.5569  loss_ce_dn_7: 0.426  loss_mask_dn_7: 0.05229  loss_dice_dn_7: 0.9237  loss_bbox_dn_7: 0.0862  loss_giou_dn_7: 0.42  loss_ce_8: 1.784  loss_mask_8: 0.07147  loss_dice_8: 1.109  loss_bbox_8: 0.1414  loss_giou_8: 0.5545  loss_ce_dn_8: 0.4318  loss_mask_dn_8: 0.05401  loss_dice_dn_8: 0.9236  loss_bbox_dn_8: 0.08592  loss_giou_dn_8: 0.4172  loss_ce_interm: 2.043  loss_mask_interm: 0.06655  loss_dice_interm: 1.013  loss_bbox_interm: 0.1676  loss_giou_interm: 0.6786  time: 2.7228  data_time: 0.8781  lr: 0.0001  max_mem: 6620M\n",
            "[05/20 16:37:17 d2.utils.events]:  eta: 3:21:34  iter: 559  total_loss: 50.79  loss_ce: 1.473  loss_mask: 0.04637  loss_dice: 0.4624  loss_bbox: 0.05629  loss_giou: 0.3775  loss_ce_dn: 0.4324  loss_mask_dn: 0.05106  loss_dice_dn: 0.5323  loss_bbox_dn: 0.06098  loss_giou_dn: 0.3612  loss_ce_0: 1.745  loss_mask_0: 0.0597  loss_dice_0: 0.5695  loss_bbox_0: 0.05035  loss_giou_0: 0.3997  loss_ce_dn_0: 1.541  loss_mask_dn_0: 0.3658  loss_dice_dn_0: 2.526  loss_bbox_dn_0: 0.306  loss_giou_dn_0: 0.8683  loss_ce_1: 1.68  loss_mask_1: 0.05899  loss_dice_1: 0.4468  loss_bbox_1: 0.05219  loss_giou_1: 0.3954  loss_ce_dn_1: 0.4265  loss_mask_dn_1: 0.05476  loss_dice_dn_1: 0.6077  loss_bbox_dn_1: 0.1069  loss_giou_dn_1: 0.4044  loss_ce_2: 1.632  loss_mask_2: 0.05884  loss_dice_2: 0.4471  loss_bbox_2: 0.05299  loss_giou_2: 0.3619  loss_ce_dn_2: 0.4108  loss_mask_dn_2: 0.05265  loss_dice_dn_2: 0.5067  loss_bbox_dn_2: 0.07446  loss_giou_dn_2: 0.393  loss_ce_3: 1.592  loss_mask_3: 0.05927  loss_dice_3: 0.5502  loss_bbox_3: 0.05307  loss_giou_3: 0.3426  loss_ce_dn_3: 0.4136  loss_mask_dn_3: 0.05208  loss_dice_dn_3: 0.5055  loss_bbox_dn_3: 0.06265  loss_giou_dn_3: 0.3537  loss_ce_4: 1.549  loss_mask_4: 0.05639  loss_dice_4: 0.5052  loss_bbox_4: 0.05509  loss_giou_4: 0.362  loss_ce_dn_4: 0.4114  loss_mask_dn_4: 0.05131  loss_dice_dn_4: 0.5018  loss_bbox_dn_4: 0.06432  loss_giou_dn_4: 0.3528  loss_ce_5: 1.506  loss_mask_5: 0.04804  loss_dice_5: 0.4875  loss_bbox_5: 0.05261  loss_giou_5: 0.3557  loss_ce_dn_5: 0.388  loss_mask_dn_5: 0.05009  loss_dice_dn_5: 0.5514  loss_bbox_dn_5: 0.06109  loss_giou_dn_5: 0.3533  loss_ce_6: 1.498  loss_mask_6: 0.05086  loss_dice_6: 0.6946  loss_bbox_6: 0.05664  loss_giou_6: 0.3478  loss_ce_dn_6: 0.3996  loss_mask_dn_6: 0.04835  loss_dice_dn_6: 0.5126  loss_bbox_dn_6: 0.06227  loss_giou_dn_6: 0.3535  loss_ce_7: 1.532  loss_mask_7: 0.05201  loss_dice_7: 0.5781  loss_bbox_7: 0.05624  loss_giou_7: 0.3492  loss_ce_dn_7: 0.4039  loss_mask_dn_7: 0.04745  loss_dice_dn_7: 0.5052  loss_bbox_dn_7: 0.06266  loss_giou_dn_7: 0.3573  loss_ce_8: 1.505  loss_mask_8: 0.04849  loss_dice_8: 0.5017  loss_bbox_8: 0.05554  loss_giou_8: 0.3818  loss_ce_dn_8: 0.4171  loss_mask_dn_8: 0.05023  loss_dice_dn_8: 0.5188  loss_bbox_dn_8: 0.06153  loss_giou_dn_8: 0.3616  loss_ce_interm: 1.743  loss_mask_interm: 0.06189  loss_dice_interm: 0.4962  loss_bbox_interm: 0.1188  loss_giou_interm: 0.5355  time: 2.7155  data_time: 0.8751  lr: 0.0001  max_mem: 6620M\n",
            "[05/20 16:38:02 d2.utils.events]:  eta: 3:20:34  iter: 579  total_loss: 63.59  loss_ce: 1.628  loss_mask: 0.02986  loss_dice: 0.7537  loss_bbox: 0.1245  loss_giou: 0.5483  loss_ce_dn: 0.3791  loss_mask_dn: 0.03778  loss_dice_dn: 0.711  loss_bbox_dn: 0.0529  loss_giou_dn: 0.3863  loss_ce_0: 1.87  loss_mask_0: 0.04342  loss_dice_0: 0.8059  loss_bbox_0: 0.1362  loss_giou_0: 0.6198  loss_ce_dn_0: 1.635  loss_mask_dn_0: 0.1454  loss_dice_dn_0: 2.467  loss_bbox_dn_0: 0.219  loss_giou_dn_0: 0.8534  loss_ce_1: 1.868  loss_mask_1: 0.04398  loss_dice_1: 0.8332  loss_bbox_1: 0.1161  loss_giou_1: 0.555  loss_ce_dn_1: 0.376  loss_mask_dn_1: 0.03763  loss_dice_dn_1: 0.7907  loss_bbox_dn_1: 0.09502  loss_giou_dn_1: 0.4785  loss_ce_2: 1.733  loss_mask_2: 0.03623  loss_dice_2: 0.8639  loss_bbox_2: 0.1183  loss_giou_2: 0.5859  loss_ce_dn_2: 0.3668  loss_mask_dn_2: 0.03764  loss_dice_dn_2: 0.7001  loss_bbox_dn_2: 0.07686  loss_giou_dn_2: 0.4153  loss_ce_3: 1.717  loss_mask_3: 0.03281  loss_dice_3: 0.7819  loss_bbox_3: 0.1215  loss_giou_3: 0.6132  loss_ce_dn_3: 0.3673  loss_mask_dn_3: 0.03668  loss_dice_dn_3: 0.6897  loss_bbox_dn_3: 0.06144  loss_giou_dn_3: 0.3891  loss_ce_4: 1.775  loss_mask_4: 0.03302  loss_dice_4: 0.8211  loss_bbox_4: 0.1375  loss_giou_4: 0.5834  loss_ce_dn_4: 0.371  loss_mask_dn_4: 0.03838  loss_dice_dn_4: 0.7098  loss_bbox_dn_4: 0.05631  loss_giou_dn_4: 0.3798  loss_ce_5: 1.742  loss_mask_5: 0.03105  loss_dice_5: 0.706  loss_bbox_5: 0.1333  loss_giou_5: 0.5642  loss_ce_dn_5: 0.3603  loss_mask_dn_5: 0.03815  loss_dice_dn_5: 0.6985  loss_bbox_dn_5: 0.05367  loss_giou_dn_5: 0.3799  loss_ce_6: 1.698  loss_mask_6: 0.03837  loss_dice_6: 0.8531  loss_bbox_6: 0.1375  loss_giou_6: 0.5488  loss_ce_dn_6: 0.3775  loss_mask_dn_6: 0.03597  loss_dice_dn_6: 0.6697  loss_bbox_dn_6: 0.05592  loss_giou_dn_6: 0.3782  loss_ce_7: 1.711  loss_mask_7: 0.03095  loss_dice_7: 0.7956  loss_bbox_7: 0.1401  loss_giou_7: 0.5493  loss_ce_dn_7: 0.3733  loss_mask_dn_7: 0.0385  loss_dice_dn_7: 0.6897  loss_bbox_dn_7: 0.05332  loss_giou_dn_7: 0.3848  loss_ce_8: 1.605  loss_mask_8: 0.03719  loss_dice_8: 0.7819  loss_bbox_8: 0.1293  loss_giou_8: 0.5481  loss_ce_dn_8: 0.3761  loss_mask_dn_8: 0.03698  loss_dice_dn_8: 0.6985  loss_bbox_dn_8: 0.05301  loss_giou_dn_8: 0.3844  loss_ce_interm: 1.889  loss_mask_interm: 0.03601  loss_dice_interm: 0.8846  loss_bbox_interm: 0.1732  loss_giou_interm: 0.6674  time: 2.7002  data_time: 0.6881  lr: 0.0001  max_mem: 6620M\n",
            "[05/20 16:38:48 d2.utils.events]:  eta: 3:19:27  iter: 599  total_loss: 51.42  loss_ce: 1.437  loss_mask: 0.03638  loss_dice: 0.484  loss_bbox: 0.07102  loss_giou: 0.3126  loss_ce_dn: 0.4424  loss_mask_dn: 0.04941  loss_dice_dn: 0.5402  loss_bbox_dn: 0.07447  loss_giou_dn: 0.2593  loss_ce_0: 1.524  loss_mask_0: 0.06024  loss_dice_0: 0.5695  loss_bbox_0: 0.0878  loss_giou_0: 0.3907  loss_ce_dn_0: 1.404  loss_mask_dn_0: 0.2999  loss_dice_dn_0: 2.992  loss_bbox_dn_0: 0.3065  loss_giou_dn_0: 0.8544  loss_ce_1: 1.603  loss_mask_1: 0.05951  loss_dice_1: 0.5414  loss_bbox_1: 0.0827  loss_giou_1: 0.2926  loss_ce_dn_1: 0.4242  loss_mask_dn_1: 0.04298  loss_dice_dn_1: 0.6323  loss_bbox_dn_1: 0.09819  loss_giou_dn_1: 0.4088  loss_ce_2: 1.656  loss_mask_2: 0.04944  loss_dice_2: 0.4529  loss_bbox_2: 0.07703  loss_giou_2: 0.2494  loss_ce_dn_2: 0.4007  loss_mask_dn_2: 0.04535  loss_dice_dn_2: 0.5535  loss_bbox_dn_2: 0.07695  loss_giou_dn_2: 0.319  loss_ce_3: 1.508  loss_mask_3: 0.03784  loss_dice_3: 0.5643  loss_bbox_3: 0.07274  loss_giou_3: 0.2905  loss_ce_dn_3: 0.4106  loss_mask_dn_3: 0.04573  loss_dice_dn_3: 0.5565  loss_bbox_dn_3: 0.08058  loss_giou_dn_3: 0.2963  loss_ce_4: 1.467  loss_mask_4: 0.03976  loss_dice_4: 0.4983  loss_bbox_4: 0.07286  loss_giou_4: 0.299  loss_ce_dn_4: 0.406  loss_mask_dn_4: 0.04815  loss_dice_dn_4: 0.5572  loss_bbox_dn_4: 0.07471  loss_giou_dn_4: 0.2775  loss_ce_5: 1.504  loss_mask_5: 0.04571  loss_dice_5: 0.5452  loss_bbox_5: 0.07494  loss_giou_5: 0.2831  loss_ce_dn_5: 0.3933  loss_mask_dn_5: 0.04736  loss_dice_dn_5: 0.5358  loss_bbox_dn_5: 0.07439  loss_giou_dn_5: 0.2636  loss_ce_6: 1.47  loss_mask_6: 0.04243  loss_dice_6: 0.5589  loss_bbox_6: 0.07954  loss_giou_6: 0.2869  loss_ce_dn_6: 0.4235  loss_mask_dn_6: 0.0442  loss_dice_dn_6: 0.529  loss_bbox_dn_6: 0.07475  loss_giou_dn_6: 0.2679  loss_ce_7: 1.449  loss_mask_7: 0.03467  loss_dice_7: 0.539  loss_bbox_7: 0.07277  loss_giou_7: 0.2865  loss_ce_dn_7: 0.4351  loss_mask_dn_7: 0.05089  loss_dice_dn_7: 0.5475  loss_bbox_dn_7: 0.0757  loss_giou_dn_7: 0.2603  loss_ce_8: 1.482  loss_mask_8: 0.0372  loss_dice_8: 0.4805  loss_bbox_8: 0.07032  loss_giou_8: 0.3057  loss_ce_dn_8: 0.4436  loss_mask_dn_8: 0.04726  loss_dice_dn_8: 0.5409  loss_bbox_dn_8: 0.07517  loss_giou_dn_8: 0.2585  loss_ce_interm: 1.727  loss_mask_interm: 0.04167  loss_dice_interm: 0.6289  loss_bbox_interm: 0.1412  loss_giou_interm: 0.4926  time: 2.6861  data_time: 0.6593  lr: 0.0001  max_mem: 6620M\n",
            "[05/20 16:39:24 d2.utils.events]:  eta: 3:15:41  iter: 619  total_loss: 52.76  loss_ce: 1.477  loss_mask: 0.05837  loss_dice: 0.7103  loss_bbox: 0.1241  loss_giou: 0.4328  loss_ce_dn: 0.3511  loss_mask_dn: 0.05205  loss_dice_dn: 0.7234  loss_bbox_dn: 0.06612  loss_giou_dn: 0.3618  loss_ce_0: 1.734  loss_mask_0: 0.07467  loss_dice_0: 0.7948  loss_bbox_0: 0.1615  loss_giou_0: 0.5427  loss_ce_dn_0: 1.564  loss_mask_dn_0: 0.2635  loss_dice_dn_0: 2.906  loss_bbox_dn_0: 0.3196  loss_giou_dn_0: 0.8585  loss_ce_1: 1.729  loss_mask_1: 0.05656  loss_dice_1: 0.7532  loss_bbox_1: 0.1055  loss_giou_1: 0.4827  loss_ce_dn_1: 0.3903  loss_mask_dn_1: 0.06465  loss_dice_dn_1: 0.7678  loss_bbox_dn_1: 0.1044  loss_giou_dn_1: 0.4631  loss_ce_2: 1.658  loss_mask_2: 0.05283  loss_dice_2: 0.5945  loss_bbox_2: 0.1548  loss_giou_2: 0.435  loss_ce_dn_2: 0.3837  loss_mask_dn_2: 0.05265  loss_dice_dn_2: 0.7781  loss_bbox_dn_2: 0.07728  loss_giou_dn_2: 0.3961  loss_ce_3: 1.566  loss_mask_3: 0.06254  loss_dice_3: 0.7846  loss_bbox_3: 0.1482  loss_giou_3: 0.4575  loss_ce_dn_3: 0.3547  loss_mask_dn_3: 0.05317  loss_dice_dn_3: 0.7455  loss_bbox_dn_3: 0.06678  loss_giou_dn_3: 0.3823  loss_ce_4: 1.508  loss_mask_4: 0.05973  loss_dice_4: 0.719  loss_bbox_4: 0.1089  loss_giou_4: 0.4605  loss_ce_dn_4: 0.3528  loss_mask_dn_4: 0.05333  loss_dice_dn_4: 0.7499  loss_bbox_dn_4: 0.06944  loss_giou_dn_4: 0.371  loss_ce_5: 1.485  loss_mask_5: 0.07042  loss_dice_5: 0.8356  loss_bbox_5: 0.1344  loss_giou_5: 0.4558  loss_ce_dn_5: 0.3332  loss_mask_dn_5: 0.05409  loss_dice_dn_5: 0.7294  loss_bbox_dn_5: 0.06687  loss_giou_dn_5: 0.3647  loss_ce_6: 1.402  loss_mask_6: 0.05834  loss_dice_6: 0.7527  loss_bbox_6: 0.1221  loss_giou_6: 0.4437  loss_ce_dn_6: 0.3391  loss_mask_dn_6: 0.05406  loss_dice_dn_6: 0.7254  loss_bbox_dn_6: 0.06703  loss_giou_dn_6: 0.3622  loss_ce_7: 1.427  loss_mask_7: 0.06893  loss_dice_7: 0.7646  loss_bbox_7: 0.1528  loss_giou_7: 0.4335  loss_ce_dn_7: 0.3532  loss_mask_dn_7: 0.05246  loss_dice_dn_7: 0.7336  loss_bbox_dn_7: 0.0661  loss_giou_dn_7: 0.3662  loss_ce_8: 1.4  loss_mask_8: 0.05931  loss_dice_8: 0.8525  loss_bbox_8: 0.1251  loss_giou_8: 0.431  loss_ce_dn_8: 0.3411  loss_mask_dn_8: 0.05286  loss_dice_dn_8: 0.7359  loss_bbox_dn_8: 0.06779  loss_giou_dn_8: 0.3639  loss_ce_interm: 1.606  loss_mask_interm: 0.06675  loss_dice_interm: 0.8997  loss_bbox_interm: 0.1648  loss_giou_interm: 0.5407  time: 2.6574  data_time: 0.1016  lr: 0.0001  max_mem: 6620M\n",
            "[05/20 16:40:01 d2.utils.events]:  eta: 3:13:39  iter: 639  total_loss: 58.12  loss_ce: 1.424  loss_mask: 0.07612  loss_dice: 0.566  loss_bbox: 0.06255  loss_giou: 0.3014  loss_ce_dn: 0.3596  loss_mask_dn: 0.06073  loss_dice_dn: 0.7365  loss_bbox_dn: 0.08331  loss_giou_dn: 0.3013  loss_ce_0: 1.63  loss_mask_0: 0.07309  loss_dice_0: 0.7082  loss_bbox_0: 0.09726  loss_giou_0: 0.3503  loss_ce_dn_0: 1.325  loss_mask_dn_0: 0.1535  loss_dice_dn_0: 2.434  loss_bbox_dn_0: 0.3363  loss_giou_dn_0: 0.854  loss_ce_1: 1.642  loss_mask_1: 0.07273  loss_dice_1: 0.7575  loss_bbox_1: 0.07761  loss_giou_1: 0.3503  loss_ce_dn_1: 0.3839  loss_mask_dn_1: 0.05483  loss_dice_dn_1: 0.7518  loss_bbox_dn_1: 0.109  loss_giou_dn_1: 0.4277  loss_ce_2: 1.529  loss_mask_2: 0.05867  loss_dice_2: 0.7309  loss_bbox_2: 0.08326  loss_giou_2: 0.3539  loss_ce_dn_2: 0.3592  loss_mask_dn_2: 0.05839  loss_dice_dn_2: 0.6863  loss_bbox_dn_2: 0.09936  loss_giou_dn_2: 0.3653  loss_ce_3: 1.531  loss_mask_3: 0.05078  loss_dice_3: 0.5837  loss_bbox_3: 0.05758  loss_giou_3: 0.3468  loss_ce_dn_3: 0.3496  loss_mask_dn_3: 0.06067  loss_dice_dn_3: 0.6719  loss_bbox_dn_3: 0.09232  loss_giou_dn_3: 0.3305  loss_ce_4: 1.481  loss_mask_4: 0.07125  loss_dice_4: 0.5317  loss_bbox_4: 0.06808  loss_giou_4: 0.3215  loss_ce_dn_4: 0.3504  loss_mask_dn_4: 0.06153  loss_dice_dn_4: 0.6541  loss_bbox_dn_4: 0.09086  loss_giou_dn_4: 0.3151  loss_ce_5: 1.422  loss_mask_5: 0.06641  loss_dice_5: 0.6356  loss_bbox_5: 0.06709  loss_giou_5: 0.3054  loss_ce_dn_5: 0.3316  loss_mask_dn_5: 0.05778  loss_dice_dn_5: 0.6739  loss_bbox_dn_5: 0.08621  loss_giou_dn_5: 0.298  loss_ce_6: 1.443  loss_mask_6: 0.06572  loss_dice_6: 0.6968  loss_bbox_6: 0.06389  loss_giou_6: 0.3003  loss_ce_dn_6: 0.3255  loss_mask_dn_6: 0.05945  loss_dice_dn_6: 0.6107  loss_bbox_dn_6: 0.08693  loss_giou_dn_6: 0.2979  loss_ce_7: 1.385  loss_mask_7: 0.0668  loss_dice_7: 0.6328  loss_bbox_7: 0.06359  loss_giou_7: 0.3034  loss_ce_dn_7: 0.3455  loss_mask_dn_7: 0.05866  loss_dice_dn_7: 0.648  loss_bbox_dn_7: 0.08636  loss_giou_dn_7: 0.3057  loss_ce_8: 1.4  loss_mask_8: 0.06701  loss_dice_8: 0.667  loss_bbox_8: 0.06465  loss_giou_8: 0.2974  loss_ce_dn_8: 0.3454  loss_mask_dn_8: 0.06085  loss_dice_dn_8: 0.6611  loss_bbox_dn_8: 0.08522  loss_giou_dn_8: 0.3052  loss_ce_interm: 1.681  loss_mask_interm: 0.0706  loss_dice_interm: 0.687  loss_bbox_interm: 0.1428  loss_giou_interm: 0.4998  time: 2.6324  data_time: 0.0758  lr: 0.0001  max_mem: 6620M\n",
            "[05/20 16:40:38 d2.utils.events]:  eta: 3:10:44  iter: 659  total_loss: 48.08  loss_ce: 1.367  loss_mask: 0.07927  loss_dice: 0.5256  loss_bbox: 0.08012  loss_giou: 0.3273  loss_ce_dn: 0.344  loss_mask_dn: 0.07602  loss_dice_dn: 0.535  loss_bbox_dn: 0.05094  loss_giou_dn: 0.2835  loss_ce_0: 1.623  loss_mask_0: 0.07299  loss_dice_0: 0.5041  loss_bbox_0: 0.08657  loss_giou_0: 0.3085  loss_ce_dn_0: 1.424  loss_mask_dn_0: 0.197  loss_dice_dn_0: 2.272  loss_bbox_dn_0: 0.3964  loss_giou_dn_0: 0.8512  loss_ce_1: 1.565  loss_mask_1: 0.07116  loss_dice_1: 0.5733  loss_bbox_1: 0.06978  loss_giou_1: 0.2693  loss_ce_dn_1: 0.3512  loss_mask_dn_1: 0.07747  loss_dice_dn_1: 0.524  loss_bbox_dn_1: 0.1275  loss_giou_dn_1: 0.3999  loss_ce_2: 1.567  loss_mask_2: 0.0631  loss_dice_2: 0.5114  loss_bbox_2: 0.07974  loss_giou_2: 0.2902  loss_ce_dn_2: 0.3136  loss_mask_dn_2: 0.08228  loss_dice_dn_2: 0.5087  loss_bbox_dn_2: 0.09319  loss_giou_dn_2: 0.3566  loss_ce_3: 1.374  loss_mask_3: 0.06512  loss_dice_3: 0.6061  loss_bbox_3: 0.0753  loss_giou_3: 0.2887  loss_ce_dn_3: 0.2971  loss_mask_dn_3: 0.07696  loss_dice_dn_3: 0.5133  loss_bbox_dn_3: 0.0741  loss_giou_dn_3: 0.313  loss_ce_4: 1.459  loss_mask_4: 0.06301  loss_dice_4: 0.6219  loss_bbox_4: 0.08433  loss_giou_4: 0.2931  loss_ce_dn_4: 0.2923  loss_mask_dn_4: 0.07058  loss_dice_dn_4: 0.4819  loss_bbox_dn_4: 0.06527  loss_giou_dn_4: 0.3056  loss_ce_5: 1.359  loss_mask_5: 0.06563  loss_dice_5: 0.6437  loss_bbox_5: 0.08022  loss_giou_5: 0.3001  loss_ce_dn_5: 0.3002  loss_mask_dn_5: 0.07065  loss_dice_dn_5: 0.4903  loss_bbox_dn_5: 0.05878  loss_giou_dn_5: 0.2792  loss_ce_6: 1.304  loss_mask_6: 0.064  loss_dice_6: 0.4956  loss_bbox_6: 0.07179  loss_giou_6: 0.3024  loss_ce_dn_6: 0.2802  loss_mask_dn_6: 0.06986  loss_dice_dn_6: 0.504  loss_bbox_dn_6: 0.05838  loss_giou_dn_6: 0.2886  loss_ce_7: 1.31  loss_mask_7: 0.06624  loss_dice_7: 0.5378  loss_bbox_7: 0.06986  loss_giou_7: 0.2868  loss_ce_dn_7: 0.3154  loss_mask_dn_7: 0.07365  loss_dice_dn_7: 0.5343  loss_bbox_dn_7: 0.0538  loss_giou_dn_7: 0.2905  loss_ce_8: 1.352  loss_mask_8: 0.07854  loss_dice_8: 0.5786  loss_bbox_8: 0.07834  loss_giou_8: 0.3208  loss_ce_dn_8: 0.3303  loss_mask_dn_8: 0.07469  loss_dice_dn_8: 0.5234  loss_bbox_dn_8: 0.05074  loss_giou_dn_8: 0.2861  loss_ce_interm: 1.56  loss_mask_interm: 0.07669  loss_dice_interm: 0.5198  loss_bbox_interm: 0.1244  loss_giou_interm: 0.4014  time: 2.6083  data_time: 0.0417  lr: 0.0001  max_mem: 6620M\n",
            "[05/20 16:41:17 d2.utils.events]:  eta: 3:08:14  iter: 679  total_loss: 52.15  loss_ce: 1.603  loss_mask: 0.04563  loss_dice: 0.6244  loss_bbox: 0.0657  loss_giou: 0.3767  loss_ce_dn: 0.2868  loss_mask_dn: 0.04571  loss_dice_dn: 0.5658  loss_bbox_dn: 0.058  loss_giou_dn: 0.3075  loss_ce_0: 1.592  loss_mask_0: 0.05291  loss_dice_0: 0.6613  loss_bbox_0: 0.07836  loss_giou_0: 0.4099  loss_ce_dn_0: 1.258  loss_mask_dn_0: 0.3585  loss_dice_dn_0: 2.534  loss_bbox_dn_0: 0.3284  loss_giou_dn_0: 0.8494  loss_ce_1: 1.529  loss_mask_1: 0.05094  loss_dice_1: 0.5966  loss_bbox_1: 0.07416  loss_giou_1: 0.3815  loss_ce_dn_1: 0.3388  loss_mask_dn_1: 0.04535  loss_dice_dn_1: 0.6179  loss_bbox_dn_1: 0.1122  loss_giou_dn_1: 0.4239  loss_ce_2: 1.753  loss_mask_2: 0.05839  loss_dice_2: 0.613  loss_bbox_2: 0.1071  loss_giou_2: 0.3752  loss_ce_dn_2: 0.3281  loss_mask_dn_2: 0.04367  loss_dice_dn_2: 0.6299  loss_bbox_dn_2: 0.07343  loss_giou_dn_2: 0.3779  loss_ce_3: 1.597  loss_mask_3: 0.04446  loss_dice_3: 0.5887  loss_bbox_3: 0.08404  loss_giou_3: 0.3944  loss_ce_dn_3: 0.2794  loss_mask_dn_3: 0.04555  loss_dice_dn_3: 0.613  loss_bbox_dn_3: 0.06072  loss_giou_dn_3: 0.3313  loss_ce_4: 1.489  loss_mask_4: 0.05145  loss_dice_4: 0.664  loss_bbox_4: 0.07242  loss_giou_4: 0.398  loss_ce_dn_4: 0.2997  loss_mask_dn_4: 0.04613  loss_dice_dn_4: 0.6011  loss_bbox_dn_4: 0.06046  loss_giou_dn_4: 0.3242  loss_ce_5: 1.461  loss_mask_5: 0.05289  loss_dice_5: 0.5962  loss_bbox_5: 0.07922  loss_giou_5: 0.3741  loss_ce_dn_5: 0.3041  loss_mask_dn_5: 0.04418  loss_dice_dn_5: 0.5919  loss_bbox_dn_5: 0.06007  loss_giou_dn_5: 0.3114  loss_ce_6: 1.605  loss_mask_6: 0.0507  loss_dice_6: 0.5538  loss_bbox_6: 0.08286  loss_giou_6: 0.388  loss_ce_dn_6: 0.2916  loss_mask_dn_6: 0.04217  loss_dice_dn_6: 0.5864  loss_bbox_dn_6: 0.06087  loss_giou_dn_6: 0.3083  loss_ce_7: 1.599  loss_mask_7: 0.05216  loss_dice_7: 0.5092  loss_bbox_7: 0.07643  loss_giou_7: 0.3803  loss_ce_dn_7: 0.2683  loss_mask_dn_7: 0.04456  loss_dice_dn_7: 0.6086  loss_bbox_dn_7: 0.06026  loss_giou_dn_7: 0.3082  loss_ce_8: 1.605  loss_mask_8: 0.0498  loss_dice_8: 0.4744  loss_bbox_8: 0.071  loss_giou_8: 0.3733  loss_ce_dn_8: 0.2776  loss_mask_dn_8: 0.04462  loss_dice_dn_8: 0.5583  loss_bbox_dn_8: 0.06072  loss_giou_dn_8: 0.3089  loss_ce_interm: 1.673  loss_mask_interm: 0.04777  loss_dice_interm: 0.6243  loss_bbox_interm: 0.1145  loss_giou_interm: 0.4246  time: 2.5881  data_time: 0.1496  lr: 0.0001  max_mem: 6620M\n",
            "[05/20 16:41:53 d2.utils.events]:  eta: 3:05:57  iter: 699  total_loss: 64.92  loss_ce: 1.597  loss_mask: 0.02726  loss_dice: 0.9999  loss_bbox: 0.07383  loss_giou: 0.5019  loss_ce_dn: 0.4504  loss_mask_dn: 0.02115  loss_dice_dn: 0.9493  loss_bbox_dn: 0.04511  loss_giou_dn: 0.4329  loss_ce_0: 1.732  loss_mask_0: 0.02231  loss_dice_0: 1.06  loss_bbox_0: 0.06802  loss_giou_0: 0.6239  loss_ce_dn_0: 1.388  loss_mask_dn_0: 0.06119  loss_dice_dn_0: 2.907  loss_bbox_dn_0: 0.1631  loss_giou_dn_0: 0.8523  loss_ce_1: 1.657  loss_mask_1: 0.02563  loss_dice_1: 1.092  loss_bbox_1: 0.06716  loss_giou_1: 0.5723  loss_ce_dn_1: 0.4577  loss_mask_dn_1: 0.02052  loss_dice_dn_1: 1.001  loss_bbox_dn_1: 0.05457  loss_giou_dn_1: 0.5287  loss_ce_2: 1.655  loss_mask_2: 0.02291  loss_dice_2: 1.086  loss_bbox_2: 0.0913  loss_giou_2: 0.576  loss_ce_dn_2: 0.4397  loss_mask_dn_2: 0.02242  loss_dice_dn_2: 1.009  loss_bbox_dn_2: 0.0504  loss_giou_dn_2: 0.478  loss_ce_3: 1.631  loss_mask_3: 0.02615  loss_dice_3: 0.9983  loss_bbox_3: 0.08564  loss_giou_3: 0.5451  loss_ce_dn_3: 0.4425  loss_mask_dn_3: 0.02273  loss_dice_dn_3: 0.9582  loss_bbox_dn_3: 0.04671  loss_giou_dn_3: 0.4403  loss_ce_4: 1.675  loss_mask_4: 0.02561  loss_dice_4: 1  loss_bbox_4: 0.09924  loss_giou_4: 0.5642  loss_ce_dn_4: 0.4338  loss_mask_dn_4: 0.02308  loss_dice_dn_4: 0.963  loss_bbox_dn_4: 0.04664  loss_giou_dn_4: 0.4385  loss_ce_5: 1.605  loss_mask_5: 0.02091  loss_dice_5: 1.048  loss_bbox_5: 0.07269  loss_giou_5: 0.5198  loss_ce_dn_5: 0.4448  loss_mask_dn_5: 0.0226  loss_dice_dn_5: 0.9294  loss_bbox_dn_5: 0.04488  loss_giou_dn_5: 0.4389  loss_ce_6: 1.579  loss_mask_6: 0.02211  loss_dice_6: 0.9785  loss_bbox_6: 0.09356  loss_giou_6: 0.5775  loss_ce_dn_6: 0.44  loss_mask_dn_6: 0.022  loss_dice_dn_6: 0.9506  loss_bbox_dn_6: 0.04459  loss_giou_dn_6: 0.4297  loss_ce_7: 1.593  loss_mask_7: 0.02235  loss_dice_7: 1.009  loss_bbox_7: 0.07183  loss_giou_7: 0.5276  loss_ce_dn_7: 0.45  loss_mask_dn_7: 0.02173  loss_dice_dn_7: 0.9242  loss_bbox_dn_7: 0.04413  loss_giou_dn_7: 0.4277  loss_ce_8: 1.596  loss_mask_8: 0.02074  loss_dice_8: 0.9442  loss_bbox_8: 0.07628  loss_giou_8: 0.5039  loss_ce_dn_8: 0.4515  loss_mask_dn_8: 0.02044  loss_dice_dn_8: 0.9544  loss_bbox_dn_8: 0.0449  loss_giou_dn_8: 0.4413  loss_ce_interm: 1.786  loss_mask_interm: 0.02861  loss_dice_interm: 1.046  loss_bbox_interm: 0.1184  loss_giou_interm: 0.7756  time: 2.5658  data_time: 0.1096  lr: 0.0001  max_mem: 6620M\n",
            "[05/20 16:42:30 d2.utils.events]:  eta: 3:03:02  iter: 719  total_loss: 52.07  loss_ce: 1.382  loss_mask: 0.03913  loss_dice: 0.7034  loss_bbox: 0.0736  loss_giou: 0.3343  loss_ce_dn: 0.3668  loss_mask_dn: 0.04397  loss_dice_dn: 0.7028  loss_bbox_dn: 0.06219  loss_giou_dn: 0.3811  loss_ce_0: 1.658  loss_mask_0: 0.04889  loss_dice_0: 0.7049  loss_bbox_0: 0.1056  loss_giou_0: 0.4743  loss_ce_dn_0: 1.181  loss_mask_dn_0: 0.1971  loss_dice_dn_0: 2.46  loss_bbox_dn_0: 0.2993  loss_giou_dn_0: 0.8541  loss_ce_1: 1.745  loss_mask_1: 0.0439  loss_dice_1: 0.84  loss_bbox_1: 0.08585  loss_giou_1: 0.3273  loss_ce_dn_1: 0.4103  loss_mask_dn_1: 0.04308  loss_dice_dn_1: 0.8084  loss_bbox_dn_1: 0.1048  loss_giou_dn_1: 0.454  loss_ce_2: 1.539  loss_mask_2: 0.03417  loss_dice_2: 0.7158  loss_bbox_2: 0.07276  loss_giou_2: 0.3214  loss_ce_dn_2: 0.3826  loss_mask_dn_2: 0.0376  loss_dice_dn_2: 0.6901  loss_bbox_dn_2: 0.08582  loss_giou_dn_2: 0.3788  loss_ce_3: 1.557  loss_mask_3: 0.03797  loss_dice_3: 0.73  loss_bbox_3: 0.05538  loss_giou_3: 0.3384  loss_ce_dn_3: 0.3946  loss_mask_dn_3: 0.03814  loss_dice_dn_3: 0.6293  loss_bbox_dn_3: 0.06909  loss_giou_dn_3: 0.3565  loss_ce_4: 1.494  loss_mask_4: 0.03879  loss_dice_4: 0.6727  loss_bbox_4: 0.06528  loss_giou_4: 0.3484  loss_ce_dn_4: 0.3855  loss_mask_dn_4: 0.04163  loss_dice_dn_4: 0.7079  loss_bbox_dn_4: 0.0626  loss_giou_dn_4: 0.3906  loss_ce_5: 1.518  loss_mask_5: 0.03838  loss_dice_5: 0.7385  loss_bbox_5: 0.06226  loss_giou_5: 0.339  loss_ce_dn_5: 0.3583  loss_mask_dn_5: 0.04439  loss_dice_dn_5: 0.7348  loss_bbox_dn_5: 0.06367  loss_giou_dn_5: 0.3413  loss_ce_6: 1.431  loss_mask_6: 0.03551  loss_dice_6: 0.7157  loss_bbox_6: 0.05914  loss_giou_6: 0.3209  loss_ce_dn_6: 0.3529  loss_mask_dn_6: 0.04238  loss_dice_dn_6: 0.712  loss_bbox_dn_6: 0.06302  loss_giou_dn_6: 0.3728  loss_ce_7: 1.461  loss_mask_7: 0.04822  loss_dice_7: 0.8103  loss_bbox_7: 0.07087  loss_giou_7: 0.326  loss_ce_dn_7: 0.3642  loss_mask_dn_7: 0.04458  loss_dice_dn_7: 0.6869  loss_bbox_dn_7: 0.06179  loss_giou_dn_7: 0.368  loss_ce_8: 1.377  loss_mask_8: 0.04074  loss_dice_8: 0.6412  loss_bbox_8: 0.07111  loss_giou_8: 0.3363  loss_ce_dn_8: 0.3652  loss_mask_dn_8: 0.04465  loss_dice_dn_8: 0.6937  loss_bbox_dn_8: 0.06272  loss_giou_dn_8: 0.3756  loss_ce_interm: 1.611  loss_mask_interm: 0.04429  loss_dice_interm: 0.7957  loss_bbox_interm: 0.1407  loss_giou_interm: 0.4928  time: 2.5453  data_time: 0.0639  lr: 0.0001  max_mem: 6620M\n",
            "[05/20 16:43:09 d2.utils.events]:  eta: 3:00:50  iter: 739  total_loss: 63.64  loss_ce: 1.657  loss_mask: 0.03995  loss_dice: 0.6967  loss_bbox: 0.1087  loss_giou: 0.4534  loss_ce_dn: 0.3527  loss_mask_dn: 0.03822  loss_dice_dn: 0.7567  loss_bbox_dn: 0.05691  loss_giou_dn: 0.4079  loss_ce_0: 1.661  loss_mask_0: 0.04529  loss_dice_0: 0.8721  loss_bbox_0: 0.1185  loss_giou_0: 0.5686  loss_ce_dn_0: 1.302  loss_mask_dn_0: 0.2081  loss_dice_dn_0: 3.36  loss_bbox_dn_0: 0.2381  loss_giou_dn_0: 0.8525  loss_ce_1: 1.867  loss_mask_1: 0.04957  loss_dice_1: 0.973  loss_bbox_1: 0.1053  loss_giou_1: 0.543  loss_ce_dn_1: 0.3675  loss_mask_dn_1: 0.03703  loss_dice_dn_1: 0.8511  loss_bbox_dn_1: 0.08189  loss_giou_dn_1: 0.4833  loss_ce_2: 1.693  loss_mask_2: 0.03871  loss_dice_2: 0.8777  loss_bbox_2: 0.0821  loss_giou_2: 0.434  loss_ce_dn_2: 0.3672  loss_mask_dn_2: 0.03982  loss_dice_dn_2: 0.8466  loss_bbox_dn_2: 0.06329  loss_giou_dn_2: 0.4329  loss_ce_3: 1.673  loss_mask_3: 0.0365  loss_dice_3: 0.8333  loss_bbox_3: 0.09334  loss_giou_3: 0.433  loss_ce_dn_3: 0.3373  loss_mask_dn_3: 0.04109  loss_dice_dn_3: 0.7916  loss_bbox_dn_3: 0.05763  loss_giou_dn_3: 0.4238  loss_ce_4: 1.599  loss_mask_4: 0.03943  loss_dice_4: 0.9335  loss_bbox_4: 0.1024  loss_giou_4: 0.4569  loss_ce_dn_4: 0.344  loss_mask_dn_4: 0.03922  loss_dice_dn_4: 0.7679  loss_bbox_dn_4: 0.05522  loss_giou_dn_4: 0.4155  loss_ce_5: 1.569  loss_mask_5: 0.03778  loss_dice_5: 0.8526  loss_bbox_5: 0.116  loss_giou_5: 0.4749  loss_ce_dn_5: 0.3536  loss_mask_dn_5: 0.0379  loss_dice_dn_5: 0.7823  loss_bbox_dn_5: 0.05243  loss_giou_dn_5: 0.413  loss_ce_6: 1.605  loss_mask_6: 0.04718  loss_dice_6: 0.8041  loss_bbox_6: 0.1142  loss_giou_6: 0.4552  loss_ce_dn_6: 0.3655  loss_mask_dn_6: 0.03772  loss_dice_dn_6: 0.7787  loss_bbox_dn_6: 0.05392  loss_giou_dn_6: 0.4142  loss_ce_7: 1.602  loss_mask_7: 0.04107  loss_dice_7: 0.8507  loss_bbox_7: 0.1034  loss_giou_7: 0.4583  loss_ce_dn_7: 0.3583  loss_mask_dn_7: 0.04  loss_dice_dn_7: 0.7729  loss_bbox_dn_7: 0.05608  loss_giou_dn_7: 0.3965  loss_ce_8: 1.623  loss_mask_8: 0.03946  loss_dice_8: 0.8466  loss_bbox_8: 0.1019  loss_giou_8: 0.4473  loss_ce_dn_8: 0.3484  loss_mask_dn_8: 0.03825  loss_dice_dn_8: 0.7684  loss_bbox_dn_8: 0.0569  loss_giou_dn_8: 0.4056  loss_ce_interm: 1.804  loss_mask_interm: 0.05258  loss_dice_interm: 0.9378  loss_bbox_interm: 0.139  loss_giou_interm: 0.6711  time: 2.5293  data_time: 0.1680  lr: 0.0001  max_mem: 6620M\n",
            "[05/20 16:43:46 d2.utils.events]:  eta: 2:57:51  iter: 759  total_loss: 48.82  loss_ce: 1.567  loss_mask: 0.0363  loss_dice: 0.7357  loss_bbox: 0.09714  loss_giou: 0.3843  loss_ce_dn: 0.3931  loss_mask_dn: 0.04361  loss_dice_dn: 0.6268  loss_bbox_dn: 0.05664  loss_giou_dn: 0.3368  loss_ce_0: 1.651  loss_mask_0: 0.05406  loss_dice_0: 0.7409  loss_bbox_0: 0.1504  loss_giou_0: 0.4908  loss_ce_dn_0: 1.179  loss_mask_dn_0: 0.1658  loss_dice_dn_0: 2.55  loss_bbox_dn_0: 0.3141  loss_giou_dn_0: 0.8524  loss_ce_1: 1.627  loss_mask_1: 0.0423  loss_dice_1: 0.7911  loss_bbox_1: 0.0962  loss_giou_1: 0.4074  loss_ce_dn_1: 0.3928  loss_mask_dn_1: 0.05414  loss_dice_dn_1: 0.829  loss_bbox_dn_1: 0.09309  loss_giou_dn_1: 0.4419  loss_ce_2: 1.692  loss_mask_2: 0.03651  loss_dice_2: 0.5677  loss_bbox_2: 0.09434  loss_giou_2: 0.4198  loss_ce_dn_2: 0.3914  loss_mask_dn_2: 0.043  loss_dice_dn_2: 0.6839  loss_bbox_dn_2: 0.06757  loss_giou_dn_2: 0.3579  loss_ce_3: 1.616  loss_mask_3: 0.03698  loss_dice_3: 0.6909  loss_bbox_3: 0.09431  loss_giou_3: 0.4558  loss_ce_dn_3: 0.4009  loss_mask_dn_3: 0.04242  loss_dice_dn_3: 0.664  loss_bbox_dn_3: 0.06164  loss_giou_dn_3: 0.3502  loss_ce_4: 1.654  loss_mask_4: 0.03593  loss_dice_4: 0.7942  loss_bbox_4: 0.07966  loss_giou_4: 0.4407  loss_ce_dn_4: 0.3879  loss_mask_dn_4: 0.04582  loss_dice_dn_4: 0.6881  loss_bbox_dn_4: 0.0618  loss_giou_dn_4: 0.342  loss_ce_5: 1.537  loss_mask_5: 0.0365  loss_dice_5: 0.6405  loss_bbox_5: 0.06911  loss_giou_5: 0.4537  loss_ce_dn_5: 0.3762  loss_mask_dn_5: 0.04315  loss_dice_dn_5: 0.6702  loss_bbox_dn_5: 0.05678  loss_giou_dn_5: 0.3428  loss_ce_6: 1.618  loss_mask_6: 0.03475  loss_dice_6: 0.7031  loss_bbox_6: 0.07527  loss_giou_6: 0.4158  loss_ce_dn_6: 0.3878  loss_mask_dn_6: 0.04353  loss_dice_dn_6: 0.6205  loss_bbox_dn_6: 0.05673  loss_giou_dn_6: 0.3468  loss_ce_7: 1.569  loss_mask_7: 0.04067  loss_dice_7: 0.6231  loss_bbox_7: 0.08391  loss_giou_7: 0.4126  loss_ce_dn_7: 0.389  loss_mask_dn_7: 0.04563  loss_dice_dn_7: 0.64  loss_bbox_dn_7: 0.05706  loss_giou_dn_7: 0.3477  loss_ce_8: 1.596  loss_mask_8: 0.03351  loss_dice_8: 0.6816  loss_bbox_8: 0.09737  loss_giou_8: 0.4138  loss_ce_dn_8: 0.3863  loss_mask_dn_8: 0.04568  loss_dice_dn_8: 0.6353  loss_bbox_dn_8: 0.05819  loss_giou_dn_8: 0.3421  loss_ce_interm: 1.708  loss_mask_interm: 0.0382  loss_dice_interm: 0.7338  loss_bbox_interm: 0.1172  loss_giou_interm: 0.4696  time: 2.5114  data_time: 0.1019  lr: 0.0001  max_mem: 6620M\n",
            "[05/20 16:44:21 d2.utils.events]:  eta: 2:55:08  iter: 779  total_loss: 57.94  loss_ce: 1.386  loss_mask: 0.03941  loss_dice: 0.8503  loss_bbox: 0.06948  loss_giou: 0.4878  loss_ce_dn: 0.3101  loss_mask_dn: 0.02933  loss_dice_dn: 0.8932  loss_bbox_dn: 0.05143  loss_giou_dn: 0.4136  loss_ce_0: 1.555  loss_mask_0: 0.03458  loss_dice_0: 0.9769  loss_bbox_0: 0.1007  loss_giou_0: 0.796  loss_ce_dn_0: 1.211  loss_mask_dn_0: 0.2002  loss_dice_dn_0: 2.767  loss_bbox_dn_0: 0.1868  loss_giou_dn_0: 0.8666  loss_ce_1: 1.618  loss_mask_1: 0.0423  loss_dice_1: 1.019  loss_bbox_1: 0.08958  loss_giou_1: 0.5784  loss_ce_dn_1: 0.3751  loss_mask_dn_1: 0.03101  loss_dice_dn_1: 0.9917  loss_bbox_dn_1: 0.07942  loss_giou_dn_1: 0.5335  loss_ce_2: 1.576  loss_mask_2: 0.03581  loss_dice_2: 0.9288  loss_bbox_2: 0.08497  loss_giou_2: 0.5773  loss_ce_dn_2: 0.3574  loss_mask_dn_2: 0.02901  loss_dice_dn_2: 0.9052  loss_bbox_dn_2: 0.07198  loss_giou_dn_2: 0.4514  loss_ce_3: 1.546  loss_mask_3: 0.03383  loss_dice_3: 1.018  loss_bbox_3: 0.07933  loss_giou_3: 0.5246  loss_ce_dn_3: 0.309  loss_mask_dn_3: 0.02823  loss_dice_dn_3: 0.8954  loss_bbox_dn_3: 0.05745  loss_giou_dn_3: 0.4159  loss_ce_4: 1.489  loss_mask_4: 0.04017  loss_dice_4: 0.85  loss_bbox_4: 0.095  loss_giou_4: 0.5194  loss_ce_dn_4: 0.3079  loss_mask_dn_4: 0.0277  loss_dice_dn_4: 0.862  loss_bbox_dn_4: 0.05365  loss_giou_dn_4: 0.4051  loss_ce_5: 1.452  loss_mask_5: 0.03551  loss_dice_5: 0.8963  loss_bbox_5: 0.07741  loss_giou_5: 0.4765  loss_ce_dn_5: 0.3078  loss_mask_dn_5: 0.0271  loss_dice_dn_5: 0.9087  loss_bbox_dn_5: 0.05219  loss_giou_dn_5: 0.4142  loss_ce_6: 1.438  loss_mask_6: 0.03735  loss_dice_6: 0.7856  loss_bbox_6: 0.07432  loss_giou_6: 0.4677  loss_ce_dn_6: 0.3027  loss_mask_dn_6: 0.02674  loss_dice_dn_6: 0.8757  loss_bbox_dn_6: 0.05504  loss_giou_dn_6: 0.4117  loss_ce_7: 1.415  loss_mask_7: 0.03961  loss_dice_7: 0.9112  loss_bbox_7: 0.07827  loss_giou_7: 0.4783  loss_ce_dn_7: 0.3047  loss_mask_dn_7: 0.03035  loss_dice_dn_7: 0.8802  loss_bbox_dn_7: 0.05228  loss_giou_dn_7: 0.4113  loss_ce_8: 1.418  loss_mask_8: 0.03662  loss_dice_8: 1.057  loss_bbox_8: 0.07649  loss_giou_8: 0.5024  loss_ce_dn_8: 0.3039  loss_mask_dn_8: 0.0297  loss_dice_dn_8: 0.9059  loss_bbox_dn_8: 0.0521  loss_giou_dn_8: 0.4133  loss_ce_interm: 1.555  loss_mask_interm: 0.03541  loss_dice_interm: 1.166  loss_bbox_interm: 0.1107  loss_giou_interm: 0.6472  time: 2.4913  data_time: 0.0709  lr: 0.0001  max_mem: 6620M\n",
            "[05/20 16:44:56 d2.utils.events]:  eta: 2:53:56  iter: 799  total_loss: 55.8  loss_ce: 1.372  loss_mask: 0.04892  loss_dice: 0.6422  loss_bbox: 0.08449  loss_giou: 0.5001  loss_ce_dn: 0.2628  loss_mask_dn: 0.04249  loss_dice_dn: 0.6703  loss_bbox_dn: 0.05957  loss_giou_dn: 0.345  loss_ce_0: 1.559  loss_mask_0: 0.04576  loss_dice_0: 0.7579  loss_bbox_0: 0.09012  loss_giou_0: 0.5343  loss_ce_dn_0: 1.174  loss_mask_dn_0: 0.2784  loss_dice_dn_0: 2.591  loss_bbox_dn_0: 0.2316  loss_giou_dn_0: 0.8635  loss_ce_1: 1.626  loss_mask_1: 0.03787  loss_dice_1: 0.6379  loss_bbox_1: 0.08108  loss_giou_1: 0.408  loss_ce_dn_1: 0.3399  loss_mask_dn_1: 0.05455  loss_dice_dn_1: 0.7258  loss_bbox_dn_1: 0.08614  loss_giou_dn_1: 0.4425  loss_ce_2: 1.498  loss_mask_2: 0.03607  loss_dice_2: 0.5831  loss_bbox_2: 0.08427  loss_giou_2: 0.395  loss_ce_dn_2: 0.2838  loss_mask_dn_2: 0.04437  loss_dice_dn_2: 0.6758  loss_bbox_dn_2: 0.08011  loss_giou_dn_2: 0.3866  loss_ce_3: 1.397  loss_mask_3: 0.04384  loss_dice_3: 0.65  loss_bbox_3: 0.08272  loss_giou_3: 0.3943  loss_ce_dn_3: 0.2722  loss_mask_dn_3: 0.0421  loss_dice_dn_3: 0.7316  loss_bbox_dn_3: 0.06967  loss_giou_dn_3: 0.3628  loss_ce_4: 1.393  loss_mask_4: 0.04254  loss_dice_4: 0.6648  loss_bbox_4: 0.08386  loss_giou_4: 0.3932  loss_ce_dn_4: 0.2615  loss_mask_dn_4: 0.039  loss_dice_dn_4: 0.6983  loss_bbox_dn_4: 0.06534  loss_giou_dn_4: 0.3685  loss_ce_5: 1.369  loss_mask_5: 0.04035  loss_dice_5: 0.635  loss_bbox_5: 0.07225  loss_giou_5: 0.3932  loss_ce_dn_5: 0.2533  loss_mask_dn_5: 0.04027  loss_dice_dn_5: 0.7223  loss_bbox_dn_5: 0.06352  loss_giou_dn_5: 0.3501  loss_ce_6: 1.363  loss_mask_6: 0.04063  loss_dice_6: 0.6681  loss_bbox_6: 0.08313  loss_giou_6: 0.3947  loss_ce_dn_6: 0.255  loss_mask_dn_6: 0.04015  loss_dice_dn_6: 0.6727  loss_bbox_dn_6: 0.06082  loss_giou_dn_6: 0.3528  loss_ce_7: 1.332  loss_mask_7: 0.05234  loss_dice_7: 0.7315  loss_bbox_7: 0.08675  loss_giou_7: 0.3927  loss_ce_dn_7: 0.2607  loss_mask_dn_7: 0.04101  loss_dice_dn_7: 0.6709  loss_bbox_dn_7: 0.06073  loss_giou_dn_7: 0.3485  loss_ce_8: 1.368  loss_mask_8: 0.04946  loss_dice_8: 0.8125  loss_bbox_8: 0.0839  loss_giou_8: 0.4475  loss_ce_dn_8: 0.264  loss_mask_dn_8: 0.04267  loss_dice_dn_8: 0.6699  loss_bbox_dn_8: 0.06021  loss_giou_dn_8: 0.347  loss_ce_interm: 1.63  loss_mask_interm: 0.04605  loss_dice_interm: 0.7199  loss_bbox_interm: 0.1239  loss_giou_interm: 0.4947  time: 2.4729  data_time: 0.0771  lr: 0.0001  max_mem: 6620M\n",
            "[05/20 16:45:31 d2.utils.events]:  eta: 2:51:52  iter: 819  total_loss: 51.76  loss_ce: 1.386  loss_mask: 0.06824  loss_dice: 0.5483  loss_bbox: 0.09622  loss_giou: 0.3387  loss_ce_dn: 0.2815  loss_mask_dn: 0.06586  loss_dice_dn: 0.5664  loss_bbox_dn: 0.08087  loss_giou_dn: 0.2677  loss_ce_0: 1.789  loss_mask_0: 0.08377  loss_dice_0: 0.8048  loss_bbox_0: 0.08862  loss_giou_0: 0.4064  loss_ce_dn_0: 1.21  loss_mask_dn_0: 0.2868  loss_dice_dn_0: 2.7  loss_bbox_dn_0: 0.3384  loss_giou_dn_0: 0.8556  loss_ce_1: 1.543  loss_mask_1: 0.06267  loss_dice_1: 0.7427  loss_bbox_1: 0.1268  loss_giou_1: 0.3778  loss_ce_dn_1: 0.3527  loss_mask_dn_1: 0.07223  loss_dice_dn_1: 0.8181  loss_bbox_dn_1: 0.1154  loss_giou_dn_1: 0.4105  loss_ce_2: 1.609  loss_mask_2: 0.06718  loss_dice_2: 0.7518  loss_bbox_2: 0.108  loss_giou_2: 0.3671  loss_ce_dn_2: 0.3051  loss_mask_dn_2: 0.06646  loss_dice_dn_2: 0.711  loss_bbox_dn_2: 0.09348  loss_giou_dn_2: 0.3345  loss_ce_3: 1.522  loss_mask_3: 0.06854  loss_dice_3: 0.646  loss_bbox_3: 0.1043  loss_giou_3: 0.351  loss_ce_dn_3: 0.3047  loss_mask_dn_3: 0.06232  loss_dice_dn_3: 0.6145  loss_bbox_dn_3: 0.08129  loss_giou_dn_3: 0.2963  loss_ce_4: 1.363  loss_mask_4: 0.07247  loss_dice_4: 0.6697  loss_bbox_4: 0.1059  loss_giou_4: 0.3658  loss_ce_dn_4: 0.2658  loss_mask_dn_4: 0.0617  loss_dice_dn_4: 0.5739  loss_bbox_dn_4: 0.08207  loss_giou_dn_4: 0.2858  loss_ce_5: 1.446  loss_mask_5: 0.07075  loss_dice_5: 0.4524  loss_bbox_5: 0.09188  loss_giou_5: 0.3582  loss_ce_dn_5: 0.2754  loss_mask_dn_5: 0.06614  loss_dice_dn_5: 0.6442  loss_bbox_dn_5: 0.07806  loss_giou_dn_5: 0.2654  loss_ce_6: 1.304  loss_mask_6: 0.06661  loss_dice_6: 0.5794  loss_bbox_6: 0.09069  loss_giou_6: 0.3614  loss_ce_dn_6: 0.259  loss_mask_dn_6: 0.06453  loss_dice_dn_6: 0.6015  loss_bbox_dn_6: 0.07699  loss_giou_dn_6: 0.2711  loss_ce_7: 1.253  loss_mask_7: 0.06386  loss_dice_7: 0.6286  loss_bbox_7: 0.09588  loss_giou_7: 0.3593  loss_ce_dn_7: 0.2718  loss_mask_dn_7: 0.06609  loss_dice_dn_7: 0.5657  loss_bbox_dn_7: 0.08141  loss_giou_dn_7: 0.2738  loss_ce_8: 1.281  loss_mask_8: 0.06743  loss_dice_8: 0.6655  loss_bbox_8: 0.09646  loss_giou_8: 0.3501  loss_ce_dn_8: 0.2746  loss_mask_dn_8: 0.06477  loss_dice_dn_8: 0.5489  loss_bbox_dn_8: 0.08059  loss_giou_dn_8: 0.271  loss_ce_interm: 1.647  loss_mask_interm: 0.08682  loss_dice_interm: 0.6389  loss_bbox_interm: 0.1709  loss_giou_interm: 0.4573  time: 2.4557  data_time: 0.1096  lr: 0.0001  max_mem: 6620M\n",
            "[05/20 16:46:06 d2.utils.events]:  eta: 2:48:17  iter: 839  total_loss: 59.22  loss_ce: 1.633  loss_mask: 0.04102  loss_dice: 0.6864  loss_bbox: 0.09012  loss_giou: 0.4977  loss_ce_dn: 0.328  loss_mask_dn: 0.03589  loss_dice_dn: 0.6058  loss_bbox_dn: 0.05423  loss_giou_dn: 0.3213  loss_ce_0: 1.798  loss_mask_0: 0.03202  loss_dice_0: 0.624  loss_bbox_0: 0.1105  loss_giou_0: 0.41  loss_ce_dn_0: 1.179  loss_mask_dn_0: 0.2398  loss_dice_dn_0: 2.622  loss_bbox_dn_0: 0.283  loss_giou_dn_0: 0.8586  loss_ce_1: 1.756  loss_mask_1: 0.03449  loss_dice_1: 0.6808  loss_bbox_1: 0.09662  loss_giou_1: 0.393  loss_ce_dn_1: 0.376  loss_mask_dn_1: 0.03432  loss_dice_dn_1: 0.6464  loss_bbox_dn_1: 0.09391  loss_giou_dn_1: 0.4298  loss_ce_2: 1.789  loss_mask_2: 0.03576  loss_dice_2: 0.6899  loss_bbox_2: 0.108  loss_giou_2: 0.4034  loss_ce_dn_2: 0.3425  loss_mask_dn_2: 0.03756  loss_dice_dn_2: 0.6335  loss_bbox_dn_2: 0.07337  loss_giou_dn_2: 0.3678  loss_ce_3: 1.643  loss_mask_3: 0.03353  loss_dice_3: 0.6318  loss_bbox_3: 0.0804  loss_giou_3: 0.4516  loss_ce_dn_3: 0.3217  loss_mask_dn_3: 0.03842  loss_dice_dn_3: 0.5984  loss_bbox_dn_3: 0.06131  loss_giou_dn_3: 0.3346  loss_ce_4: 1.502  loss_mask_4: 0.03485  loss_dice_4: 0.5927  loss_bbox_4: 0.08933  loss_giou_4: 0.4521  loss_ce_dn_4: 0.3285  loss_mask_dn_4: 0.03744  loss_dice_dn_4: 0.6222  loss_bbox_dn_4: 0.05852  loss_giou_dn_4: 0.3192  loss_ce_5: 1.509  loss_mask_5: 0.04471  loss_dice_5: 0.7109  loss_bbox_5: 0.1056  loss_giou_5: 0.4717  loss_ce_dn_5: 0.3207  loss_mask_dn_5: 0.03509  loss_dice_dn_5: 0.6379  loss_bbox_dn_5: 0.05345  loss_giou_dn_5: 0.314  loss_ce_6: 1.478  loss_mask_6: 0.03671  loss_dice_6: 0.6606  loss_bbox_6: 0.09692  loss_giou_6: 0.4802  loss_ce_dn_6: 0.3136  loss_mask_dn_6: 0.03458  loss_dice_dn_6: 0.6076  loss_bbox_dn_6: 0.05532  loss_giou_dn_6: 0.3161  loss_ce_7: 1.438  loss_mask_7: 0.04005  loss_dice_7: 0.747  loss_bbox_7: 0.1136  loss_giou_7: 0.4917  loss_ce_dn_7: 0.314  loss_mask_dn_7: 0.0351  loss_dice_dn_7: 0.6016  loss_bbox_dn_7: 0.0551  loss_giou_dn_7: 0.3188  loss_ce_8: 1.45  loss_mask_8: 0.04321  loss_dice_8: 0.7128  loss_bbox_8: 0.0925  loss_giou_8: 0.4937  loss_ce_dn_8: 0.3101  loss_mask_dn_8: 0.03898  loss_dice_dn_8: 0.6041  loss_bbox_dn_8: 0.05451  loss_giou_dn_8: 0.3161  loss_ce_interm: 1.673  loss_mask_interm: 0.03756  loss_dice_interm: 0.618  loss_bbox_interm: 0.1278  loss_giou_interm: 0.4915  time: 2.4383  data_time: 0.0763  lr: 0.0001  max_mem: 6620M\n",
            "[05/20 16:46:40 d2.utils.events]:  eta: 2:46:03  iter: 859  total_loss: 65.39  loss_ce: 1.547  loss_mask: 0.04149  loss_dice: 0.7005  loss_bbox: 0.1554  loss_giou: 0.7536  loss_ce_dn: 0.2808  loss_mask_dn: 0.0355  loss_dice_dn: 0.9386  loss_bbox_dn: 0.05327  loss_giou_dn: 0.4603  loss_ce_0: 1.707  loss_mask_0: 0.04065  loss_dice_0: 1.215  loss_bbox_0: 0.1171  loss_giou_0: 1.009  loss_ce_dn_0: 1.184  loss_mask_dn_0: 0.2359  loss_dice_dn_0: 3.063  loss_bbox_dn_0: 0.2198  loss_giou_dn_0: 0.8608  loss_ce_1: 1.742  loss_mask_1: 0.0396  loss_dice_1: 0.6742  loss_bbox_1: 0.1278  loss_giou_1: 0.8365  loss_ce_dn_1: 0.3458  loss_mask_dn_1: 0.04462  loss_dice_dn_1: 0.8709  loss_bbox_dn_1: 0.08773  loss_giou_dn_1: 0.5602  loss_ce_2: 1.762  loss_mask_2: 0.04633  loss_dice_2: 0.547  loss_bbox_2: 0.1272  loss_giou_2: 0.7931  loss_ce_dn_2: 0.3358  loss_mask_dn_2: 0.04481  loss_dice_dn_2: 0.8369  loss_bbox_dn_2: 0.0775  loss_giou_dn_2: 0.4853  loss_ce_3: 1.561  loss_mask_3: 0.05752  loss_dice_3: 0.8886  loss_bbox_3: 0.1168  loss_giou_3: 0.8255  loss_ce_dn_3: 0.2967  loss_mask_dn_3: 0.04175  loss_dice_dn_3: 1.017  loss_bbox_dn_3: 0.05538  loss_giou_dn_3: 0.4661  loss_ce_4: 1.639  loss_mask_4: 0.04474  loss_dice_4: 0.6442  loss_bbox_4: 0.1463  loss_giou_4: 0.8241  loss_ce_dn_4: 0.3037  loss_mask_dn_4: 0.0387  loss_dice_dn_4: 0.9117  loss_bbox_dn_4: 0.05522  loss_giou_dn_4: 0.4665  loss_ce_5: 1.676  loss_mask_5: 0.04123  loss_dice_5: 0.685  loss_bbox_5: 0.1551  loss_giou_5: 0.7499  loss_ce_dn_5: 0.2918  loss_mask_dn_5: 0.0372  loss_dice_dn_5: 1.011  loss_bbox_dn_5: 0.05369  loss_giou_dn_5: 0.4514  loss_ce_6: 1.592  loss_mask_6: 0.04242  loss_dice_6: 0.6222  loss_bbox_6: 0.1547  loss_giou_6: 0.748  loss_ce_dn_6: 0.3039  loss_mask_dn_6: 0.03698  loss_dice_dn_6: 0.9516  loss_bbox_dn_6: 0.05348  loss_giou_dn_6: 0.4529  loss_ce_7: 1.604  loss_mask_7: 0.0457  loss_dice_7: 0.6313  loss_bbox_7: 0.1084  loss_giou_7: 0.7399  loss_ce_dn_7: 0.2754  loss_mask_dn_7: 0.03617  loss_dice_dn_7: 0.9593  loss_bbox_dn_7: 0.05246  loss_giou_dn_7: 0.4558  loss_ce_8: 1.587  loss_mask_8: 0.04687  loss_dice_8: 0.6167  loss_bbox_8: 0.1446  loss_giou_8: 0.8013  loss_ce_dn_8: 0.2707  loss_mask_dn_8: 0.03451  loss_dice_dn_8: 0.945  loss_bbox_dn_8: 0.05347  loss_giou_dn_8: 0.458  loss_ce_interm: 1.775  loss_mask_interm: 0.04368  loss_dice_interm: 0.7093  loss_bbox_interm: 0.1515  loss_giou_interm: 0.7807  time: 2.4216  data_time: 0.0811  lr: 0.0001  max_mem: 6620M\n",
            "[05/20 16:47:14 d2.utils.events]:  eta: 2:43:45  iter: 879  total_loss: 56.49  loss_ce: 1.37  loss_mask: 0.04074  loss_dice: 0.6703  loss_bbox: 0.1215  loss_giou: 0.4365  loss_ce_dn: 0.2614  loss_mask_dn: 0.03821  loss_dice_dn: 0.8929  loss_bbox_dn: 0.04827  loss_giou_dn: 0.3954  loss_ce_0: 1.571  loss_mask_0: 0.03579  loss_dice_0: 0.7663  loss_bbox_0: 0.1479  loss_giou_0: 0.617  loss_ce_dn_0: 1.319  loss_mask_dn_0: 0.1904  loss_dice_dn_0: 2.347  loss_bbox_dn_0: 0.2229  loss_giou_dn_0: 0.8565  loss_ce_1: 1.498  loss_mask_1: 0.03673  loss_dice_1: 0.8758  loss_bbox_1: 0.1073  loss_giou_1: 0.457  loss_ce_dn_1: 0.3721  loss_mask_dn_1: 0.04606  loss_dice_dn_1: 0.8458  loss_bbox_dn_1: 0.08104  loss_giou_dn_1: 0.4913  loss_ce_2: 1.517  loss_mask_2: 0.03403  loss_dice_2: 0.6301  loss_bbox_2: 0.1054  loss_giou_2: 0.4766  loss_ce_dn_2: 0.3094  loss_mask_dn_2: 0.0427  loss_dice_dn_2: 0.8799  loss_bbox_dn_2: 0.06397  loss_giou_dn_2: 0.4243  loss_ce_3: 1.431  loss_mask_3: 0.03455  loss_dice_3: 0.5913  loss_bbox_3: 0.09995  loss_giou_3: 0.4615  loss_ce_dn_3: 0.2889  loss_mask_dn_3: 0.03875  loss_dice_dn_3: 0.8213  loss_bbox_dn_3: 0.0526  loss_giou_dn_3: 0.3993  loss_ce_4: 1.422  loss_mask_4: 0.03677  loss_dice_4: 0.7964  loss_bbox_4: 0.09084  loss_giou_4: 0.4664  loss_ce_dn_4: 0.2639  loss_mask_dn_4: 0.03894  loss_dice_dn_4: 0.8937  loss_bbox_dn_4: 0.04861  loss_giou_dn_4: 0.3942  loss_ce_5: 1.383  loss_mask_5: 0.04226  loss_dice_5: 0.7176  loss_bbox_5: 0.09626  loss_giou_5: 0.4884  loss_ce_dn_5: 0.2477  loss_mask_dn_5: 0.03705  loss_dice_dn_5: 0.8699  loss_bbox_dn_5: 0.04697  loss_giou_dn_5: 0.4049  loss_ce_6: 1.335  loss_mask_6: 0.03993  loss_dice_6: 0.6626  loss_bbox_6: 0.1252  loss_giou_6: 0.4899  loss_ce_dn_6: 0.2406  loss_mask_dn_6: 0.03908  loss_dice_dn_6: 0.8867  loss_bbox_dn_6: 0.04862  loss_giou_dn_6: 0.4083  loss_ce_7: 1.383  loss_mask_7: 0.0399  loss_dice_7: 0.9087  loss_bbox_7: 0.1218  loss_giou_7: 0.4543  loss_ce_dn_7: 0.2449  loss_mask_dn_7: 0.03831  loss_dice_dn_7: 0.8779  loss_bbox_dn_7: 0.04839  loss_giou_dn_7: 0.4016  loss_ce_8: 1.347  loss_mask_8: 0.03638  loss_dice_8: 0.7305  loss_bbox_8: 0.1215  loss_giou_8: 0.457  loss_ce_dn_8: 0.2533  loss_mask_dn_8: 0.03675  loss_dice_dn_8: 0.869  loss_bbox_dn_8: 0.04811  loss_giou_dn_8: 0.3921  loss_ce_interm: 1.645  loss_mask_interm: 0.03593  loss_dice_interm: 0.5505  loss_bbox_interm: 0.1088  loss_giou_interm: 0.5435  time: 2.4049  data_time: 0.0709  lr: 0.0001  max_mem: 6620M\n",
            "[05/20 16:47:50 d2.utils.events]:  eta: 2:42:19  iter: 899  total_loss: 55.13  loss_ce: 1.365  loss_mask: 0.04201  loss_dice: 0.7755  loss_bbox: 0.0942  loss_giou: 0.553  loss_ce_dn: 0.3438  loss_mask_dn: 0.03376  loss_dice_dn: 0.6849  loss_bbox_dn: 0.04748  loss_giou_dn: 0.3958  loss_ce_0: 1.614  loss_mask_0: 0.04413  loss_dice_0: 0.8044  loss_bbox_0: 0.1569  loss_giou_0: 0.663  loss_ce_dn_0: 1.187  loss_mask_dn_0: 0.2327  loss_dice_dn_0: 3.151  loss_bbox_dn_0: 0.2626  loss_giou_dn_0: 0.8619  loss_ce_1: 1.604  loss_mask_1: 0.03742  loss_dice_1: 0.9468  loss_bbox_1: 0.1084  loss_giou_1: 0.5997  loss_ce_dn_1: 0.4092  loss_mask_dn_1: 0.03658  loss_dice_dn_1: 0.7794  loss_bbox_dn_1: 0.07165  loss_giou_dn_1: 0.4865  loss_ce_2: 1.628  loss_mask_2: 0.04098  loss_dice_2: 0.8138  loss_bbox_2: 0.1019  loss_giou_2: 0.5491  loss_ce_dn_2: 0.3721  loss_mask_dn_2: 0.03777  loss_dice_dn_2: 0.7627  loss_bbox_dn_2: 0.06266  loss_giou_dn_2: 0.4304  loss_ce_3: 1.446  loss_mask_3: 0.04011  loss_dice_3: 0.728  loss_bbox_3: 0.1046  loss_giou_3: 0.5807  loss_ce_dn_3: 0.354  loss_mask_dn_3: 0.03567  loss_dice_dn_3: 0.7327  loss_bbox_dn_3: 0.05112  loss_giou_dn_3: 0.4142  loss_ce_4: 1.375  loss_mask_4: 0.04323  loss_dice_4: 0.6395  loss_bbox_4: 0.1068  loss_giou_4: 0.5661  loss_ce_dn_4: 0.331  loss_mask_dn_4: 0.03358  loss_dice_dn_4: 0.7443  loss_bbox_dn_4: 0.04804  loss_giou_dn_4: 0.3987  loss_ce_5: 1.364  loss_mask_5: 0.04285  loss_dice_5: 0.7606  loss_bbox_5: 0.09773  loss_giou_5: 0.5564  loss_ce_dn_5: 0.3301  loss_mask_dn_5: 0.03395  loss_dice_dn_5: 0.7615  loss_bbox_dn_5: 0.04655  loss_giou_dn_5: 0.4009  loss_ce_6: 1.401  loss_mask_6: 0.03851  loss_dice_6: 0.8362  loss_bbox_6: 0.09346  loss_giou_6: 0.5485  loss_ce_dn_6: 0.3396  loss_mask_dn_6: 0.03497  loss_dice_dn_6: 0.6906  loss_bbox_dn_6: 0.04687  loss_giou_dn_6: 0.4014  loss_ce_7: 1.405  loss_mask_7: 0.04207  loss_dice_7: 0.6818  loss_bbox_7: 0.09504  loss_giou_7: 0.5317  loss_ce_dn_7: 0.3394  loss_mask_dn_7: 0.03415  loss_dice_dn_7: 0.7308  loss_bbox_dn_7: 0.04615  loss_giou_dn_7: 0.3958  loss_ce_8: 1.421  loss_mask_8: 0.03976  loss_dice_8: 0.8438  loss_bbox_8: 0.0976  loss_giou_8: 0.5428  loss_ce_dn_8: 0.3401  loss_mask_dn_8: 0.03385  loss_dice_dn_8: 0.7108  loss_bbox_dn_8: 0.04804  loss_giou_dn_8: 0.3994  loss_ce_interm: 1.662  loss_mask_interm: 0.04287  loss_dice_interm: 0.6282  loss_bbox_interm: 0.1141  loss_giou_interm: 0.6668  time: 2.3912  data_time: 0.1174  lr: 0.0001  max_mem: 6620M\n",
            "[05/20 16:48:25 d2.utils.events]:  eta: 2:40:59  iter: 919  total_loss: 56.53  loss_ce: 1.477  loss_mask: 0.05093  loss_dice: 0.457  loss_bbox: 0.07704  loss_giou: 0.4024  loss_ce_dn: 0.3711  loss_mask_dn: 0.04981  loss_dice_dn: 0.5863  loss_bbox_dn: 0.04939  loss_giou_dn: 0.3489  loss_ce_0: 1.574  loss_mask_0: 0.04851  loss_dice_0: 0.7457  loss_bbox_0: 0.1104  loss_giou_0: 0.6828  loss_ce_dn_0: 1.182  loss_mask_dn_0: 0.1883  loss_dice_dn_0: 3.061  loss_bbox_dn_0: 0.2085  loss_giou_dn_0: 0.8573  loss_ce_1: 1.605  loss_mask_1: 0.04324  loss_dice_1: 0.7583  loss_bbox_1: 0.08214  loss_giou_1: 0.5369  loss_ce_dn_1: 0.419  loss_mask_dn_1: 0.05546  loss_dice_dn_1: 0.623  loss_bbox_dn_1: 0.0802  loss_giou_dn_1: 0.4895  loss_ce_2: 1.487  loss_mask_2: 0.05003  loss_dice_2: 0.6223  loss_bbox_2: 0.08771  loss_giou_2: 0.552  loss_ce_dn_2: 0.3806  loss_mask_dn_2: 0.05134  loss_dice_dn_2: 0.6578  loss_bbox_dn_2: 0.06757  loss_giou_dn_2: 0.4199  loss_ce_3: 1.48  loss_mask_3: 0.054  loss_dice_3: 0.6771  loss_bbox_3: 0.08539  loss_giou_3: 0.535  loss_ce_dn_3: 0.3792  loss_mask_dn_3: 0.04637  loss_dice_dn_3: 0.5873  loss_bbox_dn_3: 0.05717  loss_giou_dn_3: 0.3643  loss_ce_4: 1.437  loss_mask_4: 0.05044  loss_dice_4: 0.6287  loss_bbox_4: 0.08011  loss_giou_4: 0.5176  loss_ce_dn_4: 0.3585  loss_mask_dn_4: 0.05123  loss_dice_dn_4: 0.6013  loss_bbox_dn_4: 0.05014  loss_giou_dn_4: 0.3652  loss_ce_5: 1.542  loss_mask_5: 0.0652  loss_dice_5: 0.5121  loss_bbox_5: 0.07804  loss_giou_5: 0.5219  loss_ce_dn_5: 0.3643  loss_mask_dn_5: 0.05078  loss_dice_dn_5: 0.5787  loss_bbox_dn_5: 0.0518  loss_giou_dn_5: 0.3659  loss_ce_6: 1.514  loss_mask_6: 0.05527  loss_dice_6: 0.5128  loss_bbox_6: 0.07753  loss_giou_6: 0.4467  loss_ce_dn_6: 0.3553  loss_mask_dn_6: 0.05209  loss_dice_dn_6: 0.5737  loss_bbox_dn_6: 0.0518  loss_giou_dn_6: 0.3567  loss_ce_7: 1.407  loss_mask_7: 0.06004  loss_dice_7: 0.5765  loss_bbox_7: 0.07797  loss_giou_7: 0.4657  loss_ce_dn_7: 0.3672  loss_mask_dn_7: 0.05221  loss_dice_dn_7: 0.6587  loss_bbox_dn_7: 0.05063  loss_giou_dn_7: 0.3546  loss_ce_8: 1.392  loss_mask_8: 0.05429  loss_dice_8: 0.6847  loss_bbox_8: 0.07752  loss_giou_8: 0.4799  loss_ce_dn_8: 0.3643  loss_mask_dn_8: 0.05212  loss_dice_dn_8: 0.6178  loss_bbox_dn_8: 0.05026  loss_giou_dn_8: 0.3538  loss_ce_interm: 1.575  loss_mask_interm: 0.04753  loss_dice_interm: 0.5802  loss_bbox_interm: 0.1334  loss_giou_interm: 0.4771  time: 2.3770  data_time: 0.1075  lr: 0.0001  max_mem: 6620M\n",
            "[05/20 16:49:00 d2.utils.events]:  eta: 2:39:46  iter: 939  total_loss: 49.18  loss_ce: 1.317  loss_mask: 0.05686  loss_dice: 0.9029  loss_bbox: 0.1331  loss_giou: 0.439  loss_ce_dn: 0.2967  loss_mask_dn: 0.04048  loss_dice_dn: 0.6799  loss_bbox_dn: 0.05075  loss_giou_dn: 0.3274  loss_ce_0: 1.425  loss_mask_0: 0.06596  loss_dice_0: 0.6017  loss_bbox_0: 0.1239  loss_giou_0: 0.4386  loss_ce_dn_0: 1.072  loss_mask_dn_0: 0.2758  loss_dice_dn_0: 3.096  loss_bbox_dn_0: 0.3035  loss_giou_dn_0: 0.8585  loss_ce_1: 1.542  loss_mask_1: 0.0592  loss_dice_1: 0.7065  loss_bbox_1: 0.1142  loss_giou_1: 0.4555  loss_ce_dn_1: 0.3276  loss_mask_dn_1: 0.04787  loss_dice_dn_1: 0.6824  loss_bbox_dn_1: 0.07836  loss_giou_dn_1: 0.4239  loss_ce_2: 1.672  loss_mask_2: 0.05333  loss_dice_2: 0.7549  loss_bbox_2: 0.1052  loss_giou_2: 0.4371  loss_ce_dn_2: 0.314  loss_mask_dn_2: 0.04135  loss_dice_dn_2: 0.7016  loss_bbox_dn_2: 0.05776  loss_giou_dn_2: 0.3571  loss_ce_3: 1.532  loss_mask_3: 0.06025  loss_dice_3: 0.7661  loss_bbox_3: 0.1039  loss_giou_3: 0.4423  loss_ce_dn_3: 0.3194  loss_mask_dn_3: 0.0419  loss_dice_dn_3: 0.6724  loss_bbox_dn_3: 0.05747  loss_giou_dn_3: 0.3472  loss_ce_4: 1.432  loss_mask_4: 0.0514  loss_dice_4: 0.7603  loss_bbox_4: 0.1324  loss_giou_4: 0.444  loss_ce_dn_4: 0.299  loss_mask_dn_4: 0.04256  loss_dice_dn_4: 0.6655  loss_bbox_dn_4: 0.05268  loss_giou_dn_4: 0.3326  loss_ce_5: 1.37  loss_mask_5: 0.05634  loss_dice_5: 0.6775  loss_bbox_5: 0.1248  loss_giou_5: 0.4556  loss_ce_dn_5: 0.2845  loss_mask_dn_5: 0.04245  loss_dice_dn_5: 0.6625  loss_bbox_dn_5: 0.05096  loss_giou_dn_5: 0.3268  loss_ce_6: 1.36  loss_mask_6: 0.06093  loss_dice_6: 0.725  loss_bbox_6: 0.1426  loss_giou_6: 0.4772  loss_ce_dn_6: 0.3047  loss_mask_dn_6: 0.04535  loss_dice_dn_6: 0.6386  loss_bbox_dn_6: 0.05178  loss_giou_dn_6: 0.3259  loss_ce_7: 1.311  loss_mask_7: 0.05588  loss_dice_7: 0.7532  loss_bbox_7: 0.1376  loss_giou_7: 0.4493  loss_ce_dn_7: 0.3061  loss_mask_dn_7: 0.04389  loss_dice_dn_7: 0.6944  loss_bbox_dn_7: 0.05023  loss_giou_dn_7: 0.3242  loss_ce_8: 1.326  loss_mask_8: 0.05117  loss_dice_8: 0.6958  loss_bbox_8: 0.139  loss_giou_8: 0.4445  loss_ce_dn_8: 0.2945  loss_mask_dn_8: 0.04406  loss_dice_dn_8: 0.6618  loss_bbox_dn_8: 0.05058  loss_giou_dn_8: 0.329  loss_ce_interm: 1.471  loss_mask_interm: 0.05582  loss_dice_interm: 0.7495  loss_bbox_interm: 0.1111  loss_giou_interm: 0.4991  time: 2.3633  data_time: 0.0289  lr: 0.0001  max_mem: 6620M\n",
            "[05/20 16:49:36 d2.utils.events]:  eta: 2:37:56  iter: 959  total_loss: 64.45  loss_ce: 1.634  loss_mask: 0.03196  loss_dice: 0.7659  loss_bbox: 0.1446  loss_giou: 0.887  loss_ce_dn: 0.2642  loss_mask_dn: 0.02611  loss_dice_dn: 0.8237  loss_bbox_dn: 0.04854  loss_giou_dn: 0.4638  loss_ce_0: 1.675  loss_mask_0: 0.03699  loss_dice_0: 0.8337  loss_bbox_0: 0.1411  loss_giou_0: 0.949  loss_ce_dn_0: 1.152  loss_mask_dn_0: 0.1475  loss_dice_dn_0: 2.555  loss_bbox_dn_0: 0.1289  loss_giou_dn_0: 0.8544  loss_ce_1: 1.647  loss_mask_1: 0.05203  loss_dice_1: 0.8545  loss_bbox_1: 0.1357  loss_giou_1: 0.9041  loss_ce_dn_1: 0.3258  loss_mask_dn_1: 0.0357  loss_dice_dn_1: 0.8503  loss_bbox_dn_1: 0.06515  loss_giou_dn_1: 0.5286  loss_ce_2: 1.747  loss_mask_2: 0.0387  loss_dice_2: 0.6559  loss_bbox_2: 0.1725  loss_giou_2: 0.9979  loss_ce_dn_2: 0.2759  loss_mask_dn_2: 0.03123  loss_dice_dn_2: 0.8583  loss_bbox_dn_2: 0.05499  loss_giou_dn_2: 0.4802  loss_ce_3: 1.673  loss_mask_3: 0.0389  loss_dice_3: 0.6882  loss_bbox_3: 0.1423  loss_giou_3: 1.002  loss_ce_dn_3: 0.2611  loss_mask_dn_3: 0.02958  loss_dice_dn_3: 0.8603  loss_bbox_dn_3: 0.04955  loss_giou_dn_3: 0.4695  loss_ce_4: 1.657  loss_mask_4: 0.03731  loss_dice_4: 0.8089  loss_bbox_4: 0.1523  loss_giou_4: 0.9763  loss_ce_dn_4: 0.2786  loss_mask_dn_4: 0.02714  loss_dice_dn_4: 0.8455  loss_bbox_dn_4: 0.05063  loss_giou_dn_4: 0.461  loss_ce_5: 1.619  loss_mask_5: 0.03989  loss_dice_5: 0.7869  loss_bbox_5: 0.1321  loss_giou_5: 0.9702  loss_ce_dn_5: 0.2747  loss_mask_dn_5: 0.02738  loss_dice_dn_5: 0.8023  loss_bbox_dn_5: 0.04965  loss_giou_dn_5: 0.4579  loss_ce_6: 1.571  loss_mask_6: 0.03521  loss_dice_6: 0.6651  loss_bbox_6: 0.1157  loss_giou_6: 0.9615  loss_ce_dn_6: 0.2739  loss_mask_dn_6: 0.02643  loss_dice_dn_6: 0.8048  loss_bbox_dn_6: 0.04929  loss_giou_dn_6: 0.4595  loss_ce_7: 1.666  loss_mask_7: 0.03925  loss_dice_7: 0.7252  loss_bbox_7: 0.1259  loss_giou_7: 0.9043  loss_ce_dn_7: 0.2616  loss_mask_dn_7: 0.02651  loss_dice_dn_7: 0.7812  loss_bbox_dn_7: 0.04875  loss_giou_dn_7: 0.4565  loss_ce_8: 1.607  loss_mask_8: 0.03111  loss_dice_8: 0.697  loss_bbox_8: 0.1298  loss_giou_8: 0.8246  loss_ce_dn_8: 0.265  loss_mask_dn_8: 0.02617  loss_dice_dn_8: 0.8437  loss_bbox_dn_8: 0.04874  loss_giou_dn_8: 0.4598  loss_ce_interm: 1.777  loss_mask_interm: 0.03601  loss_dice_interm: 0.8947  loss_bbox_interm: 0.1392  loss_giou_interm: 0.8863  time: 2.3506  data_time: 0.1478  lr: 0.0001  max_mem: 6620M\n",
            "[05/20 16:50:11 d2.utils.events]:  eta: 2:36:37  iter: 979  total_loss: 60.05  loss_ce: 1.585  loss_mask: 0.06484  loss_dice: 0.7602  loss_bbox: 0.1659  loss_giou: 0.4688  loss_ce_dn: 0.3048  loss_mask_dn: 0.059  loss_dice_dn: 0.8836  loss_bbox_dn: 0.06682  loss_giou_dn: 0.3637  loss_ce_0: 1.695  loss_mask_0: 0.0731  loss_dice_0: 0.8555  loss_bbox_0: 0.1945  loss_giou_0: 0.5935  loss_ce_dn_0: 1.191  loss_mask_dn_0: 0.3383  loss_dice_dn_0: 3.215  loss_bbox_dn_0: 0.2493  loss_giou_dn_0: 0.8573  loss_ce_1: 1.584  loss_mask_1: 0.07418  loss_dice_1: 0.9747  loss_bbox_1: 0.1898  loss_giou_1: 0.5193  loss_ce_dn_1: 0.3729  loss_mask_dn_1: 0.06373  loss_dice_dn_1: 0.9324  loss_bbox_dn_1: 0.09978  loss_giou_dn_1: 0.4568  loss_ce_2: 1.638  loss_mask_2: 0.06966  loss_dice_2: 0.7848  loss_bbox_2: 0.1634  loss_giou_2: 0.4693  loss_ce_dn_2: 0.3466  loss_mask_dn_2: 0.0588  loss_dice_dn_2: 0.8681  loss_bbox_dn_2: 0.08281  loss_giou_dn_2: 0.4093  loss_ce_3: 1.648  loss_mask_3: 0.06255  loss_dice_3: 0.7663  loss_bbox_3: 0.1905  loss_giou_3: 0.5267  loss_ce_dn_3: 0.3581  loss_mask_dn_3: 0.06097  loss_dice_dn_3: 0.8759  loss_bbox_dn_3: 0.07126  loss_giou_dn_3: 0.3897  loss_ce_4: 1.577  loss_mask_4: 0.06324  loss_dice_4: 0.7452  loss_bbox_4: 0.159  loss_giou_4: 0.5291  loss_ce_dn_4: 0.3299  loss_mask_dn_4: 0.05817  loss_dice_dn_4: 0.8133  loss_bbox_dn_4: 0.06989  loss_giou_dn_4: 0.3748  loss_ce_5: 1.485  loss_mask_5: 0.06332  loss_dice_5: 0.7856  loss_bbox_5: 0.1645  loss_giou_5: 0.4866  loss_ce_dn_5: 0.3127  loss_mask_dn_5: 0.05593  loss_dice_dn_5: 0.7915  loss_bbox_dn_5: 0.06699  loss_giou_dn_5: 0.375  loss_ce_6: 1.585  loss_mask_6: 0.06682  loss_dice_6: 0.745  loss_bbox_6: 0.1811  loss_giou_6: 0.5928  loss_ce_dn_6: 0.3172  loss_mask_dn_6: 0.05847  loss_dice_dn_6: 0.8499  loss_bbox_dn_6: 0.0674  loss_giou_dn_6: 0.373  loss_ce_7: 1.575  loss_mask_7: 0.05731  loss_dice_7: 0.7339  loss_bbox_7: 0.1632  loss_giou_7: 0.47  loss_ce_dn_7: 0.3141  loss_mask_dn_7: 0.05743  loss_dice_dn_7: 0.8669  loss_bbox_dn_7: 0.06819  loss_giou_dn_7: 0.3681  loss_ce_8: 1.599  loss_mask_8: 0.0572  loss_dice_8: 0.8334  loss_bbox_8: 0.167  loss_giou_8: 0.4709  loss_ce_dn_8: 0.3045  loss_mask_dn_8: 0.06231  loss_dice_dn_8: 0.9062  loss_bbox_dn_8: 0.06756  loss_giou_dn_8: 0.3631  loss_ce_interm: 1.662  loss_mask_interm: 0.07922  loss_dice_interm: 0.9349  loss_bbox_interm: 0.1245  loss_giou_interm: 0.5232  time: 2.3377  data_time: 0.0784  lr: 0.0001  max_mem: 6620M\n",
            "[05/20 16:50:45 d2.data.datasets.coco]: Loaded 150 images in COCO format from /content/TACO-expl/data/annotations_off_0_resval.json\n",
            "[05/20 16:50:45 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "[05/20 16:50:45 d2.data.common]: Serializing 150 elements to byte tensors and concatenating them all ...\n",
            "[05/20 16:50:45 d2.data.common]: Serialized dataset takes 0.21 MiB\n",
            "WARNING [05/20 16:50:45 d2.evaluation.coco_evaluation]: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
            "[05/20 16:50:45 d2.evaluation.evaluator]: Start inference on 150 batches\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1066, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1066, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1066, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1066])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 16:50:55 d2.evaluation.evaluator]: Inference done 11/150. Dataloading: 0.0027 s/iter. Inference: 0.3495 s/iter. Eval: 0.6150 s/iter. Total: 0.9671 s/iter. ETA=0:02:14\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 608])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 608])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 608])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1200])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 750])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 16:51:01 d2.evaluation.evaluator]: Inference done 18/150. Dataloading: 0.0024 s/iter. Inference: 0.3181 s/iter. Eval: 0.5403 s/iter. Total: 0.8611 s/iter. ETA=0:01:53\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 750])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([750, 1333])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 16:51:06 d2.evaluation.evaluator]: Inference done 24/150. Dataloading: 0.0027 s/iter. Inference: 0.3201 s/iter. Eval: 0.5343 s/iter. Total: 0.8573 s/iter. ETA=0:01:48\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 750])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([750, 1333])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 16:51:11 d2.evaluation.evaluator]: Inference done 29/150. Dataloading: 0.0050 s/iter. Inference: 0.3317 s/iter. Eval: 0.5652 s/iter. Total: 0.9023 s/iter. ETA=0:01:49\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 750])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 16:51:17 d2.evaluation.evaluator]: Inference done 36/150. Dataloading: 0.0047 s/iter. Inference: 0.3245 s/iter. Eval: 0.5452 s/iter. Total: 0.8749 s/iter. ETA=0:01:39\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 750])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 16:51:22 d2.evaluation.evaluator]: Inference done 43/150. Dataloading: 0.0045 s/iter. Inference: 0.3209 s/iter. Eval: 0.5372 s/iter. Total: 0.8629 s/iter. ETA=0:01:32\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 16:51:27 d2.evaluation.evaluator]: Inference done 48/150. Dataloading: 0.0043 s/iter. Inference: 0.3241 s/iter. Eval: 0.5505 s/iter. Total: 0.8793 s/iter. ETA=0:01:29\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 16:51:33 d2.evaluation.evaluator]: Inference done 55/150. Dataloading: 0.0041 s/iter. Inference: 0.3197 s/iter. Eval: 0.5383 s/iter. Total: 0.8625 s/iter. ETA=0:01:21\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 16:51:38 d2.evaluation.evaluator]: Inference done 62/150. Dataloading: 0.0038 s/iter. Inference: 0.3181 s/iter. Eval: 0.5307 s/iter. Total: 0.8530 s/iter. ETA=0:01:15\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 16:51:44 d2.evaluation.evaluator]: Inference done 68/150. Dataloading: 0.0046 s/iter. Inference: 0.3213 s/iter. Eval: 0.5408 s/iter. Total: 0.8672 s/iter. ETA=0:01:11\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 16:51:49 d2.evaluation.evaluator]: Inference done 75/150. Dataloading: 0.0044 s/iter. Inference: 0.3182 s/iter. Eval: 0.5332 s/iter. Total: 0.8562 s/iter. ETA=0:01:04\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([852, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 16:51:55 d2.evaluation.evaluator]: Inference done 82/150. Dataloading: 0.0042 s/iter. Inference: 0.3145 s/iter. Eval: 0.5277 s/iter. Total: 0.8469 s/iter. ETA=0:00:57\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 16:52:00 d2.evaluation.evaluator]: Inference done 87/150. Dataloading: 0.0043 s/iter. Inference: 0.3235 s/iter. Eval: 0.5354 s/iter. Total: 0.8637 s/iter. ETA=0:00:54\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 16:52:06 d2.evaluation.evaluator]: Inference done 94/150. Dataloading: 0.0042 s/iter. Inference: 0.3215 s/iter. Eval: 0.5314 s/iter. Total: 0.8576 s/iter. ETA=0:00:48\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 16:52:11 d2.evaluation.evaluator]: Inference done 101/150. Dataloading: 0.0041 s/iter. Inference: 0.3196 s/iter. Eval: 0.5261 s/iter. Total: 0.8502 s/iter. ETA=0:00:41\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 16:52:17 d2.evaluation.evaluator]: Inference done 107/150. Dataloading: 0.0042 s/iter. Inference: 0.3208 s/iter. Eval: 0.5330 s/iter. Total: 0.8585 s/iter. ETA=0:00:36\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 16:52:22 d2.evaluation.evaluator]: Inference done 113/150. Dataloading: 0.0041 s/iter. Inference: 0.3206 s/iter. Eval: 0.5326 s/iter. Total: 0.8577 s/iter. ETA=0:00:31\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 16:52:27 d2.evaluation.evaluator]: Inference done 120/150. Dataloading: 0.0041 s/iter. Inference: 0.3189 s/iter. Eval: 0.5282 s/iter. Total: 0.8516 s/iter. ETA=0:00:25\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 16:52:33 d2.evaluation.evaluator]: Inference done 126/150. Dataloading: 0.0041 s/iter. Inference: 0.3191 s/iter. Eval: 0.5306 s/iter. Total: 0.8542 s/iter. ETA=0:00:20\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 16:52:38 d2.evaluation.evaluator]: Inference done 132/150. Dataloading: 0.0041 s/iter. Inference: 0.3191 s/iter. Eval: 0.5314 s/iter. Total: 0.8551 s/iter. ETA=0:00:15\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 750])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 750])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 750])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 16:52:44 d2.evaluation.evaluator]: Inference done 139/150. Dataloading: 0.0040 s/iter. Inference: 0.3185 s/iter. Eval: 0.5291 s/iter. Total: 0.8520 s/iter. ETA=0:00:09\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 16:52:49 d2.evaluation.evaluator]: Inference done 145/150. Dataloading: 0.0039 s/iter. Inference: 0.3186 s/iter. Eval: 0.5295 s/iter. Total: 0.8525 s/iter. ETA=0:00:04\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 608])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 608])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 608])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 608])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 16:52:54 d2.evaluation.evaluator]: Total inference time: 0:02:04.244452 (0.856858 s / iter per device, on 1 devices)\n",
            "[05/20 16:52:54 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:46 (0.319334 s / iter per device, on 1 devices)\n",
            "[05/20 16:52:54 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...\n",
            "[05/20 16:52:54 d2.evaluation.coco_evaluation]: Saving results to /content/output/chkpt/inference/coco_instances_results.json\n",
            "[05/20 16:52:54 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "[05/20 16:52:54 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*\n",
            "[05/20 16:52:54 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.17 seconds.\n",
            "[05/20 16:52:54 d2.evaluation.fast_eval_api]: Accumulating evaluation results...\n",
            "[05/20 16:52:55 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.07 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.176\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.288\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.184\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.061\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.190\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.339\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.272\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.395\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.400\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.089\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.370\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.700\n",
            "[05/20 16:52:55 d2.evaluation.coco_evaluation]: Evaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
            "| 17.647 | 28.764 | 18.416 | 6.065 | 19.017 | 33.857 |\n",
            "[05/20 16:52:55 d2.evaluation.coco_evaluation]: Per-category bbox AP: \n",
            "| category   | AP     | category              | AP     | category   | AP     |\n",
            "|:-----------|:-------|:----------------------|:-------|:-----------|:-------|\n",
            "| Bottle     | 43.199 | Bottle cap            | 10.757 | Can        | 24.578 |\n",
            "| Cigarette  | 1.583  | Cup                   | 25.155 | Lid        | 12.795 |\n",
            "| Other      | 17.593 | Plastic bag & wrapper | 20.004 | Pop tab    | 6.895  |\n",
            "| Straw      | 13.911 |                       |        |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.28s)\n",
            "creating index...\n",
            "index created!\n",
            "[05/20 16:52:55 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*\n",
            "[05/20 16:52:55 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.33 seconds.\n",
            "[05/20 16:52:55 d2.evaluation.fast_eval_api]: Accumulating evaluation results...\n",
            "[05/20 16:52:56 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.08 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.263\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.337\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.279\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.118\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.306\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.432\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.389\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.577\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.584\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.329\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.624\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.777\n",
            "[05/20 16:52:56 d2.evaluation.coco_evaluation]: Evaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 26.258 | 33.749 | 27.885 | 11.751 | 30.592 | 43.154 |\n",
            "[05/20 16:52:56 d2.evaluation.coco_evaluation]: Per-category segm AP: \n",
            "| category   | AP     | category              | AP     | category   | AP     |\n",
            "|:-----------|:-------|:----------------------|:-------|:-----------|:-------|\n",
            "| Bottle     | 58.230 | Bottle cap            | 27.484 | Can        | 31.219 |\n",
            "| Cigarette  | 9.831  | Cup                   | 32.280 | Lid        | 18.226 |\n",
            "| Other      | 26.911 | Plastic bag & wrapper | 30.653 | Pop tab    | 11.134 |\n",
            "| Straw      | 16.610 |                       |        |            |        |\n",
            "[05/20 16:52:56 d2.engine.defaults]: Evaluation results for TACO_val in csv format:\n",
            "[05/20 16:52:56 d2.evaluation.testing]: copypaste: Task: bbox\n",
            "[05/20 16:52:56 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl\n",
            "[05/20 16:52:56 d2.evaluation.testing]: copypaste: 17.6471,28.7640,18.4164,6.0647,19.0170,33.8568\n",
            "[05/20 16:52:56 d2.evaluation.testing]: copypaste: Task: segm\n",
            "[05/20 16:52:56 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl\n",
            "[05/20 16:52:56 d2.evaluation.testing]: copypaste: 26.2578,33.7493,27.8847,11.7509,30.5925,43.1541\n",
            "[05/20 16:52:56 d2.utils.events]:  eta: 2:35:37  iter: 999  total_loss: 55.31  loss_ce: 1.427  loss_mask: 0.03339  loss_dice: 0.6407  loss_bbox: 0.06278  loss_giou: 0.3823  loss_ce_dn: 0.2682  loss_mask_dn: 0.02854  loss_dice_dn: 0.6495  loss_bbox_dn: 0.04043  loss_giou_dn: 0.3273  loss_ce_0: 1.683  loss_mask_0: 0.0358  loss_dice_0: 0.7356  loss_bbox_0: 0.06984  loss_giou_0: 0.415  loss_ce_dn_0: 1.149  loss_mask_dn_0: 0.1627  loss_dice_dn_0: 3.111  loss_bbox_dn_0: 0.2106  loss_giou_dn_0: 0.8611  loss_ce_1: 1.705  loss_mask_1: 0.03113  loss_dice_1: 0.7054  loss_bbox_1: 0.06891  loss_giou_1: 0.3948  loss_ce_dn_1: 0.3876  loss_mask_dn_1: 0.03086  loss_dice_dn_1: 0.7688  loss_bbox_dn_1: 0.06704  loss_giou_dn_1: 0.4375  loss_ce_2: 1.659  loss_mask_2: 0.03535  loss_dice_2: 0.7459  loss_bbox_2: 0.09359  loss_giou_2: 0.3913  loss_ce_dn_2: 0.3472  loss_mask_dn_2: 0.02659  loss_dice_dn_2: 0.6579  loss_bbox_dn_2: 0.05332  loss_giou_dn_2: 0.3525  loss_ce_3: 1.5  loss_mask_3: 0.03809  loss_dice_3: 0.6425  loss_bbox_3: 0.07428  loss_giou_3: 0.3794  loss_ce_dn_3: 0.3534  loss_mask_dn_3: 0.0261  loss_dice_dn_3: 0.651  loss_bbox_dn_3: 0.04589  loss_giou_dn_3: 0.3415  loss_ce_4: 1.488  loss_mask_4: 0.04437  loss_dice_4: 0.6614  loss_bbox_4: 0.07668  loss_giou_4: 0.3898  loss_ce_dn_4: 0.3241  loss_mask_dn_4: 0.02745  loss_dice_dn_4: 0.6475  loss_bbox_dn_4: 0.04457  loss_giou_dn_4: 0.3306  loss_ce_5: 1.426  loss_mask_5: 0.03117  loss_dice_5: 0.6271  loss_bbox_5: 0.07577  loss_giou_5: 0.367  loss_ce_dn_5: 0.295  loss_mask_dn_5: 0.02918  loss_dice_dn_5: 0.6368  loss_bbox_dn_5: 0.04097  loss_giou_dn_5: 0.3248  loss_ce_6: 1.435  loss_mask_6: 0.0422  loss_dice_6: 0.7087  loss_bbox_6: 0.07792  loss_giou_6: 0.3847  loss_ce_dn_6: 0.2855  loss_mask_dn_6: 0.02895  loss_dice_dn_6: 0.6385  loss_bbox_dn_6: 0.04083  loss_giou_dn_6: 0.3296  loss_ce_7: 1.434  loss_mask_7: 0.03407  loss_dice_7: 0.6357  loss_bbox_7: 0.0663  loss_giou_7: 0.3876  loss_ce_dn_7: 0.2794  loss_mask_dn_7: 0.03021  loss_dice_dn_7: 0.6384  loss_bbox_dn_7: 0.03967  loss_giou_dn_7: 0.3266  loss_ce_8: 1.478  loss_mask_8: 0.02693  loss_dice_8: 0.6597  loss_bbox_8: 0.07623  loss_giou_8: 0.4059  loss_ce_dn_8: 0.2628  loss_mask_dn_8: 0.02979  loss_dice_dn_8: 0.6215  loss_bbox_dn_8: 0.04044  loss_giou_dn_8: 0.3286  loss_ce_interm: 1.686  loss_mask_interm: 0.04657  loss_dice_interm: 0.7695  loss_bbox_interm: 0.1035  loss_giou_interm: 0.5414  time: 2.3251  data_time: 0.0791  lr: 0.0001  max_mem: 6620M\n",
            "[05/20 16:53:32 d2.utils.events]:  eta: 2:34:11  iter: 1019  total_loss: 42.42  loss_ce: 1.273  loss_mask: 0.03575  loss_dice: 0.5006  loss_bbox: 0.05896  loss_giou: 0.3064  loss_ce_dn: 0.22  loss_mask_dn: 0.04003  loss_dice_dn: 0.489  loss_bbox_dn: 0.06707  loss_giou_dn: 0.2971  loss_ce_0: 1.604  loss_mask_0: 0.03872  loss_dice_0: 0.4564  loss_bbox_0: 0.08162  loss_giou_0: 0.3763  loss_ce_dn_0: 0.9664  loss_mask_dn_0: 0.2442  loss_dice_dn_0: 2.42  loss_bbox_dn_0: 0.3779  loss_giou_dn_0: 0.8607  loss_ce_1: 1.617  loss_mask_1: 0.0375  loss_dice_1: 0.4166  loss_bbox_1: 0.06222  loss_giou_1: 0.3191  loss_ce_dn_1: 0.3168  loss_mask_dn_1: 0.03485  loss_dice_dn_1: 0.5595  loss_bbox_dn_1: 0.1111  loss_giou_dn_1: 0.3992  loss_ce_2: 1.547  loss_mask_2: 0.03598  loss_dice_2: 0.3506  loss_bbox_2: 0.06715  loss_giou_2: 0.313  loss_ce_dn_2: 0.2635  loss_mask_dn_2: 0.0371  loss_dice_dn_2: 0.4935  loss_bbox_dn_2: 0.08627  loss_giou_dn_2: 0.3289  loss_ce_3: 1.457  loss_mask_3: 0.03136  loss_dice_3: 0.3879  loss_bbox_3: 0.06308  loss_giou_3: 0.3236  loss_ce_dn_3: 0.2362  loss_mask_dn_3: 0.04093  loss_dice_dn_3: 0.4767  loss_bbox_dn_3: 0.07457  loss_giou_dn_3: 0.314  loss_ce_4: 1.392  loss_mask_4: 0.03101  loss_dice_4: 0.4068  loss_bbox_4: 0.06159  loss_giou_4: 0.3227  loss_ce_dn_4: 0.225  loss_mask_dn_4: 0.03934  loss_dice_dn_4: 0.4487  loss_bbox_dn_4: 0.07053  loss_giou_dn_4: 0.3038  loss_ce_5: 1.387  loss_mask_5: 0.03498  loss_dice_5: 0.4311  loss_bbox_5: 0.06055  loss_giou_5: 0.2944  loss_ce_dn_5: 0.2108  loss_mask_dn_5: 0.03998  loss_dice_dn_5: 0.4678  loss_bbox_dn_5: 0.06753  loss_giou_dn_5: 0.3077  loss_ce_6: 1.281  loss_mask_6: 0.03395  loss_dice_6: 0.4126  loss_bbox_6: 0.05801  loss_giou_6: 0.3085  loss_ce_dn_6: 0.2061  loss_mask_dn_6: 0.04093  loss_dice_dn_6: 0.4847  loss_bbox_dn_6: 0.06912  loss_giou_dn_6: 0.307  loss_ce_7: 1.293  loss_mask_7: 0.03543  loss_dice_7: 0.3826  loss_bbox_7: 0.05801  loss_giou_7: 0.2973  loss_ce_dn_7: 0.2128  loss_mask_dn_7: 0.04039  loss_dice_dn_7: 0.486  loss_bbox_dn_7: 0.06785  loss_giou_dn_7: 0.2996  loss_ce_8: 1.256  loss_mask_8: 0.02692  loss_dice_8: 0.4364  loss_bbox_8: 0.05647  loss_giou_8: 0.3017  loss_ce_dn_8: 0.2198  loss_mask_dn_8: 0.04183  loss_dice_dn_8: 0.4744  loss_bbox_dn_8: 0.06693  loss_giou_dn_8: 0.2945  loss_ce_interm: 1.604  loss_mask_interm: 0.04019  loss_dice_interm: 0.5372  loss_bbox_interm: 0.1197  loss_giou_interm: 0.4036  time: 2.3152  data_time: 0.1211  lr: 0.0001  max_mem: 6620M\n",
            "[05/20 16:54:08 d2.utils.events]:  eta: 2:32:14  iter: 1039  total_loss: 52.51  loss_ce: 1.541  loss_mask: 0.03508  loss_dice: 0.7218  loss_bbox: 0.07309  loss_giou: 0.3857  loss_ce_dn: 0.3213  loss_mask_dn: 0.03418  loss_dice_dn: 0.582  loss_bbox_dn: 0.04361  loss_giou_dn: 0.32  loss_ce_0: 1.632  loss_mask_0: 0.03616  loss_dice_0: 0.7098  loss_bbox_0: 0.08253  loss_giou_0: 0.4821  loss_ce_dn_0: 1.005  loss_mask_dn_0: 0.1278  loss_dice_dn_0: 2.869  loss_bbox_dn_0: 0.1992  loss_giou_dn_0: 0.8519  loss_ce_1: 1.626  loss_mask_1: 0.03624  loss_dice_1: 0.5804  loss_bbox_1: 0.07132  loss_giou_1: 0.4277  loss_ce_dn_1: 0.3361  loss_mask_dn_1: 0.03394  loss_dice_dn_1: 0.6961  loss_bbox_dn_1: 0.0742  loss_giou_dn_1: 0.4372  loss_ce_2: 1.643  loss_mask_2: 0.03426  loss_dice_2: 0.5958  loss_bbox_2: 0.06627  loss_giou_2: 0.3744  loss_ce_dn_2: 0.2945  loss_mask_dn_2: 0.03408  loss_dice_dn_2: 0.5755  loss_bbox_dn_2: 0.05588  loss_giou_dn_2: 0.3779  loss_ce_3: 1.593  loss_mask_3: 0.02849  loss_dice_3: 0.6009  loss_bbox_3: 0.05647  loss_giou_3: 0.3628  loss_ce_dn_3: 0.31  loss_mask_dn_3: 0.03401  loss_dice_dn_3: 0.6196  loss_bbox_dn_3: 0.04683  loss_giou_dn_3: 0.3591  loss_ce_4: 1.526  loss_mask_4: 0.03709  loss_dice_4: 0.5015  loss_bbox_4: 0.06912  loss_giou_4: 0.3656  loss_ce_dn_4: 0.3062  loss_mask_dn_4: 0.03562  loss_dice_dn_4: 0.6059  loss_bbox_dn_4: 0.04648  loss_giou_dn_4: 0.3382  loss_ce_5: 1.47  loss_mask_5: 0.03376  loss_dice_5: 0.5451  loss_bbox_5: 0.06737  loss_giou_5: 0.3738  loss_ce_dn_5: 0.343  loss_mask_dn_5: 0.03655  loss_dice_dn_5: 0.6129  loss_bbox_dn_5: 0.04614  loss_giou_dn_5: 0.3327  loss_ce_6: 1.459  loss_mask_6: 0.03731  loss_dice_6: 0.8191  loss_bbox_6: 0.07381  loss_giou_6: 0.3789  loss_ce_dn_6: 0.3202  loss_mask_dn_6: 0.03645  loss_dice_dn_6: 0.63  loss_bbox_dn_6: 0.04595  loss_giou_dn_6: 0.3288  loss_ce_7: 1.506  loss_mask_7: 0.03121  loss_dice_7: 0.5998  loss_bbox_7: 0.06025  loss_giou_7: 0.3794  loss_ce_dn_7: 0.3247  loss_mask_dn_7: 0.03502  loss_dice_dn_7: 0.6391  loss_bbox_dn_7: 0.04622  loss_giou_dn_7: 0.3305  loss_ce_8: 1.517  loss_mask_8: 0.03313  loss_dice_8: 0.6008  loss_bbox_8: 0.06057  loss_giou_8: 0.3817  loss_ce_dn_8: 0.3291  loss_mask_dn_8: 0.03606  loss_dice_dn_8: 0.648  loss_bbox_dn_8: 0.04498  loss_giou_dn_8: 0.3169  loss_ce_interm: 1.716  loss_mask_interm: 0.03398  loss_dice_interm: 0.6757  loss_bbox_interm: 0.08692  loss_giou_interm: 0.507  time: 2.3050  data_time: 0.1287  lr: 0.0001  max_mem: 6620M\n",
            "[05/20 16:54:43 d2.utils.events]:  eta: 2:30:31  iter: 1059  total_loss: 61.12  loss_ce: 1.36  loss_mask: 0.03623  loss_dice: 0.9495  loss_bbox: 0.08773  loss_giou: 0.5507  loss_ce_dn: 0.3356  loss_mask_dn: 0.03779  loss_dice_dn: 1.005  loss_bbox_dn: 0.04972  loss_giou_dn: 0.4245  loss_ce_0: 1.585  loss_mask_0: 0.04522  loss_dice_0: 0.9702  loss_bbox_0: 0.1548  loss_giou_0: 0.7022  loss_ce_dn_0: 0.9736  loss_mask_dn_0: 0.303  loss_dice_dn_0: 2.822  loss_bbox_dn_0: 0.268  loss_giou_dn_0: 0.8537  loss_ce_1: 1.516  loss_mask_1: 0.03998  loss_dice_1: 0.97  loss_bbox_1: 0.1219  loss_giou_1: 0.5594  loss_ce_dn_1: 0.3794  loss_mask_dn_1: 0.05057  loss_dice_dn_1: 1.044  loss_bbox_dn_1: 0.09968  loss_giou_dn_1: 0.514  loss_ce_2: 1.628  loss_mask_2: 0.04743  loss_dice_2: 1.113  loss_bbox_2: 0.09478  loss_giou_2: 0.5433  loss_ce_dn_2: 0.3408  loss_mask_dn_2: 0.04454  loss_dice_dn_2: 0.9411  loss_bbox_dn_2: 0.06377  loss_giou_dn_2: 0.4379  loss_ce_3: 1.457  loss_mask_3: 0.04036  loss_dice_3: 1.129  loss_bbox_3: 0.1104  loss_giou_3: 0.6075  loss_ce_dn_3: 0.3367  loss_mask_dn_3: 0.03957  loss_dice_dn_3: 0.9138  loss_bbox_dn_3: 0.0586  loss_giou_dn_3: 0.4211  loss_ce_4: 1.478  loss_mask_4: 0.04324  loss_dice_4: 0.9511  loss_bbox_4: 0.1263  loss_giou_4: 0.5557  loss_ce_dn_4: 0.3442  loss_mask_dn_4: 0.0388  loss_dice_dn_4: 1.001  loss_bbox_dn_4: 0.05823  loss_giou_dn_4: 0.4226  loss_ce_5: 1.405  loss_mask_5: 0.04564  loss_dice_5: 0.9314  loss_bbox_5: 0.09429  loss_giou_5: 0.5646  loss_ce_dn_5: 0.3358  loss_mask_dn_5: 0.03871  loss_dice_dn_5: 0.943  loss_bbox_dn_5: 0.05455  loss_giou_dn_5: 0.4201  loss_ce_6: 1.428  loss_mask_6: 0.04134  loss_dice_6: 0.9026  loss_bbox_6: 0.1049  loss_giou_6: 0.6101  loss_ce_dn_6: 0.3361  loss_mask_dn_6: 0.03937  loss_dice_dn_6: 0.9751  loss_bbox_dn_6: 0.05316  loss_giou_dn_6: 0.4209  loss_ce_7: 1.458  loss_mask_7: 0.04965  loss_dice_7: 0.9368  loss_bbox_7: 0.09794  loss_giou_7: 0.5819  loss_ce_dn_7: 0.3357  loss_mask_dn_7: 0.04066  loss_dice_dn_7: 0.9941  loss_bbox_dn_7: 0.05033  loss_giou_dn_7: 0.4215  loss_ce_8: 1.405  loss_mask_8: 0.04017  loss_dice_8: 0.9018  loss_bbox_8: 0.08756  loss_giou_8: 0.664  loss_ce_dn_8: 0.34  loss_mask_dn_8: 0.03849  loss_dice_dn_8: 0.9743  loss_bbox_dn_8: 0.05137  loss_giou_dn_8: 0.4233  loss_ce_interm: 1.529  loss_mask_interm: 0.04542  loss_dice_interm: 1.081  loss_bbox_interm: 0.1305  loss_giou_interm: 0.6411  time: 2.2941  data_time: 0.0923  lr: 0.0001  max_mem: 6620M\n",
            "[05/20 16:55:19 d2.utils.events]:  eta: 2:28:50  iter: 1079  total_loss: 43.87  loss_ce: 1.19  loss_mask: 0.04963  loss_dice: 0.5754  loss_bbox: 0.1004  loss_giou: 0.3381  loss_ce_dn: 0.2693  loss_mask_dn: 0.04445  loss_dice_dn: 0.5699  loss_bbox_dn: 0.05173  loss_giou_dn: 0.3287  loss_ce_0: 1.492  loss_mask_0: 0.04853  loss_dice_0: 0.5499  loss_bbox_0: 0.0767  loss_giou_0: 0.5414  loss_ce_dn_0: 1.058  loss_mask_dn_0: 0.2499  loss_dice_dn_0: 2.429  loss_bbox_dn_0: 0.311  loss_giou_dn_0: 0.8464  loss_ce_1: 1.458  loss_mask_1: 0.04873  loss_dice_1: 0.5953  loss_bbox_1: 0.0679  loss_giou_1: 0.3797  loss_ce_dn_1: 0.3264  loss_mask_dn_1: 0.03844  loss_dice_dn_1: 0.597  loss_bbox_dn_1: 0.0812  loss_giou_dn_1: 0.4115  loss_ce_2: 1.33  loss_mask_2: 0.04931  loss_dice_2: 0.4301  loss_bbox_2: 0.08049  loss_giou_2: 0.2855  loss_ce_dn_2: 0.2907  loss_mask_dn_2: 0.03972  loss_dice_dn_2: 0.5644  loss_bbox_dn_2: 0.06464  loss_giou_dn_2: 0.3566  loss_ce_3: 1.255  loss_mask_3: 0.05641  loss_dice_3: 0.5809  loss_bbox_3: 0.08591  loss_giou_3: 0.325  loss_ce_dn_3: 0.2823  loss_mask_dn_3: 0.04091  loss_dice_dn_3: 0.547  loss_bbox_dn_3: 0.05769  loss_giou_dn_3: 0.3375  loss_ce_4: 1.312  loss_mask_4: 0.04993  loss_dice_4: 0.4597  loss_bbox_4: 0.07761  loss_giou_4: 0.3102  loss_ce_dn_4: 0.278  loss_mask_dn_4: 0.04193  loss_dice_dn_4: 0.6001  loss_bbox_dn_4: 0.05237  loss_giou_dn_4: 0.3336  loss_ce_5: 1.219  loss_mask_5: 0.04631  loss_dice_5: 0.5185  loss_bbox_5: 0.08004  loss_giou_5: 0.3122  loss_ce_dn_5: 0.277  loss_mask_dn_5: 0.04522  loss_dice_dn_5: 0.5758  loss_bbox_dn_5: 0.04962  loss_giou_dn_5: 0.3356  loss_ce_6: 1.185  loss_mask_6: 0.03976  loss_dice_6: 0.4951  loss_bbox_6: 0.09012  loss_giou_6: 0.3128  loss_ce_dn_6: 0.2559  loss_mask_dn_6: 0.04439  loss_dice_dn_6: 0.5927  loss_bbox_dn_6: 0.05018  loss_giou_dn_6: 0.3473  loss_ce_7: 1.338  loss_mask_7: 0.04777  loss_dice_7: 0.4947  loss_bbox_7: 0.08953  loss_giou_7: 0.3321  loss_ce_dn_7: 0.264  loss_mask_dn_7: 0.0452  loss_dice_dn_7: 0.6334  loss_bbox_dn_7: 0.04948  loss_giou_dn_7: 0.3342  loss_ce_8: 1.24  loss_mask_8: 0.04881  loss_dice_8: 0.589  loss_bbox_8: 0.08968  loss_giou_8: 0.339  loss_ce_dn_8: 0.273  loss_mask_dn_8: 0.04688  loss_dice_dn_8: 0.5625  loss_bbox_dn_8: 0.05094  loss_giou_dn_8: 0.3293  loss_ce_interm: 1.355  loss_mask_interm: 0.05455  loss_dice_interm: 0.4473  loss_bbox_interm: 0.114  loss_giou_interm: 0.4432  time: 2.2852  data_time: 0.1276  lr: 0.0001  max_mem: 6620M\n",
            "[05/20 16:55:53 d2.utils.events]:  eta: 2:27:12  iter: 1099  total_loss: 46.03  loss_ce: 1.454  loss_mask: 0.0437  loss_dice: 0.4543  loss_bbox: 0.06015  loss_giou: 0.3223  loss_ce_dn: 0.3573  loss_mask_dn: 0.04531  loss_dice_dn: 0.5491  loss_bbox_dn: 0.0536  loss_giou_dn: 0.311  loss_ce_0: 1.417  loss_mask_0: 0.04809  loss_dice_0: 0.7396  loss_bbox_0: 0.1211  loss_giou_0: 0.4832  loss_ce_dn_0: 1.06  loss_mask_dn_0: 0.2485  loss_dice_dn_0: 2.735  loss_bbox_dn_0: 0.246  loss_giou_dn_0: 0.8577  loss_ce_1: 1.368  loss_mask_1: 0.04966  loss_dice_1: 0.6201  loss_bbox_1: 0.08452  loss_giou_1: 0.3694  loss_ce_dn_1: 0.3764  loss_mask_dn_1: 0.04167  loss_dice_dn_1: 0.5645  loss_bbox_dn_1: 0.0724  loss_giou_dn_1: 0.405  loss_ce_2: 1.547  loss_mask_2: 0.05005  loss_dice_2: 0.6223  loss_bbox_2: 0.09686  loss_giou_2: 0.3575  loss_ce_dn_2: 0.3487  loss_mask_dn_2: 0.04262  loss_dice_dn_2: 0.5524  loss_bbox_dn_2: 0.06199  loss_giou_dn_2: 0.3728  loss_ce_3: 1.467  loss_mask_3: 0.04555  loss_dice_3: 0.4701  loss_bbox_3: 0.07524  loss_giou_3: 0.3519  loss_ce_dn_3: 0.3325  loss_mask_dn_3: 0.04252  loss_dice_dn_3: 0.5718  loss_bbox_dn_3: 0.05821  loss_giou_dn_3: 0.322  loss_ce_4: 1.451  loss_mask_4: 0.04927  loss_dice_4: 0.5813  loss_bbox_4: 0.07237  loss_giou_4: 0.3514  loss_ce_dn_4: 0.3306  loss_mask_dn_4: 0.04131  loss_dice_dn_4: 0.6034  loss_bbox_dn_4: 0.0572  loss_giou_dn_4: 0.3271  loss_ce_5: 1.481  loss_mask_5: 0.04309  loss_dice_5: 0.4757  loss_bbox_5: 0.06162  loss_giou_5: 0.3309  loss_ce_dn_5: 0.3281  loss_mask_dn_5: 0.04332  loss_dice_dn_5: 0.6021  loss_bbox_dn_5: 0.05567  loss_giou_dn_5: 0.3191  loss_ce_6: 1.494  loss_mask_6: 0.04069  loss_dice_6: 0.7481  loss_bbox_6: 0.0612  loss_giou_6: 0.3325  loss_ce_dn_6: 0.3312  loss_mask_dn_6: 0.04115  loss_dice_dn_6: 0.6012  loss_bbox_dn_6: 0.05556  loss_giou_dn_6: 0.3236  loss_ce_7: 1.478  loss_mask_7: 0.04889  loss_dice_7: 0.5589  loss_bbox_7: 0.06097  loss_giou_7: 0.3336  loss_ce_dn_7: 0.3509  loss_mask_dn_7: 0.04584  loss_dice_dn_7: 0.5996  loss_bbox_dn_7: 0.05606  loss_giou_dn_7: 0.3111  loss_ce_8: 1.354  loss_mask_8: 0.04604  loss_dice_8: 0.4931  loss_bbox_8: 0.05994  loss_giou_8: 0.3188  loss_ce_dn_8: 0.3495  loss_mask_dn_8: 0.04853  loss_dice_dn_8: 0.5419  loss_bbox_dn_8: 0.05368  loss_giou_dn_8: 0.3098  loss_ce_interm: 1.588  loss_mask_interm: 0.04684  loss_dice_interm: 0.5544  loss_bbox_interm: 0.1092  loss_giou_interm: 0.5573  time: 2.2750  data_time: 0.0369  lr: 0.0001  max_mem: 6620M\n",
            "[05/20 16:56:29 d2.utils.events]:  eta: 2:25:31  iter: 1119  total_loss: 49.59  loss_ce: 1.537  loss_mask: 0.02513  loss_dice: 0.6378  loss_bbox: 0.06967  loss_giou: 0.3492  loss_ce_dn: 0.3254  loss_mask_dn: 0.02843  loss_dice_dn: 0.693  loss_bbox_dn: 0.04552  loss_giou_dn: 0.329  loss_ce_0: 1.617  loss_mask_0: 0.02528  loss_dice_0: 0.6475  loss_bbox_0: 0.09229  loss_giou_0: 0.5313  loss_ce_dn_0: 0.9824  loss_mask_dn_0: 0.1677  loss_dice_dn_0: 2.501  loss_bbox_dn_0: 0.2203  loss_giou_dn_0: 0.8626  loss_ce_1: 1.633  loss_mask_1: 0.03418  loss_dice_1: 0.5989  loss_bbox_1: 0.07013  loss_giou_1: 0.412  loss_ce_dn_1: 0.387  loss_mask_dn_1: 0.03963  loss_dice_dn_1: 0.7181  loss_bbox_dn_1: 0.08595  loss_giou_dn_1: 0.4202  loss_ce_2: 1.727  loss_mask_2: 0.02832  loss_dice_2: 0.6  loss_bbox_2: 0.07721  loss_giou_2: 0.4344  loss_ce_dn_2: 0.3518  loss_mask_dn_2: 0.03668  loss_dice_dn_2: 0.6659  loss_bbox_dn_2: 0.07463  loss_giou_dn_2: 0.3672  loss_ce_3: 1.585  loss_mask_3: 0.03077  loss_dice_3: 0.5312  loss_bbox_3: 0.06877  loss_giou_3: 0.3625  loss_ce_dn_3: 0.3089  loss_mask_dn_3: 0.03443  loss_dice_dn_3: 0.6673  loss_bbox_dn_3: 0.05482  loss_giou_dn_3: 0.3434  loss_ce_4: 1.595  loss_mask_4: 0.02518  loss_dice_4: 0.5149  loss_bbox_4: 0.0657  loss_giou_4: 0.3423  loss_ce_dn_4: 0.2842  loss_mask_dn_4: 0.03216  loss_dice_dn_4: 0.6868  loss_bbox_dn_4: 0.0512  loss_giou_dn_4: 0.3406  loss_ce_5: 1.516  loss_mask_5: 0.03025  loss_dice_5: 0.6716  loss_bbox_5: 0.07232  loss_giou_5: 0.3686  loss_ce_dn_5: 0.315  loss_mask_dn_5: 0.03071  loss_dice_dn_5: 0.6642  loss_bbox_dn_5: 0.04987  loss_giou_dn_5: 0.3375  loss_ce_6: 1.497  loss_mask_6: 0.03561  loss_dice_6: 0.599  loss_bbox_6: 0.06987  loss_giou_6: 0.3516  loss_ce_dn_6: 0.3214  loss_mask_dn_6: 0.03075  loss_dice_dn_6: 0.6828  loss_bbox_dn_6: 0.04857  loss_giou_dn_6: 0.3371  loss_ce_7: 1.521  loss_mask_7: 0.0275  loss_dice_7: 0.6645  loss_bbox_7: 0.07135  loss_giou_7: 0.365  loss_ce_dn_7: 0.3208  loss_mask_dn_7: 0.02936  loss_dice_dn_7: 0.678  loss_bbox_dn_7: 0.04787  loss_giou_dn_7: 0.3336  loss_ce_8: 1.478  loss_mask_8: 0.02799  loss_dice_8: 0.6425  loss_bbox_8: 0.07285  loss_giou_8: 0.3578  loss_ce_dn_8: 0.3196  loss_mask_dn_8: 0.02863  loss_dice_dn_8: 0.6862  loss_bbox_dn_8: 0.04839  loss_giou_dn_8: 0.3296  loss_ce_interm: 1.742  loss_mask_interm: 0.03359  loss_dice_interm: 0.7092  loss_bbox_interm: 0.1039  loss_giou_interm: 0.5369  time: 2.2664  data_time: 0.0843  lr: 0.0001  max_mem: 6620M\n",
            "[05/20 16:57:05 d2.utils.events]:  eta: 2:23:53  iter: 1139  total_loss: 59.62  loss_ce: 1.347  loss_mask: 0.05199  loss_dice: 0.8602  loss_bbox: 0.1121  loss_giou: 0.408  loss_ce_dn: 0.2581  loss_mask_dn: 0.03554  loss_dice_dn: 0.755  loss_bbox_dn: 0.04527  loss_giou_dn: 0.4068  loss_ce_0: 1.649  loss_mask_0: 0.05276  loss_dice_0: 0.8908  loss_bbox_0: 0.1042  loss_giou_0: 0.6255  loss_ce_dn_0: 0.9556  loss_mask_dn_0: 0.2142  loss_dice_dn_0: 3.241  loss_bbox_dn_0: 0.2192  loss_giou_dn_0: 0.8547  loss_ce_1: 1.615  loss_mask_1: 0.05262  loss_dice_1: 1.159  loss_bbox_1: 0.1342  loss_giou_1: 0.4783  loss_ce_dn_1: 0.3213  loss_mask_dn_1: 0.0324  loss_dice_dn_1: 0.8186  loss_bbox_dn_1: 0.06909  loss_giou_dn_1: 0.4339  loss_ce_2: 1.577  loss_mask_2: 0.05072  loss_dice_2: 0.7647  loss_bbox_2: 0.1054  loss_giou_2: 0.4984  loss_ce_dn_2: 0.2731  loss_mask_dn_2: 0.03367  loss_dice_dn_2: 0.8679  loss_bbox_dn_2: 0.05867  loss_giou_dn_2: 0.4363  loss_ce_3: 1.391  loss_mask_3: 0.04637  loss_dice_3: 0.6185  loss_bbox_3: 0.1103  loss_giou_3: 0.3999  loss_ce_dn_3: 0.2983  loss_mask_dn_3: 0.03311  loss_dice_dn_3: 0.8774  loss_bbox_dn_3: 0.05027  loss_giou_dn_3: 0.4143  loss_ce_4: 1.394  loss_mask_4: 0.05354  loss_dice_4: 0.7186  loss_bbox_4: 0.1403  loss_giou_4: 0.4089  loss_ce_dn_4: 0.2623  loss_mask_dn_4: 0.03153  loss_dice_dn_4: 0.8506  loss_bbox_dn_4: 0.04749  loss_giou_dn_4: 0.4186  loss_ce_5: 1.451  loss_mask_5: 0.05371  loss_dice_5: 0.8497  loss_bbox_5: 0.1049  loss_giou_5: 0.4317  loss_ce_dn_5: 0.2981  loss_mask_dn_5: 0.0318  loss_dice_dn_5: 0.8345  loss_bbox_dn_5: 0.04675  loss_giou_dn_5: 0.4142  loss_ce_6: 1.328  loss_mask_6: 0.04673  loss_dice_6: 0.7108  loss_bbox_6: 0.1318  loss_giou_6: 0.4332  loss_ce_dn_6: 0.279  loss_mask_dn_6: 0.03164  loss_dice_dn_6: 0.85  loss_bbox_dn_6: 0.0469  loss_giou_dn_6: 0.4142  loss_ce_7: 1.276  loss_mask_7: 0.04885  loss_dice_7: 0.7256  loss_bbox_7: 0.1125  loss_giou_7: 0.4318  loss_ce_dn_7: 0.2563  loss_mask_dn_7: 0.03296  loss_dice_dn_7: 0.765  loss_bbox_dn_7: 0.04441  loss_giou_dn_7: 0.4088  loss_ce_8: 1.273  loss_mask_8: 0.04788  loss_dice_8: 0.7564  loss_bbox_8: 0.1176  loss_giou_8: 0.4118  loss_ce_dn_8: 0.2619  loss_mask_dn_8: 0.03472  loss_dice_dn_8: 0.7878  loss_bbox_dn_8: 0.04546  loss_giou_dn_8: 0.4076  loss_ce_interm: 1.614  loss_mask_interm: 0.03954  loss_dice_interm: 0.848  loss_bbox_interm: 0.1606  loss_giou_interm: 0.5733  time: 2.2576  data_time: 0.0898  lr: 0.0001  max_mem: 6620M\n",
            "[05/20 16:57:40 d2.utils.events]:  eta: 2:22:20  iter: 1159  total_loss: 47.66  loss_ce: 1.332  loss_mask: 0.04649  loss_dice: 0.678  loss_bbox: 0.07145  loss_giou: 0.4038  loss_ce_dn: 0.2964  loss_mask_dn: 0.04978  loss_dice_dn: 0.6848  loss_bbox_dn: 0.04715  loss_giou_dn: 0.3116  loss_ce_0: 1.511  loss_mask_0: 0.04816  loss_dice_0: 0.9254  loss_bbox_0: 0.06768  loss_giou_0: 0.4478  loss_ce_dn_0: 0.9069  loss_mask_dn_0: 0.2362  loss_dice_dn_0: 2.152  loss_bbox_dn_0: 0.2667  loss_giou_dn_0: 0.8593  loss_ce_1: 1.488  loss_mask_1: 0.04712  loss_dice_1: 0.5904  loss_bbox_1: 0.06595  loss_giou_1: 0.3884  loss_ce_dn_1: 0.3305  loss_mask_dn_1: 0.05253  loss_dice_dn_1: 0.8025  loss_bbox_dn_1: 0.07265  loss_giou_dn_1: 0.4348  loss_ce_2: 1.461  loss_mask_2: 0.04169  loss_dice_2: 0.7068  loss_bbox_2: 0.06354  loss_giou_2: 0.3796  loss_ce_dn_2: 0.3099  loss_mask_dn_2: 0.04684  loss_dice_dn_2: 0.7781  loss_bbox_dn_2: 0.05977  loss_giou_dn_2: 0.357  loss_ce_3: 1.367  loss_mask_3: 0.04508  loss_dice_3: 0.795  loss_bbox_3: 0.07078  loss_giou_3: 0.4091  loss_ce_dn_3: 0.3038  loss_mask_dn_3: 0.04718  loss_dice_dn_3: 0.7535  loss_bbox_dn_3: 0.04843  loss_giou_dn_3: 0.3165  loss_ce_4: 1.305  loss_mask_4: 0.04712  loss_dice_4: 0.7829  loss_bbox_4: 0.07655  loss_giou_4: 0.4035  loss_ce_dn_4: 0.3058  loss_mask_dn_4: 0.04854  loss_dice_dn_4: 0.6833  loss_bbox_dn_4: 0.05045  loss_giou_dn_4: 0.3161  loss_ce_5: 1.353  loss_mask_5: 0.04623  loss_dice_5: 0.5823  loss_bbox_5: 0.07617  loss_giou_5: 0.4147  loss_ce_dn_5: 0.2959  loss_mask_dn_5: 0.048  loss_dice_dn_5: 0.7049  loss_bbox_dn_5: 0.04821  loss_giou_dn_5: 0.3105  loss_ce_6: 1.304  loss_mask_6: 0.04815  loss_dice_6: 0.7827  loss_bbox_6: 0.06763  loss_giou_6: 0.441  loss_ce_dn_6: 0.3033  loss_mask_dn_6: 0.04623  loss_dice_dn_6: 0.6689  loss_bbox_dn_6: 0.048  loss_giou_dn_6: 0.3087  loss_ce_7: 1.313  loss_mask_7: 0.0487  loss_dice_7: 0.5712  loss_bbox_7: 0.07219  loss_giou_7: 0.4084  loss_ce_dn_7: 0.2919  loss_mask_dn_7: 0.04944  loss_dice_dn_7: 0.6691  loss_bbox_dn_7: 0.04809  loss_giou_dn_7: 0.3133  loss_ce_8: 1.33  loss_mask_8: 0.04393  loss_dice_8: 0.6447  loss_bbox_8: 0.072  loss_giou_8: 0.4082  loss_ce_dn_8: 0.2903  loss_mask_dn_8: 0.05027  loss_dice_dn_8: 0.7194  loss_bbox_dn_8: 0.04802  loss_giou_dn_8: 0.3097  loss_ce_interm: 1.342  loss_mask_interm: 0.05277  loss_dice_interm: 0.6868  loss_bbox_interm: 0.08495  loss_giou_interm: 0.4171  time: 2.2492  data_time: 0.1011  lr: 0.0001  max_mem: 6620M\n",
            "[05/20 16:58:14 d2.utils.events]:  eta: 2:20:56  iter: 1179  total_loss: 56.14  loss_ce: 1.138  loss_mask: 0.05216  loss_dice: 0.8089  loss_bbox: 0.04412  loss_giou: 0.4314  loss_ce_dn: 0.2826  loss_mask_dn: 0.05194  loss_dice_dn: 0.7023  loss_bbox_dn: 0.05457  loss_giou_dn: 0.3501  loss_ce_0: 1.505  loss_mask_0: 0.06232  loss_dice_0: 0.7995  loss_bbox_0: 0.1155  loss_giou_0: 0.4942  loss_ce_dn_0: 0.884  loss_mask_dn_0: 0.1545  loss_dice_dn_0: 2.493  loss_bbox_dn_0: 0.3562  loss_giou_dn_0: 0.8628  loss_ce_1: 1.541  loss_mask_1: 0.06119  loss_dice_1: 0.8992  loss_bbox_1: 0.09839  loss_giou_1: 0.467  loss_ce_dn_1: 0.3587  loss_mask_dn_1: 0.05965  loss_dice_dn_1: 0.7561  loss_bbox_dn_1: 0.1037  loss_giou_dn_1: 0.4631  loss_ce_2: 1.42  loss_mask_2: 0.06299  loss_dice_2: 0.6993  loss_bbox_2: 0.0957  loss_giou_2: 0.4483  loss_ce_dn_2: 0.333  loss_mask_dn_2: 0.0577  loss_dice_dn_2: 0.7227  loss_bbox_dn_2: 0.07839  loss_giou_dn_2: 0.382  loss_ce_3: 1.214  loss_mask_3: 0.05265  loss_dice_3: 0.8992  loss_bbox_3: 0.06276  loss_giou_3: 0.458  loss_ce_dn_3: 0.3339  loss_mask_dn_3: 0.05398  loss_dice_dn_3: 0.7123  loss_bbox_dn_3: 0.0555  loss_giou_dn_3: 0.3647  loss_ce_4: 1.187  loss_mask_4: 0.06204  loss_dice_4: 0.9156  loss_bbox_4: 0.08785  loss_giou_4: 0.5114  loss_ce_dn_4: 0.2994  loss_mask_dn_4: 0.05348  loss_dice_dn_4: 0.6964  loss_bbox_dn_4: 0.06053  loss_giou_dn_4: 0.352  loss_ce_5: 1.221  loss_mask_5: 0.05418  loss_dice_5: 0.5684  loss_bbox_5: 0.0886  loss_giou_5: 0.488  loss_ce_dn_5: 0.2957  loss_mask_dn_5: 0.05259  loss_dice_dn_5: 0.7003  loss_bbox_dn_5: 0.05755  loss_giou_dn_5: 0.3454  loss_ce_6: 1.185  loss_mask_6: 0.06817  loss_dice_6: 0.8367  loss_bbox_6: 0.06678  loss_giou_6: 0.4926  loss_ce_dn_6: 0.2858  loss_mask_dn_6: 0.05101  loss_dice_dn_6: 0.7102  loss_bbox_dn_6: 0.0539  loss_giou_dn_6: 0.3468  loss_ce_7: 1.125  loss_mask_7: 0.06217  loss_dice_7: 0.8027  loss_bbox_7: 0.06802  loss_giou_7: 0.4691  loss_ce_dn_7: 0.2856  loss_mask_dn_7: 0.05216  loss_dice_dn_7: 0.7291  loss_bbox_dn_7: 0.05308  loss_giou_dn_7: 0.3476  loss_ce_8: 1.149  loss_mask_8: 0.06143  loss_dice_8: 0.8576  loss_bbox_8: 0.06891  loss_giou_8: 0.4496  loss_ce_dn_8: 0.2904  loss_mask_dn_8: 0.0521  loss_dice_dn_8: 0.7011  loss_bbox_dn_8: 0.05448  loss_giou_dn_8: 0.3498  loss_ce_interm: 1.411  loss_mask_interm: 0.06321  loss_dice_interm: 0.663  loss_bbox_interm: 0.12  loss_giou_interm: 0.6746  time: 2.2399  data_time: 0.0605  lr: 0.0001  max_mem: 6620M\n",
            "[05/20 16:58:49 d2.utils.events]:  eta: 2:19:17  iter: 1199  total_loss: 54.91  loss_ce: 1.459  loss_mask: 0.06294  loss_dice: 0.7897  loss_bbox: 0.07492  loss_giou: 0.3567  loss_ce_dn: 0.3198  loss_mask_dn: 0.05332  loss_dice_dn: 0.6722  loss_bbox_dn: 0.06223  loss_giou_dn: 0.3048  loss_ce_0: 1.397  loss_mask_0: 0.06707  loss_dice_0: 0.8986  loss_bbox_0: 0.1102  loss_giou_0: 0.4152  loss_ce_dn_0: 1.018  loss_mask_dn_0: 0.2627  loss_dice_dn_0: 2.424  loss_bbox_dn_0: 0.3411  loss_giou_dn_0: 0.8554  loss_ce_1: 1.478  loss_mask_1: 0.06016  loss_dice_1: 0.7648  loss_bbox_1: 0.09542  loss_giou_1: 0.4172  loss_ce_dn_1: 0.3809  loss_mask_dn_1: 0.06495  loss_dice_dn_1: 0.6714  loss_bbox_dn_1: 0.1185  loss_giou_dn_1: 0.415  loss_ce_2: 1.537  loss_mask_2: 0.05803  loss_dice_2: 0.6597  loss_bbox_2: 0.09875  loss_giou_2: 0.3761  loss_ce_dn_2: 0.3719  loss_mask_dn_2: 0.05898  loss_dice_dn_2: 0.6831  loss_bbox_dn_2: 0.08478  loss_giou_dn_2: 0.3728  loss_ce_3: 1.469  loss_mask_3: 0.05508  loss_dice_3: 0.671  loss_bbox_3: 0.09932  loss_giou_3: 0.4034  loss_ce_dn_3: 0.3577  loss_mask_dn_3: 0.06069  loss_dice_dn_3: 0.6892  loss_bbox_dn_3: 0.07404  loss_giou_dn_3: 0.3325  loss_ce_4: 1.472  loss_mask_4: 0.06041  loss_dice_4: 0.6156  loss_bbox_4: 0.06876  loss_giou_4: 0.3841  loss_ce_dn_4: 0.3563  loss_mask_dn_4: 0.05873  loss_dice_dn_4: 0.6552  loss_bbox_dn_4: 0.06993  loss_giou_dn_4: 0.3219  loss_ce_5: 1.411  loss_mask_5: 0.0558  loss_dice_5: 0.5713  loss_bbox_5: 0.06168  loss_giou_5: 0.408  loss_ce_dn_5: 0.3457  loss_mask_dn_5: 0.05662  loss_dice_dn_5: 0.6504  loss_bbox_dn_5: 0.06837  loss_giou_dn_5: 0.3229  loss_ce_6: 1.382  loss_mask_6: 0.05391  loss_dice_6: 0.6067  loss_bbox_6: 0.06913  loss_giou_6: 0.4041  loss_ce_dn_6: 0.3182  loss_mask_dn_6: 0.05605  loss_dice_dn_6: 0.6679  loss_bbox_dn_6: 0.06709  loss_giou_dn_6: 0.3229  loss_ce_7: 1.46  loss_mask_7: 0.05755  loss_dice_7: 0.653  loss_bbox_7: 0.07198  loss_giou_7: 0.4023  loss_ce_dn_7: 0.312  loss_mask_dn_7: 0.05293  loss_dice_dn_7: 0.6953  loss_bbox_dn_7: 0.06846  loss_giou_dn_7: 0.3105  loss_ce_8: 1.46  loss_mask_8: 0.05642  loss_dice_8: 0.6214  loss_bbox_8: 0.07347  loss_giou_8: 0.4012  loss_ce_dn_8: 0.3116  loss_mask_dn_8: 0.05273  loss_dice_dn_8: 0.6852  loss_bbox_dn_8: 0.06472  loss_giou_dn_8: 0.3076  loss_ce_interm: 1.553  loss_mask_interm: 0.06492  loss_dice_interm: 0.6753  loss_bbox_interm: 0.1906  loss_giou_interm: 0.5587  time: 2.2315  data_time: 0.0884  lr: 0.0001  max_mem: 6620M\n",
            "[05/20 16:59:23 d2.utils.events]:  eta: 2:17:33  iter: 1219  total_loss: 47.25  loss_ce: 1.272  loss_mask: 0.03068  loss_dice: 0.7674  loss_bbox: 0.1022  loss_giou: 0.4672  loss_ce_dn: 0.2617  loss_mask_dn: 0.05131  loss_dice_dn: 0.6872  loss_bbox_dn: 0.04909  loss_giou_dn: 0.3148  loss_ce_0: 1.349  loss_mask_0: 0.0306  loss_dice_0: 0.7531  loss_bbox_0: 0.1055  loss_giou_0: 0.5672  loss_ce_dn_0: 0.9982  loss_mask_dn_0: 0.2491  loss_dice_dn_0: 2.999  loss_bbox_dn_0: 0.2273  loss_giou_dn_0: 0.8538  loss_ce_1: 1.325  loss_mask_1: 0.03122  loss_dice_1: 0.6709  loss_bbox_1: 0.07338  loss_giou_1: 0.4609  loss_ce_dn_1: 0.3146  loss_mask_dn_1: 0.04327  loss_dice_dn_1: 0.6716  loss_bbox_dn_1: 0.08059  loss_giou_dn_1: 0.4244  loss_ce_2: 1.288  loss_mask_2: 0.03652  loss_dice_2: 0.6964  loss_bbox_2: 0.08821  loss_giou_2: 0.5353  loss_ce_dn_2: 0.3422  loss_mask_dn_2: 0.03977  loss_dice_dn_2: 0.6216  loss_bbox_dn_2: 0.05816  loss_giou_dn_2: 0.3705  loss_ce_3: 1.325  loss_mask_3: 0.04408  loss_dice_3: 0.5542  loss_bbox_3: 0.08543  loss_giou_3: 0.4834  loss_ce_dn_3: 0.2873  loss_mask_dn_3: 0.04114  loss_dice_dn_3: 0.6598  loss_bbox_dn_3: 0.05199  loss_giou_dn_3: 0.3338  loss_ce_4: 1.369  loss_mask_4: 0.04804  loss_dice_4: 0.6636  loss_bbox_4: 0.0858  loss_giou_4: 0.467  loss_ce_dn_4: 0.272  loss_mask_dn_4: 0.04271  loss_dice_dn_4: 0.6258  loss_bbox_dn_4: 0.05362  loss_giou_dn_4: 0.3291  loss_ce_5: 1.302  loss_mask_5: 0.03926  loss_dice_5: 0.7994  loss_bbox_5: 0.1107  loss_giou_5: 0.4652  loss_ce_dn_5: 0.2624  loss_mask_dn_5: 0.04418  loss_dice_dn_5: 0.6557  loss_bbox_dn_5: 0.04998  loss_giou_dn_5: 0.3204  loss_ce_6: 1.352  loss_mask_6: 0.03178  loss_dice_6: 0.7495  loss_bbox_6: 0.09141  loss_giou_6: 0.4642  loss_ce_dn_6: 0.2493  loss_mask_dn_6: 0.04149  loss_dice_dn_6: 0.6488  loss_bbox_dn_6: 0.05052  loss_giou_dn_6: 0.321  loss_ce_7: 1.281  loss_mask_7: 0.03225  loss_dice_7: 0.6734  loss_bbox_7: 0.1024  loss_giou_7: 0.463  loss_ce_dn_7: 0.2538  loss_mask_dn_7: 0.04808  loss_dice_dn_7: 0.6418  loss_bbox_dn_7: 0.04853  loss_giou_dn_7: 0.3131  loss_ce_8: 1.247  loss_mask_8: 0.03916  loss_dice_8: 0.5991  loss_bbox_8: 0.1013  loss_giou_8: 0.4671  loss_ce_dn_8: 0.2629  loss_mask_dn_8: 0.05135  loss_dice_dn_8: 0.6621  loss_bbox_dn_8: 0.0479  loss_giou_dn_8: 0.3143  loss_ce_interm: 1.405  loss_mask_interm: 0.03395  loss_dice_interm: 0.6857  loss_bbox_interm: 0.113  loss_giou_interm: 0.61  time: 2.2227  data_time: 0.0773  lr: 0.0001  max_mem: 6620M\n",
            "[05/20 16:59:58 d2.utils.events]:  eta: 2:16:33  iter: 1239  total_loss: 53.87  loss_ce: 1.442  loss_mask: 0.02611  loss_dice: 0.6463  loss_bbox: 0.07961  loss_giou: 0.467  loss_ce_dn: 0.3899  loss_mask_dn: 0.02365  loss_dice_dn: 0.7516  loss_bbox_dn: 0.03984  loss_giou_dn: 0.4131  loss_ce_0: 1.628  loss_mask_0: 0.02736  loss_dice_0: 0.8058  loss_bbox_0: 0.1126  loss_giou_0: 0.6011  loss_ce_dn_0: 0.9546  loss_mask_dn_0: 0.1603  loss_dice_dn_0: 2.837  loss_bbox_dn_0: 0.2038  loss_giou_dn_0: 0.8623  loss_ce_1: 1.628  loss_mask_1: 0.02206  loss_dice_1: 0.7888  loss_bbox_1: 0.1159  loss_giou_1: 0.553  loss_ce_dn_1: 0.3589  loss_mask_dn_1: 0.02454  loss_dice_dn_1: 0.7375  loss_bbox_dn_1: 0.07347  loss_giou_dn_1: 0.5228  loss_ce_2: 1.549  loss_mask_2: 0.02378  loss_dice_2: 0.7358  loss_bbox_2: 0.1236  loss_giou_2: 0.501  loss_ce_dn_2: 0.3579  loss_mask_dn_2: 0.02543  loss_dice_dn_2: 0.7017  loss_bbox_dn_2: 0.05075  loss_giou_dn_2: 0.4506  loss_ce_3: 1.507  loss_mask_3: 0.02644  loss_dice_3: 0.7878  loss_bbox_3: 0.1216  loss_giou_3: 0.4947  loss_ce_dn_3: 0.3577  loss_mask_dn_3: 0.0219  loss_dice_dn_3: 0.723  loss_bbox_dn_3: 0.04649  loss_giou_dn_3: 0.4244  loss_ce_4: 1.583  loss_mask_4: 0.02799  loss_dice_4: 0.7875  loss_bbox_4: 0.07936  loss_giou_4: 0.5158  loss_ce_dn_4: 0.3673  loss_mask_dn_4: 0.02407  loss_dice_dn_4: 0.7437  loss_bbox_dn_4: 0.0452  loss_giou_dn_4: 0.4146  loss_ce_5: 1.515  loss_mask_5: 0.02242  loss_dice_5: 0.7016  loss_bbox_5: 0.08849  loss_giou_5: 0.4823  loss_ce_dn_5: 0.3756  loss_mask_dn_5: 0.02328  loss_dice_dn_5: 0.7318  loss_bbox_dn_5: 0.04122  loss_giou_dn_5: 0.4154  loss_ce_6: 1.483  loss_mask_6: 0.02576  loss_dice_6: 0.7576  loss_bbox_6: 0.07854  loss_giou_6: 0.4542  loss_ce_dn_6: 0.4036  loss_mask_dn_6: 0.0239  loss_dice_dn_6: 0.7228  loss_bbox_dn_6: 0.04189  loss_giou_dn_6: 0.4143  loss_ce_7: 1.487  loss_mask_7: 0.02811  loss_dice_7: 0.6823  loss_bbox_7: 0.0763  loss_giou_7: 0.4695  loss_ce_dn_7: 0.4121  loss_mask_dn_7: 0.02445  loss_dice_dn_7: 0.715  loss_bbox_dn_7: 0.04022  loss_giou_dn_7: 0.4199  loss_ce_8: 1.439  loss_mask_8: 0.02558  loss_dice_8: 0.5403  loss_bbox_8: 0.07524  loss_giou_8: 0.4515  loss_ce_dn_8: 0.3993  loss_mask_dn_8: 0.02346  loss_dice_dn_8: 0.7266  loss_bbox_dn_8: 0.0398  loss_giou_dn_8: 0.4148  loss_ce_interm: 1.608  loss_mask_interm: 0.02623  loss_dice_interm: 0.8427  loss_bbox_interm: 0.08887  loss_giou_interm: 0.658  time: 2.2152  data_time: 0.0977  lr: 0.0001  max_mem: 6620M\n",
            "[05/20 17:00:33 d2.utils.events]:  eta: 2:14:57  iter: 1259  total_loss: 52.23  loss_ce: 1.268  loss_mask: 0.04481  loss_dice: 0.683  loss_bbox: 0.06746  loss_giou: 0.41  loss_ce_dn: 0.2781  loss_mask_dn: 0.04144  loss_dice_dn: 0.6169  loss_bbox_dn: 0.05369  loss_giou_dn: 0.318  loss_ce_0: 1.581  loss_mask_0: 0.04119  loss_dice_0: 0.4646  loss_bbox_0: 0.08608  loss_giou_0: 0.4689  loss_ce_dn_0: 0.8603  loss_mask_dn_0: 0.2479  loss_dice_dn_0: 2.183  loss_bbox_dn_0: 0.2769  loss_giou_dn_0: 0.8554  loss_ce_1: 1.523  loss_mask_1: 0.04658  loss_dice_1: 0.6866  loss_bbox_1: 0.07358  loss_giou_1: 0.3936  loss_ce_dn_1: 0.3349  loss_mask_dn_1: 0.0535  loss_dice_dn_1: 0.7901  loss_bbox_dn_1: 0.09968  loss_giou_dn_1: 0.4236  loss_ce_2: 1.529  loss_mask_2: 0.04357  loss_dice_2: 0.6439  loss_bbox_2: 0.08141  loss_giou_2: 0.3944  loss_ce_dn_2: 0.2722  loss_mask_dn_2: 0.05153  loss_dice_dn_2: 0.613  loss_bbox_dn_2: 0.08262  loss_giou_dn_2: 0.3598  loss_ce_3: 1.383  loss_mask_3: 0.03723  loss_dice_3: 0.6221  loss_bbox_3: 0.08029  loss_giou_3: 0.42  loss_ce_dn_3: 0.2718  loss_mask_dn_3: 0.04621  loss_dice_dn_3: 0.6298  loss_bbox_dn_3: 0.06382  loss_giou_dn_3: 0.3311  loss_ce_4: 1.434  loss_mask_4: 0.03384  loss_dice_4: 0.6992  loss_bbox_4: 0.1001  loss_giou_4: 0.3941  loss_ce_dn_4: 0.2667  loss_mask_dn_4: 0.04772  loss_dice_dn_4: 0.5915  loss_bbox_dn_4: 0.05428  loss_giou_dn_4: 0.3208  loss_ce_5: 1.321  loss_mask_5: 0.0424  loss_dice_5: 0.6698  loss_bbox_5: 0.07821  loss_giou_5: 0.3704  loss_ce_dn_5: 0.2632  loss_mask_dn_5: 0.04919  loss_dice_dn_5: 0.5871  loss_bbox_dn_5: 0.05619  loss_giou_dn_5: 0.3138  loss_ce_6: 1.35  loss_mask_6: 0.04549  loss_dice_6: 0.6078  loss_bbox_6: 0.08324  loss_giou_6: 0.3909  loss_ce_dn_6: 0.2654  loss_mask_dn_6: 0.04932  loss_dice_dn_6: 0.6091  loss_bbox_dn_6: 0.05816  loss_giou_dn_6: 0.3158  loss_ce_7: 1.285  loss_mask_7: 0.03654  loss_dice_7: 0.6864  loss_bbox_7: 0.07987  loss_giou_7: 0.4055  loss_ce_dn_7: 0.2759  loss_mask_dn_7: 0.04397  loss_dice_dn_7: 0.6145  loss_bbox_dn_7: 0.05415  loss_giou_dn_7: 0.3177  loss_ce_8: 1.278  loss_mask_8: 0.03984  loss_dice_8: 0.8351  loss_bbox_8: 0.07946  loss_giou_8: 0.3834  loss_ce_dn_8: 0.2782  loss_mask_dn_8: 0.04293  loss_dice_dn_8: 0.5927  loss_bbox_dn_8: 0.0545  loss_giou_dn_8: 0.3146  loss_ce_interm: 1.535  loss_mask_interm: 0.04977  loss_dice_interm: 0.6584  loss_bbox_interm: 0.14  loss_giou_interm: 0.5365  time: 2.2072  data_time: 0.0859  lr: 0.0001  max_mem: 6620M\n",
            "[05/20 17:01:08 d2.utils.events]:  eta: 2:13:09  iter: 1279  total_loss: 52.92  loss_ce: 1.377  loss_mask: 0.06219  loss_dice: 0.7184  loss_bbox: 0.08149  loss_giou: 0.401  loss_ce_dn: 0.2712  loss_mask_dn: 0.04558  loss_dice_dn: 0.5682  loss_bbox_dn: 0.05844  loss_giou_dn: 0.3396  loss_ce_0: 1.418  loss_mask_0: 0.05897  loss_dice_0: 0.6199  loss_bbox_0: 0.1159  loss_giou_0: 0.5606  loss_ce_dn_0: 0.8885  loss_mask_dn_0: 0.2434  loss_dice_dn_0: 2.913  loss_bbox_dn_0: 0.3345  loss_giou_dn_0: 0.8579  loss_ce_1: 1.401  loss_mask_1: 0.0732  loss_dice_1: 0.7529  loss_bbox_1: 0.1185  loss_giou_1: 0.4301  loss_ce_dn_1: 0.3346  loss_mask_dn_1: 0.0512  loss_dice_dn_1: 0.6554  loss_bbox_dn_1: 0.1076  loss_giou_dn_1: 0.446  loss_ce_2: 1.54  loss_mask_2: 0.06106  loss_dice_2: 0.6648  loss_bbox_2: 0.1019  loss_giou_2: 0.438  loss_ce_dn_2: 0.2896  loss_mask_dn_2: 0.04567  loss_dice_dn_2: 0.6078  loss_bbox_dn_2: 0.0772  loss_giou_dn_2: 0.3709  loss_ce_3: 1.495  loss_mask_3: 0.05689  loss_dice_3: 0.6258  loss_bbox_3: 0.1014  loss_giou_3: 0.4371  loss_ce_dn_3: 0.2744  loss_mask_dn_3: 0.0414  loss_dice_dn_3: 0.5661  loss_bbox_dn_3: 0.06819  loss_giou_dn_3: 0.3461  loss_ce_4: 1.558  loss_mask_4: 0.05883  loss_dice_4: 0.6904  loss_bbox_4: 0.08444  loss_giou_4: 0.4318  loss_ce_dn_4: 0.2613  loss_mask_dn_4: 0.04161  loss_dice_dn_4: 0.5771  loss_bbox_dn_4: 0.05985  loss_giou_dn_4: 0.3379  loss_ce_5: 1.458  loss_mask_5: 0.05841  loss_dice_5: 0.6303  loss_bbox_5: 0.08751  loss_giou_5: 0.4168  loss_ce_dn_5: 0.2633  loss_mask_dn_5: 0.04391  loss_dice_dn_5: 0.5428  loss_bbox_dn_5: 0.0586  loss_giou_dn_5: 0.3308  loss_ce_6: 1.361  loss_mask_6: 0.06406  loss_dice_6: 0.8003  loss_bbox_6: 0.08463  loss_giou_6: 0.4127  loss_ce_dn_6: 0.2508  loss_mask_dn_6: 0.04743  loss_dice_dn_6: 0.5293  loss_bbox_dn_6: 0.05821  loss_giou_dn_6: 0.3356  loss_ce_7: 1.286  loss_mask_7: 0.05728  loss_dice_7: 0.5884  loss_bbox_7: 0.08404  loss_giou_7: 0.4096  loss_ce_dn_7: 0.2675  loss_mask_dn_7: 0.04297  loss_dice_dn_7: 0.5641  loss_bbox_dn_7: 0.06052  loss_giou_dn_7: 0.3364  loss_ce_8: 1.373  loss_mask_8: 0.05663  loss_dice_8: 0.5908  loss_bbox_8: 0.08573  loss_giou_8: 0.4052  loss_ce_dn_8: 0.2718  loss_mask_dn_8: 0.04569  loss_dice_dn_8: 0.5599  loss_bbox_dn_8: 0.05932  loss_giou_dn_8: 0.3375  loss_ce_interm: 1.612  loss_mask_interm: 0.06029  loss_dice_interm: 0.6291  loss_bbox_interm: 0.1371  loss_giou_interm: 0.6238  time: 2.2005  data_time: 0.0791  lr: 0.0001  max_mem: 6620M\n",
            "[05/20 17:01:44 d2.utils.events]:  eta: 2:11:00  iter: 1299  total_loss: 43.09  loss_ce: 1.123  loss_mask: 0.03782  loss_dice: 0.4895  loss_bbox: 0.05251  loss_giou: 0.2565  loss_ce_dn: 0.2227  loss_mask_dn: 0.04292  loss_dice_dn: 0.5086  loss_bbox_dn: 0.05257  loss_giou_dn: 0.2343  loss_ce_0: 1.426  loss_mask_0: 0.03688  loss_dice_0: 0.4796  loss_bbox_0: 0.05129  loss_giou_0: 0.2794  loss_ce_dn_0: 0.8527  loss_mask_dn_0: 0.2049  loss_dice_dn_0: 2.09  loss_bbox_dn_0: 0.3417  loss_giou_dn_0: 0.851  loss_ce_1: 1.325  loss_mask_1: 0.03559  loss_dice_1: 0.4216  loss_bbox_1: 0.04725  loss_giou_1: 0.2689  loss_ce_dn_1: 0.2888  loss_mask_dn_1: 0.04251  loss_dice_dn_1: 0.5598  loss_bbox_dn_1: 0.08615  loss_giou_dn_1: 0.34  loss_ce_2: 1.323  loss_mask_2: 0.03646  loss_dice_2: 0.4331  loss_bbox_2: 0.0491  loss_giou_2: 0.2567  loss_ce_dn_2: 0.2776  loss_mask_dn_2: 0.04056  loss_dice_dn_2: 0.5227  loss_bbox_dn_2: 0.06653  loss_giou_dn_2: 0.2828  loss_ce_3: 1.206  loss_mask_3: 0.03776  loss_dice_3: 0.4817  loss_bbox_3: 0.05652  loss_giou_3: 0.2411  loss_ce_dn_3: 0.2381  loss_mask_dn_3: 0.03991  loss_dice_dn_3: 0.5193  loss_bbox_dn_3: 0.06009  loss_giou_dn_3: 0.2388  loss_ce_4: 1.14  loss_mask_4: 0.04059  loss_dice_4: 0.4914  loss_bbox_4: 0.05474  loss_giou_4: 0.2356  loss_ce_dn_4: 0.2359  loss_mask_dn_4: 0.0418  loss_dice_dn_4: 0.4923  loss_bbox_dn_4: 0.05635  loss_giou_dn_4: 0.2475  loss_ce_5: 0.9696  loss_mask_5: 0.04229  loss_dice_5: 0.4747  loss_bbox_5: 0.05247  loss_giou_5: 0.2377  loss_ce_dn_5: 0.227  loss_mask_dn_5: 0.04131  loss_dice_dn_5: 0.4968  loss_bbox_dn_5: 0.05056  loss_giou_dn_5: 0.2331  loss_ce_6: 1.045  loss_mask_6: 0.04221  loss_dice_6: 0.4684  loss_bbox_6: 0.05382  loss_giou_6: 0.2455  loss_ce_dn_6: 0.2384  loss_mask_dn_6: 0.04528  loss_dice_dn_6: 0.5148  loss_bbox_dn_6: 0.04962  loss_giou_dn_6: 0.2374  loss_ce_7: 1.067  loss_mask_7: 0.0392  loss_dice_7: 0.4319  loss_bbox_7: 0.05288  loss_giou_7: 0.2461  loss_ce_dn_7: 0.2314  loss_mask_dn_7: 0.04359  loss_dice_dn_7: 0.4987  loss_bbox_dn_7: 0.05031  loss_giou_dn_7: 0.2365  loss_ce_8: 1.107  loss_mask_8: 0.0396  loss_dice_8: 0.4178  loss_bbox_8: 0.04991  loss_giou_8: 0.253  loss_ce_dn_8: 0.2352  loss_mask_dn_8: 0.0451  loss_dice_dn_8: 0.4976  loss_bbox_dn_8: 0.05278  loss_giou_dn_8: 0.2274  loss_ce_interm: 1.412  loss_mask_interm: 0.04157  loss_dice_interm: 0.5957  loss_bbox_interm: 0.1035  loss_giou_interm: 0.4337  time: 2.1937  data_time: 0.1145  lr: 0.0001  max_mem: 6620M\n",
            "[05/20 17:02:17 d2.utils.events]:  eta: 2:09:36  iter: 1319  total_loss: 44.29  loss_ce: 1.148  loss_mask: 0.02839  loss_dice: 0.5546  loss_bbox: 0.04991  loss_giou: 0.3917  loss_ce_dn: 0.2668  loss_mask_dn: 0.02843  loss_dice_dn: 0.52  loss_bbox_dn: 0.04334  loss_giou_dn: 0.2878  loss_ce_0: 1.331  loss_mask_0: 0.03109  loss_dice_0: 0.7286  loss_bbox_0: 0.05355  loss_giou_0: 0.434  loss_ce_dn_0: 0.8771  loss_mask_dn_0: 0.1127  loss_dice_dn_0: 2.348  loss_bbox_dn_0: 0.2409  loss_giou_dn_0: 0.8496  loss_ce_1: 1.328  loss_mask_1: 0.02767  loss_dice_1: 0.5065  loss_bbox_1: 0.04938  loss_giou_1: 0.3929  loss_ce_dn_1: 0.3188  loss_mask_dn_1: 0.03416  loss_dice_dn_1: 0.5908  loss_bbox_dn_1: 0.08271  loss_giou_dn_1: 0.4014  loss_ce_2: 1.295  loss_mask_2: 0.02771  loss_dice_2: 0.604  loss_bbox_2: 0.05758  loss_giou_2: 0.3895  loss_ce_dn_2: 0.2985  loss_mask_dn_2: 0.02923  loss_dice_dn_2: 0.5122  loss_bbox_dn_2: 0.05375  loss_giou_dn_2: 0.3385  loss_ce_3: 1.286  loss_mask_3: 0.03186  loss_dice_3: 0.4817  loss_bbox_3: 0.0521  loss_giou_3: 0.4038  loss_ce_dn_3: 0.2766  loss_mask_dn_3: 0.03027  loss_dice_dn_3: 0.5148  loss_bbox_dn_3: 0.04273  loss_giou_dn_3: 0.3084  loss_ce_4: 1.202  loss_mask_4: 0.02762  loss_dice_4: 0.6096  loss_bbox_4: 0.04647  loss_giou_4: 0.4067  loss_ce_dn_4: 0.2661  loss_mask_dn_4: 0.02775  loss_dice_dn_4: 0.5419  loss_bbox_dn_4: 0.03721  loss_giou_dn_4: 0.298  loss_ce_5: 1.117  loss_mask_5: 0.02837  loss_dice_5: 0.5443  loss_bbox_5: 0.04798  loss_giou_5: 0.4024  loss_ce_dn_5: 0.2546  loss_mask_dn_5: 0.02777  loss_dice_dn_5: 0.5348  loss_bbox_dn_5: 0.04463  loss_giou_dn_5: 0.2904  loss_ce_6: 1.209  loss_mask_6: 0.02835  loss_dice_6: 0.4943  loss_bbox_6: 0.05106  loss_giou_6: 0.3966  loss_ce_dn_6: 0.2636  loss_mask_dn_6: 0.0267  loss_dice_dn_6: 0.5333  loss_bbox_dn_6: 0.04043  loss_giou_dn_6: 0.2921  loss_ce_7: 1.17  loss_mask_7: 0.02928  loss_dice_7: 0.5551  loss_bbox_7: 0.04926  loss_giou_7: 0.3844  loss_ce_dn_7: 0.2639  loss_mask_dn_7: 0.02896  loss_dice_dn_7: 0.5221  loss_bbox_dn_7: 0.04352  loss_giou_dn_7: 0.2823  loss_ce_8: 1.214  loss_mask_8: 0.02871  loss_dice_8: 0.5683  loss_bbox_8: 0.0499  loss_giou_8: 0.3911  loss_ce_dn_8: 0.2696  loss_mask_dn_8: 0.02846  loss_dice_dn_8: 0.528  loss_bbox_dn_8: 0.04404  loss_giou_dn_8: 0.2899  loss_ce_interm: 1.356  loss_mask_interm: 0.03375  loss_dice_interm: 0.4509  loss_bbox_interm: 0.1046  loss_giou_interm: 0.5171  time: 2.1858  data_time: 0.0793  lr: 0.0001  max_mem: 6620M\n",
            "[05/20 17:02:52 d2.utils.events]:  eta: 2:07:59  iter: 1339  total_loss: 48.31  loss_ce: 1.159  loss_mask: 0.04429  loss_dice: 0.6671  loss_bbox: 0.05217  loss_giou: 0.3699  loss_ce_dn: 0.2354  loss_mask_dn: 0.04224  loss_dice_dn: 0.651  loss_bbox_dn: 0.04607  loss_giou_dn: 0.3233  loss_ce_0: 1.295  loss_mask_0: 0.0433  loss_dice_0: 0.6961  loss_bbox_0: 0.07813  loss_giou_0: 0.461  loss_ce_dn_0: 0.8347  loss_mask_dn_0: 0.221  loss_dice_dn_0: 2.769  loss_bbox_dn_0: 0.2279  loss_giou_dn_0: 0.8664  loss_ce_1: 1.298  loss_mask_1: 0.04215  loss_dice_1: 0.677  loss_bbox_1: 0.07001  loss_giou_1: 0.4588  loss_ce_dn_1: 0.3189  loss_mask_dn_1: 0.05091  loss_dice_dn_1: 0.6516  loss_bbox_dn_1: 0.07419  loss_giou_dn_1: 0.42  loss_ce_2: 1.249  loss_mask_2: 0.04833  loss_dice_2: 0.6864  loss_bbox_2: 0.05327  loss_giou_2: 0.4198  loss_ce_dn_2: 0.2881  loss_mask_dn_2: 0.03998  loss_dice_dn_2: 0.6495  loss_bbox_dn_2: 0.05955  loss_giou_dn_2: 0.3584  loss_ce_3: 1.177  loss_mask_3: 0.04152  loss_dice_3: 0.5284  loss_bbox_3: 0.05868  loss_giou_3: 0.4326  loss_ce_dn_3: 0.2832  loss_mask_dn_3: 0.0424  loss_dice_dn_3: 0.645  loss_bbox_dn_3: 0.05199  loss_giou_dn_3: 0.3264  loss_ce_4: 1.17  loss_mask_4: 0.04515  loss_dice_4: 0.6537  loss_bbox_4: 0.05316  loss_giou_4: 0.3921  loss_ce_dn_4: 0.2632  loss_mask_dn_4: 0.04493  loss_dice_dn_4: 0.6676  loss_bbox_dn_4: 0.05107  loss_giou_dn_4: 0.3244  loss_ce_5: 1.101  loss_mask_5: 0.04282  loss_dice_5: 0.6575  loss_bbox_5: 0.05077  loss_giou_5: 0.3615  loss_ce_dn_5: 0.253  loss_mask_dn_5: 0.04536  loss_dice_dn_5: 0.6757  loss_bbox_dn_5: 0.04565  loss_giou_dn_5: 0.3139  loss_ce_6: 1.139  loss_mask_6: 0.04329  loss_dice_6: 0.5805  loss_bbox_6: 0.05244  loss_giou_6: 0.351  loss_ce_dn_6: 0.2428  loss_mask_dn_6: 0.04402  loss_dice_dn_6: 0.6623  loss_bbox_dn_6: 0.04672  loss_giou_dn_6: 0.3217  loss_ce_7: 1.182  loss_mask_7: 0.04306  loss_dice_7: 0.657  loss_bbox_7: 0.05197  loss_giou_7: 0.3701  loss_ce_dn_7: 0.246  loss_mask_dn_7: 0.04202  loss_dice_dn_7: 0.6421  loss_bbox_dn_7: 0.0467  loss_giou_dn_7: 0.3214  loss_ce_8: 1.187  loss_mask_8: 0.03939  loss_dice_8: 0.5944  loss_bbox_8: 0.05162  loss_giou_8: 0.3473  loss_ce_dn_8: 0.2349  loss_mask_dn_8: 0.04218  loss_dice_dn_8: 0.6353  loss_bbox_dn_8: 0.04689  loss_giou_dn_8: 0.3207  loss_ce_interm: 1.227  loss_mask_interm: 0.03978  loss_dice_interm: 0.6144  loss_bbox_interm: 0.0895  loss_giou_interm: 0.5046  time: 2.1793  data_time: 0.1109  lr: 0.0001  max_mem: 6620M\n",
            "[05/20 17:03:27 d2.utils.events]:  eta: 2:06:23  iter: 1359  total_loss: 51.67  loss_ce: 1.42  loss_mask: 0.05788  loss_dice: 0.8012  loss_bbox: 0.1186  loss_giou: 0.4982  loss_ce_dn: 0.2684  loss_mask_dn: 0.05539  loss_dice_dn: 0.8286  loss_bbox_dn: 0.06431  loss_giou_dn: 0.3944  loss_ce_0: 1.356  loss_mask_0: 0.06363  loss_dice_0: 0.7566  loss_bbox_0: 0.1145  loss_giou_0: 0.5629  loss_ce_dn_0: 0.8816  loss_mask_dn_0: 0.2454  loss_dice_dn_0: 3.164  loss_bbox_dn_0: 0.3544  loss_giou_dn_0: 0.8485  loss_ce_1: 1.397  loss_mask_1: 0.08092  loss_dice_1: 0.8389  loss_bbox_1: 0.1139  loss_giou_1: 0.5216  loss_ce_dn_1: 0.2691  loss_mask_dn_1: 0.06632  loss_dice_dn_1: 0.9  loss_bbox_dn_1: 0.116  loss_giou_dn_1: 0.45  loss_ce_2: 1.397  loss_mask_2: 0.07006  loss_dice_2: 0.8005  loss_bbox_2: 0.1275  loss_giou_2: 0.5627  loss_ce_dn_2: 0.2534  loss_mask_dn_2: 0.05882  loss_dice_dn_2: 0.8346  loss_bbox_dn_2: 0.0878  loss_giou_dn_2: 0.4204  loss_ce_3: 1.428  loss_mask_3: 0.05328  loss_dice_3: 0.7161  loss_bbox_3: 0.1007  loss_giou_3: 0.5238  loss_ce_dn_3: 0.2581  loss_mask_dn_3: 0.0581  loss_dice_dn_3: 0.7841  loss_bbox_dn_3: 0.073  loss_giou_dn_3: 0.3977  loss_ce_4: 1.37  loss_mask_4: 0.0498  loss_dice_4: 0.8498  loss_bbox_4: 0.1138  loss_giou_4: 0.5125  loss_ce_dn_4: 0.2624  loss_mask_dn_4: 0.05144  loss_dice_dn_4: 0.7716  loss_bbox_dn_4: 0.06442  loss_giou_dn_4: 0.3834  loss_ce_5: 1.311  loss_mask_5: 0.06784  loss_dice_5: 0.8174  loss_bbox_5: 0.1242  loss_giou_5: 0.492  loss_ce_dn_5: 0.2574  loss_mask_dn_5: 0.05907  loss_dice_dn_5: 0.8059  loss_bbox_dn_5: 0.06796  loss_giou_dn_5: 0.3922  loss_ce_6: 1.322  loss_mask_6: 0.05988  loss_dice_6: 0.8319  loss_bbox_6: 0.1203  loss_giou_6: 0.4852  loss_ce_dn_6: 0.2552  loss_mask_dn_6: 0.05968  loss_dice_dn_6: 0.7924  loss_bbox_dn_6: 0.06514  loss_giou_dn_6: 0.3916  loss_ce_7: 1.322  loss_mask_7: 0.05799  loss_dice_7: 0.7383  loss_bbox_7: 0.1163  loss_giou_7: 0.4469  loss_ce_dn_7: 0.2633  loss_mask_dn_7: 0.05812  loss_dice_dn_7: 0.8152  loss_bbox_dn_7: 0.06378  loss_giou_dn_7: 0.3913  loss_ce_8: 1.274  loss_mask_8: 0.06363  loss_dice_8: 0.8925  loss_bbox_8: 0.1126  loss_giou_8: 0.4311  loss_ce_dn_8: 0.2619  loss_mask_dn_8: 0.05764  loss_dice_dn_8: 0.8109  loss_bbox_dn_8: 0.06467  loss_giou_dn_8: 0.3965  loss_ce_interm: 1.34  loss_mask_interm: 0.05655  loss_dice_interm: 0.696  loss_bbox_interm: 0.162  loss_giou_interm: 0.6106  time: 2.1726  data_time: 0.0575  lr: 0.0001  max_mem: 6620M\n",
            "[05/20 17:04:02 d2.utils.events]:  eta: 2:04:56  iter: 1379  total_loss: 62.46  loss_ce: 1.464  loss_mask: 0.03096  loss_dice: 0.9873  loss_bbox: 0.09881  loss_giou: 0.5562  loss_ce_dn: 0.3376  loss_mask_dn: 0.02418  loss_dice_dn: 0.8236  loss_bbox_dn: 0.04402  loss_giou_dn: 0.3691  loss_ce_0: 1.691  loss_mask_0: 0.03514  loss_dice_0: 1.008  loss_bbox_0: 0.1057  loss_giou_0: 0.7272  loss_ce_dn_0: 0.8688  loss_mask_dn_0: 0.08396  loss_dice_dn_0: 2.837  loss_bbox_dn_0: 0.1651  loss_giou_dn_0: 0.8653  loss_ce_1: 1.703  loss_mask_1: 0.03364  loss_dice_1: 1.098  loss_bbox_1: 0.09576  loss_giou_1: 0.6473  loss_ce_dn_1: 0.39  loss_mask_dn_1: 0.02618  loss_dice_dn_1: 0.9484  loss_bbox_dn_1: 0.05939  loss_giou_dn_1: 0.4557  loss_ce_2: 1.579  loss_mask_2: 0.0353  loss_dice_2: 1.033  loss_bbox_2: 0.09344  loss_giou_2: 0.6528  loss_ce_dn_2: 0.357  loss_mask_dn_2: 0.02527  loss_dice_dn_2: 0.8985  loss_bbox_dn_2: 0.05371  loss_giou_dn_2: 0.4054  loss_ce_3: 1.479  loss_mask_3: 0.0334  loss_dice_3: 0.9208  loss_bbox_3: 0.1232  loss_giou_3: 0.6676  loss_ce_dn_3: 0.3403  loss_mask_dn_3: 0.02411  loss_dice_dn_3: 0.9004  loss_bbox_dn_3: 0.05331  loss_giou_dn_3: 0.3958  loss_ce_4: 1.516  loss_mask_4: 0.02835  loss_dice_4: 1.006  loss_bbox_4: 0.09789  loss_giou_4: 0.5921  loss_ce_dn_4: 0.3483  loss_mask_dn_4: 0.0241  loss_dice_dn_4: 0.833  loss_bbox_dn_4: 0.04763  loss_giou_dn_4: 0.3925  loss_ce_5: 1.519  loss_mask_5: 0.03025  loss_dice_5: 0.851  loss_bbox_5: 0.09494  loss_giou_5: 0.5747  loss_ce_dn_5: 0.356  loss_mask_dn_5: 0.02396  loss_dice_dn_5: 0.8391  loss_bbox_dn_5: 0.05002  loss_giou_dn_5: 0.382  loss_ce_6: 1.512  loss_mask_6: 0.0373  loss_dice_6: 1.031  loss_bbox_6: 0.09582  loss_giou_6: 0.5659  loss_ce_dn_6: 0.3502  loss_mask_dn_6: 0.0243  loss_dice_dn_6: 0.8425  loss_bbox_dn_6: 0.0464  loss_giou_dn_6: 0.3754  loss_ce_7: 1.473  loss_mask_7: 0.03148  loss_dice_7: 0.9039  loss_bbox_7: 0.09787  loss_giou_7: 0.5623  loss_ce_dn_7: 0.339  loss_mask_dn_7: 0.02487  loss_dice_dn_7: 0.8632  loss_bbox_dn_7: 0.0461  loss_giou_dn_7: 0.3634  loss_ce_8: 1.437  loss_mask_8: 0.03098  loss_dice_8: 0.9849  loss_bbox_8: 0.0975  loss_giou_8: 0.5519  loss_ce_dn_8: 0.3375  loss_mask_dn_8: 0.02588  loss_dice_dn_8: 0.8351  loss_bbox_dn_8: 0.04422  loss_giou_dn_8: 0.3689  loss_ce_interm: 1.591  loss_mask_interm: 0.0391  loss_dice_interm: 0.9152  loss_bbox_interm: 0.09148  loss_giou_interm: 0.5952  time: 2.1668  data_time: 0.0760  lr: 0.0001  max_mem: 6620M\n",
            "[05/20 17:04:37 d2.utils.events]:  eta: 2:03:56  iter: 1399  total_loss: 56.05  loss_ce: 1.381  loss_mask: 0.04233  loss_dice: 0.5899  loss_bbox: 0.113  loss_giou: 0.4985  loss_ce_dn: 0.2538  loss_mask_dn: 0.02949  loss_dice_dn: 0.6395  loss_bbox_dn: 0.05786  loss_giou_dn: 0.3778  loss_ce_0: 1.568  loss_mask_0: 0.05396  loss_dice_0: 0.5631  loss_bbox_0: 0.2283  loss_giou_0: 0.7007  loss_ce_dn_0: 0.8594  loss_mask_dn_0: 0.2133  loss_dice_dn_0: 2.527  loss_bbox_dn_0: 0.2687  loss_giou_dn_0: 0.8568  loss_ce_1: 1.465  loss_mask_1: 0.05884  loss_dice_1: 0.7223  loss_bbox_1: 0.1452  loss_giou_1: 0.6925  loss_ce_dn_1: 0.3205  loss_mask_dn_1: 0.03305  loss_dice_dn_1: 0.7464  loss_bbox_dn_1: 0.09873  loss_giou_dn_1: 0.4758  loss_ce_2: 1.399  loss_mask_2: 0.05039  loss_dice_2: 0.732  loss_bbox_2: 0.1825  loss_giou_2: 0.7543  loss_ce_dn_2: 0.2866  loss_mask_dn_2: 0.03051  loss_dice_dn_2: 0.7348  loss_bbox_dn_2: 0.07309  loss_giou_dn_2: 0.4099  loss_ce_3: 1.417  loss_mask_3: 0.04315  loss_dice_3: 0.7236  loss_bbox_3: 0.1312  loss_giou_3: 0.6093  loss_ce_dn_3: 0.2846  loss_mask_dn_3: 0.03095  loss_dice_dn_3: 0.7513  loss_bbox_dn_3: 0.0637  loss_giou_dn_3: 0.3822  loss_ce_4: 1.296  loss_mask_4: 0.04482  loss_dice_4: 0.7394  loss_bbox_4: 0.1455  loss_giou_4: 0.7026  loss_ce_dn_4: 0.2743  loss_mask_dn_4: 0.03281  loss_dice_dn_4: 0.6938  loss_bbox_dn_4: 0.06201  loss_giou_dn_4: 0.3731  loss_ce_5: 1.374  loss_mask_5: 0.04224  loss_dice_5: 0.7769  loss_bbox_5: 0.1275  loss_giou_5: 0.5284  loss_ce_dn_5: 0.2748  loss_mask_dn_5: 0.03105  loss_dice_dn_5: 0.6908  loss_bbox_dn_5: 0.05869  loss_giou_dn_5: 0.37  loss_ce_6: 1.4  loss_mask_6: 0.04446  loss_dice_6: 0.7667  loss_bbox_6: 0.1164  loss_giou_6: 0.5199  loss_ce_dn_6: 0.2734  loss_mask_dn_6: 0.03194  loss_dice_dn_6: 0.6292  loss_bbox_dn_6: 0.05797  loss_giou_dn_6: 0.3689  loss_ce_7: 1.36  loss_mask_7: 0.04575  loss_dice_7: 0.6596  loss_bbox_7: 0.1149  loss_giou_7: 0.5036  loss_ce_dn_7: 0.2626  loss_mask_dn_7: 0.03165  loss_dice_dn_7: 0.6304  loss_bbox_dn_7: 0.05745  loss_giou_dn_7: 0.3731  loss_ce_8: 1.378  loss_mask_8: 0.04507  loss_dice_8: 0.6062  loss_bbox_8: 0.115  loss_giou_8: 0.5029  loss_ce_dn_8: 0.2508  loss_mask_dn_8: 0.03033  loss_dice_dn_8: 0.6245  loss_bbox_dn_8: 0.05825  loss_giou_dn_8: 0.3753  loss_ce_interm: 1.607  loss_mask_interm: 0.05311  loss_dice_interm: 0.6223  loss_bbox_interm: 0.1628  loss_giou_interm: 0.7158  time: 2.1605  data_time: 0.0616  lr: 0.0001  max_mem: 6620M\n",
            "[05/20 17:05:12 d2.utils.events]:  eta: 2:02:40  iter: 1419  total_loss: 45.14  loss_ce: 1.343  loss_mask: 0.04877  loss_dice: 0.6241  loss_bbox: 0.06736  loss_giou: 0.3363  loss_ce_dn: 0.2009  loss_mask_dn: 0.04115  loss_dice_dn: 0.5813  loss_bbox_dn: 0.0549  loss_giou_dn: 0.298  loss_ce_0: 1.7  loss_mask_0: 0.043  loss_dice_0: 0.5599  loss_bbox_0: 0.07342  loss_giou_0: 0.4578  loss_ce_dn_0: 0.7522  loss_mask_dn_0: 0.1945  loss_dice_dn_0: 2.995  loss_bbox_dn_0: 0.278  loss_giou_dn_0: 0.8522  loss_ce_1: 1.716  loss_mask_1: 0.04266  loss_dice_1: 0.5443  loss_bbox_1: 0.06713  loss_giou_1: 0.367  loss_ce_dn_1: 0.302  loss_mask_dn_1: 0.03945  loss_dice_dn_1: 0.6464  loss_bbox_dn_1: 0.09218  loss_giou_dn_1: 0.462  loss_ce_2: 1.591  loss_mask_2: 0.05083  loss_dice_2: 0.6016  loss_bbox_2: 0.07696  loss_giou_2: 0.3667  loss_ce_dn_2: 0.266  loss_mask_dn_2: 0.04166  loss_dice_dn_2: 0.6478  loss_bbox_dn_2: 0.06595  loss_giou_dn_2: 0.3432  loss_ce_3: 1.402  loss_mask_3: 0.04683  loss_dice_3: 0.6162  loss_bbox_3: 0.07259  loss_giou_3: 0.3466  loss_ce_dn_3: 0.2509  loss_mask_dn_3: 0.0393  loss_dice_dn_3: 0.5682  loss_bbox_dn_3: 0.05538  loss_giou_dn_3: 0.3205  loss_ce_4: 1.423  loss_mask_4: 0.0484  loss_dice_4: 0.5594  loss_bbox_4: 0.05335  loss_giou_4: 0.3463  loss_ce_dn_4: 0.2182  loss_mask_dn_4: 0.0402  loss_dice_dn_4: 0.5814  loss_bbox_dn_4: 0.05388  loss_giou_dn_4: 0.3163  loss_ce_5: 1.326  loss_mask_5: 0.05272  loss_dice_5: 0.6504  loss_bbox_5: 0.07231  loss_giou_5: 0.3444  loss_ce_dn_5: 0.225  loss_mask_dn_5: 0.04371  loss_dice_dn_5: 0.5736  loss_bbox_dn_5: 0.05511  loss_giou_dn_5: 0.3053  loss_ce_6: 1.392  loss_mask_6: 0.05359  loss_dice_6: 0.5752  loss_bbox_6: 0.06904  loss_giou_6: 0.3479  loss_ce_dn_6: 0.2113  loss_mask_dn_6: 0.04262  loss_dice_dn_6: 0.576  loss_bbox_dn_6: 0.05492  loss_giou_dn_6: 0.3024  loss_ce_7: 1.467  loss_mask_7: 0.05217  loss_dice_7: 0.7177  loss_bbox_7: 0.04826  loss_giou_7: 0.3342  loss_ce_dn_7: 0.204  loss_mask_dn_7: 0.04382  loss_dice_dn_7: 0.5827  loss_bbox_dn_7: 0.05196  loss_giou_dn_7: 0.2981  loss_ce_8: 1.326  loss_mask_8: 0.05561  loss_dice_8: 0.6603  loss_bbox_8: 0.06613  loss_giou_8: 0.3345  loss_ce_dn_8: 0.1998  loss_mask_dn_8: 0.04414  loss_dice_dn_8: 0.5664  loss_bbox_dn_8: 0.05379  loss_giou_dn_8: 0.3007  loss_ce_interm: 1.473  loss_mask_interm: 0.04196  loss_dice_interm: 0.6332  loss_bbox_interm: 0.1282  loss_giou_interm: 0.4558  time: 2.1546  data_time: 0.0739  lr: 0.0001  max_mem: 6620M\n",
            "[05/20 17:05:51 d2.utils.events]:  eta: 2:01:22  iter: 1439  total_loss: 51.98  loss_ce: 1.232  loss_mask: 0.05343  loss_dice: 0.7557  loss_bbox: 0.0636  loss_giou: 0.3288  loss_ce_dn: 0.2669  loss_mask_dn: 0.0482  loss_dice_dn: 0.7494  loss_bbox_dn: 0.05944  loss_giou_dn: 0.3225  loss_ce_0: 1.489  loss_mask_0: 0.04894  loss_dice_0: 0.8901  loss_bbox_0: 0.113  loss_giou_0: 0.5943  loss_ce_dn_0: 0.7846  loss_mask_dn_0: 0.302  loss_dice_dn_0: 2.874  loss_bbox_dn_0: 0.2718  loss_giou_dn_0: 0.8499  loss_ce_1: 1.525  loss_mask_1: 0.05062  loss_dice_1: 0.6657  loss_bbox_1: 0.09269  loss_giou_1: 0.4752  loss_ce_dn_1: 0.3361  loss_mask_dn_1: 0.04623  loss_dice_dn_1: 0.8916  loss_bbox_dn_1: 0.09188  loss_giou_dn_1: 0.4001  loss_ce_2: 1.583  loss_mask_2: 0.04001  loss_dice_2: 0.701  loss_bbox_2: 0.07719  loss_giou_2: 0.3808  loss_ce_dn_2: 0.3429  loss_mask_dn_2: 0.03871  loss_dice_dn_2: 0.7378  loss_bbox_dn_2: 0.07388  loss_giou_dn_2: 0.3587  loss_ce_3: 1.368  loss_mask_3: 0.05502  loss_dice_3: 0.7038  loss_bbox_3: 0.07596  loss_giou_3: 0.406  loss_ce_dn_3: 0.3104  loss_mask_dn_3: 0.03933  loss_dice_dn_3: 0.7406  loss_bbox_dn_3: 0.05524  loss_giou_dn_3: 0.3471  loss_ce_4: 1.196  loss_mask_4: 0.05406  loss_dice_4: 0.7132  loss_bbox_4: 0.07162  loss_giou_4: 0.3717  loss_ce_dn_4: 0.2926  loss_mask_dn_4: 0.04767  loss_dice_dn_4: 0.7084  loss_bbox_dn_4: 0.05872  loss_giou_dn_4: 0.3275  loss_ce_5: 1.124  loss_mask_5: 0.04883  loss_dice_5: 0.7612  loss_bbox_5: 0.06996  loss_giou_5: 0.3792  loss_ce_dn_5: 0.2828  loss_mask_dn_5: 0.04496  loss_dice_dn_5: 0.6829  loss_bbox_dn_5: 0.06077  loss_giou_dn_5: 0.3226  loss_ce_6: 1.389  loss_mask_6: 0.04904  loss_dice_6: 0.7087  loss_bbox_6: 0.07021  loss_giou_6: 0.369  loss_ce_dn_6: 0.2751  loss_mask_dn_6: 0.0462  loss_dice_dn_6: 0.7036  loss_bbox_dn_6: 0.05969  loss_giou_dn_6: 0.328  loss_ce_7: 1.215  loss_mask_7: 0.0512  loss_dice_7: 0.5974  loss_bbox_7: 0.0655  loss_giou_7: 0.3616  loss_ce_dn_7: 0.2718  loss_mask_dn_7: 0.04854  loss_dice_dn_7: 0.7421  loss_bbox_dn_7: 0.06088  loss_giou_dn_7: 0.3258  loss_ce_8: 1.255  loss_mask_8: 0.04953  loss_dice_8: 0.823  loss_bbox_8: 0.06914  loss_giou_8: 0.3402  loss_ce_dn_8: 0.2711  loss_mask_dn_8: 0.04785  loss_dice_dn_8: 0.7463  loss_bbox_dn_8: 0.05995  loss_giou_dn_8: 0.3268  loss_ce_interm: 1.434  loss_mask_interm: 0.05669  loss_dice_interm: 0.7057  loss_bbox_interm: 0.1009  loss_giou_interm: 0.4326  time: 2.1492  data_time: 0.1281  lr: 0.0001  max_mem: 6620M\n",
            "[05/20 17:06:26 d2.utils.events]:  eta: 2:00:36  iter: 1459  total_loss: 55.19  loss_ce: 1.296  loss_mask: 0.03933  loss_dice: 0.5866  loss_bbox: 0.06493  loss_giou: 0.4371  loss_ce_dn: 0.2585  loss_mask_dn: 0.03666  loss_dice_dn: 0.5801  loss_bbox_dn: 0.04766  loss_giou_dn: 0.3555  loss_ce_0: 1.73  loss_mask_0: 0.04111  loss_dice_0: 0.5876  loss_bbox_0: 0.08512  loss_giou_0: 0.4947  loss_ce_dn_0: 0.8754  loss_mask_dn_0: 0.1529  loss_dice_dn_0: 2.843  loss_bbox_dn_0: 0.2326  loss_giou_dn_0: 0.8548  loss_ce_1: 1.504  loss_mask_1: 0.04323  loss_dice_1: 0.6954  loss_bbox_1: 0.08189  loss_giou_1: 0.5712  loss_ce_dn_1: 0.349  loss_mask_dn_1: 0.04657  loss_dice_dn_1: 0.7552  loss_bbox_dn_1: 0.08102  loss_giou_dn_1: 0.4995  loss_ce_2: 1.504  loss_mask_2: 0.0363  loss_dice_2: 0.6424  loss_bbox_2: 0.07972  loss_giou_2: 0.492  loss_ce_dn_2: 0.2881  loss_mask_dn_2: 0.03641  loss_dice_dn_2: 0.6933  loss_bbox_dn_2: 0.07142  loss_giou_dn_2: 0.4263  loss_ce_3: 1.547  loss_mask_3: 0.03679  loss_dice_3: 0.5873  loss_bbox_3: 0.06981  loss_giou_3: 0.4318  loss_ce_dn_3: 0.2559  loss_mask_dn_3: 0.03728  loss_dice_dn_3: 0.6496  loss_bbox_dn_3: 0.05847  loss_giou_dn_3: 0.398  loss_ce_4: 1.376  loss_mask_4: 0.03637  loss_dice_4: 0.7952  loss_bbox_4: 0.06982  loss_giou_4: 0.4104  loss_ce_dn_4: 0.2456  loss_mask_dn_4: 0.03729  loss_dice_dn_4: 0.6383  loss_bbox_dn_4: 0.05461  loss_giou_dn_4: 0.37  loss_ce_5: 1.431  loss_mask_5: 0.03459  loss_dice_5: 0.6299  loss_bbox_5: 0.05952  loss_giou_5: 0.4042  loss_ce_dn_5: 0.2343  loss_mask_dn_5: 0.03606  loss_dice_dn_5: 0.5868  loss_bbox_dn_5: 0.05187  loss_giou_dn_5: 0.3622  loss_ce_6: 1.402  loss_mask_6: 0.0374  loss_dice_6: 0.621  loss_bbox_6: 0.07386  loss_giou_6: 0.4159  loss_ce_dn_6: 0.2439  loss_mask_dn_6: 0.03522  loss_dice_dn_6: 0.5827  loss_bbox_dn_6: 0.05221  loss_giou_dn_6: 0.3595  loss_ce_7: 1.258  loss_mask_7: 0.03902  loss_dice_7: 0.6433  loss_bbox_7: 0.06656  loss_giou_7: 0.4065  loss_ce_dn_7: 0.2525  loss_mask_dn_7: 0.03484  loss_dice_dn_7: 0.6489  loss_bbox_dn_7: 0.05223  loss_giou_dn_7: 0.3576  loss_ce_8: 1.287  loss_mask_8: 0.0362  loss_dice_8: 0.5761  loss_bbox_8: 0.06018  loss_giou_8: 0.4219  loss_ce_dn_8: 0.259  loss_mask_dn_8: 0.03733  loss_dice_dn_8: 0.6174  loss_bbox_dn_8: 0.05024  loss_giou_dn_8: 0.3552  loss_ce_interm: 1.595  loss_mask_interm: 0.04199  loss_dice_interm: 0.8643  loss_bbox_interm: 0.1083  loss_giou_interm: 0.5776  time: 2.1440  data_time: 0.1208  lr: 0.0001  max_mem: 6620M\n",
            "[05/20 17:07:01 d2.utils.events]:  eta: 1:59:25  iter: 1479  total_loss: 47.92  loss_ce: 1.159  loss_mask: 0.02455  loss_dice: 0.7638  loss_bbox: 0.04678  loss_giou: 0.3996  loss_ce_dn: 0.2348  loss_mask_dn: 0.0248  loss_dice_dn: 0.7123  loss_bbox_dn: 0.03756  loss_giou_dn: 0.3287  loss_ce_0: 1.312  loss_mask_0: 0.02886  loss_dice_0: 0.7653  loss_bbox_0: 0.05722  loss_giou_0: 0.5895  loss_ce_dn_0: 0.7841  loss_mask_dn_0: 0.1698  loss_dice_dn_0: 2.244  loss_bbox_dn_0: 0.167  loss_giou_dn_0: 0.8518  loss_ce_1: 1.505  loss_mask_1: 0.02474  loss_dice_1: 0.7091  loss_bbox_1: 0.05102  loss_giou_1: 0.4345  loss_ce_dn_1: 0.2886  loss_mask_dn_1: 0.02432  loss_dice_dn_1: 0.6769  loss_bbox_dn_1: 0.05233  loss_giou_dn_1: 0.4234  loss_ce_2: 1.505  loss_mask_2: 0.02315  loss_dice_2: 0.68  loss_bbox_2: 0.05153  loss_giou_2: 0.4908  loss_ce_dn_2: 0.2826  loss_mask_dn_2: 0.02303  loss_dice_dn_2: 0.6921  loss_bbox_dn_2: 0.04418  loss_giou_dn_2: 0.3509  loss_ce_3: 1.482  loss_mask_3: 0.02908  loss_dice_3: 0.715  loss_bbox_3: 0.04788  loss_giou_3: 0.4696  loss_ce_dn_3: 0.2662  loss_mask_dn_3: 0.02354  loss_dice_dn_3: 0.6586  loss_bbox_dn_3: 0.04492  loss_giou_dn_3: 0.3502  loss_ce_4: 1.293  loss_mask_4: 0.03413  loss_dice_4: 0.6735  loss_bbox_4: 0.05463  loss_giou_4: 0.4083  loss_ce_dn_4: 0.2718  loss_mask_dn_4: 0.02487  loss_dice_dn_4: 0.7288  loss_bbox_dn_4: 0.04372  loss_giou_dn_4: 0.3346  loss_ce_5: 1.226  loss_mask_5: 0.02719  loss_dice_5: 0.5384  loss_bbox_5: 0.0466  loss_giou_5: 0.4058  loss_ce_dn_5: 0.2593  loss_mask_dn_5: 0.02442  loss_dice_dn_5: 0.6371  loss_bbox_dn_5: 0.04172  loss_giou_dn_5: 0.3346  loss_ce_6: 1.181  loss_mask_6: 0.02995  loss_dice_6: 0.5267  loss_bbox_6: 0.05086  loss_giou_6: 0.423  loss_ce_dn_6: 0.2341  loss_mask_dn_6: 0.02342  loss_dice_dn_6: 0.7157  loss_bbox_dn_6: 0.0404  loss_giou_dn_6: 0.3351  loss_ce_7: 1.177  loss_mask_7: 0.02674  loss_dice_7: 0.7022  loss_bbox_7: 0.04736  loss_giou_7: 0.4114  loss_ce_dn_7: 0.2461  loss_mask_dn_7: 0.02494  loss_dice_dn_7: 0.6441  loss_bbox_dn_7: 0.03944  loss_giou_dn_7: 0.3276  loss_ce_8: 1.154  loss_mask_8: 0.0294  loss_dice_8: 0.8217  loss_bbox_8: 0.04788  loss_giou_8: 0.4041  loss_ce_dn_8: 0.2414  loss_mask_dn_8: 0.02474  loss_dice_dn_8: 0.6659  loss_bbox_dn_8: 0.03931  loss_giou_dn_8: 0.3289  loss_ce_interm: 1.317  loss_mask_interm: 0.03036  loss_dice_interm: 0.9192  loss_bbox_interm: 0.08126  loss_giou_interm: 0.5863  time: 2.1386  data_time: 0.0995  lr: 0.0001  max_mem: 6620M\n",
            "[05/20 17:07:36 d2.data.datasets.coco]: Loaded 150 images in COCO format from /content/TACO-expl/data/annotations_off_0_resval.json\n",
            "[05/20 17:07:36 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "[05/20 17:07:36 d2.data.common]: Serializing 150 elements to byte tensors and concatenating them all ...\n",
            "[05/20 17:07:36 d2.data.common]: Serialized dataset takes 0.21 MiB\n",
            "WARNING [05/20 17:07:36 d2.evaluation.coco_evaluation]: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
            "[05/20 17:07:36 d2.evaluation.evaluator]: Start inference on 150 batches\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1066, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1066, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1066, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1066])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 17:07:45 d2.evaluation.evaluator]: Inference done 11/150. Dataloading: 0.0046 s/iter. Inference: 0.3085 s/iter. Eval: 0.5532 s/iter. Total: 0.8663 s/iter. ETA=0:02:00\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 608])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 608])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 608])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1200])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 750])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 17:07:50 d2.evaluation.evaluator]: Inference done 17/150. Dataloading: 0.0058 s/iter. Inference: 0.3113 s/iter. Eval: 0.5440 s/iter. Total: 0.8614 s/iter. ETA=0:01:54\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 750])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([750, 1333])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 17:07:56 d2.evaluation.evaluator]: Inference done 24/150. Dataloading: 0.0052 s/iter. Inference: 0.3063 s/iter. Eval: 0.5156 s/iter. Total: 0.8274 s/iter. ETA=0:01:44\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 750])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([750, 1333])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 750])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 17:08:01 d2.evaluation.evaluator]: Inference done 30/150. Dataloading: 0.0051 s/iter. Inference: 0.3140 s/iter. Eval: 0.5325 s/iter. Total: 0.8519 s/iter. ETA=0:01:42\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 17:08:07 d2.evaluation.evaluator]: Inference done 36/150. Dataloading: 0.0050 s/iter. Inference: 0.3155 s/iter. Eval: 0.5352 s/iter. Total: 0.8561 s/iter. ETA=0:01:37\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 750])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 17:08:12 d2.evaluation.evaluator]: Inference done 43/150. Dataloading: 0.0045 s/iter. Inference: 0.3116 s/iter. Eval: 0.5210 s/iter. Total: 0.8375 s/iter. ETA=0:01:29\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 17:08:18 d2.evaluation.evaluator]: Inference done 50/150. Dataloading: 0.0045 s/iter. Inference: 0.3111 s/iter. Eval: 0.5212 s/iter. Total: 0.8371 s/iter. ETA=0:01:23\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 17:08:23 d2.evaluation.evaluator]: Inference done 56/150. Dataloading: 0.0047 s/iter. Inference: 0.3133 s/iter. Eval: 0.5267 s/iter. Total: 0.8451 s/iter. ETA=0:01:19\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 17:08:28 d2.evaluation.evaluator]: Inference done 63/150. Dataloading: 0.0044 s/iter. Inference: 0.3103 s/iter. Eval: 0.5167 s/iter. Total: 0.8318 s/iter. ETA=0:01:12\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 17:08:34 d2.evaluation.evaluator]: Inference done 70/150. Dataloading: 0.0042 s/iter. Inference: 0.3091 s/iter. Eval: 0.5150 s/iter. Total: 0.8287 s/iter. ETA=0:01:06\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 17:08:39 d2.evaluation.evaluator]: Inference done 76/150. Dataloading: 0.0042 s/iter. Inference: 0.3105 s/iter. Eval: 0.5198 s/iter. Total: 0.8349 s/iter. ETA=0:01:01\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([852, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 17:08:44 d2.evaluation.evaluator]: Inference done 83/150. Dataloading: 0.0041 s/iter. Inference: 0.3076 s/iter. Eval: 0.5125 s/iter. Total: 0.8245 s/iter. ETA=0:00:55\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 17:08:50 d2.evaluation.evaluator]: Inference done 90/150. Dataloading: 0.0039 s/iter. Inference: 0.3067 s/iter. Eval: 0.5107 s/iter. Total: 0.8217 s/iter. ETA=0:00:49\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 17:08:55 d2.evaluation.evaluator]: Inference done 96/150. Dataloading: 0.0041 s/iter. Inference: 0.3085 s/iter. Eval: 0.5156 s/iter. Total: 0.8287 s/iter. ETA=0:00:44\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 17:09:01 d2.evaluation.evaluator]: Inference done 103/150. Dataloading: 0.0040 s/iter. Inference: 0.3068 s/iter. Eval: 0.5107 s/iter. Total: 0.8219 s/iter. ETA=0:00:38\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 17:09:06 d2.evaluation.evaluator]: Inference done 110/150. Dataloading: 0.0039 s/iter. Inference: 0.3060 s/iter. Eval: 0.5081 s/iter. Total: 0.8183 s/iter. ETA=0:00:32\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 17:09:12 d2.evaluation.evaluator]: Inference done 116/150. Dataloading: 0.0043 s/iter. Inference: 0.3080 s/iter. Eval: 0.5152 s/iter. Total: 0.8279 s/iter. ETA=0:00:28\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 17:09:17 d2.evaluation.evaluator]: Inference done 122/150. Dataloading: 0.0046 s/iter. Inference: 0.3083 s/iter. Eval: 0.5165 s/iter. Total: 0.8298 s/iter. ETA=0:00:23\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 17:09:22 d2.evaluation.evaluator]: Inference done 129/150. Dataloading: 0.0045 s/iter. Inference: 0.3071 s/iter. Eval: 0.5137 s/iter. Total: 0.8256 s/iter. ETA=0:00:17\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 17:09:28 d2.evaluation.evaluator]: Inference done 135/150. Dataloading: 0.0049 s/iter. Inference: 0.3079 s/iter. Eval: 0.5183 s/iter. Total: 0.8315 s/iter. ETA=0:00:12\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 750])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 750])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 750])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 17:09:33 d2.evaluation.evaluator]: Inference done 141/150. Dataloading: 0.0049 s/iter. Inference: 0.3082 s/iter. Eval: 0.5183 s/iter. Total: 0.8319 s/iter. ETA=0:00:07\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 608])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 608])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 17:09:38 d2.evaluation.evaluator]: Inference done 148/150. Dataloading: 0.0048 s/iter. Inference: 0.3073 s/iter. Eval: 0.5148 s/iter. Total: 0.8273 s/iter. ETA=0:00:01\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 608])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 608])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[05/20 17:09:40 d2.evaluation.evaluator]: Total inference time: 0:02:00.119657 (0.828411 s / iter per device, on 1 devices)\n",
            "[05/20 17:09:40 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:44 (0.307172 s / iter per device, on 1 devices)\n",
            "[05/20 17:09:41 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...\n",
            "[05/20 17:09:41 d2.evaluation.coco_evaluation]: Saving results to /content/output/chkpt/inference/coco_instances_results.json\n",
            "[05/20 17:09:41 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.03s)\n",
            "creating index...\n",
            "index created!\n",
            "[05/20 17:09:41 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*\n",
            "[05/20 17:09:41 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.20 seconds.\n",
            "[05/20 17:09:41 d2.evaluation.fast_eval_api]: Accumulating evaluation results...\n",
            "[05/20 17:09:41 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.08 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.218\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.384\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.226\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.067\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.205\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.455\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.307\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.402\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.411\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.096\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.442\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.773\n",
            "[05/20 17:09:41 d2.evaluation.coco_evaluation]: Evaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
            "| 21.825 | 38.371 | 22.565 | 6.705 | 20.483 | 45.459 |\n",
            "[05/20 17:09:41 d2.evaluation.coco_evaluation]: Per-category bbox AP: \n",
            "| category   | AP     | category              | AP     | category   | AP     |\n",
            "|:-----------|:-------|:----------------------|:-------|:-----------|:-------|\n",
            "| Bottle     | 46.108 | Bottle cap            | 9.062  | Can        | 35.229 |\n",
            "| Cigarette  | 0.915  | Cup                   | 21.965 | Lid        | 37.713 |\n",
            "| Other      | 18.080 | Plastic bag & wrapper | 20.228 | Pop tab    | 12.637 |\n",
            "| Straw      | 16.317 |                       |        |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.27s)\n",
            "creating index...\n",
            "index created!\n",
            "[05/20 17:09:42 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*\n",
            "[05/20 17:09:43 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.84 seconds.\n",
            "[05/20 17:09:43 d2.evaluation.fast_eval_api]: Accumulating evaluation results...\n",
            "[05/20 17:09:43 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.08 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.335\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.451\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.343\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.218\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.402\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.581\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.428\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.586\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.597\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.350\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.653\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.820\n",
            "[05/20 17:09:43 d2.evaluation.coco_evaluation]: Evaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 33.496 | 45.102 | 34.312 | 21.825 | 40.214 | 58.123 |\n",
            "[05/20 17:09:43 d2.evaluation.coco_evaluation]: Per-category segm AP: \n",
            "| category   | AP     | category              | AP     | category   | AP     |\n",
            "|:-----------|:-------|:----------------------|:-------|:-----------|:-------|\n",
            "| Bottle     | 68.422 | Bottle cap            | 32.410 | Can        | 46.618 |\n",
            "| Cigarette  | 12.040 | Cup                   | 31.180 | Lid        | 48.306 |\n",
            "| Other      | 27.367 | Plastic bag & wrapper | 33.899 | Pop tab    | 14.457 |\n",
            "| Straw      | 20.260 |                       |        |            |        |\n",
            "[05/20 17:09:43 d2.engine.defaults]: Evaluation results for TACO_val in csv format:\n",
            "[05/20 17:09:43 d2.evaluation.testing]: copypaste: Task: bbox\n",
            "[05/20 17:09:43 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl\n",
            "[05/20 17:09:43 d2.evaluation.testing]: copypaste: 21.8254,38.3712,22.5646,6.7052,20.4834,45.4595\n",
            "[05/20 17:09:43 d2.evaluation.testing]: copypaste: Task: segm\n",
            "[05/20 17:09:43 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl\n",
            "[05/20 17:09:43 d2.evaluation.testing]: copypaste: 33.4959,45.1017,34.3120,21.8247,40.2142,58.1232\n",
            "[05/20 17:09:43 d2.utils.events]:  eta: 1:58:16  iter: 1499  total_loss: 53.17  loss_ce: 1.386  loss_mask: 0.04884  loss_dice: 0.7375  loss_bbox: 0.07709  loss_giou: 0.3112  loss_ce_dn: 0.2764  loss_mask_dn: 0.04639  loss_dice_dn: 0.6923  loss_bbox_dn: 0.07636  loss_giou_dn: 0.2777  loss_ce_0: 1.734  loss_mask_0: 0.05321  loss_dice_0: 0.7627  loss_bbox_0: 0.1084  loss_giou_0: 0.5514  loss_ce_dn_0: 0.8532  loss_mask_dn_0: 0.116  loss_dice_dn_0: 1.902  loss_bbox_dn_0: 0.2852  loss_giou_dn_0: 0.8571  loss_ce_1: 1.619  loss_mask_1: 0.05839  loss_dice_1: 0.7118  loss_bbox_1: 0.08632  loss_giou_1: 0.3706  loss_ce_dn_1: 0.3122  loss_mask_dn_1: 0.05394  loss_dice_dn_1: 0.7502  loss_bbox_dn_1: 0.09087  loss_giou_dn_1: 0.4079  loss_ce_2: 1.543  loss_mask_2: 0.05643  loss_dice_2: 0.9422  loss_bbox_2: 0.07868  loss_giou_2: 0.3119  loss_ce_dn_2: 0.3239  loss_mask_dn_2: 0.04833  loss_dice_dn_2: 0.851  loss_bbox_dn_2: 0.08029  loss_giou_dn_2: 0.3163  loss_ce_3: 1.439  loss_mask_3: 0.05703  loss_dice_3: 0.7182  loss_bbox_3: 0.07651  loss_giou_3: 0.3154  loss_ce_dn_3: 0.298  loss_mask_dn_3: 0.04517  loss_dice_dn_3: 0.8545  loss_bbox_dn_3: 0.07769  loss_giou_dn_3: 0.2765  loss_ce_4: 1.413  loss_mask_4: 0.05821  loss_dice_4: 0.6834  loss_bbox_4: 0.07424  loss_giou_4: 0.304  loss_ce_dn_4: 0.2872  loss_mask_dn_4: 0.04594  loss_dice_dn_4: 0.7755  loss_bbox_dn_4: 0.07335  loss_giou_dn_4: 0.2716  loss_ce_5: 1.448  loss_mask_5: 0.05222  loss_dice_5: 0.8552  loss_bbox_5: 0.07852  loss_giou_5: 0.3197  loss_ce_dn_5: 0.2852  loss_mask_dn_5: 0.04681  loss_dice_dn_5: 0.7099  loss_bbox_dn_5: 0.07827  loss_giou_dn_5: 0.2701  loss_ce_6: 1.392  loss_mask_6: 0.05477  loss_dice_6: 0.7847  loss_bbox_6: 0.07598  loss_giou_6: 0.3173  loss_ce_dn_6: 0.2744  loss_mask_dn_6: 0.04563  loss_dice_dn_6: 0.6873  loss_bbox_dn_6: 0.07648  loss_giou_dn_6: 0.2714  loss_ce_7: 1.44  loss_mask_7: 0.05461  loss_dice_7: 0.7551  loss_bbox_7: 0.07814  loss_giou_7: 0.3145  loss_ce_dn_7: 0.2743  loss_mask_dn_7: 0.04592  loss_dice_dn_7: 0.6776  loss_bbox_dn_7: 0.07395  loss_giou_dn_7: 0.2772  loss_ce_8: 1.404  loss_mask_8: 0.04529  loss_dice_8: 0.7119  loss_bbox_8: 0.08738  loss_giou_8: 0.3123  loss_ce_dn_8: 0.2803  loss_mask_dn_8: 0.04969  loss_dice_dn_8: 0.7062  loss_bbox_dn_8: 0.07556  loss_giou_dn_8: 0.2765  loss_ce_interm: 1.543  loss_mask_interm: 0.0564  loss_dice_interm: 0.7103  loss_bbox_interm: 0.1462  loss_giou_interm: 0.5521  time: 2.1333  data_time: 0.1125  lr: 0.0001  max_mem: 6620M\n",
            "[05/20 17:10:18 d2.utils.events]:  eta: 1:57:26  iter: 1519  total_loss: 51.54  loss_ce: 1.176  loss_mask: 0.05561  loss_dice: 1.003  loss_bbox: 0.07182  loss_giou: 0.4156  loss_ce_dn: 0.2611  loss_mask_dn: 0.05354  loss_dice_dn: 0.7662  loss_bbox_dn: 0.05136  loss_giou_dn: 0.3518  loss_ce_0: 1.432  loss_mask_0: 0.04487  loss_dice_0: 0.9199  loss_bbox_0: 0.05723  loss_giou_0: 0.5704  loss_ce_dn_0: 0.8192  loss_mask_dn_0: 0.186  loss_dice_dn_0: 3.195  loss_bbox_dn_0: 0.2973  loss_giou_dn_0: 0.8557  loss_ce_1: 1.439  loss_mask_1: 0.05874  loss_dice_1: 0.934  loss_bbox_1: 0.05332  loss_giou_1: 0.4642  loss_ce_dn_1: 0.3075  loss_mask_dn_1: 0.05126  loss_dice_dn_1: 0.9  loss_bbox_dn_1: 0.08937  loss_giou_dn_1: 0.4286  loss_ce_2: 1.352  loss_mask_2: 0.05431  loss_dice_2: 0.9837  loss_bbox_2: 0.05566  loss_giou_2: 0.4606  loss_ce_dn_2: 0.2889  loss_mask_dn_2: 0.0537  loss_dice_dn_2: 0.8938  loss_bbox_dn_2: 0.07523  loss_giou_dn_2: 0.4002  loss_ce_3: 1.223  loss_mask_3: 0.06589  loss_dice_3: 0.8597  loss_bbox_3: 0.06463  loss_giou_3: 0.4289  loss_ce_dn_3: 0.2838  loss_mask_dn_3: 0.05266  loss_dice_dn_3: 0.9042  loss_bbox_dn_3: 0.06473  loss_giou_dn_3: 0.3623  loss_ce_4: 1.198  loss_mask_4: 0.06029  loss_dice_4: 0.8698  loss_bbox_4: 0.06968  loss_giou_4: 0.4311  loss_ce_dn_4: 0.2841  loss_mask_dn_4: 0.0495  loss_dice_dn_4: 0.9076  loss_bbox_dn_4: 0.05953  loss_giou_dn_4: 0.3513  loss_ce_5: 1.218  loss_mask_5: 0.0658  loss_dice_5: 0.8982  loss_bbox_5: 0.08873  loss_giou_5: 0.4114  loss_ce_dn_5: 0.2716  loss_mask_dn_5: 0.05099  loss_dice_dn_5: 0.9065  loss_bbox_dn_5: 0.05443  loss_giou_dn_5: 0.3456  loss_ce_6: 1.212  loss_mask_6: 0.06441  loss_dice_6: 0.9454  loss_bbox_6: 0.07377  loss_giou_6: 0.3705  loss_ce_dn_6: 0.256  loss_mask_dn_6: 0.05165  loss_dice_dn_6: 0.7611  loss_bbox_dn_6: 0.05361  loss_giou_dn_6: 0.3509  loss_ce_7: 1.286  loss_mask_7: 0.05455  loss_dice_7: 0.8724  loss_bbox_7: 0.07061  loss_giou_7: 0.3466  loss_ce_dn_7: 0.2551  loss_mask_dn_7: 0.0545  loss_dice_dn_7: 0.9087  loss_bbox_dn_7: 0.05384  loss_giou_dn_7: 0.3417  loss_ce_8: 1.195  loss_mask_8: 0.06001  loss_dice_8: 0.8075  loss_bbox_8: 0.07256  loss_giou_8: 0.3601  loss_ce_dn_8: 0.2568  loss_mask_dn_8: 0.05288  loss_dice_dn_8: 0.8282  loss_bbox_dn_8: 0.0519  loss_giou_dn_8: 0.3494  loss_ce_interm: 1.407  loss_mask_interm: 0.04664  loss_dice_interm: 0.8188  loss_bbox_interm: 0.1493  loss_giou_interm: 0.5421  time: 2.1281  data_time: 0.0711  lr: 0.0001  max_mem: 6620M\n",
            "[05/20 17:10:53 d2.utils.events]:  eta: 1:56:35  iter: 1539  total_loss: 58.3  loss_ce: 1.443  loss_mask: 0.07113  loss_dice: 0.8493  loss_bbox: 0.08927  loss_giou: 0.4263  loss_ce_dn: 0.2709  loss_mask_dn: 0.06511  loss_dice_dn: 0.7627  loss_bbox_dn: 0.07691  loss_giou_dn: 0.2968  loss_ce_0: 1.743  loss_mask_0: 0.06142  loss_dice_0: 0.8766  loss_bbox_0: 0.1035  loss_giou_0: 0.4922  loss_ce_dn_0: 0.798  loss_mask_dn_0: 0.1619  loss_dice_dn_0: 3.064  loss_bbox_dn_0: 0.2645  loss_giou_dn_0: 0.8625  loss_ce_1: 1.668  loss_mask_1: 0.07335  loss_dice_1: 0.8813  loss_bbox_1: 0.1012  loss_giou_1: 0.4823  loss_ce_dn_1: 0.3001  loss_mask_dn_1: 0.08022  loss_dice_dn_1: 0.9305  loss_bbox_dn_1: 0.09947  loss_giou_dn_1: 0.4642  loss_ce_2: 1.783  loss_mask_2: 0.06964  loss_dice_2: 1.051  loss_bbox_2: 0.09681  loss_giou_2: 0.4118  loss_ce_dn_2: 0.2756  loss_mask_dn_2: 0.07571  loss_dice_dn_2: 0.8149  loss_bbox_dn_2: 0.06871  loss_giou_dn_2: 0.3611  loss_ce_3: 1.536  loss_mask_3: 0.06682  loss_dice_3: 0.9483  loss_bbox_3: 0.09467  loss_giou_3: 0.426  loss_ce_dn_3: 0.2648  loss_mask_dn_3: 0.07426  loss_dice_dn_3: 0.8638  loss_bbox_dn_3: 0.0804  loss_giou_dn_3: 0.3343  loss_ce_4: 1.419  loss_mask_4: 0.0742  loss_dice_4: 0.8175  loss_bbox_4: 0.09388  loss_giou_4: 0.4467  loss_ce_dn_4: 0.2452  loss_mask_dn_4: 0.07229  loss_dice_dn_4: 0.8053  loss_bbox_dn_4: 0.07999  loss_giou_dn_4: 0.3209  loss_ce_5: 1.442  loss_mask_5: 0.0662  loss_dice_5: 0.8514  loss_bbox_5: 0.092  loss_giou_5: 0.4703  loss_ce_dn_5: 0.2559  loss_mask_dn_5: 0.06563  loss_dice_dn_5: 0.8111  loss_bbox_dn_5: 0.07833  loss_giou_dn_5: 0.3192  loss_ce_6: 1.447  loss_mask_6: 0.06747  loss_dice_6: 0.928  loss_bbox_6: 0.09233  loss_giou_6: 0.4283  loss_ce_dn_6: 0.2602  loss_mask_dn_6: 0.0644  loss_dice_dn_6: 0.7672  loss_bbox_dn_6: 0.0773  loss_giou_dn_6: 0.3067  loss_ce_7: 1.494  loss_mask_7: 0.0717  loss_dice_7: 0.8495  loss_bbox_7: 0.08941  loss_giou_7: 0.3968  loss_ce_dn_7: 0.2661  loss_mask_dn_7: 0.06526  loss_dice_dn_7: 0.7709  loss_bbox_dn_7: 0.07627  loss_giou_dn_7: 0.3044  loss_ce_8: 1.485  loss_mask_8: 0.06985  loss_dice_8: 0.9647  loss_bbox_8: 0.09009  loss_giou_8: 0.3986  loss_ce_dn_8: 0.2706  loss_mask_dn_8: 0.07015  loss_dice_dn_8: 0.7094  loss_bbox_dn_8: 0.07699  loss_giou_dn_8: 0.2998  loss_ce_interm: 1.68  loss_mask_interm: 0.06785  loss_dice_interm: 0.8628  loss_bbox_interm: 0.1396  loss_giou_interm: 0.5648  time: 2.1234  data_time: 0.1570  lr: 0.0001  max_mem: 6620M\n",
            "[05/20 17:11:27 d2.utils.events]:  eta: 1:55:10  iter: 1559  total_loss: 57.45  loss_ce: 1.288  loss_mask: 0.02727  loss_dice: 0.7508  loss_bbox: 0.06532  loss_giou: 0.4533  loss_ce_dn: 0.283  loss_mask_dn: 0.02777  loss_dice_dn: 0.68  loss_bbox_dn: 0.03959  loss_giou_dn: 0.3745  loss_ce_0: 1.395  loss_mask_0: 0.03121  loss_dice_0: 0.7405  loss_bbox_0: 0.08411  loss_giou_0: 0.4788  loss_ce_dn_0: 0.9094  loss_mask_dn_0: 0.07176  loss_dice_dn_0: 2.665  loss_bbox_dn_0: 0.19  loss_giou_dn_0: 0.8526  loss_ce_1: 1.365  loss_mask_1: 0.0304  loss_dice_1: 0.6873  loss_bbox_1: 0.07152  loss_giou_1: 0.4531  loss_ce_dn_1: 0.3493  loss_mask_dn_1: 0.0266  loss_dice_dn_1: 0.7185  loss_bbox_dn_1: 0.0625  loss_giou_dn_1: 0.4383  loss_ce_2: 1.31  loss_mask_2: 0.02664  loss_dice_2: 0.7199  loss_bbox_2: 0.06295  loss_giou_2: 0.4805  loss_ce_dn_2: 0.3092  loss_mask_dn_2: 0.02748  loss_dice_dn_2: 0.666  loss_bbox_dn_2: 0.05372  loss_giou_dn_2: 0.4033  loss_ce_3: 1.405  loss_mask_3: 0.02871  loss_dice_3: 0.6699  loss_bbox_3: 0.06812  loss_giou_3: 0.427  loss_ce_dn_3: 0.3007  loss_mask_dn_3: 0.02828  loss_dice_dn_3: 0.6768  loss_bbox_dn_3: 0.0461  loss_giou_dn_3: 0.3626  loss_ce_4: 1.376  loss_mask_4: 0.02542  loss_dice_4: 0.7469  loss_bbox_4: 0.06753  loss_giou_4: 0.4353  loss_ce_dn_4: 0.2961  loss_mask_dn_4: 0.02835  loss_dice_dn_4: 0.6742  loss_bbox_dn_4: 0.04004  loss_giou_dn_4: 0.3689  loss_ce_5: 1.364  loss_mask_5: 0.02795  loss_dice_5: 0.6761  loss_bbox_5: 0.06524  loss_giou_5: 0.4342  loss_ce_dn_5: 0.2787  loss_mask_dn_5: 0.02778  loss_dice_dn_5: 0.6437  loss_bbox_dn_5: 0.04041  loss_giou_dn_5: 0.3708  loss_ce_6: 1.321  loss_mask_6: 0.02539  loss_dice_6: 0.6781  loss_bbox_6: 0.06651  loss_giou_6: 0.4522  loss_ce_dn_6: 0.2797  loss_mask_dn_6: 0.02778  loss_dice_dn_6: 0.6577  loss_bbox_dn_6: 0.0385  loss_giou_dn_6: 0.3742  loss_ce_7: 1.265  loss_mask_7: 0.03054  loss_dice_7: 0.7333  loss_bbox_7: 0.06862  loss_giou_7: 0.4508  loss_ce_dn_7: 0.2834  loss_mask_dn_7: 0.02795  loss_dice_dn_7: 0.6554  loss_bbox_dn_7: 0.03834  loss_giou_dn_7: 0.3678  loss_ce_8: 1.276  loss_mask_8: 0.02992  loss_dice_8: 0.8042  loss_bbox_8: 0.07004  loss_giou_8: 0.4546  loss_ce_dn_8: 0.2763  loss_mask_dn_8: 0.02805  loss_dice_dn_8: 0.6836  loss_bbox_dn_8: 0.0381  loss_giou_dn_8: 0.3758  loss_ce_interm: 1.42  loss_mask_interm: 0.02777  loss_dice_interm: 0.7363  loss_bbox_interm: 0.1062  loss_giou_interm: 0.5192  time: 2.1177  data_time: 0.0322  lr: 0.0001  max_mem: 6620M\n",
            "[05/20 17:12:01 d2.utils.events]:  eta: 1:54:19  iter: 1579  total_loss: 54.9  loss_ce: 1.142  loss_mask: 0.04501  loss_dice: 0.5518  loss_bbox: 0.1012  loss_giou: 0.3945  loss_ce_dn: 0.2911  loss_mask_dn: 0.04834  loss_dice_dn: 0.6645  loss_bbox_dn: 0.05385  loss_giou_dn: 0.3564  loss_ce_0: 1.478  loss_mask_0: 0.06794  loss_dice_0: 0.5591  loss_bbox_0: 0.1287  loss_giou_0: 0.4476  loss_ce_dn_0: 0.7583  loss_mask_dn_0: 0.3902  loss_dice_dn_0: 2.372  loss_bbox_dn_0: 0.3401  loss_giou_dn_0: 0.861  loss_ce_1: 1.325  loss_mask_1: 0.05526  loss_dice_1: 0.7231  loss_bbox_1: 0.1412  loss_giou_1: 0.4677  loss_ce_dn_1: 0.3247  loss_mask_dn_1: 0.05437  loss_dice_dn_1: 0.7219  loss_bbox_dn_1: 0.1096  loss_giou_dn_1: 0.4596  loss_ce_2: 1.341  loss_mask_2: 0.0527  loss_dice_2: 0.7284  loss_bbox_2: 0.1216  loss_giou_2: 0.4012  loss_ce_dn_2: 0.3158  loss_mask_dn_2: 0.05035  loss_dice_dn_2: 0.6665  loss_bbox_dn_2: 0.07828  loss_giou_dn_2: 0.4009  loss_ce_3: 1.227  loss_mask_3: 0.05828  loss_dice_3: 0.6454  loss_bbox_3: 0.1236  loss_giou_3: 0.4077  loss_ce_dn_3: 0.2873  loss_mask_dn_3: 0.04834  loss_dice_dn_3: 0.6865  loss_bbox_dn_3: 0.06769  loss_giou_dn_3: 0.3664  loss_ce_4: 1.254  loss_mask_4: 0.04995  loss_dice_4: 0.6229  loss_bbox_4: 0.1401  loss_giou_4: 0.3951  loss_ce_dn_4: 0.2817  loss_mask_dn_4: 0.05038  loss_dice_dn_4: 0.6757  loss_bbox_dn_4: 0.06502  loss_giou_dn_4: 0.3514  loss_ce_5: 1.119  loss_mask_5: 0.04861  loss_dice_5: 0.6112  loss_bbox_5: 0.1086  loss_giou_5: 0.3996  loss_ce_dn_5: 0.2653  loss_mask_dn_5: 0.05041  loss_dice_dn_5: 0.6445  loss_bbox_dn_5: 0.05827  loss_giou_dn_5: 0.3567  loss_ce_6: 1.196  loss_mask_6: 0.04259  loss_dice_6: 0.4535  loss_bbox_6: 0.1062  loss_giou_6: 0.3971  loss_ce_dn_6: 0.2764  loss_mask_dn_6: 0.04843  loss_dice_dn_6: 0.6575  loss_bbox_dn_6: 0.05809  loss_giou_dn_6: 0.3511  loss_ce_7: 1.132  loss_mask_7: 0.04645  loss_dice_7: 0.5205  loss_bbox_7: 0.1036  loss_giou_7: 0.3978  loss_ce_dn_7: 0.2719  loss_mask_dn_7: 0.04795  loss_dice_dn_7: 0.6604  loss_bbox_dn_7: 0.05508  loss_giou_dn_7: 0.3488  loss_ce_8: 1.136  loss_mask_8: 0.04267  loss_dice_8: 0.6658  loss_bbox_8: 0.1061  loss_giou_8: 0.3957  loss_ce_dn_8: 0.2831  loss_mask_dn_8: 0.04797  loss_dice_dn_8: 0.6739  loss_bbox_dn_8: 0.05536  loss_giou_dn_8: 0.3528  loss_ce_interm: 1.531  loss_mask_interm: 0.0759  loss_dice_interm: 0.8066  loss_bbox_interm: 0.1743  loss_giou_interm: 0.5343  time: 2.1124  data_time: 0.0688  lr: 0.0001  max_mem: 6620M\n",
            "[05/20 17:12:35 d2.utils.events]:  eta: 1:53:39  iter: 1599  total_loss: 40.91  loss_ce: 0.9879  loss_mask: 0.06909  loss_dice: 0.3624  loss_bbox: 0.1303  loss_giou: 0.2798  loss_ce_dn: 0.2505  loss_mask_dn: 0.06822  loss_dice_dn: 0.3649  loss_bbox_dn: 0.0773  loss_giou_dn: 0.2678  loss_ce_0: 1.423  loss_mask_0: 0.07627  loss_dice_0: 0.4771  loss_bbox_0: 0.1319  loss_giou_0: 0.3336  loss_ce_dn_0: 0.809  loss_mask_dn_0: 0.4236  loss_dice_dn_0: 2.504  loss_bbox_dn_0: 0.3349  loss_giou_dn_0: 0.8605  loss_ce_1: 1.515  loss_mask_1: 0.07071  loss_dice_1: 0.4193  loss_bbox_1: 0.1182  loss_giou_1: 0.2955  loss_ce_dn_1: 0.2625  loss_mask_dn_1: 0.07678  loss_dice_dn_1: 0.4894  loss_bbox_dn_1: 0.1176  loss_giou_dn_1: 0.3622  loss_ce_2: 1.399  loss_mask_2: 0.06743  loss_dice_2: 0.3403  loss_bbox_2: 0.1355  loss_giou_2: 0.2758  loss_ce_dn_2: 0.2463  loss_mask_dn_2: 0.06859  loss_dice_dn_2: 0.3851  loss_bbox_dn_2: 0.09035  loss_giou_dn_2: 0.3012  loss_ce_3: 1.2  loss_mask_3: 0.0648  loss_dice_3: 0.3418  loss_bbox_3: 0.1279  loss_giou_3: 0.2774  loss_ce_dn_3: 0.2218  loss_mask_dn_3: 0.06927  loss_dice_dn_3: 0.345  loss_bbox_dn_3: 0.07479  loss_giou_dn_3: 0.264  loss_ce_4: 1.057  loss_mask_4: 0.07041  loss_dice_4: 0.2687  loss_bbox_4: 0.1335  loss_giou_4: 0.268  loss_ce_dn_4: 0.2372  loss_mask_dn_4: 0.06866  loss_dice_dn_4: 0.356  loss_bbox_dn_4: 0.07455  loss_giou_dn_4: 0.2612  loss_ce_5: 0.971  loss_mask_5: 0.06354  loss_dice_5: 0.3927  loss_bbox_5: 0.1337  loss_giou_5: 0.29  loss_ce_dn_5: 0.2274  loss_mask_dn_5: 0.07145  loss_dice_dn_5: 0.3573  loss_bbox_dn_5: 0.07546  loss_giou_dn_5: 0.269  loss_ce_6: 0.99  loss_mask_6: 0.07415  loss_dice_6: 0.3633  loss_bbox_6: 0.1256  loss_giou_6: 0.288  loss_ce_dn_6: 0.2434  loss_mask_dn_6: 0.06844  loss_dice_dn_6: 0.3751  loss_bbox_dn_6: 0.08019  loss_giou_dn_6: 0.2712  loss_ce_7: 0.9882  loss_mask_7: 0.06959  loss_dice_7: 0.4893  loss_bbox_7: 0.1348  loss_giou_7: 0.284  loss_ce_dn_7: 0.2471  loss_mask_dn_7: 0.06702  loss_dice_dn_7: 0.362  loss_bbox_dn_7: 0.07854  loss_giou_dn_7: 0.2666  loss_ce_8: 0.9868  loss_mask_8: 0.07261  loss_dice_8: 0.4338  loss_bbox_8: 0.1323  loss_giou_8: 0.2769  loss_ce_dn_8: 0.2505  loss_mask_dn_8: 0.06862  loss_dice_dn_8: 0.3703  loss_bbox_dn_8: 0.07703  loss_giou_dn_8: 0.268  loss_ce_interm: 1.438  loss_mask_interm: 0.08168  loss_dice_interm: 0.4885  loss_bbox_interm: 0.1709  loss_giou_interm: 0.4287  time: 2.1073  data_time: 0.0935  lr: 0.0001  max_mem: 6620M\n",
            "[05/20 17:13:09 d2.utils.events]:  eta: 1:53:06  iter: 1619  total_loss: 52.52  loss_ce: 1.066  loss_mask: 0.03562  loss_dice: 0.8802  loss_bbox: 0.07795  loss_giou: 0.5738  loss_ce_dn: 0.1949  loss_mask_dn: 0.02665  loss_dice_dn: 0.8177  loss_bbox_dn: 0.03834  loss_giou_dn: 0.3767  loss_ce_0: 1.468  loss_mask_0: 0.0372  loss_dice_0: 0.9267  loss_bbox_0: 0.08874  loss_giou_0: 0.6815  loss_ce_dn_0: 0.8324  loss_mask_dn_0: 0.1095  loss_dice_dn_0: 2.816  loss_bbox_dn_0: 0.2037  loss_giou_dn_0: 0.8508  loss_ce_1: 1.248  loss_mask_1: 0.04354  loss_dice_1: 1.089  loss_bbox_1: 0.08765  loss_giou_1: 0.6405  loss_ce_dn_1: 0.3092  loss_mask_dn_1: 0.02802  loss_dice_dn_1: 0.8978  loss_bbox_dn_1: 0.07043  loss_giou_dn_1: 0.4887  loss_ce_2: 1.193  loss_mask_2: 0.03644  loss_dice_2: 1.04  loss_bbox_2: 0.08974  loss_giou_2: 0.6482  loss_ce_dn_2: 0.2548  loss_mask_dn_2: 0.02576  loss_dice_dn_2: 0.9127  loss_bbox_dn_2: 0.05316  loss_giou_dn_2: 0.4278  loss_ce_3: 1.211  loss_mask_3: 0.04032  loss_dice_3: 1.011  loss_bbox_3: 0.09442  loss_giou_3: 0.5776  loss_ce_dn_3: 0.2239  loss_mask_dn_3: 0.02652  loss_dice_dn_3: 0.8273  loss_bbox_dn_3: 0.04303  loss_giou_dn_3: 0.4043  loss_ce_4: 1.161  loss_mask_4: 0.03708  loss_dice_4: 0.7614  loss_bbox_4: 0.09551  loss_giou_4: 0.5777  loss_ce_dn_4: 0.2185  loss_mask_dn_4: 0.02676  loss_dice_dn_4: 0.873  loss_bbox_dn_4: 0.03929  loss_giou_dn_4: 0.4042  loss_ce_5: 1.183  loss_mask_5: 0.02978  loss_dice_5: 0.8057  loss_bbox_5: 0.08065  loss_giou_5: 0.5416  loss_ce_dn_5: 0.2093  loss_mask_dn_5: 0.02698  loss_dice_dn_5: 0.7815  loss_bbox_dn_5: 0.03863  loss_giou_dn_5: 0.3886  loss_ce_6: 1.102  loss_mask_6: 0.03408  loss_dice_6: 0.9065  loss_bbox_6: 0.0729  loss_giou_6: 0.5226  loss_ce_dn_6: 0.2073  loss_mask_dn_6: 0.02521  loss_dice_dn_6: 0.8337  loss_bbox_dn_6: 0.03889  loss_giou_dn_6: 0.3828  loss_ce_7: 1.083  loss_mask_7: 0.02909  loss_dice_7: 0.8049  loss_bbox_7: 0.07189  loss_giou_7: 0.5059  loss_ce_dn_7: 0.2014  loss_mask_dn_7: 0.02647  loss_dice_dn_7: 0.7875  loss_bbox_dn_7: 0.03843  loss_giou_dn_7: 0.3799  loss_ce_8: 1.067  loss_mask_8: 0.03305  loss_dice_8: 0.9282  loss_bbox_8: 0.09296  loss_giou_8: 0.5084  loss_ce_dn_8: 0.2003  loss_mask_dn_8: 0.0263  loss_dice_dn_8: 0.7782  loss_bbox_dn_8: 0.03852  loss_giou_dn_8: 0.3779  loss_ce_interm: 1.409  loss_mask_interm: 0.03604  loss_dice_interm: 0.8642  loss_bbox_interm: 0.09995  loss_giou_interm: 0.6401  time: 2.1019  data_time: 0.0851  lr: 0.0001  max_mem: 6620M\n",
            "[05/20 17:13:44 d2.utils.events]:  eta: 1:52:33  iter: 1639  total_loss: 51.16  loss_ce: 1.629  loss_mask: 0.05588  loss_dice: 0.7692  loss_bbox: 0.09911  loss_giou: 0.4641  loss_ce_dn: 0.382  loss_mask_dn: 0.04579  loss_dice_dn: 0.627  loss_bbox_dn: 0.0482  loss_giou_dn: 0.321  loss_ce_0: 1.599  loss_mask_0: 0.05177  loss_dice_0: 0.8482  loss_bbox_0: 0.1642  loss_giou_0: 0.538  loss_ce_dn_0: 0.829  loss_mask_dn_0: 0.1519  loss_dice_dn_0: 2.523  loss_bbox_dn_0: 0.2971  loss_giou_dn_0: 0.8524  loss_ce_1: 1.629  loss_mask_1: 0.05264  loss_dice_1: 0.7885  loss_bbox_1: 0.1041  loss_giou_1: 0.489  loss_ce_dn_1: 0.4121  loss_mask_dn_1: 0.05573  loss_dice_dn_1: 0.6822  loss_bbox_dn_1: 0.08539  loss_giou_dn_1: 0.4165  loss_ce_2: 1.615  loss_mask_2: 0.05689  loss_dice_2: 0.7829  loss_bbox_2: 0.1117  loss_giou_2: 0.4743  loss_ce_dn_2: 0.4066  loss_mask_dn_2: 0.04729  loss_dice_dn_2: 0.6543  loss_bbox_dn_2: 0.07991  loss_giou_dn_2: 0.3838  loss_ce_3: 1.655  loss_mask_3: 0.05174  loss_dice_3: 0.7897  loss_bbox_3: 0.1005  loss_giou_3: 0.4688  loss_ce_dn_3: 0.3895  loss_mask_dn_3: 0.0472  loss_dice_dn_3: 0.6097  loss_bbox_dn_3: 0.05279  loss_giou_dn_3: 0.344  loss_ce_4: 1.677  loss_mask_4: 0.05651  loss_dice_4: 0.7272  loss_bbox_4: 0.1088  loss_giou_4: 0.4902  loss_ce_dn_4: 0.3481  loss_mask_dn_4: 0.04746  loss_dice_dn_4: 0.6319  loss_bbox_dn_4: 0.05299  loss_giou_dn_4: 0.3375  loss_ce_5: 1.625  loss_mask_5: 0.05269  loss_dice_5: 0.6283  loss_bbox_5: 0.1088  loss_giou_5: 0.4702  loss_ce_dn_5: 0.3696  loss_mask_dn_5: 0.04749  loss_dice_dn_5: 0.6299  loss_bbox_dn_5: 0.05151  loss_giou_dn_5: 0.3298  loss_ce_6: 1.589  loss_mask_6: 0.04372  loss_dice_6: 0.7001  loss_bbox_6: 0.1018  loss_giou_6: 0.4707  loss_ce_dn_6: 0.3565  loss_mask_dn_6: 0.0475  loss_dice_dn_6: 0.5976  loss_bbox_dn_6: 0.05135  loss_giou_dn_6: 0.3311  loss_ce_7: 1.585  loss_mask_7: 0.05222  loss_dice_7: 0.6588  loss_bbox_7: 0.09778  loss_giou_7: 0.4669  loss_ce_dn_7: 0.3693  loss_mask_dn_7: 0.04706  loss_dice_dn_7: 0.6322  loss_bbox_dn_7: 0.04725  loss_giou_dn_7: 0.3237  loss_ce_8: 1.65  loss_mask_8: 0.05505  loss_dice_8: 0.6228  loss_bbox_8: 0.1022  loss_giou_8: 0.4655  loss_ce_dn_8: 0.3733  loss_mask_dn_8: 0.0461  loss_dice_dn_8: 0.6185  loss_bbox_dn_8: 0.04877  loss_giou_dn_8: 0.3233  loss_ce_interm: 1.692  loss_mask_interm: 0.05492  loss_dice_interm: 0.688  loss_bbox_interm: 0.1359  loss_giou_interm: 0.519  time: 2.0979  data_time: 0.0502  lr: 0.0001  max_mem: 6620M\n",
            "[05/20 17:14:19 d2.utils.events]:  eta: 1:51:54  iter: 1659  total_loss: 45.63  loss_ce: 1.09  loss_mask: 0.02874  loss_dice: 0.5959  loss_bbox: 0.05534  loss_giou: 0.3576  loss_ce_dn: 0.2714  loss_mask_dn: 0.03065  loss_dice_dn: 0.6878  loss_bbox_dn: 0.04695  loss_giou_dn: 0.324  loss_ce_0: 1.458  loss_mask_0: 0.03073  loss_dice_0: 0.7078  loss_bbox_0: 0.05677  loss_giou_0: 0.4864  loss_ce_dn_0: 0.7779  loss_mask_dn_0: 0.132  loss_dice_dn_0: 2.238  loss_bbox_dn_0: 0.2325  loss_giou_dn_0: 0.8569  loss_ce_1: 1.439  loss_mask_1: 0.0336  loss_dice_1: 0.6445  loss_bbox_1: 0.05427  loss_giou_1: 0.4446  loss_ce_dn_1: 0.3263  loss_mask_dn_1: 0.03112  loss_dice_dn_1: 0.6803  loss_bbox_dn_1: 0.07511  loss_giou_dn_1: 0.4151  loss_ce_2: 1.389  loss_mask_2: 0.0274  loss_dice_2: 0.5816  loss_bbox_2: 0.05639  loss_giou_2: 0.4207  loss_ce_dn_2: 0.3099  loss_mask_dn_2: 0.03015  loss_dice_dn_2: 0.724  loss_bbox_dn_2: 0.06191  loss_giou_dn_2: 0.3727  loss_ce_3: 1.222  loss_mask_3: 0.02912  loss_dice_3: 0.6158  loss_bbox_3: 0.05791  loss_giou_3: 0.4156  loss_ce_dn_3: 0.2918  loss_mask_dn_3: 0.03151  loss_dice_dn_3: 0.5867  loss_bbox_dn_3: 0.04683  loss_giou_dn_3: 0.3326  loss_ce_4: 1.049  loss_mask_4: 0.03279  loss_dice_4: 0.5601  loss_bbox_4: 0.06161  loss_giou_4: 0.3957  loss_ce_dn_4: 0.2787  loss_mask_dn_4: 0.0318  loss_dice_dn_4: 0.6599  loss_bbox_dn_4: 0.04452  loss_giou_dn_4: 0.3246  loss_ce_5: 1.127  loss_mask_5: 0.03164  loss_dice_5: 0.4799  loss_bbox_5: 0.05375  loss_giou_5: 0.3658  loss_ce_dn_5: 0.2667  loss_mask_dn_5: 0.03142  loss_dice_dn_5: 0.6679  loss_bbox_dn_5: 0.0466  loss_giou_dn_5: 0.3222  loss_ce_6: 1.074  loss_mask_6: 0.02756  loss_dice_6: 0.6753  loss_bbox_6: 0.0555  loss_giou_6: 0.3622  loss_ce_dn_6: 0.2718  loss_mask_dn_6: 0.03053  loss_dice_dn_6: 0.6488  loss_bbox_dn_6: 0.0455  loss_giou_dn_6: 0.3279  loss_ce_7: 1.079  loss_mask_7: 0.02787  loss_dice_7: 0.5829  loss_bbox_7: 0.05544  loss_giou_7: 0.3741  loss_ce_dn_7: 0.2701  loss_mask_dn_7: 0.03242  loss_dice_dn_7: 0.699  loss_bbox_dn_7: 0.04656  loss_giou_dn_7: 0.324  loss_ce_8: 1.065  loss_mask_8: 0.03072  loss_dice_8: 0.7232  loss_bbox_8: 0.0558  loss_giou_8: 0.3605  loss_ce_dn_8: 0.2705  loss_mask_dn_8: 0.03202  loss_dice_dn_8: 0.6839  loss_bbox_dn_8: 0.04769  loss_giou_dn_8: 0.3218  loss_ce_interm: 1.408  loss_mask_interm: 0.03329  loss_dice_interm: 0.5299  loss_bbox_interm: 0.1191  loss_giou_interm: 0.5547  time: 2.0935  data_time: 0.0928  lr: 0.0001  max_mem: 6620M\n",
            "[05/20 17:14:53 d2.utils.events]:  eta: 1:51:06  iter: 1679  total_loss: 55.48  loss_ce: 1.308  loss_mask: 0.03636  loss_dice: 0.6579  loss_bbox: 0.1051  loss_giou: 0.3738  loss_ce_dn: 0.2684  loss_mask_dn: 0.03735  loss_dice_dn: 0.6305  loss_bbox_dn: 0.05335  loss_giou_dn: 0.2972  loss_ce_0: 1.556  loss_mask_0: 0.03734  loss_dice_0: 0.6244  loss_bbox_0: 0.1262  loss_giou_0: 0.5348  loss_ce_dn_0: 0.7501  loss_mask_dn_0: 0.1573  loss_dice_dn_0: 2.936  loss_bbox_dn_0: 0.2978  loss_giou_dn_0: 0.8573  loss_ce_1: 1.621  loss_mask_1: 0.0453  loss_dice_1: 0.6274  loss_bbox_1: 0.09587  loss_giou_1: 0.4954  loss_ce_dn_1: 0.2918  loss_mask_dn_1: 0.04621  loss_dice_dn_1: 0.8356  loss_bbox_dn_1: 0.09595  loss_giou_dn_1: 0.4414  loss_ce_2: 1.38  loss_mask_2: 0.03754  loss_dice_2: 0.7912  loss_bbox_2: 0.09088  loss_giou_2: 0.3574  loss_ce_dn_2: 0.263  loss_mask_dn_2: 0.03662  loss_dice_dn_2: 0.7265  loss_bbox_dn_2: 0.05885  loss_giou_dn_2: 0.365  loss_ce_3: 1.412  loss_mask_3: 0.03407  loss_dice_3: 0.6166  loss_bbox_3: 0.09625  loss_giou_3: 0.3571  loss_ce_dn_3: 0.2452  loss_mask_dn_3: 0.0368  loss_dice_dn_3: 0.7014  loss_bbox_dn_3: 0.05037  loss_giou_dn_3: 0.3228  loss_ce_4: 1.337  loss_mask_4: 0.03352  loss_dice_4: 0.6716  loss_bbox_4: 0.0931  loss_giou_4: 0.3495  loss_ce_dn_4: 0.2491  loss_mask_dn_4: 0.03571  loss_dice_dn_4: 0.6411  loss_bbox_dn_4: 0.04561  loss_giou_dn_4: 0.3256  loss_ce_5: 1.308  loss_mask_5: 0.03455  loss_dice_5: 0.5936  loss_bbox_5: 0.09964  loss_giou_5: 0.3846  loss_ce_dn_5: 0.2633  loss_mask_dn_5: 0.03682  loss_dice_dn_5: 0.6562  loss_bbox_dn_5: 0.05004  loss_giou_dn_5: 0.3055  loss_ce_6: 1.189  loss_mask_6: 0.03561  loss_dice_6: 0.5658  loss_bbox_6: 0.1056  loss_giou_6: 0.4002  loss_ce_dn_6: 0.2667  loss_mask_dn_6: 0.03679  loss_dice_dn_6: 0.6244  loss_bbox_dn_6: 0.05277  loss_giou_dn_6: 0.3053  loss_ce_7: 1.174  loss_mask_7: 0.03785  loss_dice_7: 0.5895  loss_bbox_7: 0.1062  loss_giou_7: 0.3938  loss_ce_dn_7: 0.2745  loss_mask_dn_7: 0.03587  loss_dice_dn_7: 0.6195  loss_bbox_dn_7: 0.05227  loss_giou_dn_7: 0.2989  loss_ce_8: 1.168  loss_mask_8: 0.03445  loss_dice_8: 0.5802  loss_bbox_8: 0.1068  loss_giou_8: 0.3671  loss_ce_dn_8: 0.272  loss_mask_dn_8: 0.03654  loss_dice_dn_8: 0.6261  loss_bbox_dn_8: 0.0542  loss_giou_dn_8: 0.2992  loss_ce_interm: 1.52  loss_mask_interm: 0.03031  loss_dice_interm: 0.7287  loss_bbox_interm: 0.1328  loss_giou_interm: 0.46  time: 2.0886  data_time: 0.0428  lr: 0.0001  max_mem: 6620M\n",
            "[05/20 17:15:26 d2.utils.events]:  eta: 1:50:15  iter: 1699  total_loss: 52  loss_ce: 1.426  loss_mask: 0.03484  loss_dice: 0.5753  loss_bbox: 0.08803  loss_giou: 0.4589  loss_ce_dn: 0.3062  loss_mask_dn: 0.0372  loss_dice_dn: 0.6826  loss_bbox_dn: 0.0575  loss_giou_dn: 0.3859  loss_ce_0: 1.632  loss_mask_0: 0.04397  loss_dice_0: 0.9006  loss_bbox_0: 0.07377  loss_giou_0: 0.4801  loss_ce_dn_0: 0.8263  loss_mask_dn_0: 0.1703  loss_dice_dn_0: 2.626  loss_bbox_dn_0: 0.2425  loss_giou_dn_0: 0.8574  loss_ce_1: 1.628  loss_mask_1: 0.03708  loss_dice_1: 0.7803  loss_bbox_1: 0.07196  loss_giou_1: 0.4773  loss_ce_dn_1: 0.3428  loss_mask_dn_1: 0.04753  loss_dice_dn_1: 0.7979  loss_bbox_dn_1: 0.09783  loss_giou_dn_1: 0.4548  loss_ce_2: 1.692  loss_mask_2: 0.0355  loss_dice_2: 0.6331  loss_bbox_2: 0.076  loss_giou_2: 0.4236  loss_ce_dn_2: 0.3072  loss_mask_dn_2: 0.0376  loss_dice_dn_2: 0.6952  loss_bbox_dn_2: 0.08759  loss_giou_dn_2: 0.4121  loss_ce_3: 1.523  loss_mask_3: 0.03914  loss_dice_3: 0.6172  loss_bbox_3: 0.08412  loss_giou_3: 0.4582  loss_ce_dn_3: 0.2861  loss_mask_dn_3: 0.03689  loss_dice_dn_3: 0.6623  loss_bbox_dn_3: 0.07142  loss_giou_dn_3: 0.3882  loss_ce_4: 1.564  loss_mask_4: 0.03432  loss_dice_4: 0.6905  loss_bbox_4: 0.08866  loss_giou_4: 0.4371  loss_ce_dn_4: 0.2988  loss_mask_dn_4: 0.03563  loss_dice_dn_4: 0.6517  loss_bbox_dn_4: 0.06237  loss_giou_dn_4: 0.3763  loss_ce_5: 1.425  loss_mask_5: 0.03318  loss_dice_5: 0.7236  loss_bbox_5: 0.08916  loss_giou_5: 0.4445  loss_ce_dn_5: 0.304  loss_mask_dn_5: 0.0371  loss_dice_dn_5: 0.6669  loss_bbox_dn_5: 0.05796  loss_giou_dn_5: 0.3792  loss_ce_6: 1.377  loss_mask_6: 0.0347  loss_dice_6: 0.6273  loss_bbox_6: 0.09572  loss_giou_6: 0.4391  loss_ce_dn_6: 0.2921  loss_mask_dn_6: 0.03694  loss_dice_dn_6: 0.6962  loss_bbox_dn_6: 0.05934  loss_giou_dn_6: 0.3832  loss_ce_7: 1.359  loss_mask_7: 0.03191  loss_dice_7: 0.6274  loss_bbox_7: 0.09426  loss_giou_7: 0.4469  loss_ce_dn_7: 0.2996  loss_mask_dn_7: 0.03828  loss_dice_dn_7: 0.6452  loss_bbox_dn_7: 0.05866  loss_giou_dn_7: 0.3828  loss_ce_8: 1.368  loss_mask_8: 0.03294  loss_dice_8: 0.7919  loss_bbox_8: 0.08871  loss_giou_8: 0.459  loss_ce_dn_8: 0.2959  loss_mask_dn_8: 0.03846  loss_dice_dn_8: 0.6958  loss_bbox_dn_8: 0.05945  loss_giou_dn_8: 0.3888  loss_ce_interm: 1.538  loss_mask_interm: 0.04092  loss_dice_interm: 0.6687  loss_bbox_interm: 0.1273  loss_giou_interm: 0.5826  time: 2.0839  data_time: 0.0535  lr: 0.0001  max_mem: 6620M\n",
            "[05/20 17:16:00 d2.utils.events]:  eta: 1:49:36  iter: 1719  total_loss: 56.2  loss_ce: 1.219  loss_mask: 0.02052  loss_dice: 0.502  loss_bbox: 0.09431  loss_giou: 0.5035  loss_ce_dn: 0.2572  loss_mask_dn: 0.02005  loss_dice_dn: 0.5956  loss_bbox_dn: 0.0446  loss_giou_dn: 0.415  loss_ce_0: 1.488  loss_mask_0: 0.02432  loss_dice_0: 0.4047  loss_bbox_0: 0.08435  loss_giou_0: 0.4913  loss_ce_dn_0: 0.6701  loss_mask_dn_0: 0.1319  loss_dice_dn_0: 2.306  loss_bbox_dn_0: 0.144  loss_giou_dn_0: 0.8567  loss_ce_1: 1.677  loss_mask_1: 0.0227  loss_dice_1: 0.5616  loss_bbox_1: 0.08733  loss_giou_1: 0.449  loss_ce_dn_1: 0.2961  loss_mask_dn_1: 0.02578  loss_dice_dn_1: 0.5868  loss_bbox_dn_1: 0.05687  loss_giou_dn_1: 0.4968  loss_ce_2: 1.546  loss_mask_2: 0.01694  loss_dice_2: 0.5368  loss_bbox_2: 0.07192  loss_giou_2: 0.4759  loss_ce_dn_2: 0.2587  loss_mask_dn_2: 0.02271  loss_dice_dn_2: 0.5898  loss_bbox_dn_2: 0.04686  loss_giou_dn_2: 0.4502  loss_ce_3: 1.477  loss_mask_3: 0.01764  loss_dice_3: 0.5655  loss_bbox_3: 0.07923  loss_giou_3: 0.4943  loss_ce_dn_3: 0.2718  loss_mask_dn_3: 0.02242  loss_dice_dn_3: 0.6238  loss_bbox_dn_3: 0.04513  loss_giou_dn_3: 0.4385  loss_ce_4: 1.385  loss_mask_4: 0.01842  loss_dice_4: 0.7882  loss_bbox_4: 0.08526  loss_giou_4: 0.5155  loss_ce_dn_4: 0.2677  loss_mask_dn_4: 0.02268  loss_dice_dn_4: 0.6048  loss_bbox_dn_4: 0.0425  loss_giou_dn_4: 0.4223  loss_ce_5: 1.35  loss_mask_5: 0.01853  loss_dice_5: 0.5754  loss_bbox_5: 0.08762  loss_giou_5: 0.4853  loss_ce_dn_5: 0.2515  loss_mask_dn_5: 0.02199  loss_dice_dn_5: 0.593  loss_bbox_dn_5: 0.04518  loss_giou_dn_5: 0.4194  loss_ce_6: 1.234  loss_mask_6: 0.01892  loss_dice_6: 0.7656  loss_bbox_6: 0.08869  loss_giou_6: 0.5033  loss_ce_dn_6: 0.259  loss_mask_dn_6: 0.02101  loss_dice_dn_6: 0.6033  loss_bbox_dn_6: 0.04476  loss_giou_dn_6: 0.4069  loss_ce_7: 1.199  loss_mask_7: 0.01884  loss_dice_7: 0.5785  loss_bbox_7: 0.09185  loss_giou_7: 0.5089  loss_ce_dn_7: 0.2535  loss_mask_dn_7: 0.02011  loss_dice_dn_7: 0.5733  loss_bbox_dn_7: 0.04387  loss_giou_dn_7: 0.4136  loss_ce_8: 1.195  loss_mask_8: 0.01591  loss_dice_8: 0.5142  loss_bbox_8: 0.09135  loss_giou_8: 0.5085  loss_ce_dn_8: 0.2568  loss_mask_dn_8: 0.02048  loss_dice_dn_8: 0.605  loss_bbox_dn_8: 0.04474  loss_giou_dn_8: 0.423  loss_ce_interm: 1.571  loss_mask_interm: 0.02618  loss_dice_interm: 0.7854  loss_bbox_interm: 0.107  loss_giou_interm: 0.6668  time: 2.0792  data_time: 0.0722  lr: 0.0001  max_mem: 6620M\n",
            "[05/20 17:16:33 d2.utils.events]:  eta: 1:48:47  iter: 1739  total_loss: 42.09  loss_ce: 1.008  loss_mask: 0.03462  loss_dice: 0.6049  loss_bbox: 0.06222  loss_giou: 0.3291  loss_ce_dn: 0.2527  loss_mask_dn: 0.03084  loss_dice_dn: 0.6585  loss_bbox_dn: 0.0412  loss_giou_dn: 0.2827  loss_ce_0: 1.411  loss_mask_0: 0.04307  loss_dice_0: 0.6604  loss_bbox_0: 0.07354  loss_giou_0: 0.4437  loss_ce_dn_0: 0.7967  loss_mask_dn_0: 0.1222  loss_dice_dn_0: 2.043  loss_bbox_dn_0: 0.2699  loss_giou_dn_0: 0.8515  loss_ce_1: 1.487  loss_mask_1: 0.04279  loss_dice_1: 0.6479  loss_bbox_1: 0.06931  loss_giou_1: 0.3526  loss_ce_dn_1: 0.3254  loss_mask_dn_1: 0.03635  loss_dice_dn_1: 0.7066  loss_bbox_dn_1: 0.07842  loss_giou_dn_1: 0.3696  loss_ce_2: 1.293  loss_mask_2: 0.03651  loss_dice_2: 0.6401  loss_bbox_2: 0.07615  loss_giou_2: 0.3826  loss_ce_dn_2: 0.3055  loss_mask_dn_2: 0.03412  loss_dice_dn_2: 0.6869  loss_bbox_dn_2: 0.05637  loss_giou_dn_2: 0.3174  loss_ce_3: 1.201  loss_mask_3: 0.03561  loss_dice_3: 0.6213  loss_bbox_3: 0.06394  loss_giou_3: 0.3145  loss_ce_dn_3: 0.2892  loss_mask_dn_3: 0.03545  loss_dice_dn_3: 0.6519  loss_bbox_dn_3: 0.04385  loss_giou_dn_3: 0.2961  loss_ce_4: 1.079  loss_mask_4: 0.03512  loss_dice_4: 0.6078  loss_bbox_4: 0.06519  loss_giou_4: 0.3298  loss_ce_dn_4: 0.2812  loss_mask_dn_4: 0.03324  loss_dice_dn_4: 0.67  loss_bbox_dn_4: 0.0401  loss_giou_dn_4: 0.2814  loss_ce_5: 1.015  loss_mask_5: 0.04009  loss_dice_5: 0.5788  loss_bbox_5: 0.07322  loss_giou_5: 0.3333  loss_ce_dn_5: 0.2725  loss_mask_dn_5: 0.03299  loss_dice_dn_5: 0.6767  loss_bbox_dn_5: 0.04073  loss_giou_dn_5: 0.2927  loss_ce_6: 1.017  loss_mask_6: 0.03287  loss_dice_6: 0.6268  loss_bbox_6: 0.0614  loss_giou_6: 0.3135  loss_ce_dn_6: 0.2589  loss_mask_dn_6: 0.03038  loss_dice_dn_6: 0.6354  loss_bbox_dn_6: 0.04057  loss_giou_dn_6: 0.2915  loss_ce_7: 1.128  loss_mask_7: 0.03848  loss_dice_7: 0.4484  loss_bbox_7: 0.06195  loss_giou_7: 0.3219  loss_ce_dn_7: 0.2542  loss_mask_dn_7: 0.03134  loss_dice_dn_7: 0.6323  loss_bbox_dn_7: 0.04073  loss_giou_dn_7: 0.2889  loss_ce_8: 0.9932  loss_mask_8: 0.03679  loss_dice_8: 0.5079  loss_bbox_8: 0.06179  loss_giou_8: 0.325  loss_ce_dn_8: 0.252  loss_mask_dn_8: 0.03319  loss_dice_dn_8: 0.6621  loss_bbox_dn_8: 0.04077  loss_giou_dn_8: 0.2887  loss_ce_interm: 1.254  loss_mask_interm: 0.03696  loss_dice_interm: 0.679  loss_bbox_interm: 0.096  loss_giou_interm: 0.4088  time: 2.0744  data_time: 0.0408  lr: 0.0001  max_mem: 6620M\n",
            "[05/20 17:17:07 d2.utils.events]:  eta: 1:47:47  iter: 1759  total_loss: 48.66  loss_ce: 1.33  loss_mask: 0.02837  loss_dice: 0.5449  loss_bbox: 0.06286  loss_giou: 0.421  loss_ce_dn: 0.3354  loss_mask_dn: 0.02826  loss_dice_dn: 0.6122  loss_bbox_dn: 0.04928  loss_giou_dn: 0.3369  loss_ce_0: 1.55  loss_mask_0: 0.02419  loss_dice_0: 0.6465  loss_bbox_0: 0.07962  loss_giou_0: 0.4336  loss_ce_dn_0: 0.739  loss_mask_dn_0: 0.1439  loss_dice_dn_0: 2.694  loss_bbox_dn_0: 0.2689  loss_giou_dn_0: 0.8587  loss_ce_1: 1.586  loss_mask_1: 0.03871  loss_dice_1: 0.6065  loss_bbox_1: 0.07238  loss_giou_1: 0.3423  loss_ce_dn_1: 0.3731  loss_mask_dn_1: 0.0349  loss_dice_dn_1: 0.7665  loss_bbox_dn_1: 0.07365  loss_giou_dn_1: 0.4607  loss_ce_2: 1.473  loss_mask_2: 0.03401  loss_dice_2: 0.5584  loss_bbox_2: 0.07078  loss_giou_2: 0.462  loss_ce_dn_2: 0.3416  loss_mask_dn_2: 0.02665  loss_dice_dn_2: 0.7249  loss_bbox_dn_2: 0.05685  loss_giou_dn_2: 0.3999  loss_ce_3: 1.311  loss_mask_3: 0.03159  loss_dice_3: 0.6405  loss_bbox_3: 0.08447  loss_giou_3: 0.3945  loss_ce_dn_3: 0.3135  loss_mask_dn_3: 0.02475  loss_dice_dn_3: 0.6421  loss_bbox_dn_3: 0.05272  loss_giou_dn_3: 0.3576  loss_ce_4: 1.379  loss_mask_4: 0.03296  loss_dice_4: 0.6171  loss_bbox_4: 0.09054  loss_giou_4: 0.3753  loss_ce_dn_4: 0.3295  loss_mask_dn_4: 0.0252  loss_dice_dn_4: 0.6527  loss_bbox_dn_4: 0.05141  loss_giou_dn_4: 0.3585  loss_ce_5: 1.417  loss_mask_5: 0.0269  loss_dice_5: 0.57  loss_bbox_5: 0.07282  loss_giou_5: 0.4228  loss_ce_dn_5: 0.3315  loss_mask_dn_5: 0.02796  loss_dice_dn_5: 0.608  loss_bbox_dn_5: 0.04994  loss_giou_dn_5: 0.3472  loss_ce_6: 1.366  loss_mask_6: 0.02539  loss_dice_6: 0.5234  loss_bbox_6: 0.08085  loss_giou_6: 0.4274  loss_ce_dn_6: 0.3212  loss_mask_dn_6: 0.02722  loss_dice_dn_6: 0.6119  loss_bbox_dn_6: 0.05048  loss_giou_dn_6: 0.3462  loss_ce_7: 1.352  loss_mask_7: 0.03137  loss_dice_7: 0.6378  loss_bbox_7: 0.06863  loss_giou_7: 0.4224  loss_ce_dn_7: 0.3236  loss_mask_dn_7: 0.02728  loss_dice_dn_7: 0.6215  loss_bbox_dn_7: 0.04847  loss_giou_dn_7: 0.3445  loss_ce_8: 1.322  loss_mask_8: 0.02609  loss_dice_8: 0.5775  loss_bbox_8: 0.06404  loss_giou_8: 0.4241  loss_ce_dn_8: 0.3343  loss_mask_dn_8: 0.0272  loss_dice_dn_8: 0.6022  loss_bbox_dn_8: 0.04889  loss_giou_dn_8: 0.3426  loss_ce_interm: 1.438  loss_mask_interm: 0.02967  loss_dice_interm: 0.6534  loss_bbox_interm: 0.1232  loss_giou_interm: 0.5969  time: 2.0701  data_time: 0.1006  lr: 0.0001  max_mem: 6620M\n",
            "[05/20 17:17:42 d2.utils.events]:  eta: 1:47:14  iter: 1779  total_loss: 55.05  loss_ce: 1.322  loss_mask: 0.04642  loss_dice: 0.7983  loss_bbox: 0.07928  loss_giou: 0.4462  loss_ce_dn: 0.2972  loss_mask_dn: 0.03701  loss_dice_dn: 0.7495  loss_bbox_dn: 0.05054  loss_giou_dn: 0.3516  loss_ce_0: 1.574  loss_mask_0: 0.05506  loss_dice_0: 0.9745  loss_bbox_0: 0.0938  loss_giou_0: 0.5781  loss_ce_dn_0: 0.7338  loss_mask_dn_0: 0.1845  loss_dice_dn_0: 2.923  loss_bbox_dn_0: 0.2155  loss_giou_dn_0: 0.8542  loss_ce_1: 1.653  loss_mask_1: 0.06507  loss_dice_1: 0.7546  loss_bbox_1: 0.08653  loss_giou_1: 0.4924  loss_ce_dn_1: 0.3475  loss_mask_dn_1: 0.04445  loss_dice_dn_1: 0.8442  loss_bbox_dn_1: 0.08451  loss_giou_dn_1: 0.4688  loss_ce_2: 1.623  loss_mask_2: 0.04383  loss_dice_2: 0.9138  loss_bbox_2: 0.08601  loss_giou_2: 0.4886  loss_ce_dn_2: 0.33  loss_mask_dn_2: 0.03952  loss_dice_dn_2: 0.7664  loss_bbox_dn_2: 0.06627  loss_giou_dn_2: 0.4058  loss_ce_3: 1.356  loss_mask_3: 0.04708  loss_dice_3: 0.8681  loss_bbox_3: 0.07942  loss_giou_3: 0.4899  loss_ce_dn_3: 0.3134  loss_mask_dn_3: 0.036  loss_dice_dn_3: 0.7632  loss_bbox_dn_3: 0.05691  loss_giou_dn_3: 0.3684  loss_ce_4: 1.398  loss_mask_4: 0.04608  loss_dice_4: 1.069  loss_bbox_4: 0.0751  loss_giou_4: 0.4763  loss_ce_dn_4: 0.302  loss_mask_dn_4: 0.03626  loss_dice_dn_4: 0.7166  loss_bbox_dn_4: 0.05457  loss_giou_dn_4: 0.3492  loss_ce_5: 1.371  loss_mask_5: 0.04891  loss_dice_5: 0.8985  loss_bbox_5: 0.07635  loss_giou_5: 0.4682  loss_ce_dn_5: 0.3132  loss_mask_dn_5: 0.03484  loss_dice_dn_5: 0.734  loss_bbox_dn_5: 0.05247  loss_giou_dn_5: 0.3437  loss_ce_6: 1.33  loss_mask_6: 0.05579  loss_dice_6: 0.9006  loss_bbox_6: 0.07391  loss_giou_6: 0.4676  loss_ce_dn_6: 0.2988  loss_mask_dn_6: 0.03643  loss_dice_dn_6: 0.7177  loss_bbox_dn_6: 0.05143  loss_giou_dn_6: 0.3461  loss_ce_7: 1.311  loss_mask_7: 0.05738  loss_dice_7: 0.8474  loss_bbox_7: 0.08531  loss_giou_7: 0.4513  loss_ce_dn_7: 0.2921  loss_mask_dn_7: 0.03782  loss_dice_dn_7: 0.7735  loss_bbox_dn_7: 0.0511  loss_giou_dn_7: 0.3513  loss_ce_8: 1.328  loss_mask_8: 0.05095  loss_dice_8: 0.9138  loss_bbox_8: 0.08266  loss_giou_8: 0.4794  loss_ce_dn_8: 0.2851  loss_mask_dn_8: 0.03792  loss_dice_dn_8: 0.7666  loss_bbox_dn_8: 0.05096  loss_giou_dn_8: 0.349  loss_ce_interm: 1.63  loss_mask_interm: 0.06465  loss_dice_interm: 1.151  loss_bbox_interm: 0.1303  loss_giou_interm: 0.6387  time: 2.0665  data_time: 0.0756  lr: 0.0001  max_mem: 6620M\n",
            "[05/20 17:18:19 d2.utils.events]:  eta: 1:46:44  iter: 1799  total_loss: 55.32  loss_ce: 1.406  loss_mask: 0.04048  loss_dice: 0.6567  loss_bbox: 0.1256  loss_giou: 0.5515  loss_ce_dn: 0.2663  loss_mask_dn: 0.03666  loss_dice_dn: 0.6745  loss_bbox_dn: 0.05772  loss_giou_dn: 0.3981  loss_ce_0: 1.567  loss_mask_0: 0.03837  loss_dice_0: 1.032  loss_bbox_0: 0.1358  loss_giou_0: 0.6355  loss_ce_dn_0: 0.8442  loss_mask_dn_0: 0.2701  loss_dice_dn_0: 3.117  loss_bbox_dn_0: 0.2524  loss_giou_dn_0: 0.8559  loss_ce_1: 1.569  loss_mask_1: 0.04429  loss_dice_1: 1.014  loss_bbox_1: 0.1187  loss_giou_1: 0.5776  loss_ce_dn_1: 0.3232  loss_mask_dn_1: 0.0453  loss_dice_dn_1: 0.8134  loss_bbox_dn_1: 0.08702  loss_giou_dn_1: 0.495  loss_ce_2: 1.679  loss_mask_2: 0.04072  loss_dice_2: 0.7131  loss_bbox_2: 0.1164  loss_giou_2: 0.5738  loss_ce_dn_2: 0.3056  loss_mask_dn_2: 0.04538  loss_dice_dn_2: 0.7507  loss_bbox_dn_2: 0.07201  loss_giou_dn_2: 0.4474  loss_ce_3: 1.567  loss_mask_3: 0.04719  loss_dice_3: 0.6889  loss_bbox_3: 0.1032  loss_giou_3: 0.5153  loss_ce_dn_3: 0.2699  loss_mask_dn_3: 0.04006  loss_dice_dn_3: 0.7473  loss_bbox_dn_3: 0.06498  loss_giou_dn_3: 0.4262  loss_ce_4: 1.542  loss_mask_4: 0.0372  loss_dice_4: 0.6626  loss_bbox_4: 0.1184  loss_giou_4: 0.6189  loss_ce_dn_4: 0.2634  loss_mask_dn_4: 0.03877  loss_dice_dn_4: 0.7162  loss_bbox_dn_4: 0.06529  loss_giou_dn_4: 0.409  loss_ce_5: 1.432  loss_mask_5: 0.04199  loss_dice_5: 0.5539  loss_bbox_5: 0.1228  loss_giou_5: 0.5951  loss_ce_dn_5: 0.2631  loss_mask_dn_5: 0.03408  loss_dice_dn_5: 0.7036  loss_bbox_dn_5: 0.05681  loss_giou_dn_5: 0.3951  loss_ce_6: 1.431  loss_mask_6: 0.03453  loss_dice_6: 0.8213  loss_bbox_6: 0.1227  loss_giou_6: 0.5886  loss_ce_dn_6: 0.2655  loss_mask_dn_6: 0.03417  loss_dice_dn_6: 0.6714  loss_bbox_dn_6: 0.05695  loss_giou_dn_6: 0.3996  loss_ce_7: 1.411  loss_mask_7: 0.04077  loss_dice_7: 0.758  loss_bbox_7: 0.1255  loss_giou_7: 0.5981  loss_ce_dn_7: 0.2668  loss_mask_dn_7: 0.03588  loss_dice_dn_7: 0.6936  loss_bbox_dn_7: 0.05665  loss_giou_dn_7: 0.3933  loss_ce_8: 1.396  loss_mask_8: 0.04341  loss_dice_8: 0.7967  loss_bbox_8: 0.1241  loss_giou_8: 0.5626  loss_ce_dn_8: 0.2696  loss_mask_dn_8: 0.03784  loss_dice_dn_8: 0.6709  loss_bbox_dn_8: 0.05749  loss_giou_dn_8: 0.3938  loss_ce_interm: 1.564  loss_mask_interm: 0.03956  loss_dice_interm: 0.7971  loss_bbox_interm: 0.153  loss_giou_interm: 0.6335  time: 2.0637  data_time: 0.1579  lr: 0.0001  max_mem: 6620M\n",
            "[05/20 17:18:53 d2.utils.events]:  eta: 1:46:09  iter: 1819  total_loss: 41.24  loss_ce: 1.115  loss_mask: 0.04238  loss_dice: 0.4687  loss_bbox: 0.06284  loss_giou: 0.281  loss_ce_dn: 0.2232  loss_mask_dn: 0.03856  loss_dice_dn: 0.5885  loss_bbox_dn: 0.0503  loss_giou_dn: 0.2725  loss_ce_0: 1.387  loss_mask_0: 0.05645  loss_dice_0: 0.6621  loss_bbox_0: 0.07627  loss_giou_0: 0.4232  loss_ce_dn_0: 0.7212  loss_mask_dn_0: 0.2598  loss_dice_dn_0: 2.068  loss_bbox_dn_0: 0.2937  loss_giou_dn_0: 0.8534  loss_ce_1: 1.34  loss_mask_1: 0.04183  loss_dice_1: 0.5615  loss_bbox_1: 0.06947  loss_giou_1: 0.3152  loss_ce_dn_1: 0.3094  loss_mask_dn_1: 0.04732  loss_dice_dn_1: 0.6801  loss_bbox_dn_1: 0.0835  loss_giou_dn_1: 0.4193  loss_ce_2: 1.347  loss_mask_2: 0.0402  loss_dice_2: 0.5543  loss_bbox_2: 0.0603  loss_giou_2: 0.2965  loss_ce_dn_2: 0.2754  loss_mask_dn_2: 0.03702  loss_dice_dn_2: 0.6537  loss_bbox_dn_2: 0.06045  loss_giou_dn_2: 0.3316  loss_ce_3: 1.2  loss_mask_3: 0.03233  loss_dice_3: 0.5535  loss_bbox_3: 0.05893  loss_giou_3: 0.3088  loss_ce_dn_3: 0.2563  loss_mask_dn_3: 0.0373  loss_dice_dn_3: 0.6285  loss_bbox_dn_3: 0.05539  loss_giou_dn_3: 0.3123  loss_ce_4: 1.177  loss_mask_4: 0.04564  loss_dice_4: 0.4915  loss_bbox_4: 0.0611  loss_giou_4: 0.3009  loss_ce_dn_4: 0.2382  loss_mask_dn_4: 0.03691  loss_dice_dn_4: 0.6239  loss_bbox_dn_4: 0.0538  loss_giou_dn_4: 0.3017  loss_ce_5: 1.272  loss_mask_5: 0.04  loss_dice_5: 0.429  loss_bbox_5: 0.06942  loss_giou_5: 0.2963  loss_ce_dn_5: 0.2506  loss_mask_dn_5: 0.03663  loss_dice_dn_5: 0.6115  loss_bbox_dn_5: 0.05086  loss_giou_dn_5: 0.2746  loss_ce_6: 1.223  loss_mask_6: 0.04493  loss_dice_6: 0.4297  loss_bbox_6: 0.07088  loss_giou_6: 0.2856  loss_ce_dn_6: 0.2313  loss_mask_dn_6: 0.03885  loss_dice_dn_6: 0.6344  loss_bbox_dn_6: 0.05086  loss_giou_dn_6: 0.2715  loss_ce_7: 1.136  loss_mask_7: 0.03716  loss_dice_7: 0.4893  loss_bbox_7: 0.06288  loss_giou_7: 0.2963  loss_ce_dn_7: 0.2251  loss_mask_dn_7: 0.03878  loss_dice_dn_7: 0.601  loss_bbox_dn_7: 0.04993  loss_giou_dn_7: 0.2757  loss_ce_8: 1.117  loss_mask_8: 0.04509  loss_dice_8: 0.5019  loss_bbox_8: 0.06324  loss_giou_8: 0.2892  loss_ce_dn_8: 0.2182  loss_mask_dn_8: 0.03914  loss_dice_dn_8: 0.6036  loss_bbox_dn_8: 0.04953  loss_giou_dn_8: 0.2771  loss_ce_interm: 1.396  loss_mask_interm: 0.03495  loss_dice_interm: 0.5921  loss_bbox_interm: 0.1082  loss_giou_interm: 0.4816  time: 2.0598  data_time: 0.0678  lr: 1e-05  max_mem: 6620M\n",
            "[05/20 17:19:27 d2.utils.events]:  eta: 1:45:39  iter: 1839  total_loss: 43.53  loss_ce: 1.077  loss_mask: 0.05449  loss_dice: 0.5984  loss_bbox: 0.0685  loss_giou: 0.3743  loss_ce_dn: 0.1864  loss_mask_dn: 0.05153  loss_dice_dn: 0.6301  loss_bbox_dn: 0.05362  loss_giou_dn: 0.2858  loss_ce_0: 1.16  loss_mask_0: 0.05139  loss_dice_0: 0.5538  loss_bbox_0: 0.1075  loss_giou_0: 0.4772  loss_ce_dn_0: 0.7833  loss_mask_dn_0: 0.1622  loss_dice_dn_0: 2.339  loss_bbox_dn_0: 0.329  loss_giou_dn_0: 0.8594  loss_ce_1: 1.186  loss_mask_1: 0.05779  loss_dice_1: 0.6773  loss_bbox_1: 0.07087  loss_giou_1: 0.3511  loss_ce_dn_1: 0.2691  loss_mask_dn_1: 0.04848  loss_dice_dn_1: 0.6317  loss_bbox_dn_1: 0.0802  loss_giou_dn_1: 0.3791  loss_ce_2: 1.187  loss_mask_2: 0.05103  loss_dice_2: 0.5621  loss_bbox_2: 0.07823  loss_giou_2: 0.3547  loss_ce_dn_2: 0.2212  loss_mask_dn_2: 0.04791  loss_dice_dn_2: 0.6189  loss_bbox_dn_2: 0.06067  loss_giou_dn_2: 0.3179  loss_ce_3: 1.026  loss_mask_3: 0.05446  loss_dice_3: 0.7553  loss_bbox_3: 0.06872  loss_giou_3: 0.3799  loss_ce_dn_3: 0.2082  loss_mask_dn_3: 0.04879  loss_dice_dn_3: 0.6037  loss_bbox_dn_3: 0.05502  loss_giou_dn_3: 0.2996  loss_ce_4: 1.003  loss_mask_4: 0.04747  loss_dice_4: 0.6463  loss_bbox_4: 0.06674  loss_giou_4: 0.3804  loss_ce_dn_4: 0.1927  loss_mask_dn_4: 0.05041  loss_dice_dn_4: 0.611  loss_bbox_dn_4: 0.05443  loss_giou_dn_4: 0.2989  loss_ce_5: 0.9983  loss_mask_5: 0.05469  loss_dice_5: 0.6863  loss_bbox_5: 0.06382  loss_giou_5: 0.3674  loss_ce_dn_5: 0.1819  loss_mask_dn_5: 0.04868  loss_dice_dn_5: 0.648  loss_bbox_dn_5: 0.05618  loss_giou_dn_5: 0.2909  loss_ce_6: 1.03  loss_mask_6: 0.04225  loss_dice_6: 0.6488  loss_bbox_6: 0.06296  loss_giou_6: 0.3545  loss_ce_dn_6: 0.1821  loss_mask_dn_6: 0.04916  loss_dice_dn_6: 0.6458  loss_bbox_dn_6: 0.05583  loss_giou_dn_6: 0.2819  loss_ce_7: 0.9737  loss_mask_7: 0.05772  loss_dice_7: 0.6904  loss_bbox_7: 0.07248  loss_giou_7: 0.3839  loss_ce_dn_7: 0.1859  loss_mask_dn_7: 0.05304  loss_dice_dn_7: 0.6595  loss_bbox_dn_7: 0.05422  loss_giou_dn_7: 0.2869  loss_ce_8: 1.085  loss_mask_8: 0.054  loss_dice_8: 0.7631  loss_bbox_8: 0.05999  loss_giou_8: 0.34  loss_ce_dn_8: 0.1819  loss_mask_dn_8: 0.05198  loss_dice_dn_8: 0.6257  loss_bbox_dn_8: 0.05252  loss_giou_dn_8: 0.2893  loss_ce_interm: 1.164  loss_mask_interm: 0.05529  loss_dice_interm: 0.6242  loss_bbox_interm: 0.1163  loss_giou_interm: 0.4201  time: 2.0561  data_time: 0.1015  lr: 1e-05  max_mem: 6620M\n",
            "[05/20 17:20:01 d2.utils.events]:  eta: 1:44:56  iter: 1859  total_loss: 47.24  loss_ce: 1.296  loss_mask: 0.02501  loss_dice: 0.7284  loss_bbox: 0.08697  loss_giou: 0.3579  loss_ce_dn: 0.2756  loss_mask_dn: 0.02391  loss_dice_dn: 0.5429  loss_bbox_dn: 0.0409  loss_giou_dn: 0.3164  loss_ce_0: 1.52  loss_mask_0: 0.03063  loss_dice_0: 0.6195  loss_bbox_0: 0.1311  loss_giou_0: 0.5611  loss_ce_dn_0: 0.7795  loss_mask_dn_0: 0.1066  loss_dice_dn_0: 2.767  loss_bbox_dn_0: 0.2187  loss_giou_dn_0: 0.856  loss_ce_1: 1.5  loss_mask_1: 0.03177  loss_dice_1: 0.7715  loss_bbox_1: 0.07413  loss_giou_1: 0.4317  loss_ce_dn_1: 0.3427  loss_mask_dn_1: 0.02501  loss_dice_dn_1: 0.645  loss_bbox_dn_1: 0.06348  loss_giou_dn_1: 0.4261  loss_ce_2: 1.371  loss_mask_2: 0.0286  loss_dice_2: 0.6627  loss_bbox_2: 0.08242  loss_giou_2: 0.4343  loss_ce_dn_2: 0.3031  loss_mask_dn_2: 0.02286  loss_dice_dn_2: 0.5974  loss_bbox_dn_2: 0.04794  loss_giou_dn_2: 0.388  loss_ce_3: 1.424  loss_mask_3: 0.02801  loss_dice_3: 0.4697  loss_bbox_3: 0.07552  loss_giou_3: 0.3978  loss_ce_dn_3: 0.2825  loss_mask_dn_3: 0.02414  loss_dice_dn_3: 0.6157  loss_bbox_dn_3: 0.04418  loss_giou_dn_3: 0.3713  loss_ce_4: 1.274  loss_mask_4: 0.0306  loss_dice_4: 0.5581  loss_bbox_4: 0.07975  loss_giou_4: 0.3677  loss_ce_dn_4: 0.2666  loss_mask_dn_4: 0.02458  loss_dice_dn_4: 0.5727  loss_bbox_dn_4: 0.04179  loss_giou_dn_4: 0.3686  loss_ce_5: 1.282  loss_mask_5: 0.02781  loss_dice_5: 0.6821  loss_bbox_5: 0.07701  loss_giou_5: 0.3707  loss_ce_dn_5: 0.2658  loss_mask_dn_5: 0.02418  loss_dice_dn_5: 0.5737  loss_bbox_dn_5: 0.04253  loss_giou_dn_5: 0.3515  loss_ce_6: 1.326  loss_mask_6: 0.02853  loss_dice_6: 0.6216  loss_bbox_6: 0.1134  loss_giou_6: 0.3746  loss_ce_dn_6: 0.2769  loss_mask_dn_6: 0.02299  loss_dice_dn_6: 0.5358  loss_bbox_dn_6: 0.04074  loss_giou_dn_6: 0.3424  loss_ce_7: 1.318  loss_mask_7: 0.02742  loss_dice_7: 0.5912  loss_bbox_7: 0.09106  loss_giou_7: 0.355  loss_ce_dn_7: 0.2736  loss_mask_dn_7: 0.02308  loss_dice_dn_7: 0.5753  loss_bbox_dn_7: 0.04113  loss_giou_dn_7: 0.329  loss_ce_8: 1.319  loss_mask_8: 0.0267  loss_dice_8: 0.6001  loss_bbox_8: 0.1026  loss_giou_8: 0.3572  loss_ce_dn_8: 0.2822  loss_mask_dn_8: 0.02303  loss_dice_dn_8: 0.5449  loss_bbox_dn_8: 0.04014  loss_giou_dn_8: 0.3195  loss_ce_interm: 1.576  loss_mask_interm: 0.02953  loss_dice_interm: 0.5203  loss_bbox_interm: 0.1233  loss_giou_interm: 0.5209  time: 2.0522  data_time: 0.0823  lr: 1e-05  max_mem: 6620M\n",
            "[05/20 17:20:36 d2.utils.events]:  eta: 1:44:32  iter: 1879  total_loss: 41.98  loss_ce: 0.9821  loss_mask: 0.056  loss_dice: 0.415  loss_bbox: 0.05431  loss_giou: 0.2945  loss_ce_dn: 0.2251  loss_mask_dn: 0.06407  loss_dice_dn: 0.4924  loss_bbox_dn: 0.06407  loss_giou_dn: 0.2712  loss_ce_0: 1.234  loss_mask_0: 0.0562  loss_dice_0: 0.546  loss_bbox_0: 0.07396  loss_giou_0: 0.309  loss_ce_dn_0: 0.7205  loss_mask_dn_0: 0.1843  loss_dice_dn_0: 2.193  loss_bbox_dn_0: 0.414  loss_giou_dn_0: 0.8598  loss_ce_1: 1.323  loss_mask_1: 0.06006  loss_dice_1: 0.4459  loss_bbox_1: 0.06606  loss_giou_1: 0.3568  loss_ce_dn_1: 0.3232  loss_mask_dn_1: 0.0664  loss_dice_dn_1: 0.4844  loss_bbox_dn_1: 0.1235  loss_giou_dn_1: 0.3784  loss_ce_2: 1.307  loss_mask_2: 0.05868  loss_dice_2: 0.4571  loss_bbox_2: 0.0633  loss_giou_2: 0.3457  loss_ce_dn_2: 0.2827  loss_mask_dn_2: 0.06393  loss_dice_dn_2: 0.4635  loss_bbox_dn_2: 0.09331  loss_giou_dn_2: 0.3284  loss_ce_3: 1.1  loss_mask_3: 0.06163  loss_dice_3: 0.4234  loss_bbox_3: 0.05596  loss_giou_3: 0.3305  loss_ce_dn_3: 0.2342  loss_mask_dn_3: 0.0648  loss_dice_dn_3: 0.4997  loss_bbox_dn_3: 0.07763  loss_giou_dn_3: 0.3058  loss_ce_4: 1.027  loss_mask_4: 0.05589  loss_dice_4: 0.5743  loss_bbox_4: 0.05292  loss_giou_4: 0.3158  loss_ce_dn_4: 0.2258  loss_mask_dn_4: 0.05884  loss_dice_dn_4: 0.4804  loss_bbox_dn_4: 0.07034  loss_giou_dn_4: 0.2817  loss_ce_5: 0.9826  loss_mask_5: 0.05213  loss_dice_5: 0.4624  loss_bbox_5: 0.0513  loss_giou_5: 0.3112  loss_ce_dn_5: 0.2272  loss_mask_dn_5: 0.05767  loss_dice_dn_5: 0.4699  loss_bbox_dn_5: 0.06515  loss_giou_dn_5: 0.2803  loss_ce_6: 0.9088  loss_mask_6: 0.05639  loss_dice_6: 0.3822  loss_bbox_6: 0.05066  loss_giou_6: 0.323  loss_ce_dn_6: 0.2224  loss_mask_dn_6: 0.05841  loss_dice_dn_6: 0.4684  loss_bbox_dn_6: 0.06555  loss_giou_dn_6: 0.2776  loss_ce_7: 0.8955  loss_mask_7: 0.05943  loss_dice_7: 0.4653  loss_bbox_7: 0.04948  loss_giou_7: 0.2692  loss_ce_dn_7: 0.229  loss_mask_dn_7: 0.06443  loss_dice_dn_7: 0.4673  loss_bbox_dn_7: 0.06719  loss_giou_dn_7: 0.2774  loss_ce_8: 0.9295  loss_mask_8: 0.05492  loss_dice_8: 0.4089  loss_bbox_8: 0.05416  loss_giou_8: 0.304  loss_ce_dn_8: 0.2218  loss_mask_dn_8: 0.06594  loss_dice_dn_8: 0.4541  loss_bbox_dn_8: 0.06537  loss_giou_dn_8: 0.272  loss_ce_interm: 1.268  loss_mask_interm: 0.06885  loss_dice_interm: 0.4104  loss_bbox_interm: 0.125  loss_giou_interm: 0.3967  time: 2.0485  data_time: 0.0803  lr: 1e-05  max_mem: 6620M\n",
            "[05/20 17:21:11 d2.utils.events]:  eta: 1:44:06  iter: 1899  total_loss: 41.19  loss_ce: 0.9009  loss_mask: 0.02747  loss_dice: 0.5567  loss_bbox: 0.05801  loss_giou: 0.3775  loss_ce_dn: 0.188  loss_mask_dn: 0.02871  loss_dice_dn: 0.6029  loss_bbox_dn: 0.03675  loss_giou_dn: 0.3161  loss_ce_0: 1.281  loss_mask_0: 0.03266  loss_dice_0: 0.6565  loss_bbox_0: 0.07461  loss_giou_0: 0.5486  loss_ce_dn_0: 0.7216  loss_mask_dn_0: 0.1431  loss_dice_dn_0: 2.178  loss_bbox_dn_0: 0.2228  loss_giou_dn_0: 0.8543  loss_ce_1: 1.082  loss_mask_1: 0.03962  loss_dice_1: 0.6463  loss_bbox_1: 0.07324  loss_giou_1: 0.4044  loss_ce_dn_1: 0.2852  loss_mask_dn_1: 0.03893  loss_dice_dn_1: 0.6087  loss_bbox_dn_1: 0.06618  loss_giou_dn_1: 0.3835  loss_ce_2: 0.9286  loss_mask_2: 0.04391  loss_dice_2: 0.6204  loss_bbox_2: 0.07285  loss_giou_2: 0.4014  loss_ce_dn_2: 0.2389  loss_mask_dn_2: 0.03222  loss_dice_dn_2: 0.5993  loss_bbox_dn_2: 0.04629  loss_giou_dn_2: 0.3481  loss_ce_3: 1.003  loss_mask_3: 0.03836  loss_dice_3: 0.6433  loss_bbox_3: 0.07148  loss_giou_3: 0.3503  loss_ce_dn_3: 0.2252  loss_mask_dn_3: 0.03409  loss_dice_dn_3: 0.6253  loss_bbox_dn_3: 0.04022  loss_giou_dn_3: 0.318  loss_ce_4: 0.9427  loss_mask_4: 0.04038  loss_dice_4: 0.697  loss_bbox_4: 0.06949  loss_giou_4: 0.3824  loss_ce_dn_4: 0.2071  loss_mask_dn_4: 0.03005  loss_dice_dn_4: 0.5966  loss_bbox_dn_4: 0.03876  loss_giou_dn_4: 0.3225  loss_ce_5: 0.8692  loss_mask_5: 0.03862  loss_dice_5: 0.57  loss_bbox_5: 0.06574  loss_giou_5: 0.3673  loss_ce_dn_5: 0.1946  loss_mask_dn_5: 0.0281  loss_dice_dn_5: 0.5855  loss_bbox_dn_5: 0.03707  loss_giou_dn_5: 0.3081  loss_ce_6: 0.87  loss_mask_6: 0.02748  loss_dice_6: 0.4963  loss_bbox_6: 0.05911  loss_giou_6: 0.3828  loss_ce_dn_6: 0.1901  loss_mask_dn_6: 0.02721  loss_dice_dn_6: 0.6053  loss_bbox_dn_6: 0.03718  loss_giou_dn_6: 0.3119  loss_ce_7: 0.9311  loss_mask_7: 0.02932  loss_dice_7: 0.6406  loss_bbox_7: 0.05829  loss_giou_7: 0.3717  loss_ce_dn_7: 0.1884  loss_mask_dn_7: 0.02897  loss_dice_dn_7: 0.5705  loss_bbox_dn_7: 0.03672  loss_giou_dn_7: 0.3074  loss_ce_8: 0.9131  loss_mask_8: 0.02944  loss_dice_8: 0.593  loss_bbox_8: 0.05779  loss_giou_8: 0.3743  loss_ce_dn_8: 0.1898  loss_mask_dn_8: 0.02979  loss_dice_dn_8: 0.6082  loss_bbox_dn_8: 0.0362  loss_giou_dn_8: 0.3096  loss_ce_interm: 1.376  loss_mask_interm: 0.02983  loss_dice_interm: 0.6351  loss_bbox_interm: 0.08371  loss_giou_interm: 0.5233  time: 2.0457  data_time: 0.1033  lr: 1e-05  max_mem: 6620M\n",
            "[05/20 17:21:51 d2.utils.events]:  eta: 1:43:27  iter: 1919  total_loss: 44.88  loss_ce: 1.041  loss_mask: 0.03993  loss_dice: 0.5135  loss_bbox: 0.1217  loss_giou: 0.4297  loss_ce_dn: 0.1506  loss_mask_dn: 0.03211  loss_dice_dn: 0.5882  loss_bbox_dn: 0.05831  loss_giou_dn: 0.3058  loss_ce_0: 1.269  loss_mask_0: 0.03501  loss_dice_0: 0.5222  loss_bbox_0: 0.1284  loss_giou_0: 0.4409  loss_ce_dn_0: 0.7106  loss_mask_dn_0: 0.3237  loss_dice_dn_0: 2.255  loss_bbox_dn_0: 0.332  loss_giou_dn_0: 0.8639  loss_ce_1: 1.333  loss_mask_1: 0.04443  loss_dice_1: 0.4354  loss_bbox_1: 0.08737  loss_giou_1: 0.5136  loss_ce_dn_1: 0.2331  loss_mask_dn_1: 0.03047  loss_dice_dn_1: 0.7195  loss_bbox_dn_1: 0.08235  loss_giou_dn_1: 0.3795  loss_ce_2: 1.16  loss_mask_2: 0.04127  loss_dice_2: 0.5606  loss_bbox_2: 0.09641  loss_giou_2: 0.4238  loss_ce_dn_2: 0.2017  loss_mask_dn_2: 0.03033  loss_dice_dn_2: 0.5531  loss_bbox_dn_2: 0.07027  loss_giou_dn_2: 0.3083  loss_ce_3: 1.156  loss_mask_3: 0.03551  loss_dice_3: 0.6536  loss_bbox_3: 0.09462  loss_giou_3: 0.3556  loss_ce_dn_3: 0.1823  loss_mask_dn_3: 0.03042  loss_dice_dn_3: 0.5208  loss_bbox_dn_3: 0.0659  loss_giou_dn_3: 0.3243  loss_ce_4: 1.025  loss_mask_4: 0.03564  loss_dice_4: 0.4324  loss_bbox_4: 0.08734  loss_giou_4: 0.3825  loss_ce_dn_4: 0.1605  loss_mask_dn_4: 0.02859  loss_dice_dn_4: 0.5292  loss_bbox_dn_4: 0.05896  loss_giou_dn_4: 0.2968  loss_ce_5: 1.019  loss_mask_5: 0.03668  loss_dice_5: 0.4851  loss_bbox_5: 0.08226  loss_giou_5: 0.38  loss_ce_dn_5: 0.1509  loss_mask_dn_5: 0.02923  loss_dice_dn_5: 0.5683  loss_bbox_dn_5: 0.05624  loss_giou_dn_5: 0.2988  loss_ce_6: 1.026  loss_mask_6: 0.04693  loss_dice_6: 0.5  loss_bbox_6: 0.09497  loss_giou_6: 0.3844  loss_ce_dn_6: 0.151  loss_mask_dn_6: 0.03015  loss_dice_dn_6: 0.5488  loss_bbox_dn_6: 0.05645  loss_giou_dn_6: 0.2972  loss_ce_7: 1.057  loss_mask_7: 0.03804  loss_dice_7: 0.4978  loss_bbox_7: 0.1086  loss_giou_7: 0.4339  loss_ce_dn_7: 0.1506  loss_mask_dn_7: 0.03136  loss_dice_dn_7: 0.5617  loss_bbox_dn_7: 0.05694  loss_giou_dn_7: 0.3016  loss_ce_8: 1.095  loss_mask_8: 0.04081  loss_dice_8: 0.4844  loss_bbox_8: 0.1186  loss_giou_8: 0.4358  loss_ce_dn_8: 0.149  loss_mask_dn_8: 0.03318  loss_dice_dn_8: 0.5555  loss_bbox_dn_8: 0.05636  loss_giou_dn_8: 0.3048  loss_ce_interm: 1.264  loss_mask_interm: 0.03948  loss_dice_interm: 0.6417  loss_bbox_interm: 0.1055  loss_giou_interm: 0.4265  time: 2.0421  data_time: 0.0371  lr: 1e-05  max_mem: 6620M\n",
            "[05/20 17:22:25 d2.utils.events]:  eta: 1:43:01  iter: 1939  total_loss: 53.38  loss_ce: 1.422  loss_mask: 0.03378  loss_dice: 0.4692  loss_bbox: 0.08438  loss_giou: 0.489  loss_ce_dn: 0.2443  loss_mask_dn: 0.04104  loss_dice_dn: 0.542  loss_bbox_dn: 0.04028  loss_giou_dn: 0.3615  loss_ce_0: 1.559  loss_mask_0: 0.03983  loss_dice_0: 0.6596  loss_bbox_0: 0.09383  loss_giou_0: 0.525  loss_ce_dn_0: 0.7419  loss_mask_dn_0: 0.1878  loss_dice_dn_0: 2.388  loss_bbox_dn_0: 0.2512  loss_giou_dn_0: 0.8689  loss_ce_1: 1.592  loss_mask_1: 0.04988  loss_dice_1: 0.5782  loss_bbox_1: 0.1286  loss_giou_1: 0.5417  loss_ce_dn_1: 0.2926  loss_mask_dn_1: 0.04248  loss_dice_dn_1: 0.5634  loss_bbox_dn_1: 0.09664  loss_giou_dn_1: 0.4631  loss_ce_2: 1.364  loss_mask_2: 0.04159  loss_dice_2: 0.6015  loss_bbox_2: 0.1248  loss_giou_2: 0.5082  loss_ce_dn_2: 0.2766  loss_mask_dn_2: 0.04155  loss_dice_dn_2: 0.5646  loss_bbox_dn_2: 0.06699  loss_giou_dn_2: 0.3814  loss_ce_3: 1.424  loss_mask_3: 0.03738  loss_dice_3: 0.5707  loss_bbox_3: 0.1092  loss_giou_3: 0.5045  loss_ce_dn_3: 0.2612  loss_mask_dn_3: 0.04115  loss_dice_dn_3: 0.5155  loss_bbox_dn_3: 0.0577  loss_giou_dn_3: 0.3722  loss_ce_4: 1.341  loss_mask_4: 0.0356  loss_dice_4: 0.5616  loss_bbox_4: 0.09055  loss_giou_4: 0.4894  loss_ce_dn_4: 0.2431  loss_mask_dn_4: 0.04213  loss_dice_dn_4: 0.5084  loss_bbox_dn_4: 0.04755  loss_giou_dn_4: 0.3568  loss_ce_5: 1.46  loss_mask_5: 0.03767  loss_dice_5: 0.4709  loss_bbox_5: 0.1012  loss_giou_5: 0.4958  loss_ce_dn_5: 0.23  loss_mask_dn_5: 0.04274  loss_dice_dn_5: 0.5145  loss_bbox_dn_5: 0.04355  loss_giou_dn_5: 0.3583  loss_ce_6: 1.317  loss_mask_6: 0.03759  loss_dice_6: 0.4298  loss_bbox_6: 0.08482  loss_giou_6: 0.4962  loss_ce_dn_6: 0.2353  loss_mask_dn_6: 0.04441  loss_dice_dn_6: 0.5131  loss_bbox_dn_6: 0.04253  loss_giou_dn_6: 0.36  loss_ce_7: 1.391  loss_mask_7: 0.03612  loss_dice_7: 0.5333  loss_bbox_7: 0.08286  loss_giou_7: 0.4867  loss_ce_dn_7: 0.2548  loss_mask_dn_7: 0.04252  loss_dice_dn_7: 0.5069  loss_bbox_dn_7: 0.04327  loss_giou_dn_7: 0.3565  loss_ce_8: 1.372  loss_mask_8: 0.03804  loss_dice_8: 0.4831  loss_bbox_8: 0.08585  loss_giou_8: 0.4902  loss_ce_dn_8: 0.2434  loss_mask_dn_8: 0.04185  loss_dice_dn_8: 0.5257  loss_bbox_dn_8: 0.04065  loss_giou_dn_8: 0.3605  loss_ce_interm: 1.61  loss_mask_interm: 0.03878  loss_dice_interm: 0.5386  loss_bbox_interm: 0.1388  loss_giou_interm: 0.5536  time: 2.0386  data_time: 0.0618  lr: 1e-05  max_mem: 6620M\n",
            "[05/20 17:22:59 d2.utils.events]:  eta: 1:42:26  iter: 1959  total_loss: 44.22  loss_ce: 1.057  loss_mask: 0.04943  loss_dice: 0.6392  loss_bbox: 0.06912  loss_giou: 0.3775  loss_ce_dn: 0.2102  loss_mask_dn: 0.06123  loss_dice_dn: 0.595  loss_bbox_dn: 0.04762  loss_giou_dn: 0.3007  loss_ce_0: 1.24  loss_mask_0: 0.05729  loss_dice_0: 0.4529  loss_bbox_0: 0.09138  loss_giou_0: 0.4339  loss_ce_dn_0: 0.7977  loss_mask_dn_0: 0.1374  loss_dice_dn_0: 2.398  loss_bbox_dn_0: 0.2465  loss_giou_dn_0: 0.8598  loss_ce_1: 1.3  loss_mask_1: 0.05947  loss_dice_1: 0.6654  loss_bbox_1: 0.08139  loss_giou_1: 0.4034  loss_ce_dn_1: 0.29  loss_mask_dn_1: 0.05915  loss_dice_dn_1: 0.6227  loss_bbox_dn_1: 0.08962  loss_giou_dn_1: 0.3748  loss_ce_2: 1.236  loss_mask_2: 0.05581  loss_dice_2: 0.7694  loss_bbox_2: 0.06786  loss_giou_2: 0.3888  loss_ce_dn_2: 0.2531  loss_mask_dn_2: 0.05982  loss_dice_dn_2: 0.5964  loss_bbox_dn_2: 0.06293  loss_giou_dn_2: 0.3305  loss_ce_3: 1.178  loss_mask_3: 0.05755  loss_dice_3: 0.6061  loss_bbox_3: 0.0636  loss_giou_3: 0.3888  loss_ce_dn_3: 0.2478  loss_mask_dn_3: 0.06018  loss_dice_dn_3: 0.6072  loss_bbox_dn_3: 0.05556  loss_giou_dn_3: 0.3014  loss_ce_4: 1.107  loss_mask_4: 0.05774  loss_dice_4: 0.7011  loss_bbox_4: 0.06249  loss_giou_4: 0.3805  loss_ce_dn_4: 0.2442  loss_mask_dn_4: 0.06267  loss_dice_dn_4: 0.6138  loss_bbox_dn_4: 0.05002  loss_giou_dn_4: 0.2962  loss_ce_5: 1.077  loss_mask_5: 0.05572  loss_dice_5: 0.681  loss_bbox_5: 0.06836  loss_giou_5: 0.373  loss_ce_dn_5: 0.2402  loss_mask_dn_5: 0.06254  loss_dice_dn_5: 0.6029  loss_bbox_dn_5: 0.04978  loss_giou_dn_5: 0.2988  loss_ce_6: 1.124  loss_mask_6: 0.05469  loss_dice_6: 0.5823  loss_bbox_6: 0.06079  loss_giou_6: 0.377  loss_ce_dn_6: 0.2191  loss_mask_dn_6: 0.06094  loss_dice_dn_6: 0.5924  loss_bbox_dn_6: 0.05008  loss_giou_dn_6: 0.3043  loss_ce_7: 1.082  loss_mask_7: 0.06209  loss_dice_7: 0.6163  loss_bbox_7: 0.06693  loss_giou_7: 0.3752  loss_ce_dn_7: 0.2112  loss_mask_dn_7: 0.06279  loss_dice_dn_7: 0.609  loss_bbox_dn_7: 0.04629  loss_giou_dn_7: 0.2995  loss_ce_8: 1.067  loss_mask_8: 0.05379  loss_dice_8: 0.7064  loss_bbox_8: 0.0697  loss_giou_8: 0.3748  loss_ce_dn_8: 0.2167  loss_mask_dn_8: 0.06174  loss_dice_dn_8: 0.6058  loss_bbox_dn_8: 0.04802  loss_giou_dn_8: 0.2994  loss_ce_interm: 1.266  loss_mask_interm: 0.05718  loss_dice_interm: 0.588  loss_bbox_interm: 0.1142  loss_giou_interm: 0.5097  time: 2.0348  data_time: 0.0909  lr: 1e-05  max_mem: 6620M\n",
            "[05/20 17:23:34 d2.utils.events]:  eta: 1:42:07  iter: 1979  total_loss: 51.88  loss_ce: 1.106  loss_mask: 0.03566  loss_dice: 0.8674  loss_bbox: 0.04959  loss_giou: 0.3533  loss_ce_dn: 0.1758  loss_mask_dn: 0.03661  loss_dice_dn: 0.882  loss_bbox_dn: 0.04306  loss_giou_dn: 0.3582  loss_ce_0: 1.321  loss_mask_0: 0.04344  loss_dice_0: 0.9476  loss_bbox_0: 0.06569  loss_giou_0: 0.5558  loss_ce_dn_0: 0.6818  loss_mask_dn_0: 0.1873  loss_dice_dn_0: 3.26  loss_bbox_dn_0: 0.2233  loss_giou_dn_0: 0.8502  loss_ce_1: 1.327  loss_mask_1: 0.04046  loss_dice_1: 0.6931  loss_bbox_1: 0.05385  loss_giou_1: 0.4331  loss_ce_dn_1: 0.2938  loss_mask_dn_1: 0.04321  loss_dice_dn_1: 0.8998  loss_bbox_dn_1: 0.0691  loss_giou_dn_1: 0.4047  loss_ce_2: 1.29  loss_mask_2: 0.03238  loss_dice_2: 0.85  loss_bbox_2: 0.05081  loss_giou_2: 0.4331  loss_ce_dn_2: 0.233  loss_mask_dn_2: 0.04069  loss_dice_dn_2: 0.9254  loss_bbox_dn_2: 0.05575  loss_giou_dn_2: 0.3795  loss_ce_3: 1.21  loss_mask_3: 0.0374  loss_dice_3: 0.7697  loss_bbox_3: 0.04845  loss_giou_3: 0.4001  loss_ce_dn_3: 0.2188  loss_mask_dn_3: 0.0392  loss_dice_dn_3: 0.9388  loss_bbox_dn_3: 0.047  loss_giou_dn_3: 0.3533  loss_ce_4: 1.157  loss_mask_4: 0.03365  loss_dice_4: 0.917  loss_bbox_4: 0.05107  loss_giou_4: 0.3969  loss_ce_dn_4: 0.2041  loss_mask_dn_4: 0.03536  loss_dice_dn_4: 0.86  loss_bbox_dn_4: 0.04654  loss_giou_dn_4: 0.356  loss_ce_5: 1.096  loss_mask_5: 0.03514  loss_dice_5: 0.7687  loss_bbox_5: 0.04952  loss_giou_5: 0.391  loss_ce_dn_5: 0.1944  loss_mask_dn_5: 0.03602  loss_dice_dn_5: 0.8572  loss_bbox_dn_5: 0.04492  loss_giou_dn_5: 0.364  loss_ce_6: 1.088  loss_mask_6: 0.04287  loss_dice_6: 0.7709  loss_bbox_6: 0.05075  loss_giou_6: 0.377  loss_ce_dn_6: 0.19  loss_mask_dn_6: 0.03773  loss_dice_dn_6: 0.8879  loss_bbox_dn_6: 0.04455  loss_giou_dn_6: 0.3671  loss_ce_7: 1.094  loss_mask_7: 0.03674  loss_dice_7: 0.7019  loss_bbox_7: 0.05094  loss_giou_7: 0.356  loss_ce_dn_7: 0.1819  loss_mask_dn_7: 0.03558  loss_dice_dn_7: 0.8834  loss_bbox_dn_7: 0.04395  loss_giou_dn_7: 0.3564  loss_ce_8: 1.132  loss_mask_8: 0.03777  loss_dice_8: 0.8893  loss_bbox_8: 0.05718  loss_giou_8: 0.356  loss_ce_dn_8: 0.1741  loss_mask_dn_8: 0.0382  loss_dice_dn_8: 0.8777  loss_bbox_dn_8: 0.04386  loss_giou_dn_8: 0.3575  loss_ce_interm: 1.183  loss_mask_interm: 0.03904  loss_dice_interm: 0.8411  loss_bbox_interm: 0.09183  loss_giou_interm: 0.5848  time: 2.0320  data_time: 0.0847  lr: 1e-05  max_mem: 6620M\n",
            "[05/20 17:24:07 d2.data.datasets.coco]: Loaded 150 images in COCO format from /content/TACO-expl/data/annotations_off_0_resval.json\n",
            "[05/20 17:24:07 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "[05/20 17:24:07 d2.data.common]: Serializing 150 elements to byte tensors and concatenating them all ...\n",
            "[05/20 17:24:07 d2.data.common]: Serialized dataset takes 0.21 MiB\n",
            "WARNING [05/20 17:24:07 d2.evaluation.coco_evaluation]: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
            "[05/20 17:24:07 d2.evaluation.evaluator]: Start inference on 150 batches\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1066, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1066, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1066, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1066])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 17:24:16 d2.evaluation.evaluator]: Inference done 11/150. Dataloading: 0.0018 s/iter. Inference: 0.2848 s/iter. Eval: 0.4449 s/iter. Total: 0.7315 s/iter. ETA=0:01:41\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 608])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 608])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 608])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1200])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 750])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 17:24:21 d2.evaluation.evaluator]: Inference done 17/150. Dataloading: 0.0034 s/iter. Inference: 0.2867 s/iter. Eval: 0.5011 s/iter. Total: 0.7914 s/iter. ETA=0:01:45\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 750])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 17:24:26 d2.evaluation.evaluator]: Inference done 23/150. Dataloading: 0.0033 s/iter. Inference: 0.3040 s/iter. Eval: 0.5268 s/iter. Total: 0.8346 s/iter. ETA=0:01:45\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([750, 1333])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 750])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([750, 1333])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 750])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 17:24:32 d2.evaluation.evaluator]: Inference done 30/150. Dataloading: 0.0031 s/iter. Inference: 0.3029 s/iter. Eval: 0.5156 s/iter. Total: 0.8219 s/iter. ETA=0:01:38\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 750])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 17:24:38 d2.evaluation.evaluator]: Inference done 37/150. Dataloading: 0.0037 s/iter. Inference: 0.3049 s/iter. Eval: 0.5221 s/iter. Total: 0.8310 s/iter. ETA=0:01:33\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 17:24:44 d2.evaluation.evaluator]: Inference done 43/150. Dataloading: 0.0049 s/iter. Inference: 0.3070 s/iter. Eval: 0.5311 s/iter. Total: 0.8435 s/iter. ETA=0:01:30\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 17:24:49 d2.evaluation.evaluator]: Inference done 50/150. Dataloading: 0.0045 s/iter. Inference: 0.3035 s/iter. Eval: 0.5189 s/iter. Total: 0.8274 s/iter. ETA=0:01:22\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 17:24:54 d2.evaluation.evaluator]: Inference done 57/150. Dataloading: 0.0047 s/iter. Inference: 0.3023 s/iter. Eval: 0.5195 s/iter. Total: 0.8269 s/iter. ETA=0:01:16\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 17:25:00 d2.evaluation.evaluator]: Inference done 63/150. Dataloading: 0.0048 s/iter. Inference: 0.3067 s/iter. Eval: 0.5312 s/iter. Total: 0.8431 s/iter. ETA=0:01:13\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 17:25:06 d2.evaluation.evaluator]: Inference done 70/150. Dataloading: 0.0046 s/iter. Inference: 0.3055 s/iter. Eval: 0.5283 s/iter. Total: 0.8388 s/iter. ETA=0:01:07\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([852, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 17:25:12 d2.evaluation.evaluator]: Inference done 77/150. Dataloading: 0.0044 s/iter. Inference: 0.3036 s/iter. Eval: 0.5261 s/iter. Total: 0.8345 s/iter. ETA=0:01:00\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 17:25:17 d2.evaluation.evaluator]: Inference done 83/150. Dataloading: 0.0044 s/iter. Inference: 0.3040 s/iter. Eval: 0.5304 s/iter. Total: 0.8394 s/iter. ETA=0:00:56\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 17:25:22 d2.evaluation.evaluator]: Inference done 90/150. Dataloading: 0.0043 s/iter. Inference: 0.3022 s/iter. Eval: 0.5245 s/iter. Total: 0.8315 s/iter. ETA=0:00:49\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 17:25:28 d2.evaluation.evaluator]: Inference done 97/150. Dataloading: 0.0044 s/iter. Inference: 0.3013 s/iter. Eval: 0.5243 s/iter. Total: 0.8305 s/iter. ETA=0:00:44\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 17:25:33 d2.evaluation.evaluator]: Inference done 103/150. Dataloading: 0.0043 s/iter. Inference: 0.3022 s/iter. Eval: 0.5270 s/iter. Total: 0.8340 s/iter. ETA=0:00:39\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 17:25:38 d2.evaluation.evaluator]: Inference done 110/150. Dataloading: 0.0042 s/iter. Inference: 0.3004 s/iter. Eval: 0.5217 s/iter. Total: 0.8268 s/iter. ETA=0:00:33\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 17:25:44 d2.evaluation.evaluator]: Inference done 117/150. Dataloading: 0.0043 s/iter. Inference: 0.2998 s/iter. Eval: 0.5219 s/iter. Total: 0.8264 s/iter. ETA=0:00:27\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 17:25:50 d2.evaluation.evaluator]: Inference done 123/150. Dataloading: 0.0044 s/iter. Inference: 0.3010 s/iter. Eval: 0.5263 s/iter. Total: 0.8321 s/iter. ETA=0:00:22\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 17:25:55 d2.evaluation.evaluator]: Inference done 130/150. Dataloading: 0.0043 s/iter. Inference: 0.2998 s/iter. Eval: 0.5230 s/iter. Total: 0.8275 s/iter. ETA=0:00:16\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 750])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 750])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 17:26:01 d2.evaluation.evaluator]: Inference done 137/150. Dataloading: 0.0042 s/iter. Inference: 0.2994 s/iter. Eval: 0.5236 s/iter. Total: 0.8277 s/iter. ETA=0:00:10\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 750])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 17:26:06 d2.evaluation.evaluator]: Inference done 143/150. Dataloading: 0.0043 s/iter. Inference: 0.3006 s/iter. Eval: 0.5277 s/iter. Total: 0.8330 s/iter. ETA=0:00:05\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 608])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 608])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 608])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 608])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 17:26:11 d2.evaluation.evaluator]: Inference done 150/150. Dataloading: 0.0042 s/iter. Inference: 0.2996 s/iter. Eval: 0.5236 s/iter. Total: 0.8279 s/iter. ETA=0:00:00\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[05/20 17:26:12 d2.evaluation.evaluator]: Total inference time: 0:02:00.112747 (0.828364 s / iter per device, on 1 devices)\n",
            "[05/20 17:26:12 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:43 (0.299587 s / iter per device, on 1 devices)\n",
            "[05/20 17:26:12 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...\n",
            "[05/20 17:26:12 d2.evaluation.coco_evaluation]: Saving results to /content/output/chkpt/inference/coco_instances_results.json\n",
            "[05/20 17:26:12 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "[05/20 17:26:12 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*\n",
            "[05/20 17:26:12 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.14 seconds.\n",
            "[05/20 17:26:12 d2.evaluation.fast_eval_api]: Accumulating evaluation results...\n",
            "[05/20 17:26:12 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.06 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.242\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.405\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.246\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.058\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.245\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.408\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.321\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.433\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.448\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.109\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.478\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.800\n",
            "[05/20 17:26:12 d2.evaluation.coco_evaluation]: Evaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
            "| 24.203 | 40.518 | 24.614 | 5.766 | 24.469 | 40.761 |\n",
            "[05/20 17:26:12 d2.evaluation.coco_evaluation]: Per-category bbox AP: \n",
            "| category   | AP     | category              | AP     | category   | AP     |\n",
            "|:-----------|:-------|:----------------------|:-------|:-----------|:-------|\n",
            "| Bottle     | 53.000 | Bottle cap            | 12.139 | Can        | 40.311 |\n",
            "| Cigarette  | 1.606  | Cup                   | 30.381 | Lid        | 35.482 |\n",
            "| Other      | 20.402 | Plastic bag & wrapper | 21.578 | Pop tab    | 11.138 |\n",
            "| Straw      | 15.990 |                       |        |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.16s)\n",
            "creating index...\n",
            "index created!\n",
            "[05/20 17:26:13 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*\n",
            "[05/20 17:26:13 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.22 seconds.\n",
            "[05/20 17:26:13 d2.evaluation.fast_eval_api]: Accumulating evaluation results...\n",
            "[05/20 17:26:13 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.06 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.374\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.486\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.380\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.196\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.452\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.509\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.446\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.639\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.655\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.403\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.750\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.835\n",
            "[05/20 17:26:13 d2.evaluation.coco_evaluation]: Evaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 37.395 | 48.628 | 37.965 | 19.627 | 45.186 | 50.924 |\n",
            "[05/20 17:26:13 d2.evaluation.coco_evaluation]: Per-category segm AP: \n",
            "| category   | AP     | category              | AP     | category   | AP     |\n",
            "|:-----------|:-------|:----------------------|:-------|:-----------|:-------|\n",
            "| Bottle     | 71.903 | Bottle cap            | 38.823 | Can        | 52.057 |\n",
            "| Cigarette  | 19.213 | Cup                   | 42.181 | Lid        | 43.736 |\n",
            "| Other      | 29.384 | Plastic bag & wrapper | 34.509 | Pop tab    | 23.815 |\n",
            "| Straw      | 18.330 |                       |        |            |        |\n",
            "[05/20 17:26:13 d2.engine.defaults]: Evaluation results for TACO_val in csv format:\n",
            "[05/20 17:26:13 d2.evaluation.testing]: copypaste: Task: bbox\n",
            "[05/20 17:26:13 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl\n",
            "[05/20 17:26:13 d2.evaluation.testing]: copypaste: 24.2027,40.5176,24.6135,5.7657,24.4695,40.7606\n",
            "[05/20 17:26:13 d2.evaluation.testing]: copypaste: Task: segm\n",
            "[05/20 17:26:13 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl\n",
            "[05/20 17:26:13 d2.evaluation.testing]: copypaste: 37.3950,48.6283,37.9653,19.6272,45.1855,50.9242\n",
            "[05/20 17:26:13 d2.utils.events]:  eta: 1:41:44  iter: 1999  total_loss: 58.57  loss_ce: 1.225  loss_mask: 0.02671  loss_dice: 0.8044  loss_bbox: 0.08144  loss_giou: 0.5209  loss_ce_dn: 0.1976  loss_mask_dn: 0.02242  loss_dice_dn: 0.6551  loss_bbox_dn: 0.03261  loss_giou_dn: 0.4012  loss_ce_0: 1.359  loss_mask_0: 0.02863  loss_dice_0: 0.7896  loss_bbox_0: 0.1152  loss_giou_0: 0.7616  loss_ce_dn_0: 0.7955  loss_mask_dn_0: 0.08464  loss_dice_dn_0: 2.539  loss_bbox_dn_0: 0.1881  loss_giou_dn_0: 0.8577  loss_ce_1: 1.408  loss_mask_1: 0.02628  loss_dice_1: 0.8268  loss_bbox_1: 0.09027  loss_giou_1: 0.6573  loss_ce_dn_1: 0.3072  loss_mask_dn_1: 0.02158  loss_dice_dn_1: 0.7171  loss_bbox_dn_1: 0.05615  loss_giou_dn_1: 0.4579  loss_ce_2: 1.361  loss_mask_2: 0.03179  loss_dice_2: 0.9472  loss_bbox_2: 0.07755  loss_giou_2: 0.6181  loss_ce_dn_2: 0.2497  loss_mask_dn_2: 0.01724  loss_dice_dn_2: 0.7291  loss_bbox_dn_2: 0.03742  loss_giou_dn_2: 0.4232  loss_ce_3: 1.307  loss_mask_3: 0.02533  loss_dice_3: 1.009  loss_bbox_3: 0.07554  loss_giou_3: 0.6683  loss_ce_dn_3: 0.2436  loss_mask_dn_3: 0.01866  loss_dice_dn_3: 0.6123  loss_bbox_dn_3: 0.03198  loss_giou_dn_3: 0.4093  loss_ce_4: 1.172  loss_mask_4: 0.02971  loss_dice_4: 0.8451  loss_bbox_4: 0.08116  loss_giou_4: 0.5435  loss_ce_dn_4: 0.2117  loss_mask_dn_4: 0.02019  loss_dice_dn_4: 0.6026  loss_bbox_dn_4: 0.0325  loss_giou_dn_4: 0.3978  loss_ce_5: 1.19  loss_mask_5: 0.02749  loss_dice_5: 0.7524  loss_bbox_5: 0.08175  loss_giou_5: 0.5353  loss_ce_dn_5: 0.196  loss_mask_dn_5: 0.01892  loss_dice_dn_5: 0.6221  loss_bbox_dn_5: 0.03334  loss_giou_dn_5: 0.3961  loss_ce_6: 1.223  loss_mask_6: 0.03448  loss_dice_6: 0.8765  loss_bbox_6: 0.08395  loss_giou_6: 0.5744  loss_ce_dn_6: 0.1961  loss_mask_dn_6: 0.02022  loss_dice_dn_6: 0.5697  loss_bbox_dn_6: 0.03339  loss_giou_dn_6: 0.398  loss_ce_7: 1.197  loss_mask_7: 0.03002  loss_dice_7: 0.6057  loss_bbox_7: 0.07914  loss_giou_7: 0.5207  loss_ce_dn_7: 0.1991  loss_mask_dn_7: 0.02057  loss_dice_dn_7: 0.6222  loss_bbox_dn_7: 0.0337  loss_giou_dn_7: 0.4017  loss_ce_8: 1.232  loss_mask_8: 0.03004  loss_dice_8: 0.7527  loss_bbox_8: 0.08341  loss_giou_8: 0.5198  loss_ce_dn_8: 0.1989  loss_mask_dn_8: 0.0228  loss_dice_dn_8: 0.6504  loss_bbox_dn_8: 0.03354  loss_giou_dn_8: 0.4014  loss_ce_interm: 1.447  loss_mask_interm: 0.02694  loss_dice_interm: 1.044  loss_bbox_interm: 0.1042  loss_giou_interm: 0.5064  time: 2.0282  data_time: 0.0616  lr: 1e-05  max_mem: 6620M\n",
            "[05/20 17:26:48 d2.utils.events]:  eta: 1:40:54  iter: 2019  total_loss: 55.85  loss_ce: 1.071  loss_mask: 0.03945  loss_dice: 0.8032  loss_bbox: 0.08627  loss_giou: 0.6126  loss_ce_dn: 0.18  loss_mask_dn: 0.0407  loss_dice_dn: 0.8166  loss_bbox_dn: 0.0601  loss_giou_dn: 0.4212  loss_ce_0: 1.328  loss_mask_0: 0.04571  loss_dice_0: 1.033  loss_bbox_0: 0.107  loss_giou_0: 0.6756  loss_ce_dn_0: 0.7713  loss_mask_dn_0: 0.1574  loss_dice_dn_0: 3.305  loss_bbox_dn_0: 0.2472  loss_giou_dn_0: 0.8542  loss_ce_1: 1.396  loss_mask_1: 0.0454  loss_dice_1: 0.9087  loss_bbox_1: 0.09003  loss_giou_1: 0.5883  loss_ce_dn_1: 0.2873  loss_mask_dn_1: 0.04206  loss_dice_dn_1: 0.9028  loss_bbox_dn_1: 0.08486  loss_giou_dn_1: 0.5065  loss_ce_2: 1.312  loss_mask_2: 0.04397  loss_dice_2: 0.965  loss_bbox_2: 0.09122  loss_giou_2: 0.5559  loss_ce_dn_2: 0.2433  loss_mask_dn_2: 0.03979  loss_dice_dn_2: 0.8446  loss_bbox_dn_2: 0.07027  loss_giou_dn_2: 0.4635  loss_ce_3: 1.13  loss_mask_3: 0.04606  loss_dice_3: 0.9599  loss_bbox_3: 0.08245  loss_giou_3: 0.5472  loss_ce_dn_3: 0.2266  loss_mask_dn_3: 0.03911  loss_dice_dn_3: 0.8009  loss_bbox_dn_3: 0.06375  loss_giou_dn_3: 0.4429  loss_ce_4: 1.061  loss_mask_4: 0.04396  loss_dice_4: 0.8328  loss_bbox_4: 0.08655  loss_giou_4: 0.6282  loss_ce_dn_4: 0.2176  loss_mask_dn_4: 0.03891  loss_dice_dn_4: 0.7974  loss_bbox_dn_4: 0.06397  loss_giou_dn_4: 0.4339  loss_ce_5: 1.134  loss_mask_5: 0.04051  loss_dice_5: 0.7541  loss_bbox_5: 0.08921  loss_giou_5: 0.5765  loss_ce_dn_5: 0.2051  loss_mask_dn_5: 0.04088  loss_dice_dn_5: 0.7816  loss_bbox_dn_5: 0.06173  loss_giou_dn_5: 0.4228  loss_ce_6: 1.055  loss_mask_6: 0.04046  loss_dice_6: 0.8285  loss_bbox_6: 0.08429  loss_giou_6: 0.6055  loss_ce_dn_6: 0.1897  loss_mask_dn_6: 0.04208  loss_dice_dn_6: 0.7787  loss_bbox_dn_6: 0.06168  loss_giou_dn_6: 0.4218  loss_ce_7: 1.089  loss_mask_7: 0.03963  loss_dice_7: 0.9069  loss_bbox_7: 0.08764  loss_giou_7: 0.6133  loss_ce_dn_7: 0.184  loss_mask_dn_7: 0.03955  loss_dice_dn_7: 0.8271  loss_bbox_dn_7: 0.05964  loss_giou_dn_7: 0.4252  loss_ce_8: 1.085  loss_mask_8: 0.03896  loss_dice_8: 0.8028  loss_bbox_8: 0.08595  loss_giou_8: 0.6132  loss_ce_dn_8: 0.1823  loss_mask_dn_8: 0.04064  loss_dice_dn_8: 0.8076  loss_bbox_dn_8: 0.06062  loss_giou_dn_8: 0.4248  loss_ce_interm: 1.383  loss_mask_interm: 0.04288  loss_dice_interm: 0.9631  loss_bbox_interm: 0.09387  loss_giou_interm: 0.6829  time: 2.0250  data_time: 0.0546  lr: 1e-05  max_mem: 6620M\n",
            "[05/20 17:27:21 d2.utils.events]:  eta: 1:40:18  iter: 2039  total_loss: 41.79  loss_ce: 1.008  loss_mask: 0.02192  loss_dice: 0.5712  loss_bbox: 0.04689  loss_giou: 0.3431  loss_ce_dn: 0.2332  loss_mask_dn: 0.02141  loss_dice_dn: 0.4732  loss_bbox_dn: 0.03297  loss_giou_dn: 0.2757  loss_ce_0: 1.254  loss_mask_0: 0.02558  loss_dice_0: 0.4791  loss_bbox_0: 0.06089  loss_giou_0: 0.4858  loss_ce_dn_0: 0.7554  loss_mask_dn_0: 0.1042  loss_dice_dn_0: 2.626  loss_bbox_dn_0: 0.2087  loss_giou_dn_0: 0.8611  loss_ce_1: 1.386  loss_mask_1: 0.02486  loss_dice_1: 0.5786  loss_bbox_1: 0.04977  loss_giou_1: 0.3546  loss_ce_dn_1: 0.3049  loss_mask_dn_1: 0.02397  loss_dice_dn_1: 0.5391  loss_bbox_dn_1: 0.05696  loss_giou_dn_1: 0.3709  loss_ce_2: 1.181  loss_mask_2: 0.02481  loss_dice_2: 0.5533  loss_bbox_2: 0.04866  loss_giou_2: 0.3496  loss_ce_dn_2: 0.2781  loss_mask_dn_2: 0.01941  loss_dice_dn_2: 0.4641  loss_bbox_dn_2: 0.04356  loss_giou_dn_2: 0.3165  loss_ce_3: 1.03  loss_mask_3: 0.02345  loss_dice_3: 0.4732  loss_bbox_3: 0.04922  loss_giou_3: 0.3699  loss_ce_dn_3: 0.2476  loss_mask_dn_3: 0.01986  loss_dice_dn_3: 0.4766  loss_bbox_dn_3: 0.04087  loss_giou_dn_3: 0.2854  loss_ce_4: 1.014  loss_mask_4: 0.02057  loss_dice_4: 0.5696  loss_bbox_4: 0.04872  loss_giou_4: 0.3603  loss_ce_dn_4: 0.23  loss_mask_dn_4: 0.01941  loss_dice_dn_4: 0.4652  loss_bbox_dn_4: 0.03926  loss_giou_dn_4: 0.2751  loss_ce_5: 1.037  loss_mask_5: 0.02035  loss_dice_5: 0.4895  loss_bbox_5: 0.04597  loss_giou_5: 0.338  loss_ce_dn_5: 0.2282  loss_mask_dn_5: 0.02015  loss_dice_dn_5: 0.4625  loss_bbox_dn_5: 0.035  loss_giou_dn_5: 0.2762  loss_ce_6: 0.9685  loss_mask_6: 0.02403  loss_dice_6: 0.4618  loss_bbox_6: 0.04693  loss_giou_6: 0.3448  loss_ce_dn_6: 0.2433  loss_mask_dn_6: 0.02013  loss_dice_dn_6: 0.4493  loss_bbox_dn_6: 0.03396  loss_giou_dn_6: 0.2723  loss_ce_7: 0.9878  loss_mask_7: 0.02068  loss_dice_7: 0.4954  loss_bbox_7: 0.04686  loss_giou_7: 0.3327  loss_ce_dn_7: 0.2394  loss_mask_dn_7: 0.0205  loss_dice_dn_7: 0.5004  loss_bbox_dn_7: 0.03264  loss_giou_dn_7: 0.277  loss_ce_8: 0.9293  loss_mask_8: 0.02459  loss_dice_8: 0.5985  loss_bbox_8: 0.04455  loss_giou_8: 0.3748  loss_ce_dn_8: 0.243  loss_mask_dn_8: 0.02147  loss_dice_dn_8: 0.4592  loss_bbox_dn_8: 0.03285  loss_giou_dn_8: 0.2774  loss_ce_interm: 1.327  loss_mask_interm: 0.02005  loss_dice_interm: 0.4858  loss_bbox_interm: 0.06897  loss_giou_interm: 0.4608  time: 2.0216  data_time: 0.0693  lr: 1e-05  max_mem: 6620M\n",
            "[05/20 17:27:57 d2.utils.events]:  eta: 1:39:45  iter: 2059  total_loss: 41.52  loss_ce: 0.9893  loss_mask: 0.04632  loss_dice: 0.6087  loss_bbox: 0.04671  loss_giou: 0.3445  loss_ce_dn: 0.1597  loss_mask_dn: 0.0506  loss_dice_dn: 0.7006  loss_bbox_dn: 0.04199  loss_giou_dn: 0.3353  loss_ce_0: 1.266  loss_mask_0: 0.05201  loss_dice_0: 0.721  loss_bbox_0: 0.06137  loss_giou_0: 0.4417  loss_ce_dn_0: 0.7174  loss_mask_dn_0: 0.114  loss_dice_dn_0: 2.408  loss_bbox_dn_0: 0.3288  loss_giou_dn_0: 0.848  loss_ce_1: 1.264  loss_mask_1: 0.05388  loss_dice_1: 0.6621  loss_bbox_1: 0.05158  loss_giou_1: 0.359  loss_ce_dn_1: 0.2686  loss_mask_dn_1: 0.05385  loss_dice_dn_1: 0.7836  loss_bbox_dn_1: 0.07022  loss_giou_dn_1: 0.4274  loss_ce_2: 1.025  loss_mask_2: 0.04977  loss_dice_2: 0.6002  loss_bbox_2: 0.05025  loss_giou_2: 0.359  loss_ce_dn_2: 0.2231  loss_mask_dn_2: 0.04544  loss_dice_dn_2: 0.7198  loss_bbox_dn_2: 0.04985  loss_giou_dn_2: 0.349  loss_ce_3: 0.8619  loss_mask_3: 0.04372  loss_dice_3: 0.6595  loss_bbox_3: 0.05227  loss_giou_3: 0.3594  loss_ce_dn_3: 0.1955  loss_mask_dn_3: 0.04659  loss_dice_dn_3: 0.6898  loss_bbox_dn_3: 0.0449  loss_giou_dn_3: 0.3439  loss_ce_4: 0.8771  loss_mask_4: 0.04408  loss_dice_4: 0.6499  loss_bbox_4: 0.05077  loss_giou_4: 0.3673  loss_ce_dn_4: 0.1799  loss_mask_dn_4: 0.04846  loss_dice_dn_4: 0.7126  loss_bbox_dn_4: 0.04192  loss_giou_dn_4: 0.3387  loss_ce_5: 0.898  loss_mask_5: 0.04291  loss_dice_5: 0.7243  loss_bbox_5: 0.04643  loss_giou_5: 0.3568  loss_ce_dn_5: 0.1748  loss_mask_dn_5: 0.04601  loss_dice_dn_5: 0.6683  loss_bbox_dn_5: 0.04114  loss_giou_dn_5: 0.3412  loss_ce_6: 0.8686  loss_mask_6: 0.04598  loss_dice_6: 0.6347  loss_bbox_6: 0.04689  loss_giou_6: 0.3424  loss_ce_dn_6: 0.1716  loss_mask_dn_6: 0.04688  loss_dice_dn_6: 0.6701  loss_bbox_dn_6: 0.0415  loss_giou_dn_6: 0.3386  loss_ce_7: 0.8929  loss_mask_7: 0.0533  loss_dice_7: 0.7477  loss_bbox_7: 0.04862  loss_giou_7: 0.3576  loss_ce_dn_7: 0.1628  loss_mask_dn_7: 0.04901  loss_dice_dn_7: 0.7122  loss_bbox_dn_7: 0.04185  loss_giou_dn_7: 0.3318  loss_ce_8: 0.88  loss_mask_8: 0.0516  loss_dice_8: 0.6375  loss_bbox_8: 0.0471  loss_giou_8: 0.3606  loss_ce_dn_8: 0.1644  loss_mask_dn_8: 0.04873  loss_dice_dn_8: 0.7257  loss_bbox_dn_8: 0.04248  loss_giou_dn_8: 0.3348  loss_ce_interm: 1.252  loss_mask_interm: 0.04239  loss_dice_interm: 0.5259  loss_bbox_interm: 0.08045  loss_giou_interm: 0.5111  time: 2.0191  data_time: 0.0922  lr: 1e-05  max_mem: 6620M\n",
            "[05/20 17:28:31 d2.utils.events]:  eta: 1:39:13  iter: 2079  total_loss: 40.97  loss_ce: 1.032  loss_mask: 0.02823  loss_dice: 0.5742  loss_bbox: 0.04082  loss_giou: 0.3486  loss_ce_dn: 0.1996  loss_mask_dn: 0.03549  loss_dice_dn: 0.5809  loss_bbox_dn: 0.03984  loss_giou_dn: 0.2625  loss_ce_0: 1.304  loss_mask_0: 0.02944  loss_dice_0: 0.6328  loss_bbox_0: 0.05777  loss_giou_0: 0.4717  loss_ce_dn_0: 0.6959  loss_mask_dn_0: 0.2486  loss_dice_dn_0: 2.885  loss_bbox_dn_0: 0.2798  loss_giou_dn_0: 0.8608  loss_ce_1: 1.289  loss_mask_1: 0.0291  loss_dice_1: 0.5883  loss_bbox_1: 0.05407  loss_giou_1: 0.3906  loss_ce_dn_1: 0.3124  loss_mask_dn_1: 0.03134  loss_dice_dn_1: 0.5897  loss_bbox_dn_1: 0.06608  loss_giou_dn_1: 0.3561  loss_ce_2: 1.243  loss_mask_2: 0.02984  loss_dice_2: 0.6083  loss_bbox_2: 0.05565  loss_giou_2: 0.349  loss_ce_dn_2: 0.2753  loss_mask_dn_2: 0.03353  loss_dice_dn_2: 0.6237  loss_bbox_dn_2: 0.04839  loss_giou_dn_2: 0.2964  loss_ce_3: 1.116  loss_mask_3: 0.02939  loss_dice_3: 0.5718  loss_bbox_3: 0.04637  loss_giou_3: 0.326  loss_ce_dn_3: 0.2519  loss_mask_dn_3: 0.03652  loss_dice_dn_3: 0.643  loss_bbox_dn_3: 0.04094  loss_giou_dn_3: 0.2863  loss_ce_4: 1.024  loss_mask_4: 0.03322  loss_dice_4: 0.6046  loss_bbox_4: 0.04036  loss_giou_4: 0.3361  loss_ce_dn_4: 0.2277  loss_mask_dn_4: 0.03558  loss_dice_dn_4: 0.6718  loss_bbox_dn_4: 0.04115  loss_giou_dn_4: 0.2806  loss_ce_5: 1.045  loss_mask_5: 0.02595  loss_dice_5: 0.5744  loss_bbox_5: 0.04187  loss_giou_5: 0.3361  loss_ce_dn_5: 0.2156  loss_mask_dn_5: 0.03581  loss_dice_dn_5: 0.6625  loss_bbox_dn_5: 0.04036  loss_giou_dn_5: 0.264  loss_ce_6: 0.995  loss_mask_6: 0.03081  loss_dice_6: 0.7214  loss_bbox_6: 0.04667  loss_giou_6: 0.3518  loss_ce_dn_6: 0.2055  loss_mask_dn_6: 0.03461  loss_dice_dn_6: 0.6379  loss_bbox_dn_6: 0.0408  loss_giou_dn_6: 0.2654  loss_ce_7: 0.9947  loss_mask_7: 0.02715  loss_dice_7: 0.5981  loss_bbox_7: 0.03975  loss_giou_7: 0.3459  loss_ce_dn_7: 0.2006  loss_mask_dn_7: 0.03521  loss_dice_dn_7: 0.6449  loss_bbox_dn_7: 0.04004  loss_giou_dn_7: 0.2643  loss_ce_8: 1.072  loss_mask_8: 0.0265  loss_dice_8: 0.6492  loss_bbox_8: 0.05253  loss_giou_8: 0.354  loss_ce_dn_8: 0.2023  loss_mask_dn_8: 0.03394  loss_dice_dn_8: 0.6043  loss_bbox_dn_8: 0.04028  loss_giou_dn_8: 0.2607  loss_ce_interm: 1.342  loss_mask_interm: 0.03705  loss_dice_interm: 0.5388  loss_bbox_interm: 0.08264  loss_giou_interm: 0.4219  time: 2.0164  data_time: 0.0685  lr: 1e-05  max_mem: 6620M\n",
            "[05/20 17:29:06 d2.utils.events]:  eta: 1:38:40  iter: 2099  total_loss: 33.61  loss_ce: 0.9886  loss_mask: 0.04695  loss_dice: 0.46  loss_bbox: 0.04592  loss_giou: 0.2406  loss_ce_dn: 0.2169  loss_mask_dn: 0.05026  loss_dice_dn: 0.4562  loss_bbox_dn: 0.04374  loss_giou_dn: 0.2131  loss_ce_0: 1.327  loss_mask_0: 0.04609  loss_dice_0: 0.4888  loss_bbox_0: 0.05479  loss_giou_0: 0.2593  loss_ce_dn_0: 0.6683  loss_mask_dn_0: 0.4252  loss_dice_dn_0: 2.693  loss_bbox_dn_0: 0.3778  loss_giou_dn_0: 0.8567  loss_ce_1: 1.19  loss_mask_1: 0.04627  loss_dice_1: 0.3937  loss_bbox_1: 0.05369  loss_giou_1: 0.2654  loss_ce_dn_1: 0.3123  loss_mask_dn_1: 0.04758  loss_dice_dn_1: 0.4135  loss_bbox_dn_1: 0.09389  loss_giou_dn_1: 0.3109  loss_ce_2: 1.185  loss_mask_2: 0.04106  loss_dice_2: 0.3752  loss_bbox_2: 0.04867  loss_giou_2: 0.2748  loss_ce_dn_2: 0.2699  loss_mask_dn_2: 0.04461  loss_dice_dn_2: 0.4138  loss_bbox_dn_2: 0.06494  loss_giou_dn_2: 0.2712  loss_ce_3: 1.035  loss_mask_3: 0.04837  loss_dice_3: 0.4204  loss_bbox_3: 0.04721  loss_giou_3: 0.2629  loss_ce_dn_3: 0.2619  loss_mask_dn_3: 0.04533  loss_dice_dn_3: 0.4121  loss_bbox_dn_3: 0.05425  loss_giou_dn_3: 0.2369  loss_ce_4: 0.9745  loss_mask_4: 0.04842  loss_dice_4: 0.3852  loss_bbox_4: 0.05115  loss_giou_4: 0.2576  loss_ce_dn_4: 0.2487  loss_mask_dn_4: 0.04752  loss_dice_dn_4: 0.4092  loss_bbox_dn_4: 0.04762  loss_giou_dn_4: 0.2236  loss_ce_5: 0.9998  loss_mask_5: 0.05063  loss_dice_5: 0.5113  loss_bbox_5: 0.0521  loss_giou_5: 0.2451  loss_ce_dn_5: 0.2327  loss_mask_dn_5: 0.04491  loss_dice_dn_5: 0.4422  loss_bbox_dn_5: 0.04506  loss_giou_dn_5: 0.2163  loss_ce_6: 0.9824  loss_mask_6: 0.04583  loss_dice_6: 0.4533  loss_bbox_6: 0.05187  loss_giou_6: 0.2395  loss_ce_dn_6: 0.2211  loss_mask_dn_6: 0.04686  loss_dice_dn_6: 0.4286  loss_bbox_dn_6: 0.04457  loss_giou_dn_6: 0.2101  loss_ce_7: 0.9978  loss_mask_7: 0.04555  loss_dice_7: 0.4922  loss_bbox_7: 0.04401  loss_giou_7: 0.2328  loss_ce_dn_7: 0.2181  loss_mask_dn_7: 0.04926  loss_dice_dn_7: 0.4581  loss_bbox_dn_7: 0.04344  loss_giou_dn_7: 0.2151  loss_ce_8: 0.9806  loss_mask_8: 0.04766  loss_dice_8: 0.3798  loss_bbox_8: 0.04767  loss_giou_8: 0.2373  loss_ce_dn_8: 0.2273  loss_mask_dn_8: 0.04964  loss_dice_dn_8: 0.4298  loss_bbox_dn_8: 0.04502  loss_giou_dn_8: 0.2141  loss_ce_interm: 1.329  loss_mask_interm: 0.05154  loss_dice_interm: 0.3747  loss_bbox_interm: 0.08588  loss_giou_interm: 0.3543  time: 2.0138  data_time: 0.0825  lr: 1e-05  max_mem: 6620M\n",
            "[05/20 17:29:40 d2.utils.events]:  eta: 1:38:00  iter: 2119  total_loss: 29.86  loss_ce: 0.7714  loss_mask: 0.04306  loss_dice: 0.2559  loss_bbox: 0.04974  loss_giou: 0.2589  loss_ce_dn: 0.1653  loss_mask_dn: 0.04629  loss_dice_dn: 0.2931  loss_bbox_dn: 0.03152  loss_giou_dn: 0.2091  loss_ce_0: 1.047  loss_mask_0: 0.04599  loss_dice_0: 0.3438  loss_bbox_0: 0.05956  loss_giou_0: 0.408  loss_ce_dn_0: 0.8133  loss_mask_dn_0: 0.1713  loss_dice_dn_0: 1.905  loss_bbox_dn_0: 0.3654  loss_giou_dn_0: 0.8522  loss_ce_1: 1.182  loss_mask_1: 0.04871  loss_dice_1: 0.269  loss_bbox_1: 0.0557  loss_giou_1: 0.2881  loss_ce_dn_1: 0.2895  loss_mask_dn_1: 0.04925  loss_dice_dn_1: 0.3046  loss_bbox_dn_1: 0.06628  loss_giou_dn_1: 0.3195  loss_ce_2: 1.02  loss_mask_2: 0.04437  loss_dice_2: 0.2583  loss_bbox_2: 0.05473  loss_giou_2: 0.2948  loss_ce_dn_2: 0.2435  loss_mask_dn_2: 0.04444  loss_dice_dn_2: 0.3098  loss_bbox_dn_2: 0.04739  loss_giou_dn_2: 0.2443  loss_ce_3: 0.856  loss_mask_3: 0.04525  loss_dice_3: 0.2789  loss_bbox_3: 0.04982  loss_giou_3: 0.2449  loss_ce_dn_3: 0.2129  loss_mask_dn_3: 0.04484  loss_dice_dn_3: 0.2811  loss_bbox_dn_3: 0.03814  loss_giou_dn_3: 0.2143  loss_ce_4: 0.7954  loss_mask_4: 0.04488  loss_dice_4: 0.2947  loss_bbox_4: 0.053  loss_giou_4: 0.2436  loss_ce_dn_4: 0.2032  loss_mask_dn_4: 0.04721  loss_dice_dn_4: 0.29  loss_bbox_dn_4: 0.03558  loss_giou_dn_4: 0.2041  loss_ce_5: 0.7803  loss_mask_5: 0.04365  loss_dice_5: 0.274  loss_bbox_5: 0.04999  loss_giou_5: 0.2321  loss_ce_dn_5: 0.1934  loss_mask_dn_5: 0.04863  loss_dice_dn_5: 0.2964  loss_bbox_dn_5: 0.03382  loss_giou_dn_5: 0.2061  loss_ce_6: 0.779  loss_mask_6: 0.0441  loss_dice_6: 0.2552  loss_bbox_6: 0.05309  loss_giou_6: 0.2455  loss_ce_dn_6: 0.1814  loss_mask_dn_6: 0.04735  loss_dice_dn_6: 0.292  loss_bbox_dn_6: 0.03353  loss_giou_dn_6: 0.2019  loss_ce_7: 0.7713  loss_mask_7: 0.04568  loss_dice_7: 0.2699  loss_bbox_7: 0.04836  loss_giou_7: 0.2503  loss_ce_dn_7: 0.1646  loss_mask_dn_7: 0.04693  loss_dice_dn_7: 0.2963  loss_bbox_dn_7: 0.03281  loss_giou_dn_7: 0.2045  loss_ce_8: 0.7721  loss_mask_8: 0.04505  loss_dice_8: 0.3131  loss_bbox_8: 0.04849  loss_giou_8: 0.2624  loss_ce_dn_8: 0.1631  loss_mask_dn_8: 0.04614  loss_dice_dn_8: 0.2701  loss_bbox_dn_8: 0.03152  loss_giou_dn_8: 0.2149  loss_ce_interm: 1.047  loss_mask_interm: 0.04243  loss_dice_interm: 0.271  loss_bbox_interm: 0.08532  loss_giou_interm: 0.3492  time: 2.0104  data_time: 0.0302  lr: 1e-06  max_mem: 6620M\n",
            "[05/20 17:30:14 d2.utils.events]:  eta: 1:37:17  iter: 2139  total_loss: 41.37  loss_ce: 0.9099  loss_mask: 0.03866  loss_dice: 0.6194  loss_bbox: 0.04341  loss_giou: 0.3912  loss_ce_dn: 0.1961  loss_mask_dn: 0.03164  loss_dice_dn: 0.7338  loss_bbox_dn: 0.03731  loss_giou_dn: 0.2876  loss_ce_0: 1.168  loss_mask_0: 0.0385  loss_dice_0: 0.646  loss_bbox_0: 0.1012  loss_giou_0: 0.5498  loss_ce_dn_0: 0.8107  loss_mask_dn_0: 0.09041  loss_dice_dn_0: 2.472  loss_bbox_dn_0: 0.2338  loss_giou_dn_0: 0.8553  loss_ce_1: 1.09  loss_mask_1: 0.04175  loss_dice_1: 0.6412  loss_bbox_1: 0.06843  loss_giou_1: 0.4411  loss_ce_dn_1: 0.2792  loss_mask_dn_1: 0.03045  loss_dice_dn_1: 0.7367  loss_bbox_dn_1: 0.06395  loss_giou_dn_1: 0.3636  loss_ce_2: 1.202  loss_mask_2: 0.04584  loss_dice_2: 0.6678  loss_bbox_2: 0.05725  loss_giou_2: 0.4138  loss_ce_dn_2: 0.2447  loss_mask_dn_2: 0.03023  loss_dice_dn_2: 0.7456  loss_bbox_dn_2: 0.04927  loss_giou_dn_2: 0.3276  loss_ce_3: 0.9943  loss_mask_3: 0.04025  loss_dice_3: 0.6594  loss_bbox_3: 0.05715  loss_giou_3: 0.3863  loss_ce_dn_3: 0.2225  loss_mask_dn_3: 0.03226  loss_dice_dn_3: 0.7768  loss_bbox_dn_3: 0.04291  loss_giou_dn_3: 0.2935  loss_ce_4: 0.9734  loss_mask_4: 0.03283  loss_dice_4: 0.619  loss_bbox_4: 0.05224  loss_giou_4: 0.361  loss_ce_dn_4: 0.1939  loss_mask_dn_4: 0.02804  loss_dice_dn_4: 0.826  loss_bbox_dn_4: 0.04206  loss_giou_dn_4: 0.2972  loss_ce_5: 0.9257  loss_mask_5: 0.04135  loss_dice_5: 0.7701  loss_bbox_5: 0.04728  loss_giou_5: 0.3401  loss_ce_dn_5: 0.2005  loss_mask_dn_5: 0.0285  loss_dice_dn_5: 0.7565  loss_bbox_dn_5: 0.03965  loss_giou_dn_5: 0.2842  loss_ce_6: 0.9778  loss_mask_6: 0.03795  loss_dice_6: 0.579  loss_bbox_6: 0.04747  loss_giou_6: 0.3738  loss_ce_dn_6: 0.1987  loss_mask_dn_6: 0.02926  loss_dice_dn_6: 0.7038  loss_bbox_dn_6: 0.03962  loss_giou_dn_6: 0.2972  loss_ce_7: 1.072  loss_mask_7: 0.04051  loss_dice_7: 0.6534  loss_bbox_7: 0.04486  loss_giou_7: 0.3954  loss_ce_dn_7: 0.1897  loss_mask_dn_7: 0.02949  loss_dice_dn_7: 0.7669  loss_bbox_dn_7: 0.03875  loss_giou_dn_7: 0.2888  loss_ce_8: 0.954  loss_mask_8: 0.04332  loss_dice_8: 0.6761  loss_bbox_8: 0.04314  loss_giou_8: 0.348  loss_ce_dn_8: 0.1933  loss_mask_dn_8: 0.03006  loss_dice_dn_8: 0.744  loss_bbox_dn_8: 0.03867  loss_giou_dn_8: 0.2885  loss_ce_interm: 1.19  loss_mask_interm: 0.03306  loss_dice_interm: 0.5874  loss_bbox_interm: 0.08908  loss_giou_interm: 0.388  time: 2.0077  data_time: 0.0975  lr: 1e-06  max_mem: 6620M\n",
            "[05/20 17:30:48 d2.utils.events]:  eta: 1:36:44  iter: 2159  total_loss: 47.38  loss_ce: 1.048  loss_mask: 0.0344  loss_dice: 0.7364  loss_bbox: 0.05214  loss_giou: 0.3773  loss_ce_dn: 0.2022  loss_mask_dn: 0.03698  loss_dice_dn: 0.5951  loss_bbox_dn: 0.04132  loss_giou_dn: 0.3387  loss_ce_0: 1.222  loss_mask_0: 0.04556  loss_dice_0: 0.7524  loss_bbox_0: 0.08066  loss_giou_0: 0.5424  loss_ce_dn_0: 0.8005  loss_mask_dn_0: 0.1174  loss_dice_dn_0: 2.668  loss_bbox_dn_0: 0.2082  loss_giou_dn_0: 0.8593  loss_ce_1: 1.237  loss_mask_1: 0.04301  loss_dice_1: 0.6997  loss_bbox_1: 0.06391  loss_giou_1: 0.4348  loss_ce_dn_1: 0.2896  loss_mask_dn_1: 0.03659  loss_dice_dn_1: 0.6232  loss_bbox_dn_1: 0.06315  loss_giou_dn_1: 0.4063  loss_ce_2: 1.264  loss_mask_2: 0.03982  loss_dice_2: 0.6652  loss_bbox_2: 0.06208  loss_giou_2: 0.4101  loss_ce_dn_2: 0.2407  loss_mask_dn_2: 0.03527  loss_dice_dn_2: 0.5961  loss_bbox_dn_2: 0.04734  loss_giou_dn_2: 0.3406  loss_ce_3: 1.192  loss_mask_3: 0.02713  loss_dice_3: 0.6463  loss_bbox_3: 0.05371  loss_giou_3: 0.4174  loss_ce_dn_3: 0.2074  loss_mask_dn_3: 0.0381  loss_dice_dn_3: 0.5931  loss_bbox_dn_3: 0.04687  loss_giou_dn_3: 0.3375  loss_ce_4: 1.094  loss_mask_4: 0.03513  loss_dice_4: 0.6755  loss_bbox_4: 0.05851  loss_giou_4: 0.3792  loss_ce_dn_4: 0.2035  loss_mask_dn_4: 0.03652  loss_dice_dn_4: 0.5931  loss_bbox_dn_4: 0.04433  loss_giou_dn_4: 0.327  loss_ce_5: 1.054  loss_mask_5: 0.0368  loss_dice_5: 0.6391  loss_bbox_5: 0.05439  loss_giou_5: 0.4111  loss_ce_dn_5: 0.2057  loss_mask_dn_5: 0.03514  loss_dice_dn_5: 0.6039  loss_bbox_dn_5: 0.04236  loss_giou_dn_5: 0.3329  loss_ce_6: 1.067  loss_mask_6: 0.05004  loss_dice_6: 0.6288  loss_bbox_6: 0.05324  loss_giou_6: 0.3971  loss_ce_dn_6: 0.2108  loss_mask_dn_6: 0.03603  loss_dice_dn_6: 0.5955  loss_bbox_dn_6: 0.04274  loss_giou_dn_6: 0.3354  loss_ce_7: 1.104  loss_mask_7: 0.03841  loss_dice_7: 0.6685  loss_bbox_7: 0.05739  loss_giou_7: 0.3829  loss_ce_dn_7: 0.2082  loss_mask_dn_7: 0.03591  loss_dice_dn_7: 0.5922  loss_bbox_dn_7: 0.04183  loss_giou_dn_7: 0.336  loss_ce_8: 1.071  loss_mask_8: 0.04149  loss_dice_8: 0.6708  loss_bbox_8: 0.06166  loss_giou_8: 0.3804  loss_ce_dn_8: 0.2039  loss_mask_dn_8: 0.03583  loss_dice_dn_8: 0.6  loss_bbox_dn_8: 0.0416  loss_giou_dn_8: 0.3334  loss_ce_interm: 1.222  loss_mask_interm: 0.04545  loss_dice_interm: 0.6373  loss_bbox_interm: 0.08663  loss_giou_interm: 0.5158  time: 2.0048  data_time: 0.0981  lr: 1e-06  max_mem: 6620M\n",
            "[05/20 17:31:23 d2.utils.events]:  eta: 1:36:17  iter: 2179  total_loss: 38.23  loss_ce: 1.004  loss_mask: 0.0343  loss_dice: 0.6881  loss_bbox: 0.05453  loss_giou: 0.3058  loss_ce_dn: 0.2034  loss_mask_dn: 0.03655  loss_dice_dn: 0.6092  loss_bbox_dn: 0.03568  loss_giou_dn: 0.2985  loss_ce_0: 1.202  loss_mask_0: 0.04375  loss_dice_0: 0.725  loss_bbox_0: 0.07283  loss_giou_0: 0.5311  loss_ce_dn_0: 0.7114  loss_mask_dn_0: 0.1163  loss_dice_dn_0: 2.602  loss_bbox_dn_0: 0.2424  loss_giou_dn_0: 0.8535  loss_ce_1: 1.245  loss_mask_1: 0.03547  loss_dice_1: 0.6062  loss_bbox_1: 0.07053  loss_giou_1: 0.3674  loss_ce_dn_1: 0.2389  loss_mask_dn_1: 0.03445  loss_dice_dn_1: 0.6532  loss_bbox_dn_1: 0.06517  loss_giou_dn_1: 0.4161  loss_ce_2: 1.165  loss_mask_2: 0.04172  loss_dice_2: 0.6454  loss_bbox_2: 0.06449  loss_giou_2: 0.3224  loss_ce_dn_2: 0.2142  loss_mask_dn_2: 0.03482  loss_dice_dn_2: 0.6512  loss_bbox_dn_2: 0.05001  loss_giou_dn_2: 0.3311  loss_ce_3: 1.095  loss_mask_3: 0.03453  loss_dice_3: 0.7066  loss_bbox_3: 0.06213  loss_giou_3: 0.2785  loss_ce_dn_3: 0.2212  loss_mask_dn_3: 0.0347  loss_dice_dn_3: 0.6421  loss_bbox_dn_3: 0.04401  loss_giou_dn_3: 0.3031  loss_ce_4: 1.02  loss_mask_4: 0.03721  loss_dice_4: 0.6909  loss_bbox_4: 0.05569  loss_giou_4: 0.304  loss_ce_dn_4: 0.2091  loss_mask_dn_4: 0.03466  loss_dice_dn_4: 0.6634  loss_bbox_dn_4: 0.03928  loss_giou_dn_4: 0.3117  loss_ce_5: 1.056  loss_mask_5: 0.03646  loss_dice_5: 0.6915  loss_bbox_5: 0.05592  loss_giou_5: 0.2965  loss_ce_dn_5: 0.203  loss_mask_dn_5: 0.03675  loss_dice_dn_5: 0.6352  loss_bbox_dn_5: 0.03755  loss_giou_dn_5: 0.3081  loss_ce_6: 0.9957  loss_mask_6: 0.04021  loss_dice_6: 0.6789  loss_bbox_6: 0.05628  loss_giou_6: 0.3033  loss_ce_dn_6: 0.2047  loss_mask_dn_6: 0.03498  loss_dice_dn_6: 0.6567  loss_bbox_dn_6: 0.03817  loss_giou_dn_6: 0.3109  loss_ce_7: 1.019  loss_mask_7: 0.03447  loss_dice_7: 0.7442  loss_bbox_7: 0.05562  loss_giou_7: 0.291  loss_ce_dn_7: 0.2054  loss_mask_dn_7: 0.03546  loss_dice_dn_7: 0.6185  loss_bbox_dn_7: 0.03707  loss_giou_dn_7: 0.299  loss_ce_8: 1.016  loss_mask_8: 0.03642  loss_dice_8: 0.6567  loss_bbox_8: 0.05386  loss_giou_8: 0.2834  loss_ce_dn_8: 0.2066  loss_mask_dn_8: 0.03662  loss_dice_dn_8: 0.6235  loss_bbox_dn_8: 0.03528  loss_giou_dn_8: 0.2954  loss_ce_interm: 1.26  loss_mask_interm: 0.0377  loss_dice_interm: 0.7717  loss_bbox_interm: 0.08109  loss_giou_interm: 0.4233  time: 2.0025  data_time: 0.1144  lr: 1e-06  max_mem: 6620M\n",
            "[05/20 17:31:57 d2.utils.events]:  eta: 1:35:39  iter: 2199  total_loss: 45.82  loss_ce: 1.133  loss_mask: 0.02738  loss_dice: 0.7435  loss_bbox: 0.04823  loss_giou: 0.4452  loss_ce_dn: 0.187  loss_mask_dn: 0.02978  loss_dice_dn: 0.5701  loss_bbox_dn: 0.03368  loss_giou_dn: 0.3627  loss_ce_0: 1.375  loss_mask_0: 0.03109  loss_dice_0: 0.8174  loss_bbox_0: 0.0774  loss_giou_0: 0.5728  loss_ce_dn_0: 0.7739  loss_mask_dn_0: 0.1075  loss_dice_dn_0: 2.612  loss_bbox_dn_0: 0.2327  loss_giou_dn_0: 0.8524  loss_ce_1: 1.26  loss_mask_1: 0.03087  loss_dice_1: 0.7259  loss_bbox_1: 0.05821  loss_giou_1: 0.4706  loss_ce_dn_1: 0.2339  loss_mask_dn_1: 0.0279  loss_dice_dn_1: 0.7434  loss_bbox_dn_1: 0.06278  loss_giou_dn_1: 0.4287  loss_ce_2: 1.306  loss_mask_2: 0.02997  loss_dice_2: 0.9615  loss_bbox_2: 0.05412  loss_giou_2: 0.4653  loss_ce_dn_2: 0.2034  loss_mask_dn_2: 0.02622  loss_dice_dn_2: 0.6487  loss_bbox_dn_2: 0.04552  loss_giou_dn_2: 0.3975  loss_ce_3: 1.187  loss_mask_3: 0.03006  loss_dice_3: 0.7182  loss_bbox_3: 0.05505  loss_giou_3: 0.4682  loss_ce_dn_3: 0.1932  loss_mask_dn_3: 0.02862  loss_dice_dn_3: 0.6157  loss_bbox_dn_3: 0.0359  loss_giou_dn_3: 0.3824  loss_ce_4: 1.166  loss_mask_4: 0.02484  loss_dice_4: 0.6176  loss_bbox_4: 0.05648  loss_giou_4: 0.4251  loss_ce_dn_4: 0.2064  loss_mask_dn_4: 0.027  loss_dice_dn_4: 0.6231  loss_bbox_dn_4: 0.03452  loss_giou_dn_4: 0.3652  loss_ce_5: 1.165  loss_mask_5: 0.02935  loss_dice_5: 0.6719  loss_bbox_5: 0.05101  loss_giou_5: 0.3977  loss_ce_dn_5: 0.197  loss_mask_dn_5: 0.0292  loss_dice_dn_5: 0.6629  loss_bbox_dn_5: 0.03378  loss_giou_dn_5: 0.357  loss_ce_6: 1.165  loss_mask_6: 0.03183  loss_dice_6: 0.8334  loss_bbox_6: 0.04848  loss_giou_6: 0.4378  loss_ce_dn_6: 0.1947  loss_mask_dn_6: 0.02844  loss_dice_dn_6: 0.5994  loss_bbox_dn_6: 0.03335  loss_giou_dn_6: 0.3623  loss_ce_7: 1.117  loss_mask_7: 0.02709  loss_dice_7: 0.6725  loss_bbox_7: 0.04703  loss_giou_7: 0.4353  loss_ce_dn_7: 0.1961  loss_mask_dn_7: 0.02906  loss_dice_dn_7: 0.5916  loss_bbox_dn_7: 0.03346  loss_giou_dn_7: 0.3606  loss_ce_8: 1.161  loss_mask_8: 0.0294  loss_dice_8: 0.6523  loss_bbox_8: 0.04788  loss_giou_8: 0.4374  loss_ce_dn_8: 0.1929  loss_mask_dn_8: 0.03043  loss_dice_dn_8: 0.6197  loss_bbox_dn_8: 0.03338  loss_giou_dn_8: 0.359  loss_ce_interm: 1.371  loss_mask_interm: 0.03065  loss_dice_interm: 0.6604  loss_bbox_interm: 0.09742  loss_giou_interm: 0.5212  time: 1.9995  data_time: 0.0756  lr: 1e-06  max_mem: 6620M\n",
            "[05/20 17:32:31 d2.utils.events]:  eta: 1:35:07  iter: 2219  total_loss: 35.82  loss_ce: 1.136  loss_mask: 0.03605  loss_dice: 0.4534  loss_bbox: 0.04144  loss_giou: 0.2606  loss_ce_dn: 0.1724  loss_mask_dn: 0.03551  loss_dice_dn: 0.4818  loss_bbox_dn: 0.04284  loss_giou_dn: 0.2161  loss_ce_0: 1.464  loss_mask_0: 0.04438  loss_dice_0: 0.4677  loss_bbox_0: 0.0396  loss_giou_0: 0.3429  loss_ce_dn_0: 0.6546  loss_mask_dn_0: 0.129  loss_dice_dn_0: 2.542  loss_bbox_dn_0: 0.238  loss_giou_dn_0: 0.8513  loss_ce_1: 1.347  loss_mask_1: 0.03632  loss_dice_1: 0.4779  loss_bbox_1: 0.0367  loss_giou_1: 0.3976  loss_ce_dn_1: 0.2477  loss_mask_dn_1: 0.03408  loss_dice_dn_1: 0.5299  loss_bbox_dn_1: 0.07539  loss_giou_dn_1: 0.3538  loss_ce_2: 1.366  loss_mask_2: 0.03804  loss_dice_2: 0.5368  loss_bbox_2: 0.03874  loss_giou_2: 0.2961  loss_ce_dn_2: 0.2119  loss_mask_dn_2: 0.03375  loss_dice_dn_2: 0.466  loss_bbox_dn_2: 0.05924  loss_giou_dn_2: 0.2945  loss_ce_3: 1.225  loss_mask_3: 0.04041  loss_dice_3: 0.4357  loss_bbox_3: 0.04314  loss_giou_3: 0.2745  loss_ce_dn_3: 0.1941  loss_mask_dn_3: 0.03449  loss_dice_dn_3: 0.4521  loss_bbox_dn_3: 0.05283  loss_giou_dn_3: 0.2612  loss_ce_4: 1.184  loss_mask_4: 0.03406  loss_dice_4: 0.382  loss_bbox_4: 0.04066  loss_giou_4: 0.263  loss_ce_dn_4: 0.1952  loss_mask_dn_4: 0.03467  loss_dice_dn_4: 0.4451  loss_bbox_dn_4: 0.04524  loss_giou_dn_4: 0.2423  loss_ce_5: 1.166  loss_mask_5: 0.03336  loss_dice_5: 0.4324  loss_bbox_5: 0.04273  loss_giou_5: 0.2554  loss_ce_dn_5: 0.1775  loss_mask_dn_5: 0.03411  loss_dice_dn_5: 0.4671  loss_bbox_dn_5: 0.04304  loss_giou_dn_5: 0.222  loss_ce_6: 1.132  loss_mask_6: 0.03991  loss_dice_6: 0.4658  loss_bbox_6: 0.0438  loss_giou_6: 0.2576  loss_ce_dn_6: 0.1739  loss_mask_dn_6: 0.0355  loss_dice_dn_6: 0.4733  loss_bbox_dn_6: 0.0441  loss_giou_dn_6: 0.2273  loss_ce_7: 1.108  loss_mask_7: 0.03306  loss_dice_7: 0.4591  loss_bbox_7: 0.04174  loss_giou_7: 0.2534  loss_ce_dn_7: 0.169  loss_mask_dn_7: 0.03799  loss_dice_dn_7: 0.4739  loss_bbox_dn_7: 0.04467  loss_giou_dn_7: 0.2184  loss_ce_8: 1.134  loss_mask_8: 0.03962  loss_dice_8: 0.4091  loss_bbox_8: 0.04198  loss_giou_8: 0.263  loss_ce_dn_8: 0.1708  loss_mask_dn_8: 0.03643  loss_dice_dn_8: 0.4784  loss_bbox_dn_8: 0.04307  loss_giou_dn_8: 0.2195  loss_ce_interm: 1.394  loss_mask_interm: 0.04139  loss_dice_interm: 0.5294  loss_bbox_interm: 0.1254  loss_giou_interm: 0.41  time: 1.9969  data_time: 0.0791  lr: 1e-06  max_mem: 6620M\n",
            "[05/20 17:33:06 d2.utils.events]:  eta: 1:34:40  iter: 2239  total_loss: 46.84  loss_ce: 1.206  loss_mask: 0.02885  loss_dice: 0.6279  loss_bbox: 0.07692  loss_giou: 0.5195  loss_ce_dn: 0.2629  loss_mask_dn: 0.02966  loss_dice_dn: 0.5614  loss_bbox_dn: 0.04891  loss_giou_dn: 0.394  loss_ce_0: 1.611  loss_mask_0: 0.03515  loss_dice_0: 0.6061  loss_bbox_0: 0.09027  loss_giou_0: 0.55  loss_ce_dn_0: 0.7501  loss_mask_dn_0: 0.1112  loss_dice_dn_0: 2.495  loss_bbox_dn_0: 0.2294  loss_giou_dn_0: 0.8658  loss_ce_1: 1.544  loss_mask_1: 0.03872  loss_dice_1: 0.7019  loss_bbox_1: 0.08972  loss_giou_1: 0.5077  loss_ce_dn_1: 0.3605  loss_mask_dn_1: 0.02948  loss_dice_dn_1: 0.6472  loss_bbox_dn_1: 0.08198  loss_giou_dn_1: 0.4634  loss_ce_2: 1.554  loss_mask_2: 0.03299  loss_dice_2: 0.5353  loss_bbox_2: 0.06899  loss_giou_2: 0.5134  loss_ce_dn_2: 0.349  loss_mask_dn_2: 0.03276  loss_dice_dn_2: 0.599  loss_bbox_dn_2: 0.05889  loss_giou_dn_2: 0.4183  loss_ce_3: 1.451  loss_mask_3: 0.0301  loss_dice_3: 0.6377  loss_bbox_3: 0.06869  loss_giou_3: 0.4508  loss_ce_dn_3: 0.3141  loss_mask_dn_3: 0.03132  loss_dice_dn_3: 0.6121  loss_bbox_dn_3: 0.05208  loss_giou_dn_3: 0.391  loss_ce_4: 1.395  loss_mask_4: 0.02948  loss_dice_4: 0.5589  loss_bbox_4: 0.06832  loss_giou_4: 0.4521  loss_ce_dn_4: 0.3027  loss_mask_dn_4: 0.02709  loss_dice_dn_4: 0.5788  loss_bbox_dn_4: 0.04767  loss_giou_dn_4: 0.384  loss_ce_5: 1.412  loss_mask_5: 0.02995  loss_dice_5: 0.5825  loss_bbox_5: 0.07832  loss_giou_5: 0.4449  loss_ce_dn_5: 0.2985  loss_mask_dn_5: 0.02832  loss_dice_dn_5: 0.5701  loss_bbox_dn_5: 0.04948  loss_giou_dn_5: 0.3891  loss_ce_6: 1.343  loss_mask_6: 0.02662  loss_dice_6: 0.7607  loss_bbox_6: 0.06664  loss_giou_6: 0.4407  loss_ce_dn_6: 0.276  loss_mask_dn_6: 0.02785  loss_dice_dn_6: 0.5658  loss_bbox_dn_6: 0.04844  loss_giou_dn_6: 0.3911  loss_ce_7: 1.339  loss_mask_7: 0.03486  loss_dice_7: 0.7539  loss_bbox_7: 0.06599  loss_giou_7: 0.4486  loss_ce_dn_7: 0.2577  loss_mask_dn_7: 0.02871  loss_dice_dn_7: 0.5713  loss_bbox_dn_7: 0.04819  loss_giou_dn_7: 0.3879  loss_ce_8: 1.272  loss_mask_8: 0.03115  loss_dice_8: 0.6126  loss_bbox_8: 0.06731  loss_giou_8: 0.45  loss_ce_dn_8: 0.2575  loss_mask_dn_8: 0.02984  loss_dice_dn_8: 0.5774  loss_bbox_dn_8: 0.04866  loss_giou_dn_8: 0.3897  loss_ce_interm: 1.492  loss_mask_interm: 0.03113  loss_dice_interm: 0.5304  loss_bbox_interm: 0.102  loss_giou_interm: 0.5534  time: 1.9946  data_time: 0.0743  lr: 1e-06  max_mem: 6620M\n",
            "[05/20 17:33:40 d2.utils.events]:  eta: 1:34:04  iter: 2259  total_loss: 45.38  loss_ce: 1.003  loss_mask: 0.04407  loss_dice: 0.6429  loss_bbox: 0.05281  loss_giou: 0.4248  loss_ce_dn: 0.255  loss_mask_dn: 0.04241  loss_dice_dn: 0.487  loss_bbox_dn: 0.04887  loss_giou_dn: 0.3274  loss_ce_0: 1.242  loss_mask_0: 0.04672  loss_dice_0: 0.8055  loss_bbox_0: 0.06361  loss_giou_0: 0.4786  loss_ce_dn_0: 0.7656  loss_mask_dn_0: 0.1709  loss_dice_dn_0: 2.818  loss_bbox_dn_0: 0.1899  loss_giou_dn_0: 0.8611  loss_ce_1: 1.184  loss_mask_1: 0.04051  loss_dice_1: 0.6055  loss_bbox_1: 0.06062  loss_giou_1: 0.4734  loss_ce_dn_1: 0.2901  loss_mask_dn_1: 0.03721  loss_dice_dn_1: 0.557  loss_bbox_dn_1: 0.0793  loss_giou_dn_1: 0.4343  loss_ce_2: 1.269  loss_mask_2: 0.04243  loss_dice_2: 0.7215  loss_bbox_2: 0.05817  loss_giou_2: 0.468  loss_ce_dn_2: 0.3015  loss_mask_dn_2: 0.04063  loss_dice_dn_2: 0.5941  loss_bbox_dn_2: 0.05442  loss_giou_dn_2: 0.3803  loss_ce_3: 1.107  loss_mask_3: 0.03822  loss_dice_3: 0.5059  loss_bbox_3: 0.05791  loss_giou_3: 0.4579  loss_ce_dn_3: 0.2871  loss_mask_dn_3: 0.04067  loss_dice_dn_3: 0.5193  loss_bbox_dn_3: 0.05336  loss_giou_dn_3: 0.3517  loss_ce_4: 1.061  loss_mask_4: 0.03729  loss_dice_4: 0.511  loss_bbox_4: 0.0583  loss_giou_4: 0.434  loss_ce_dn_4: 0.2719  loss_mask_dn_4: 0.04197  loss_dice_dn_4: 0.5579  loss_bbox_dn_4: 0.04887  loss_giou_dn_4: 0.335  loss_ce_5: 1.043  loss_mask_5: 0.03779  loss_dice_5: 0.4217  loss_bbox_5: 0.05601  loss_giou_5: 0.4352  loss_ce_dn_5: 0.2663  loss_mask_dn_5: 0.03924  loss_dice_dn_5: 0.5259  loss_bbox_dn_5: 0.04819  loss_giou_dn_5: 0.3334  loss_ce_6: 1.052  loss_mask_6: 0.04255  loss_dice_6: 0.5419  loss_bbox_6: 0.05412  loss_giou_6: 0.3979  loss_ce_dn_6: 0.2643  loss_mask_dn_6: 0.04163  loss_dice_dn_6: 0.5135  loss_bbox_dn_6: 0.04764  loss_giou_dn_6: 0.3252  loss_ce_7: 1.059  loss_mask_7: 0.03827  loss_dice_7: 0.5166  loss_bbox_7: 0.05335  loss_giou_7: 0.3984  loss_ce_dn_7: 0.2657  loss_mask_dn_7: 0.04133  loss_dice_dn_7: 0.5427  loss_bbox_dn_7: 0.04757  loss_giou_dn_7: 0.3273  loss_ce_8: 1.006  loss_mask_8: 0.04167  loss_dice_8: 0.6084  loss_bbox_8: 0.05568  loss_giou_8: 0.4308  loss_ce_dn_8: 0.2566  loss_mask_dn_8: 0.04166  loss_dice_dn_8: 0.5392  loss_bbox_dn_8: 0.04841  loss_giou_dn_8: 0.3274  loss_ce_interm: 1.277  loss_mask_interm: 0.04472  loss_dice_interm: 0.4908  loss_bbox_interm: 0.09397  loss_giou_interm: 0.5542  time: 1.9922  data_time: 0.1010  lr: 1e-06  max_mem: 6620M\n",
            "[05/20 17:34:15 d2.utils.events]:  eta: 1:33:32  iter: 2279  total_loss: 46.64  loss_ce: 1.218  loss_mask: 0.02836  loss_dice: 0.7218  loss_bbox: 0.05232  loss_giou: 0.3798  loss_ce_dn: 0.1339  loss_mask_dn: 0.02583  loss_dice_dn: 0.6135  loss_bbox_dn: 0.04081  loss_giou_dn: 0.3049  loss_ce_0: 1.586  loss_mask_0: 0.02894  loss_dice_0: 0.772  loss_bbox_0: 0.06719  loss_giou_0: 0.457  loss_ce_dn_0: 0.7611  loss_mask_dn_0: 0.1462  loss_dice_dn_0: 2.031  loss_bbox_dn_0: 0.217  loss_giou_dn_0: 0.8574  loss_ce_1: 1.582  loss_mask_1: 0.0326  loss_dice_1: 0.6223  loss_bbox_1: 0.0602  loss_giou_1: 0.3787  loss_ce_dn_1: 0.2852  loss_mask_dn_1: 0.03091  loss_dice_dn_1: 0.7153  loss_bbox_dn_1: 0.05763  loss_giou_dn_1: 0.3952  loss_ce_2: 1.345  loss_mask_2: 0.03685  loss_dice_2: 0.7415  loss_bbox_2: 0.05818  loss_giou_2: 0.4187  loss_ce_dn_2: 0.2267  loss_mask_dn_2: 0.02696  loss_dice_dn_2: 0.6453  loss_bbox_dn_2: 0.04732  loss_giou_dn_2: 0.3429  loss_ce_3: 1.408  loss_mask_3: 0.02762  loss_dice_3: 0.6711  loss_bbox_3: 0.05461  loss_giou_3: 0.3324  loss_ce_dn_3: 0.2066  loss_mask_dn_3: 0.02719  loss_dice_dn_3: 0.6234  loss_bbox_dn_3: 0.03923  loss_giou_dn_3: 0.3121  loss_ce_4: 1.364  loss_mask_4: 0.02669  loss_dice_4: 0.7134  loss_bbox_4: 0.05439  loss_giou_4: 0.3657  loss_ce_dn_4: 0.1754  loss_mask_dn_4: 0.0261  loss_dice_dn_4: 0.6217  loss_bbox_dn_4: 0.04043  loss_giou_dn_4: 0.3146  loss_ce_5: 1.263  loss_mask_5: 0.02645  loss_dice_5: 0.5555  loss_bbox_5: 0.05358  loss_giou_5: 0.3702  loss_ce_dn_5: 0.1554  loss_mask_dn_5: 0.02914  loss_dice_dn_5: 0.6324  loss_bbox_dn_5: 0.04169  loss_giou_dn_5: 0.3133  loss_ce_6: 1.188  loss_mask_6: 0.02499  loss_dice_6: 0.6361  loss_bbox_6: 0.05332  loss_giou_6: 0.3717  loss_ce_dn_6: 0.145  loss_mask_dn_6: 0.0255  loss_dice_dn_6: 0.6349  loss_bbox_dn_6: 0.04084  loss_giou_dn_6: 0.3117  loss_ce_7: 1.204  loss_mask_7: 0.02644  loss_dice_7: 0.8107  loss_bbox_7: 0.05312  loss_giou_7: 0.3738  loss_ce_dn_7: 0.132  loss_mask_dn_7: 0.0263  loss_dice_dn_7: 0.6628  loss_bbox_dn_7: 0.04113  loss_giou_dn_7: 0.3058  loss_ce_8: 1.245  loss_mask_8: 0.02915  loss_dice_8: 0.6771  loss_bbox_8: 0.0527  loss_giou_8: 0.3802  loss_ce_dn_8: 0.128  loss_mask_dn_8: 0.02559  loss_dice_dn_8: 0.6656  loss_bbox_dn_8: 0.0408  loss_giou_dn_8: 0.3063  loss_ce_interm: 1.516  loss_mask_interm: 0.02749  loss_dice_interm: 0.7413  loss_bbox_interm: 0.08321  loss_giou_interm: 0.5055  time: 1.9898  data_time: 0.0706  lr: 1e-06  max_mem: 6620M\n",
            "[05/20 17:34:48 d2.utils.events]:  eta: 1:32:54  iter: 2299  total_loss: 37.61  loss_ce: 0.8127  loss_mask: 0.02647  loss_dice: 0.4195  loss_bbox: 0.0502  loss_giou: 0.3998  loss_ce_dn: 0.2008  loss_mask_dn: 0.02721  loss_dice_dn: 0.6301  loss_bbox_dn: 0.0372  loss_giou_dn: 0.3702  loss_ce_0: 1.071  loss_mask_0: 0.03005  loss_dice_0: 0.5844  loss_bbox_0: 0.06274  loss_giou_0: 0.4994  loss_ce_dn_0: 0.7534  loss_mask_dn_0: 0.1976  loss_dice_dn_0: 2.649  loss_bbox_dn_0: 0.2227  loss_giou_dn_0: 0.8534  loss_ce_1: 1.154  loss_mask_1: 0.0306  loss_dice_1: 0.59  loss_bbox_1: 0.0509  loss_giou_1: 0.4247  loss_ce_dn_1: 0.2779  loss_mask_dn_1: 0.02794  loss_dice_dn_1: 0.6584  loss_bbox_dn_1: 0.07004  loss_giou_dn_1: 0.4009  loss_ce_2: 1.071  loss_mask_2: 0.0283  loss_dice_2: 0.495  loss_bbox_2: 0.05242  loss_giou_2: 0.4557  loss_ce_dn_2: 0.2561  loss_mask_dn_2: 0.02598  loss_dice_dn_2: 0.6383  loss_bbox_dn_2: 0.04459  loss_giou_dn_2: 0.3546  loss_ce_3: 0.8323  loss_mask_3: 0.02984  loss_dice_3: 0.5249  loss_bbox_3: 0.05235  loss_giou_3: 0.4149  loss_ce_dn_3: 0.2393  loss_mask_dn_3: 0.02773  loss_dice_dn_3: 0.6529  loss_bbox_dn_3: 0.03857  loss_giou_dn_3: 0.3705  loss_ce_4: 0.857  loss_mask_4: 0.02644  loss_dice_4: 0.5826  loss_bbox_4: 0.04694  loss_giou_4: 0.3907  loss_ce_dn_4: 0.2383  loss_mask_dn_4: 0.02721  loss_dice_dn_4: 0.655  loss_bbox_dn_4: 0.03769  loss_giou_dn_4: 0.3718  loss_ce_5: 0.7864  loss_mask_5: 0.02498  loss_dice_5: 0.6069  loss_bbox_5: 0.04777  loss_giou_5: 0.392  loss_ce_dn_5: 0.218  loss_mask_dn_5: 0.02602  loss_dice_dn_5: 0.6457  loss_bbox_dn_5: 0.0343  loss_giou_dn_5: 0.3775  loss_ce_6: 0.8307  loss_mask_6: 0.02765  loss_dice_6: 0.6735  loss_bbox_6: 0.05054  loss_giou_6: 0.3913  loss_ce_dn_6: 0.2214  loss_mask_dn_6: 0.0274  loss_dice_dn_6: 0.66  loss_bbox_dn_6: 0.03403  loss_giou_dn_6: 0.3783  loss_ce_7: 0.7621  loss_mask_7: 0.02527  loss_dice_7: 0.6973  loss_bbox_7: 0.04901  loss_giou_7: 0.3974  loss_ce_dn_7: 0.2107  loss_mask_dn_7: 0.02721  loss_dice_dn_7: 0.6551  loss_bbox_dn_7: 0.03355  loss_giou_dn_7: 0.3746  loss_ce_8: 0.7667  loss_mask_8: 0.02871  loss_dice_8: 0.5595  loss_bbox_8: 0.05032  loss_giou_8: 0.3939  loss_ce_dn_8: 0.2038  loss_mask_dn_8: 0.02734  loss_dice_dn_8: 0.6524  loss_bbox_dn_8: 0.03466  loss_giou_dn_8: 0.371  loss_ce_interm: 1.024  loss_mask_interm: 0.03086  loss_dice_interm: 0.5825  loss_bbox_interm: 0.085  loss_giou_interm: 0.5304  time: 1.9870  data_time: 0.0610  lr: 1e-06  max_mem: 6620M\n",
            "[05/20 17:35:23 d2.utils.events]:  eta: 1:32:23  iter: 2319  total_loss: 39.98  loss_ce: 1.096  loss_mask: 0.04522  loss_dice: 0.5  loss_bbox: 0.04431  loss_giou: 0.3052  loss_ce_dn: 0.2852  loss_mask_dn: 0.0389  loss_dice_dn: 0.5242  loss_bbox_dn: 0.03967  loss_giou_dn: 0.2554  loss_ce_0: 1.25  loss_mask_0: 0.04191  loss_dice_0: 0.4457  loss_bbox_0: 0.07267  loss_giou_0: 0.444  loss_ce_dn_0: 0.7372  loss_mask_dn_0: 0.2574  loss_dice_dn_0: 2.502  loss_bbox_dn_0: 0.2819  loss_giou_dn_0: 0.8536  loss_ce_1: 1.276  loss_mask_1: 0.04013  loss_dice_1: 0.4598  loss_bbox_1: 0.06839  loss_giou_1: 0.3254  loss_ce_dn_1: 0.3699  loss_mask_dn_1: 0.04086  loss_dice_dn_1: 0.5125  loss_bbox_dn_1: 0.08107  loss_giou_dn_1: 0.3785  loss_ce_2: 1.124  loss_mask_2: 0.03839  loss_dice_2: 0.4633  loss_bbox_2: 0.06491  loss_giou_2: 0.3326  loss_ce_dn_2: 0.3402  loss_mask_dn_2: 0.03699  loss_dice_dn_2: 0.5051  loss_bbox_dn_2: 0.04972  loss_giou_dn_2: 0.3154  loss_ce_3: 1.078  loss_mask_3: 0.03902  loss_dice_3: 0.494  loss_bbox_3: 0.05563  loss_giou_3: 0.3196  loss_ce_dn_3: 0.3173  loss_mask_dn_3: 0.03918  loss_dice_dn_3: 0.5357  loss_bbox_dn_3: 0.04677  loss_giou_dn_3: 0.2774  loss_ce_4: 1.063  loss_mask_4: 0.04056  loss_dice_4: 0.5096  loss_bbox_4: 0.05455  loss_giou_4: 0.3274  loss_ce_dn_4: 0.3012  loss_mask_dn_4: 0.03917  loss_dice_dn_4: 0.5122  loss_bbox_dn_4: 0.04493  loss_giou_dn_4: 0.2762  loss_ce_5: 0.9581  loss_mask_5: 0.03941  loss_dice_5: 0.392  loss_bbox_5: 0.05712  loss_giou_5: 0.3371  loss_ce_dn_5: 0.2993  loss_mask_dn_5: 0.03782  loss_dice_dn_5: 0.5265  loss_bbox_dn_5: 0.04258  loss_giou_dn_5: 0.2637  loss_ce_6: 1.029  loss_mask_6: 0.04009  loss_dice_6: 0.4466  loss_bbox_6: 0.04773  loss_giou_6: 0.295  loss_ce_dn_6: 0.2694  loss_mask_dn_6: 0.03723  loss_dice_dn_6: 0.5334  loss_bbox_dn_6: 0.04011  loss_giou_dn_6: 0.2643  loss_ce_7: 1.015  loss_mask_7: 0.04152  loss_dice_7: 0.3668  loss_bbox_7: 0.04567  loss_giou_7: 0.3102  loss_ce_dn_7: 0.2832  loss_mask_dn_7: 0.03935  loss_dice_dn_7: 0.499  loss_bbox_dn_7: 0.03975  loss_giou_dn_7: 0.2706  loss_ce_8: 1.032  loss_mask_8: 0.04491  loss_dice_8: 0.3956  loss_bbox_8: 0.04495  loss_giou_8: 0.2994  loss_ce_dn_8: 0.2811  loss_mask_dn_8: 0.03883  loss_dice_dn_8: 0.5324  loss_bbox_dn_8: 0.03962  loss_giou_dn_8: 0.2604  loss_ce_interm: 1.327  loss_mask_interm: 0.04741  loss_dice_interm: 0.4742  loss_bbox_interm: 0.1005  loss_giou_interm: 0.4409  time: 1.9847  data_time: 0.0975  lr: 1e-06  max_mem: 6620M\n",
            "[05/20 17:35:57 d2.utils.events]:  eta: 1:31:44  iter: 2339  total_loss: 40  loss_ce: 0.8579  loss_mask: 0.04815  loss_dice: 0.6386  loss_bbox: 0.05136  loss_giou: 0.354  loss_ce_dn: 0.1521  loss_mask_dn: 0.04136  loss_dice_dn: 0.6392  loss_bbox_dn: 0.04628  loss_giou_dn: 0.3008  loss_ce_0: 1.125  loss_mask_0: 0.04399  loss_dice_0: 0.5942  loss_bbox_0: 0.07454  loss_giou_0: 0.4605  loss_ce_dn_0: 0.7672  loss_mask_dn_0: 0.2856  loss_dice_dn_0: 2.625  loss_bbox_dn_0: 0.2805  loss_giou_dn_0: 0.8524  loss_ce_1: 1.04  loss_mask_1: 0.04583  loss_dice_1: 0.5968  loss_bbox_1: 0.06704  loss_giou_1: 0.4008  loss_ce_dn_1: 0.2438  loss_mask_dn_1: 0.04083  loss_dice_dn_1: 0.6145  loss_bbox_dn_1: 0.07512  loss_giou_dn_1: 0.3941  loss_ce_2: 0.9512  loss_mask_2: 0.04942  loss_dice_2: 0.6143  loss_bbox_2: 0.06769  loss_giou_2: 0.3805  loss_ce_dn_2: 0.213  loss_mask_dn_2: 0.03726  loss_dice_dn_2: 0.6538  loss_bbox_dn_2: 0.05661  loss_giou_dn_2: 0.3486  loss_ce_3: 0.8822  loss_mask_3: 0.04745  loss_dice_3: 0.5796  loss_bbox_3: 0.06365  loss_giou_3: 0.3528  loss_ce_dn_3: 0.1935  loss_mask_dn_3: 0.03687  loss_dice_dn_3: 0.6358  loss_bbox_dn_3: 0.04945  loss_giou_dn_3: 0.3147  loss_ce_4: 0.8582  loss_mask_4: 0.0519  loss_dice_4: 0.6011  loss_bbox_4: 0.06171  loss_giou_4: 0.3718  loss_ce_dn_4: 0.1863  loss_mask_dn_4: 0.03852  loss_dice_dn_4: 0.6354  loss_bbox_dn_4: 0.04937  loss_giou_dn_4: 0.3042  loss_ce_5: 0.8483  loss_mask_5: 0.0438  loss_dice_5: 0.6178  loss_bbox_5: 0.06315  loss_giou_5: 0.3738  loss_ce_dn_5: 0.1692  loss_mask_dn_5: 0.03746  loss_dice_dn_5: 0.6358  loss_bbox_dn_5: 0.04744  loss_giou_dn_5: 0.2999  loss_ce_6: 0.85  loss_mask_6: 0.04444  loss_dice_6: 0.666  loss_bbox_6: 0.05215  loss_giou_6: 0.3574  loss_ce_dn_6: 0.1547  loss_mask_dn_6: 0.03847  loss_dice_dn_6: 0.6589  loss_bbox_dn_6: 0.04915  loss_giou_dn_6: 0.3047  loss_ce_7: 0.8357  loss_mask_7: 0.04763  loss_dice_7: 0.552  loss_bbox_7: 0.05868  loss_giou_7: 0.3624  loss_ce_dn_7: 0.1538  loss_mask_dn_7: 0.03987  loss_dice_dn_7: 0.6497  loss_bbox_dn_7: 0.04799  loss_giou_dn_7: 0.3037  loss_ce_8: 0.846  loss_mask_8: 0.04029  loss_dice_8: 0.6066  loss_bbox_8: 0.0516  loss_giou_8: 0.3609  loss_ce_dn_8: 0.1506  loss_mask_dn_8: 0.04101  loss_dice_dn_8: 0.6432  loss_bbox_dn_8: 0.04707  loss_giou_dn_8: 0.3061  loss_ce_interm: 1.125  loss_mask_interm: 0.05152  loss_dice_interm: 0.6379  loss_bbox_interm: 0.1045  loss_giou_interm: 0.449  time: 1.9823  data_time: 0.0852  lr: 1e-06  max_mem: 6620M\n",
            "[05/20 17:36:31 d2.utils.events]:  eta: 1:31:17  iter: 2359  total_loss: 49.88  loss_ce: 1.152  loss_mask: 0.05698  loss_dice: 0.614  loss_bbox: 0.08685  loss_giou: 0.4464  loss_ce_dn: 0.2543  loss_mask_dn: 0.04054  loss_dice_dn: 0.679  loss_bbox_dn: 0.04845  loss_giou_dn: 0.3405  loss_ce_0: 1.338  loss_mask_0: 0.0533  loss_dice_0: 0.773  loss_bbox_0: 0.1155  loss_giou_0: 0.5626  loss_ce_dn_0: 0.7945  loss_mask_dn_0: 0.1993  loss_dice_dn_0: 2.618  loss_bbox_dn_0: 0.2479  loss_giou_dn_0: 0.8588  loss_ce_1: 1.35  loss_mask_1: 0.05495  loss_dice_1: 0.7145  loss_bbox_1: 0.1076  loss_giou_1: 0.4728  loss_ce_dn_1: 0.3491  loss_mask_dn_1: 0.04325  loss_dice_dn_1: 0.6704  loss_bbox_dn_1: 0.08486  loss_giou_dn_1: 0.4278  loss_ce_2: 1.243  loss_mask_2: 0.0521  loss_dice_2: 0.7482  loss_bbox_2: 0.1153  loss_giou_2: 0.459  loss_ce_dn_2: 0.3088  loss_mask_dn_2: 0.04475  loss_dice_dn_2: 0.6599  loss_bbox_dn_2: 0.06545  loss_giou_dn_2: 0.3718  loss_ce_3: 1.179  loss_mask_3: 0.05814  loss_dice_3: 0.6679  loss_bbox_3: 0.1298  loss_giou_3: 0.5824  loss_ce_dn_3: 0.2816  loss_mask_dn_3: 0.04203  loss_dice_dn_3: 0.6841  loss_bbox_dn_3: 0.06098  loss_giou_dn_3: 0.3577  loss_ce_4: 1.17  loss_mask_4: 0.05212  loss_dice_4: 0.7133  loss_bbox_4: 0.1121  loss_giou_4: 0.4536  loss_ce_dn_4: 0.2707  loss_mask_dn_4: 0.04198  loss_dice_dn_4: 0.6298  loss_bbox_dn_4: 0.05777  loss_giou_dn_4: 0.3452  loss_ce_5: 1.215  loss_mask_5: 0.05402  loss_dice_5: 0.6883  loss_bbox_5: 0.1139  loss_giou_5: 0.5077  loss_ce_dn_5: 0.2499  loss_mask_dn_5: 0.04435  loss_dice_dn_5: 0.6348  loss_bbox_dn_5: 0.056  loss_giou_dn_5: 0.3345  loss_ce_6: 1.136  loss_mask_6: 0.05537  loss_dice_6: 0.6733  loss_bbox_6: 0.1381  loss_giou_6: 0.4789  loss_ce_dn_6: 0.2565  loss_mask_dn_6: 0.04005  loss_dice_dn_6: 0.6275  loss_bbox_dn_6: 0.05581  loss_giou_dn_6: 0.3343  loss_ce_7: 1.154  loss_mask_7: 0.05496  loss_dice_7: 0.62  loss_bbox_7: 0.09323  loss_giou_7: 0.4508  loss_ce_dn_7: 0.25  loss_mask_dn_7: 0.04216  loss_dice_dn_7: 0.6638  loss_bbox_dn_7: 0.04867  loss_giou_dn_7: 0.3383  loss_ce_8: 1.151  loss_mask_8: 0.05682  loss_dice_8: 0.6648  loss_bbox_8: 0.09874  loss_giou_8: 0.5007  loss_ce_dn_8: 0.2558  loss_mask_dn_8: 0.04229  loss_dice_dn_8: 0.6296  loss_bbox_dn_8: 0.0483  loss_giou_dn_8: 0.3434  loss_ce_interm: 1.445  loss_mask_interm: 0.05313  loss_dice_interm: 0.7404  loss_bbox_interm: 0.1079  loss_giou_interm: 0.5479  time: 1.9799  data_time: 0.0628  lr: 1e-06  max_mem: 6620M\n",
            "[05/20 17:37:06 d2.utils.events]:  eta: 1:30:46  iter: 2379  total_loss: 50.43  loss_ce: 1.067  loss_mask: 0.04123  loss_dice: 0.4969  loss_bbox: 0.1166  loss_giou: 0.3397  loss_ce_dn: 0.2352  loss_mask_dn: 0.04307  loss_dice_dn: 0.6733  loss_bbox_dn: 0.04332  loss_giou_dn: 0.2879  loss_ce_0: 1.426  loss_mask_0: 0.04886  loss_dice_0: 0.5475  loss_bbox_0: 0.1172  loss_giou_0: 0.4646  loss_ce_dn_0: 0.7282  loss_mask_dn_0: 0.4266  loss_dice_dn_0: 2.563  loss_bbox_dn_0: 0.4194  loss_giou_dn_0: 0.8507  loss_ce_1: 1.409  loss_mask_1: 0.05243  loss_dice_1: 0.6383  loss_bbox_1: 0.09864  loss_giou_1: 0.3464  loss_ce_dn_1: 0.3121  loss_mask_dn_1: 0.04917  loss_dice_dn_1: 0.77  loss_bbox_dn_1: 0.1178  loss_giou_dn_1: 0.402  loss_ce_2: 1.339  loss_mask_2: 0.04929  loss_dice_2: 0.7012  loss_bbox_2: 0.112  loss_giou_2: 0.3641  loss_ce_dn_2: 0.3032  loss_mask_dn_2: 0.04548  loss_dice_dn_2: 0.7852  loss_bbox_dn_2: 0.08699  loss_giou_dn_2: 0.3444  loss_ce_3: 1.22  loss_mask_3: 0.04985  loss_dice_3: 0.5304  loss_bbox_3: 0.09604  loss_giou_3: 0.3749  loss_ce_dn_3: 0.2854  loss_mask_dn_3: 0.04514  loss_dice_dn_3: 0.7318  loss_bbox_dn_3: 0.05569  loss_giou_dn_3: 0.3151  loss_ce_4: 1.225  loss_mask_4: 0.04917  loss_dice_4: 0.675  loss_bbox_4: 0.1036  loss_giou_4: 0.3618  loss_ce_dn_4: 0.263  loss_mask_dn_4: 0.04211  loss_dice_dn_4: 0.6712  loss_bbox_dn_4: 0.04778  loss_giou_dn_4: 0.3134  loss_ce_5: 1.119  loss_mask_5: 0.04396  loss_dice_5: 0.4889  loss_bbox_5: 0.1187  loss_giou_5: 0.3669  loss_ce_dn_5: 0.2435  loss_mask_dn_5: 0.0432  loss_dice_dn_5: 0.6558  loss_bbox_dn_5: 0.04589  loss_giou_dn_5: 0.3037  loss_ce_6: 1.104  loss_mask_6: 0.04484  loss_dice_6: 0.525  loss_bbox_6: 0.1263  loss_giou_6: 0.3625  loss_ce_dn_6: 0.2331  loss_mask_dn_6: 0.04191  loss_dice_dn_6: 0.6669  loss_bbox_dn_6: 0.04406  loss_giou_dn_6: 0.2989  loss_ce_7: 1.097  loss_mask_7: 0.0465  loss_dice_7: 0.5068  loss_bbox_7: 0.1092  loss_giou_7: 0.3248  loss_ce_dn_7: 0.2415  loss_mask_dn_7: 0.04254  loss_dice_dn_7: 0.6704  loss_bbox_dn_7: 0.04388  loss_giou_dn_7: 0.2896  loss_ce_8: 1.079  loss_mask_8: 0.04715  loss_dice_8: 0.6029  loss_bbox_8: 0.1051  loss_giou_8: 0.3209  loss_ce_dn_8: 0.2363  loss_mask_dn_8: 0.04166  loss_dice_dn_8: 0.6472  loss_bbox_dn_8: 0.04462  loss_giou_dn_8: 0.2898  loss_ce_interm: 1.335  loss_mask_interm: 0.04375  loss_dice_interm: 0.618  loss_bbox_interm: 0.1457  loss_giou_interm: 0.4511  time: 1.9779  data_time: 0.0754  lr: 1e-06  max_mem: 6620M\n",
            "[05/20 17:37:43 d2.utils.events]:  eta: 1:30:16  iter: 2399  total_loss: 42.6  loss_ce: 1.112  loss_mask: 0.02452  loss_dice: 0.6206  loss_bbox: 0.06257  loss_giou: 0.3401  loss_ce_dn: 0.206  loss_mask_dn: 0.02415  loss_dice_dn: 0.6325  loss_bbox_dn: 0.03857  loss_giou_dn: 0.2932  loss_ce_0: 1.157  loss_mask_0: 0.03512  loss_dice_0: 0.7939  loss_bbox_0: 0.07907  loss_giou_0: 0.4358  loss_ce_dn_0: 0.7515  loss_mask_dn_0: 0.08224  loss_dice_dn_0: 2.959  loss_bbox_dn_0: 0.1655  loss_giou_dn_0: 0.8584  loss_ce_1: 1.293  loss_mask_1: 0.0284  loss_dice_1: 0.668  loss_bbox_1: 0.07467  loss_giou_1: 0.4193  loss_ce_dn_1: 0.308  loss_mask_dn_1: 0.02493  loss_dice_dn_1: 0.632  loss_bbox_dn_1: 0.06006  loss_giou_dn_1: 0.3954  loss_ce_2: 1.198  loss_mask_2: 0.03027  loss_dice_2: 0.6463  loss_bbox_2: 0.06674  loss_giou_2: 0.3895  loss_ce_dn_2: 0.2849  loss_mask_dn_2: 0.02513  loss_dice_dn_2: 0.681  loss_bbox_dn_2: 0.0488  loss_giou_dn_2: 0.3306  loss_ce_3: 1.067  loss_mask_3: 0.02992  loss_dice_3: 0.627  loss_bbox_3: 0.06394  loss_giou_3: 0.3867  loss_ce_dn_3: 0.2411  loss_mask_dn_3: 0.02442  loss_dice_dn_3: 0.6543  loss_bbox_dn_3: 0.04447  loss_giou_dn_3: 0.3233  loss_ce_4: 1.077  loss_mask_4: 0.03  loss_dice_4: 0.5476  loss_bbox_4: 0.06496  loss_giou_4: 0.3937  loss_ce_dn_4: 0.2293  loss_mask_dn_4: 0.02553  loss_dice_dn_4: 0.6438  loss_bbox_dn_4: 0.03932  loss_giou_dn_4: 0.3099  loss_ce_5: 1.03  loss_mask_5: 0.02645  loss_dice_5: 0.6147  loss_bbox_5: 0.06565  loss_giou_5: 0.398  loss_ce_dn_5: 0.2186  loss_mask_dn_5: 0.02348  loss_dice_dn_5: 0.6563  loss_bbox_dn_5: 0.03921  loss_giou_dn_5: 0.2965  loss_ce_6: 1.086  loss_mask_6: 0.02386  loss_dice_6: 0.6168  loss_bbox_6: 0.0664  loss_giou_6: 0.4011  loss_ce_dn_6: 0.2115  loss_mask_dn_6: 0.02399  loss_dice_dn_6: 0.6498  loss_bbox_dn_6: 0.03882  loss_giou_dn_6: 0.2964  loss_ce_7: 1.078  loss_mask_7: 0.02529  loss_dice_7: 0.6423  loss_bbox_7: 0.06362  loss_giou_7: 0.3388  loss_ce_dn_7: 0.2027  loss_mask_dn_7: 0.02509  loss_dice_dn_7: 0.6141  loss_bbox_dn_7: 0.03814  loss_giou_dn_7: 0.2967  loss_ce_8: 1.106  loss_mask_8: 0.02663  loss_dice_8: 0.5579  loss_bbox_8: 0.06352  loss_giou_8: 0.3385  loss_ce_dn_8: 0.2053  loss_mask_dn_8: 0.02366  loss_dice_dn_8: 0.6199  loss_bbox_dn_8: 0.03884  loss_giou_dn_8: 0.2945  loss_ce_interm: 1.17  loss_mask_interm: 0.02793  loss_dice_interm: 0.7651  loss_bbox_interm: 0.1097  loss_giou_interm: 0.4679  time: 1.9760  data_time: 0.0818  lr: 1e-06  max_mem: 6620M\n",
            "[05/20 17:38:18 d2.utils.events]:  eta: 1:29:48  iter: 2419  total_loss: 46.93  loss_ce: 1.071  loss_mask: 0.04167  loss_dice: 0.7523  loss_bbox: 0.07646  loss_giou: 0.3277  loss_ce_dn: 0.2034  loss_mask_dn: 0.03769  loss_dice_dn: 0.7735  loss_bbox_dn: 0.03802  loss_giou_dn: 0.3009  loss_ce_0: 1.29  loss_mask_0: 0.03912  loss_dice_0: 0.7803  loss_bbox_0: 0.1177  loss_giou_0: 0.5423  loss_ce_dn_0: 0.7433  loss_mask_dn_0: 0.2083  loss_dice_dn_0: 2.97  loss_bbox_dn_0: 0.2625  loss_giou_dn_0: 0.8525  loss_ce_1: 1.283  loss_mask_1: 0.03806  loss_dice_1: 0.6831  loss_bbox_1: 0.08249  loss_giou_1: 0.39  loss_ce_dn_1: 0.2838  loss_mask_dn_1: 0.0475  loss_dice_dn_1: 0.7483  loss_bbox_dn_1: 0.07899  loss_giou_dn_1: 0.3835  loss_ce_2: 1.197  loss_mask_2: 0.03656  loss_dice_2: 0.7222  loss_bbox_2: 0.09433  loss_giou_2: 0.3919  loss_ce_dn_2: 0.2407  loss_mask_dn_2: 0.03495  loss_dice_dn_2: 0.7339  loss_bbox_dn_2: 0.05495  loss_giou_dn_2: 0.3317  loss_ce_3: 1.1  loss_mask_3: 0.03917  loss_dice_3: 0.6905  loss_bbox_3: 0.07003  loss_giou_3: 0.3828  loss_ce_dn_3: 0.2217  loss_mask_dn_3: 0.03732  loss_dice_dn_3: 0.7316  loss_bbox_dn_3: 0.041  loss_giou_dn_3: 0.3115  loss_ce_4: 1.061  loss_mask_4: 0.03967  loss_dice_4: 0.7949  loss_bbox_4: 0.06585  loss_giou_4: 0.3455  loss_ce_dn_4: 0.2129  loss_mask_dn_4: 0.038  loss_dice_dn_4: 0.7048  loss_bbox_dn_4: 0.04054  loss_giou_dn_4: 0.3113  loss_ce_5: 1.038  loss_mask_5: 0.0493  loss_dice_5: 0.6596  loss_bbox_5: 0.06719  loss_giou_5: 0.331  loss_ce_dn_5: 0.217  loss_mask_dn_5: 0.03539  loss_dice_dn_5: 0.7184  loss_bbox_dn_5: 0.03857  loss_giou_dn_5: 0.2972  loss_ce_6: 0.996  loss_mask_6: 0.04679  loss_dice_6: 0.7431  loss_bbox_6: 0.07237  loss_giou_6: 0.3603  loss_ce_dn_6: 0.2018  loss_mask_dn_6: 0.03729  loss_dice_dn_6: 0.727  loss_bbox_dn_6: 0.03796  loss_giou_dn_6: 0.3063  loss_ce_7: 1.033  loss_mask_7: 0.03934  loss_dice_7: 0.7036  loss_bbox_7: 0.05403  loss_giou_7: 0.3464  loss_ce_dn_7: 0.2043  loss_mask_dn_7: 0.03753  loss_dice_dn_7: 0.7382  loss_bbox_dn_7: 0.03756  loss_giou_dn_7: 0.3042  loss_ce_8: 1.053  loss_mask_8: 0.04141  loss_dice_8: 0.7569  loss_bbox_8: 0.07933  loss_giou_8: 0.3747  loss_ce_dn_8: 0.2098  loss_mask_dn_8: 0.03866  loss_dice_dn_8: 0.7516  loss_bbox_dn_8: 0.03769  loss_giou_dn_8: 0.3025  loss_ce_interm: 1.296  loss_mask_interm: 0.0419  loss_dice_interm: 0.7192  loss_bbox_interm: 0.08283  loss_giou_interm: 0.4386  time: 1.9742  data_time: 0.0801  lr: 1e-06  max_mem: 6620M\n",
            "[05/20 17:38:51 d2.utils.events]:  eta: 1:29:11  iter: 2439  total_loss: 50.78  loss_ce: 1.122  loss_mask: 0.02457  loss_dice: 0.6364  loss_bbox: 0.06925  loss_giou: 0.4099  loss_ce_dn: 0.2131  loss_mask_dn: 0.02365  loss_dice_dn: 0.6044  loss_bbox_dn: 0.03462  loss_giou_dn: 0.3241  loss_ce_0: 1.366  loss_mask_0: 0.03032  loss_dice_0: 0.7073  loss_bbox_0: 0.07477  loss_giou_0: 0.5205  loss_ce_dn_0: 0.726  loss_mask_dn_0: 0.09664  loss_dice_dn_0: 2.517  loss_bbox_dn_0: 0.2429  loss_giou_dn_0: 0.8603  loss_ce_1: 1.33  loss_mask_1: 0.02499  loss_dice_1: 0.5055  loss_bbox_1: 0.06074  loss_giou_1: 0.4172  loss_ce_dn_1: 0.319  loss_mask_dn_1: 0.02928  loss_dice_dn_1: 0.6719  loss_bbox_dn_1: 0.06448  loss_giou_dn_1: 0.3957  loss_ce_2: 1.123  loss_mask_2: 0.0219  loss_dice_2: 0.7842  loss_bbox_2: 0.06737  loss_giou_2: 0.4512  loss_ce_dn_2: 0.2813  loss_mask_dn_2: 0.02591  loss_dice_dn_2: 0.6326  loss_bbox_dn_2: 0.04372  loss_giou_dn_2: 0.3532  loss_ce_3: 1.129  loss_mask_3: 0.02836  loss_dice_3: 0.8845  loss_bbox_3: 0.06286  loss_giou_3: 0.4964  loss_ce_dn_3: 0.2624  loss_mask_dn_3: 0.02537  loss_dice_dn_3: 0.6568  loss_bbox_dn_3: 0.03903  loss_giou_dn_3: 0.3167  loss_ce_4: 1.219  loss_mask_4: 0.02771  loss_dice_4: 0.6714  loss_bbox_4: 0.07732  loss_giou_4: 0.5171  loss_ce_dn_4: 0.239  loss_mask_dn_4: 0.02366  loss_dice_dn_4: 0.5689  loss_bbox_dn_4: 0.04017  loss_giou_dn_4: 0.3245  loss_ce_5: 1.134  loss_mask_5: 0.03192  loss_dice_5: 0.6215  loss_bbox_5: 0.07169  loss_giou_5: 0.478  loss_ce_dn_5: 0.2175  loss_mask_dn_5: 0.02368  loss_dice_dn_5: 0.5439  loss_bbox_dn_5: 0.03527  loss_giou_dn_5: 0.3315  loss_ce_6: 1.113  loss_mask_6: 0.02383  loss_dice_6: 0.6004  loss_bbox_6: 0.06988  loss_giou_6: 0.4045  loss_ce_dn_6: 0.2145  loss_mask_dn_6: 0.02376  loss_dice_dn_6: 0.6098  loss_bbox_dn_6: 0.03486  loss_giou_dn_6: 0.327  loss_ce_7: 1.115  loss_mask_7: 0.02822  loss_dice_7: 0.6784  loss_bbox_7: 0.06488  loss_giou_7: 0.4355  loss_ce_dn_7: 0.2045  loss_mask_dn_7: 0.02328  loss_dice_dn_7: 0.609  loss_bbox_dn_7: 0.0348  loss_giou_dn_7: 0.328  loss_ce_8: 1.1  loss_mask_8: 0.02434  loss_dice_8: 0.5588  loss_bbox_8: 0.06447  loss_giou_8: 0.4033  loss_ce_dn_8: 0.2082  loss_mask_dn_8: 0.02486  loss_dice_dn_8: 0.6162  loss_bbox_dn_8: 0.03438  loss_giou_dn_8: 0.3247  loss_ce_interm: 1.361  loss_mask_interm: 0.03015  loss_dice_interm: 0.6025  loss_bbox_interm: 0.0897  loss_giou_interm: 0.5608  time: 1.9716  data_time: 0.0513  lr: 1e-06  max_mem: 6620M\n",
            "[05/20 17:39:25 d2.utils.events]:  eta: 1:28:30  iter: 2459  total_loss: 50.48  loss_ce: 1.241  loss_mask: 0.03448  loss_dice: 0.5  loss_bbox: 0.08099  loss_giou: 0.5126  loss_ce_dn: 0.2211  loss_mask_dn: 0.03187  loss_dice_dn: 0.6086  loss_bbox_dn: 0.03681  loss_giou_dn: 0.3527  loss_ce_0: 1.592  loss_mask_0: 0.03799  loss_dice_0: 0.5171  loss_bbox_0: 0.06915  loss_giou_0: 0.571  loss_ce_dn_0: 0.7309  loss_mask_dn_0: 0.2011  loss_dice_dn_0: 3.073  loss_bbox_dn_0: 0.2801  loss_giou_dn_0: 0.8595  loss_ce_1: 1.45  loss_mask_1: 0.04298  loss_dice_1: 0.5106  loss_bbox_1: 0.07778  loss_giou_1: 0.5714  loss_ce_dn_1: 0.2876  loss_mask_dn_1: 0.03856  loss_dice_dn_1: 0.6935  loss_bbox_dn_1: 0.0718  loss_giou_dn_1: 0.4411  loss_ce_2: 1.421  loss_mask_2: 0.04364  loss_dice_2: 0.678  loss_bbox_2: 0.1106  loss_giou_2: 0.6007  loss_ce_dn_2: 0.247  loss_mask_dn_2: 0.03091  loss_dice_dn_2: 0.65  loss_bbox_dn_2: 0.05581  loss_giou_dn_2: 0.3876  loss_ce_3: 1.209  loss_mask_3: 0.04005  loss_dice_3: 0.498  loss_bbox_3: 0.07963  loss_giou_3: 0.5554  loss_ce_dn_3: 0.2473  loss_mask_dn_3: 0.02989  loss_dice_dn_3: 0.6214  loss_bbox_dn_3: 0.04308  loss_giou_dn_3: 0.3603  loss_ce_4: 1.286  loss_mask_4: 0.03917  loss_dice_4: 0.4037  loss_bbox_4: 0.07344  loss_giou_4: 0.4978  loss_ce_dn_4: 0.2387  loss_mask_dn_4: 0.032  loss_dice_dn_4: 0.633  loss_bbox_dn_4: 0.04404  loss_giou_dn_4: 0.3688  loss_ce_5: 1.213  loss_mask_5: 0.03361  loss_dice_5: 0.3744  loss_bbox_5: 0.07402  loss_giou_5: 0.4847  loss_ce_dn_5: 0.2349  loss_mask_dn_5: 0.03042  loss_dice_dn_5: 0.6219  loss_bbox_dn_5: 0.04145  loss_giou_dn_5: 0.3517  loss_ce_6: 1.242  loss_mask_6: 0.03053  loss_dice_6: 0.5422  loss_bbox_6: 0.07583  loss_giou_6: 0.4898  loss_ce_dn_6: 0.2304  loss_mask_dn_6: 0.03098  loss_dice_dn_6: 0.6511  loss_bbox_dn_6: 0.0395  loss_giou_dn_6: 0.3517  loss_ce_7: 1.283  loss_mask_7: 0.03691  loss_dice_7: 0.6663  loss_bbox_7: 0.08055  loss_giou_7: 0.4923  loss_ce_dn_7: 0.2273  loss_mask_dn_7: 0.03187  loss_dice_dn_7: 0.66  loss_bbox_dn_7: 0.03954  loss_giou_dn_7: 0.3548  loss_ce_8: 1.231  loss_mask_8: 0.0325  loss_dice_8: 0.6543  loss_bbox_8: 0.1169  loss_giou_8: 0.5793  loss_ce_dn_8: 0.2245  loss_mask_dn_8: 0.03157  loss_dice_dn_8: 0.6602  loss_bbox_dn_8: 0.03892  loss_giou_dn_8: 0.3517  loss_ce_interm: 1.592  loss_mask_interm: 0.03688  loss_dice_interm: 0.8155  loss_bbox_interm: 0.09031  loss_giou_interm: 0.5714  time: 1.9691  data_time: 0.0751  lr: 1e-06  max_mem: 6639M\n",
            "[05/20 17:39:59 d2.utils.events]:  eta: 1:28:06  iter: 2479  total_loss: 48.23  loss_ce: 1.16  loss_mask: 0.0235  loss_dice: 0.6026  loss_bbox: 0.05856  loss_giou: 0.4183  loss_ce_dn: 0.2194  loss_mask_dn: 0.02467  loss_dice_dn: 0.71  loss_bbox_dn: 0.0356  loss_giou_dn: 0.3121  loss_ce_0: 1.442  loss_mask_0: 0.02403  loss_dice_0: 0.7572  loss_bbox_0: 0.07539  loss_giou_0: 0.546  loss_ce_dn_0: 0.7733  loss_mask_dn_0: 0.1416  loss_dice_dn_0: 2.839  loss_bbox_dn_0: 0.2096  loss_giou_dn_0: 0.851  loss_ce_1: 1.331  loss_mask_1: 0.03261  loss_dice_1: 0.7414  loss_bbox_1: 0.06364  loss_giou_1: 0.401  loss_ce_dn_1: 0.3082  loss_mask_dn_1: 0.02427  loss_dice_dn_1: 0.7054  loss_bbox_dn_1: 0.04793  loss_giou_dn_1: 0.3609  loss_ce_2: 1.31  loss_mask_2: 0.02908  loss_dice_2: 0.5959  loss_bbox_2: 0.07749  loss_giou_2: 0.4138  loss_ce_dn_2: 0.2539  loss_mask_dn_2: 0.02281  loss_dice_dn_2: 0.6892  loss_bbox_dn_2: 0.0415  loss_giou_dn_2: 0.3378  loss_ce_3: 1.242  loss_mask_3: 0.02616  loss_dice_3: 0.7214  loss_bbox_3: 0.06526  loss_giou_3: 0.4037  loss_ce_dn_3: 0.2424  loss_mask_dn_3: 0.02498  loss_dice_dn_3: 0.675  loss_bbox_dn_3: 0.03646  loss_giou_dn_3: 0.3042  loss_ce_4: 1.153  loss_mask_4: 0.02932  loss_dice_4: 0.6701  loss_bbox_4: 0.0669  loss_giou_4: 0.43  loss_ce_dn_4: 0.225  loss_mask_dn_4: 0.02455  loss_dice_dn_4: 0.648  loss_bbox_dn_4: 0.03668  loss_giou_dn_4: 0.3092  loss_ce_5: 1.142  loss_mask_5: 0.02499  loss_dice_5: 0.7213  loss_bbox_5: 0.05793  loss_giou_5: 0.4207  loss_ce_dn_5: 0.2202  loss_mask_dn_5: 0.02396  loss_dice_dn_5: 0.6619  loss_bbox_dn_5: 0.03636  loss_giou_dn_5: 0.3094  loss_ce_6: 1.137  loss_mask_6: 0.02432  loss_dice_6: 0.6635  loss_bbox_6: 0.05898  loss_giou_6: 0.4141  loss_ce_dn_6: 0.2195  loss_mask_dn_6: 0.02349  loss_dice_dn_6: 0.6776  loss_bbox_dn_6: 0.03666  loss_giou_dn_6: 0.3008  loss_ce_7: 1.118  loss_mask_7: 0.02431  loss_dice_7: 0.6463  loss_bbox_7: 0.05233  loss_giou_7: 0.411  loss_ce_dn_7: 0.2139  loss_mask_dn_7: 0.02467  loss_dice_dn_7: 0.6717  loss_bbox_dn_7: 0.03643  loss_giou_dn_7: 0.3103  loss_ce_8: 1.147  loss_mask_8: 0.02876  loss_dice_8: 0.7225  loss_bbox_8: 0.0549  loss_giou_8: 0.4158  loss_ce_dn_8: 0.2202  loss_mask_dn_8: 0.0253  loss_dice_dn_8: 0.6677  loss_bbox_dn_8: 0.0356  loss_giou_dn_8: 0.3099  loss_ce_interm: 1.331  loss_mask_interm: 0.02672  loss_dice_interm: 0.8063  loss_bbox_interm: 0.09978  loss_giou_interm: 0.5939  time: 1.9672  data_time: 0.1047  lr: 1e-06  max_mem: 6639M\n",
            "[05/20 17:40:35 d2.data.datasets.coco]: Loaded 150 images in COCO format from /content/TACO-expl/data/annotations_off_0_resval.json\n",
            "[05/20 17:40:35 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "[05/20 17:40:35 d2.data.common]: Serializing 150 elements to byte tensors and concatenating them all ...\n",
            "[05/20 17:40:35 d2.data.common]: Serialized dataset takes 0.21 MiB\n",
            "WARNING [05/20 17:40:35 d2.evaluation.coco_evaluation]: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
            "[05/20 17:40:35 d2.evaluation.evaluator]: Start inference on 150 batches\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1066, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1066, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1066, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1066])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 17:40:45 d2.evaluation.evaluator]: Inference done 11/150. Dataloading: 0.0020 s/iter. Inference: 0.3227 s/iter. Eval: 0.5654 s/iter. Total: 0.8902 s/iter. ETA=0:02:03\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 608])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 608])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 608])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1200])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 750])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 17:40:50 d2.evaluation.evaluator]: Inference done 18/150. Dataloading: 0.0023 s/iter. Inference: 0.2992 s/iter. Eval: 0.5027 s/iter. Total: 0.8043 s/iter. ETA=0:01:46\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 750])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([750, 1333])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 17:40:55 d2.evaluation.evaluator]: Inference done 24/150. Dataloading: 0.0024 s/iter. Inference: 0.3020 s/iter. Eval: 0.5112 s/iter. Total: 0.8159 s/iter. ETA=0:01:42\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 750])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([750, 1333])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 17:41:00 d2.evaluation.evaluator]: Inference done 29/150. Dataloading: 0.0044 s/iter. Inference: 0.3132 s/iter. Eval: 0.5430 s/iter. Total: 0.8609 s/iter. ETA=0:01:44\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 750])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 17:41:05 d2.evaluation.evaluator]: Inference done 36/150. Dataloading: 0.0040 s/iter. Inference: 0.3103 s/iter. Eval: 0.5250 s/iter. Total: 0.8397 s/iter. ETA=0:01:35\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 750])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 17:41:11 d2.evaluation.evaluator]: Inference done 43/150. Dataloading: 0.0037 s/iter. Inference: 0.3070 s/iter. Eval: 0.5163 s/iter. Total: 0.8274 s/iter. ETA=0:01:28\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 17:41:17 d2.evaluation.evaluator]: Inference done 49/150. Dataloading: 0.0052 s/iter. Inference: 0.3109 s/iter. Eval: 0.5303 s/iter. Total: 0.8469 s/iter. ETA=0:01:25\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 17:41:22 d2.evaluation.evaluator]: Inference done 56/150. Dataloading: 0.0051 s/iter. Inference: 0.3091 s/iter. Eval: 0.5234 s/iter. Total: 0.8382 s/iter. ETA=0:01:18\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 17:41:27 d2.evaluation.evaluator]: Inference done 63/150. Dataloading: 0.0049 s/iter. Inference: 0.3068 s/iter. Eval: 0.5147 s/iter. Total: 0.8270 s/iter. ETA=0:01:11\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 17:41:33 d2.evaluation.evaluator]: Inference done 69/150. Dataloading: 0.0050 s/iter. Inference: 0.3087 s/iter. Eval: 0.5245 s/iter. Total: 0.8387 s/iter. ETA=0:01:07\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 17:41:39 d2.evaluation.evaluator]: Inference done 76/150. Dataloading: 0.0049 s/iter. Inference: 0.3082 s/iter. Eval: 0.5198 s/iter. Total: 0.8335 s/iter. ETA=0:01:01\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([852, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 17:41:44 d2.evaluation.evaluator]: Inference done 83/150. Dataloading: 0.0047 s/iter. Inference: 0.3051 s/iter. Eval: 0.5126 s/iter. Total: 0.8229 s/iter. ETA=0:00:55\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 17:41:49 d2.evaluation.evaluator]: Inference done 89/150. Dataloading: 0.0051 s/iter. Inference: 0.3061 s/iter. Eval: 0.5187 s/iter. Total: 0.8304 s/iter. ETA=0:00:50\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 17:41:54 d2.evaluation.evaluator]: Inference done 95/150. Dataloading: 0.0053 s/iter. Inference: 0.3064 s/iter. Eval: 0.5189 s/iter. Total: 0.8311 s/iter. ETA=0:00:45\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 17:41:59 d2.evaluation.evaluator]: Inference done 102/150. Dataloading: 0.0051 s/iter. Inference: 0.3048 s/iter. Eval: 0.5141 s/iter. Total: 0.8245 s/iter. ETA=0:00:39\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 17:42:04 d2.evaluation.evaluator]: Inference done 108/150. Dataloading: 0.0049 s/iter. Inference: 0.3043 s/iter. Eval: 0.5163 s/iter. Total: 0.8261 s/iter. ETA=0:00:34\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 17:42:10 d2.evaluation.evaluator]: Inference done 114/150. Dataloading: 0.0049 s/iter. Inference: 0.3056 s/iter. Eval: 0.5180 s/iter. Total: 0.8290 s/iter. ETA=0:00:29\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 17:42:15 d2.evaluation.evaluator]: Inference done 121/150. Dataloading: 0.0047 s/iter. Inference: 0.3043 s/iter. Eval: 0.5140 s/iter. Total: 0.8236 s/iter. ETA=0:00:23\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 17:42:21 d2.evaluation.evaluator]: Inference done 128/150. Dataloading: 0.0048 s/iter. Inference: 0.3041 s/iter. Eval: 0.5145 s/iter. Total: 0.8239 s/iter. ETA=0:00:18\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 17:42:26 d2.evaluation.evaluator]: Inference done 134/150. Dataloading: 0.0050 s/iter. Inference: 0.3048 s/iter. Eval: 0.5175 s/iter. Total: 0.8278 s/iter. ETA=0:00:13\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 750])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 750])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 750])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 17:42:32 d2.evaluation.evaluator]: Inference done 141/150. Dataloading: 0.0050 s/iter. Inference: 0.3042 s/iter. Eval: 0.5156 s/iter. Total: 0.8252 s/iter. ETA=0:00:07\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 608])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 608])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 17:42:37 d2.evaluation.evaluator]: Inference done 148/150. Dataloading: 0.0050 s/iter. Inference: 0.3039 s/iter. Eval: 0.5151 s/iter. Total: 0.8244 s/iter. ETA=0:00:01\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 608])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 608])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[05/20 17:42:39 d2.evaluation.evaluator]: Total inference time: 0:01:59.901005 (0.826903 s / iter per device, on 1 devices)\n",
            "[05/20 17:42:39 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:44 (0.304326 s / iter per device, on 1 devices)\n",
            "[05/20 17:42:40 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...\n",
            "[05/20 17:42:40 d2.evaluation.coco_evaluation]: Saving results to /content/output/chkpt/inference/coco_instances_results.json\n",
            "[05/20 17:42:40 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.03s)\n",
            "creating index...\n",
            "index created!\n",
            "[05/20 17:42:40 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*\n",
            "[05/20 17:42:40 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.19 seconds.\n",
            "[05/20 17:42:40 d2.evaluation.fast_eval_api]: Accumulating evaluation results...\n",
            "[05/20 17:42:40 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.06 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.241\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.407\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.242\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.057\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.243\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.412\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.320\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.432\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.447\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.109\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.483\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.789\n",
            "[05/20 17:42:40 d2.evaluation.coco_evaluation]: Evaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
            "| 24.075 | 40.736 | 24.182 | 5.662 | 24.287 | 41.184 |\n",
            "[05/20 17:42:40 d2.evaluation.coco_evaluation]: Per-category bbox AP: \n",
            "| category   | AP     | category              | AP     | category   | AP     |\n",
            "|:-----------|:-------|:----------------------|:-------|:-----------|:-------|\n",
            "| Bottle     | 53.240 | Bottle cap            | 11.908 | Can        | 41.476 |\n",
            "| Cigarette  | 1.646  | Cup                   | 31.160 | Lid        | 35.245 |\n",
            "| Other      | 20.329 | Plastic bag & wrapper | 21.663 | Pop tab    | 8.923  |\n",
            "| Straw      | 15.156 |                       |        |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.16s)\n",
            "creating index...\n",
            "index created!\n",
            "[05/20 17:42:41 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*\n",
            "[05/20 17:42:41 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.23 seconds.\n",
            "[05/20 17:42:41 d2.evaluation.fast_eval_api]: Accumulating evaluation results...\n",
            "[05/20 17:42:41 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.07 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.384\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.498\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.403\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.200\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.467\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.518\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.456\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.643\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.661\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.399\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.751\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.838\n",
            "[05/20 17:42:41 d2.evaluation.coco_evaluation]: Evaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 38.438 | 49.766 | 40.348 | 20.024 | 46.720 | 51.807 |\n",
            "[05/20 17:42:41 d2.evaluation.coco_evaluation]: Per-category segm AP: \n",
            "| category   | AP     | category              | AP     | category   | AP     |\n",
            "|:-----------|:-------|:----------------------|:-------|:-----------|:-------|\n",
            "| Bottle     | 72.835 | Bottle cap            | 39.824 | Can        | 53.375 |\n",
            "| Cigarette  | 20.578 | Cup                   | 43.965 | Lid        | 44.426 |\n",
            "| Other      | 30.475 | Plastic bag & wrapper | 35.241 | Pop tab    | 24.259 |\n",
            "| Straw      | 19.404 |                       |        |            |        |\n",
            "[05/20 17:42:41 d2.engine.defaults]: Evaluation results for TACO_val in csv format:\n",
            "[05/20 17:42:41 d2.evaluation.testing]: copypaste: Task: bbox\n",
            "[05/20 17:42:41 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl\n",
            "[05/20 17:42:41 d2.evaluation.testing]: copypaste: 24.0747,40.7358,24.1825,5.6619,24.2873,41.1844\n",
            "[05/20 17:42:41 d2.evaluation.testing]: copypaste: Task: segm\n",
            "[05/20 17:42:41 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl\n",
            "[05/20 17:42:41 d2.evaluation.testing]: copypaste: 38.4382,49.7656,40.3477,20.0243,46.7199,51.8069\n",
            "[05/20 17:42:41 d2.utils.events]:  eta: 1:27:34  iter: 2499  total_loss: 44.59  loss_ce: 1.066  loss_mask: 0.03245  loss_dice: 0.6892  loss_bbox: 0.08435  loss_giou: 0.3901  loss_ce_dn: 0.2398  loss_mask_dn: 0.03363  loss_dice_dn: 0.6441  loss_bbox_dn: 0.05338  loss_giou_dn: 0.2995  loss_ce_0: 1.23  loss_mask_0: 0.03526  loss_dice_0: 0.713  loss_bbox_0: 0.1016  loss_giou_0: 0.4995  loss_ce_dn_0: 0.7335  loss_mask_dn_0: 0.3685  loss_dice_dn_0: 3.067  loss_bbox_dn_0: 0.3117  loss_giou_dn_0: 0.8574  loss_ce_1: 1.286  loss_mask_1: 0.03678  loss_dice_1: 0.6325  loss_bbox_1: 0.09925  loss_giou_1: 0.3638  loss_ce_dn_1: 0.2804  loss_mask_dn_1: 0.03368  loss_dice_dn_1: 0.6698  loss_bbox_dn_1: 0.07949  loss_giou_dn_1: 0.3763  loss_ce_2: 1.227  loss_mask_2: 0.03545  loss_dice_2: 0.6591  loss_bbox_2: 0.07182  loss_giou_2: 0.3699  loss_ce_dn_2: 0.2544  loss_mask_dn_2: 0.03218  loss_dice_dn_2: 0.6528  loss_bbox_dn_2: 0.06703  loss_giou_dn_2: 0.3317  loss_ce_3: 1.119  loss_mask_3: 0.03563  loss_dice_3: 0.5531  loss_bbox_3: 0.08318  loss_giou_3: 0.3801  loss_ce_dn_3: 0.2526  loss_mask_dn_3: 0.033  loss_dice_dn_3: 0.6424  loss_bbox_dn_3: 0.05859  loss_giou_dn_3: 0.3009  loss_ce_4: 1.086  loss_mask_4: 0.03753  loss_dice_4: 0.4978  loss_bbox_4: 0.08313  loss_giou_4: 0.399  loss_ce_dn_4: 0.2588  loss_mask_dn_4: 0.03203  loss_dice_dn_4: 0.6562  loss_bbox_dn_4: 0.05413  loss_giou_dn_4: 0.301  loss_ce_5: 0.9895  loss_mask_5: 0.0341  loss_dice_5: 0.7324  loss_bbox_5: 0.06744  loss_giou_5: 0.3622  loss_ce_dn_5: 0.2389  loss_mask_dn_5: 0.03134  loss_dice_dn_5: 0.6567  loss_bbox_dn_5: 0.05473  loss_giou_dn_5: 0.3018  loss_ce_6: 1.011  loss_mask_6: 0.03044  loss_dice_6: 0.6411  loss_bbox_6: 0.0682  loss_giou_6: 0.3606  loss_ce_dn_6: 0.2236  loss_mask_dn_6: 0.03376  loss_dice_dn_6: 0.6385  loss_bbox_dn_6: 0.05356  loss_giou_dn_6: 0.2983  loss_ce_7: 1.03  loss_mask_7: 0.03343  loss_dice_7: 0.7361  loss_bbox_7: 0.06466  loss_giou_7: 0.3564  loss_ce_dn_7: 0.2283  loss_mask_dn_7: 0.03352  loss_dice_dn_7: 0.6324  loss_bbox_dn_7: 0.05325  loss_giou_dn_7: 0.3055  loss_ce_8: 1.024  loss_mask_8: 0.03527  loss_dice_8: 0.6245  loss_bbox_8: 0.08153  loss_giou_8: 0.3954  loss_ce_dn_8: 0.2334  loss_mask_dn_8: 0.03365  loss_dice_dn_8: 0.643  loss_bbox_dn_8: 0.05322  loss_giou_dn_8: 0.2984  loss_ce_interm: 1.169  loss_mask_interm: 0.04233  loss_dice_interm: 0.7269  loss_bbox_interm: 0.09886  loss_giou_interm: 0.4383  time: 1.9656  data_time: 0.1050  lr: 1e-06  max_mem: 6639M\n",
            "[05/20 17:43:15 d2.utils.events]:  eta: 1:26:59  iter: 2519  total_loss: 51.31  loss_ce: 1.259  loss_mask: 0.03008  loss_dice: 0.6285  loss_bbox: 0.07592  loss_giou: 0.5172  loss_ce_dn: 0.2173  loss_mask_dn: 0.03402  loss_dice_dn: 0.517  loss_bbox_dn: 0.04445  loss_giou_dn: 0.3857  loss_ce_0: 1.445  loss_mask_0: 0.03374  loss_dice_0: 0.8346  loss_bbox_0: 0.0925  loss_giou_0: 0.5808  loss_ce_dn_0: 0.7789  loss_mask_dn_0: 0.1279  loss_dice_dn_0: 2.249  loss_bbox_dn_0: 0.2259  loss_giou_dn_0: 0.8598  loss_ce_1: 1.454  loss_mask_1: 0.02576  loss_dice_1: 0.5222  loss_bbox_1: 0.07801  loss_giou_1: 0.5558  loss_ce_dn_1: 0.3307  loss_mask_dn_1: 0.03077  loss_dice_dn_1: 0.5642  loss_bbox_dn_1: 0.06962  loss_giou_dn_1: 0.4778  loss_ce_2: 1.39  loss_mask_2: 0.02991  loss_dice_2: 0.5883  loss_bbox_2: 0.09576  loss_giou_2: 0.5082  loss_ce_dn_2: 0.2897  loss_mask_dn_2: 0.03029  loss_dice_dn_2: 0.5742  loss_bbox_dn_2: 0.05548  loss_giou_dn_2: 0.4183  loss_ce_3: 1.436  loss_mask_3: 0.02724  loss_dice_3: 0.6124  loss_bbox_3: 0.09615  loss_giou_3: 0.5405  loss_ce_dn_3: 0.2694  loss_mask_dn_3: 0.03283  loss_dice_dn_3: 0.5608  loss_bbox_dn_3: 0.0484  loss_giou_dn_3: 0.4175  loss_ce_4: 1.44  loss_mask_4: 0.0335  loss_dice_4: 0.6689  loss_bbox_4: 0.08151  loss_giou_4: 0.4379  loss_ce_dn_4: 0.2469  loss_mask_dn_4: 0.03305  loss_dice_dn_4: 0.5291  loss_bbox_dn_4: 0.04582  loss_giou_dn_4: 0.4083  loss_ce_5: 1.331  loss_mask_5: 0.03237  loss_dice_5: 0.529  loss_bbox_5: 0.09114  loss_giou_5: 0.5041  loss_ce_dn_5: 0.2428  loss_mask_dn_5: 0.03175  loss_dice_dn_5: 0.4978  loss_bbox_dn_5: 0.04414  loss_giou_dn_5: 0.3902  loss_ce_6: 1.318  loss_mask_6: 0.02737  loss_dice_6: 0.6266  loss_bbox_6: 0.08487  loss_giou_6: 0.5116  loss_ce_dn_6: 0.2298  loss_mask_dn_6: 0.03228  loss_dice_dn_6: 0.492  loss_bbox_dn_6: 0.04363  loss_giou_dn_6: 0.3836  loss_ce_7: 1.241  loss_mask_7: 0.02541  loss_dice_7: 0.7379  loss_bbox_7: 0.0876  loss_giou_7: 0.5677  loss_ce_dn_7: 0.2214  loss_mask_dn_7: 0.0333  loss_dice_dn_7: 0.5015  loss_bbox_dn_7: 0.04416  loss_giou_dn_7: 0.3933  loss_ce_8: 1.244  loss_mask_8: 0.03074  loss_dice_8: 0.637  loss_bbox_8: 0.07578  loss_giou_8: 0.5077  loss_ce_dn_8: 0.2226  loss_mask_dn_8: 0.0346  loss_dice_dn_8: 0.569  loss_bbox_dn_8: 0.04398  loss_giou_dn_8: 0.3837  loss_ce_interm: 1.484  loss_mask_interm: 0.02492  loss_dice_interm: 0.5175  loss_bbox_interm: 0.08376  loss_giou_interm: 0.5313  time: 1.9635  data_time: 0.1023  lr: 1e-06  max_mem: 6639M\n",
            "[05/20 17:43:48 d2.utils.events]:  eta: 1:26:20  iter: 2539  total_loss: 33.41  loss_ce: 0.7545  loss_mask: 0.02646  loss_dice: 0.3883  loss_bbox: 0.04023  loss_giou: 0.2439  loss_ce_dn: 0.1774  loss_mask_dn: 0.02516  loss_dice_dn: 0.4412  loss_bbox_dn: 0.03567  loss_giou_dn: 0.2287  loss_ce_0: 1.131  loss_mask_0: 0.03493  loss_dice_0: 0.5154  loss_bbox_0: 0.06163  loss_giou_0: 0.3969  loss_ce_dn_0: 0.705  loss_mask_dn_0: 0.1843  loss_dice_dn_0: 1.957  loss_bbox_dn_0: 0.2984  loss_giou_dn_0: 0.863  loss_ce_1: 1.033  loss_mask_1: 0.02951  loss_dice_1: 0.3762  loss_bbox_1: 0.04787  loss_giou_1: 0.3568  loss_ce_dn_1: 0.2402  loss_mask_dn_1: 0.03168  loss_dice_dn_1: 0.4224  loss_bbox_dn_1: 0.06359  loss_giou_dn_1: 0.3206  loss_ce_2: 0.926  loss_mask_2: 0.02638  loss_dice_2: 0.3985  loss_bbox_2: 0.05093  loss_giou_2: 0.2747  loss_ce_dn_2: 0.199  loss_mask_dn_2: 0.02851  loss_dice_dn_2: 0.4142  loss_bbox_dn_2: 0.04642  loss_giou_dn_2: 0.2558  loss_ce_3: 0.8709  loss_mask_3: 0.02749  loss_dice_3: 0.4956  loss_bbox_3: 0.04041  loss_giou_3: 0.2771  loss_ce_dn_3: 0.1893  loss_mask_dn_3: 0.02568  loss_dice_dn_3: 0.4186  loss_bbox_dn_3: 0.03908  loss_giou_dn_3: 0.2327  loss_ce_4: 0.8297  loss_mask_4: 0.02962  loss_dice_4: 0.4239  loss_bbox_4: 0.03646  loss_giou_4: 0.25  loss_ce_dn_4: 0.1797  loss_mask_dn_4: 0.02552  loss_dice_dn_4: 0.4344  loss_bbox_dn_4: 0.03854  loss_giou_dn_4: 0.2153  loss_ce_5: 0.7945  loss_mask_5: 0.02437  loss_dice_5: 0.3572  loss_bbox_5: 0.04087  loss_giou_5: 0.2476  loss_ce_dn_5: 0.1772  loss_mask_dn_5: 0.02435  loss_dice_dn_5: 0.4379  loss_bbox_dn_5: 0.03655  loss_giou_dn_5: 0.2243  loss_ce_6: 0.7712  loss_mask_6: 0.0275  loss_dice_6: 0.3095  loss_bbox_6: 0.04168  loss_giou_6: 0.2404  loss_ce_dn_6: 0.1788  loss_mask_dn_6: 0.02584  loss_dice_dn_6: 0.4357  loss_bbox_dn_6: 0.03688  loss_giou_dn_6: 0.2271  loss_ce_7: 0.7762  loss_mask_7: 0.02868  loss_dice_7: 0.3436  loss_bbox_7: 0.04132  loss_giou_7: 0.2366  loss_ce_dn_7: 0.1805  loss_mask_dn_7: 0.02603  loss_dice_dn_7: 0.441  loss_bbox_dn_7: 0.03649  loss_giou_dn_7: 0.2284  loss_ce_8: 0.7523  loss_mask_8: 0.02546  loss_dice_8: 0.4624  loss_bbox_8: 0.03924  loss_giou_8: 0.2407  loss_ce_dn_8: 0.1737  loss_mask_dn_8: 0.02472  loss_dice_dn_8: 0.4293  loss_bbox_dn_8: 0.03564  loss_giou_dn_8: 0.2253  loss_ce_interm: 1.134  loss_mask_interm: 0.02466  loss_dice_interm: 0.3517  loss_bbox_interm: 0.05646  loss_giou_interm: 0.3927  time: 1.9610  data_time: 0.0487  lr: 1e-06  max_mem: 6639M\n",
            "[05/20 17:44:24 d2.utils.events]:  eta: 1:25:57  iter: 2559  total_loss: 44.83  loss_ce: 1.146  loss_mask: 0.04264  loss_dice: 0.5238  loss_bbox: 0.06119  loss_giou: 0.2861  loss_ce_dn: 0.1998  loss_mask_dn: 0.03632  loss_dice_dn: 0.6205  loss_bbox_dn: 0.04856  loss_giou_dn: 0.2842  loss_ce_0: 1.335  loss_mask_0: 0.03625  loss_dice_0: 0.5642  loss_bbox_0: 0.07464  loss_giou_0: 0.4466  loss_ce_dn_0: 0.7419  loss_mask_dn_0: 0.0648  loss_dice_dn_0: 2.314  loss_bbox_dn_0: 0.1622  loss_giou_dn_0: 0.8583  loss_ce_1: 1.29  loss_mask_1: 0.04473  loss_dice_1: 0.658  loss_bbox_1: 0.07547  loss_giou_1: 0.3123  loss_ce_dn_1: 0.278  loss_mask_dn_1: 0.03811  loss_dice_dn_1: 0.6764  loss_bbox_dn_1: 0.07154  loss_giou_dn_1: 0.4063  loss_ce_2: 1.337  loss_mask_2: 0.04379  loss_dice_2: 0.5181  loss_bbox_2: 0.06623  loss_giou_2: 0.3315  loss_ce_dn_2: 0.244  loss_mask_dn_2: 0.03442  loss_dice_dn_2: 0.6641  loss_bbox_dn_2: 0.06686  loss_giou_dn_2: 0.3708  loss_ce_3: 1.209  loss_mask_3: 0.03558  loss_dice_3: 0.5567  loss_bbox_3: 0.06257  loss_giou_3: 0.3026  loss_ce_dn_3: 0.2304  loss_mask_dn_3: 0.0391  loss_dice_dn_3: 0.6153  loss_bbox_dn_3: 0.05172  loss_giou_dn_3: 0.3064  loss_ce_4: 1.178  loss_mask_4: 0.0421  loss_dice_4: 0.5912  loss_bbox_4: 0.07199  loss_giou_4: 0.2875  loss_ce_dn_4: 0.2259  loss_mask_dn_4: 0.03901  loss_dice_dn_4: 0.629  loss_bbox_dn_4: 0.04588  loss_giou_dn_4: 0.2863  loss_ce_5: 1.191  loss_mask_5: 0.04047  loss_dice_5: 0.6465  loss_bbox_5: 0.07331  loss_giou_5: 0.3302  loss_ce_dn_5: 0.203  loss_mask_dn_5: 0.03429  loss_dice_dn_5: 0.6177  loss_bbox_dn_5: 0.04619  loss_giou_dn_5: 0.284  loss_ce_6: 1.16  loss_mask_6: 0.0397  loss_dice_6: 0.5776  loss_bbox_6: 0.06437  loss_giou_6: 0.3063  loss_ce_dn_6: 0.1915  loss_mask_dn_6: 0.03518  loss_dice_dn_6: 0.6196  loss_bbox_dn_6: 0.047  loss_giou_dn_6: 0.2851  loss_ce_7: 1.135  loss_mask_7: 0.03306  loss_dice_7: 0.512  loss_bbox_7: 0.06034  loss_giou_7: 0.2945  loss_ce_dn_7: 0.1915  loss_mask_dn_7: 0.03501  loss_dice_dn_7: 0.624  loss_bbox_dn_7: 0.04251  loss_giou_dn_7: 0.2892  loss_ce_8: 1.159  loss_mask_8: 0.04243  loss_dice_8: 0.6603  loss_bbox_8: 0.0745  loss_giou_8: 0.2953  loss_ce_dn_8: 0.1956  loss_mask_dn_8: 0.03661  loss_dice_dn_8: 0.6193  loss_bbox_dn_8: 0.05079  loss_giou_dn_8: 0.2926  loss_ce_interm: 1.382  loss_mask_interm: 0.04037  loss_dice_interm: 0.6289  loss_bbox_interm: 0.1289  loss_giou_interm: 0.6021  time: 1.9595  data_time: 0.0949  lr: 1e-06  max_mem: 6639M\n",
            "[05/20 17:44:57 d2.utils.events]:  eta: 1:25:25  iter: 2579  total_loss: 48.99  loss_ce: 1.092  loss_mask: 0.03702  loss_dice: 0.6055  loss_bbox: 0.06524  loss_giou: 0.4391  loss_ce_dn: 0.1729  loss_mask_dn: 0.03923  loss_dice_dn: 0.6495  loss_bbox_dn: 0.04069  loss_giou_dn: 0.3211  loss_ce_0: 1.441  loss_mask_0: 0.0393  loss_dice_0: 0.6601  loss_bbox_0: 0.09064  loss_giou_0: 0.5343  loss_ce_dn_0: 0.7674  loss_mask_dn_0: 0.1073  loss_dice_dn_0: 2.71  loss_bbox_dn_0: 0.2228  loss_giou_dn_0: 0.8561  loss_ce_1: 1.409  loss_mask_1: 0.03886  loss_dice_1: 0.8326  loss_bbox_1: 0.05497  loss_giou_1: 0.4126  loss_ce_dn_1: 0.2581  loss_mask_dn_1: 0.03763  loss_dice_dn_1: 0.6797  loss_bbox_dn_1: 0.06255  loss_giou_dn_1: 0.4044  loss_ce_2: 1.134  loss_mask_2: 0.04345  loss_dice_2: 0.8848  loss_bbox_2: 0.07264  loss_giou_2: 0.4217  loss_ce_dn_2: 0.2244  loss_mask_dn_2: 0.04184  loss_dice_dn_2: 0.66  loss_bbox_dn_2: 0.05404  loss_giou_dn_2: 0.3592  loss_ce_3: 1.023  loss_mask_3: 0.04513  loss_dice_3: 0.7795  loss_bbox_3: 0.07126  loss_giou_3: 0.4159  loss_ce_dn_3: 0.2051  loss_mask_dn_3: 0.04096  loss_dice_dn_3: 0.6959  loss_bbox_dn_3: 0.04412  loss_giou_dn_3: 0.3397  loss_ce_4: 1.043  loss_mask_4: 0.03572  loss_dice_4: 0.8129  loss_bbox_4: 0.06075  loss_giou_4: 0.414  loss_ce_dn_4: 0.1862  loss_mask_dn_4: 0.04189  loss_dice_dn_4: 0.6377  loss_bbox_dn_4: 0.04092  loss_giou_dn_4: 0.3289  loss_ce_5: 1.052  loss_mask_5: 0.03519  loss_dice_5: 0.7029  loss_bbox_5: 0.06099  loss_giou_5: 0.3968  loss_ce_dn_5: 0.184  loss_mask_dn_5: 0.04135  loss_dice_dn_5: 0.6578  loss_bbox_dn_5: 0.03785  loss_giou_dn_5: 0.3236  loss_ce_6: 1.023  loss_mask_6: 0.03471  loss_dice_6: 0.7877  loss_bbox_6: 0.0608  loss_giou_6: 0.4011  loss_ce_dn_6: 0.1741  loss_mask_dn_6: 0.04026  loss_dice_dn_6: 0.672  loss_bbox_dn_6: 0.04016  loss_giou_dn_6: 0.3242  loss_ce_7: 1.04  loss_mask_7: 0.03393  loss_dice_7: 0.5224  loss_bbox_7: 0.06748  loss_giou_7: 0.4001  loss_ce_dn_7: 0.1703  loss_mask_dn_7: 0.039  loss_dice_dn_7: 0.646  loss_bbox_dn_7: 0.04121  loss_giou_dn_7: 0.3212  loss_ce_8: 1.032  loss_mask_8: 0.03791  loss_dice_8: 0.7039  loss_bbox_8: 0.05997  loss_giou_8: 0.3951  loss_ce_dn_8: 0.1688  loss_mask_dn_8: 0.04036  loss_dice_dn_8: 0.6793  loss_bbox_dn_8: 0.04087  loss_giou_dn_8: 0.3202  loss_ce_interm: 1.486  loss_mask_interm: 0.03849  loss_dice_interm: 0.6382  loss_bbox_interm: 0.1051  loss_giou_interm: 0.5334  time: 1.9572  data_time: 0.0618  lr: 1e-06  max_mem: 6639M\n",
            "[05/20 17:45:31 d2.utils.events]:  eta: 1:24:50  iter: 2599  total_loss: 48.82  loss_ce: 1.113  loss_mask: 0.03266  loss_dice: 1.009  loss_bbox: 0.06883  loss_giou: 0.5649  loss_ce_dn: 0.201  loss_mask_dn: 0.0277  loss_dice_dn: 0.709  loss_bbox_dn: 0.03821  loss_giou_dn: 0.3744  loss_ce_0: 1.48  loss_mask_0: 0.04035  loss_dice_0: 0.8198  loss_bbox_0: 0.09291  loss_giou_0: 0.6001  loss_ce_dn_0: 0.7301  loss_mask_dn_0: 0.1874  loss_dice_dn_0: 3.099  loss_bbox_dn_0: 0.2252  loss_giou_dn_0: 0.8536  loss_ce_1: 1.402  loss_mask_1: 0.04156  loss_dice_1: 0.7792  loss_bbox_1: 0.1009  loss_giou_1: 0.6151  loss_ce_dn_1: 0.2848  loss_mask_dn_1: 0.02757  loss_dice_dn_1: 0.7077  loss_bbox_dn_1: 0.05657  loss_giou_dn_1: 0.4514  loss_ce_2: 1.344  loss_mask_2: 0.04392  loss_dice_2: 1.044  loss_bbox_2: 0.07328  loss_giou_2: 0.5877  loss_ce_dn_2: 0.2556  loss_mask_dn_2: 0.0271  loss_dice_dn_2: 0.7154  loss_bbox_dn_2: 0.04189  loss_giou_dn_2: 0.3871  loss_ce_3: 1.259  loss_mask_3: 0.04475  loss_dice_3: 0.9928  loss_bbox_3: 0.07611  loss_giou_3: 0.5966  loss_ce_dn_3: 0.2299  loss_mask_dn_3: 0.02923  loss_dice_dn_3: 0.6585  loss_bbox_dn_3: 0.04019  loss_giou_dn_3: 0.362  loss_ce_4: 1.204  loss_mask_4: 0.04083  loss_dice_4: 0.8646  loss_bbox_4: 0.07557  loss_giou_4: 0.5747  loss_ce_dn_4: 0.2105  loss_mask_dn_4: 0.02868  loss_dice_dn_4: 0.6558  loss_bbox_dn_4: 0.03979  loss_giou_dn_4: 0.3644  loss_ce_5: 1.198  loss_mask_5: 0.03091  loss_dice_5: 0.8762  loss_bbox_5: 0.06941  loss_giou_5: 0.5781  loss_ce_dn_5: 0.2112  loss_mask_dn_5: 0.02925  loss_dice_dn_5: 0.6999  loss_bbox_dn_5: 0.03801  loss_giou_dn_5: 0.3639  loss_ce_6: 1.156  loss_mask_6: 0.03303  loss_dice_6: 0.9264  loss_bbox_6: 0.07504  loss_giou_6: 0.5665  loss_ce_dn_6: 0.2045  loss_mask_dn_6: 0.02752  loss_dice_dn_6: 0.6916  loss_bbox_dn_6: 0.03849  loss_giou_dn_6: 0.3693  loss_ce_7: 1.13  loss_mask_7: 0.04203  loss_dice_7: 0.7906  loss_bbox_7: 0.06984  loss_giou_7: 0.5666  loss_ce_dn_7: 0.2003  loss_mask_dn_7: 0.02772  loss_dice_dn_7: 0.6533  loss_bbox_dn_7: 0.03984  loss_giou_dn_7: 0.3717  loss_ce_8: 1.103  loss_mask_8: 0.0389  loss_dice_8: 1.002  loss_bbox_8: 0.07083  loss_giou_8: 0.5617  loss_ce_dn_8: 0.2064  loss_mask_dn_8: 0.02869  loss_dice_dn_8: 0.6991  loss_bbox_dn_8: 0.03898  loss_giou_dn_8: 0.3751  loss_ce_interm: 1.428  loss_mask_interm: 0.03265  loss_dice_interm: 0.6583  loss_bbox_interm: 0.1251  loss_giou_interm: 0.6852  time: 1.9554  data_time: 0.0876  lr: 1e-06  max_mem: 6639M\n",
            "[05/20 17:46:07 d2.utils.events]:  eta: 1:24:16  iter: 2619  total_loss: 40.59  loss_ce: 0.9145  loss_mask: 0.03373  loss_dice: 0.5651  loss_bbox: 0.0846  loss_giou: 0.3424  loss_ce_dn: 0.1586  loss_mask_dn: 0.03585  loss_dice_dn: 0.6773  loss_bbox_dn: 0.05464  loss_giou_dn: 0.272  loss_ce_0: 1.252  loss_mask_0: 0.04967  loss_dice_0: 0.7803  loss_bbox_0: 0.08431  loss_giou_0: 0.5671  loss_ce_dn_0: 0.8426  loss_mask_dn_0: 0.1583  loss_dice_dn_0: 2.632  loss_bbox_dn_0: 0.2381  loss_giou_dn_0: 0.8496  loss_ce_1: 1.316  loss_mask_1: 0.04643  loss_dice_1: 0.9002  loss_bbox_1: 0.0889  loss_giou_1: 0.477  loss_ce_dn_1: 0.2696  loss_mask_dn_1: 0.0357  loss_dice_dn_1: 0.6948  loss_bbox_dn_1: 0.08055  loss_giou_dn_1: 0.3903  loss_ce_2: 1.264  loss_mask_2: 0.04694  loss_dice_2: 0.802  loss_bbox_2: 0.08712  loss_giou_2: 0.4513  loss_ce_dn_2: 0.1892  loss_mask_dn_2: 0.03138  loss_dice_dn_2: 0.6663  loss_bbox_dn_2: 0.06511  loss_giou_dn_2: 0.3411  loss_ce_3: 1.093  loss_mask_3: 0.04525  loss_dice_3: 0.79  loss_bbox_3: 0.08742  loss_giou_3: 0.4295  loss_ce_dn_3: 0.1579  loss_mask_dn_3: 0.03183  loss_dice_dn_3: 0.6932  loss_bbox_dn_3: 0.06175  loss_giou_dn_3: 0.2936  loss_ce_4: 1.043  loss_mask_4: 0.04065  loss_dice_4: 0.8993  loss_bbox_4: 0.07285  loss_giou_4: 0.3726  loss_ce_dn_4: 0.1688  loss_mask_dn_4: 0.03664  loss_dice_dn_4: 0.6701  loss_bbox_dn_4: 0.05987  loss_giou_dn_4: 0.2837  loss_ce_5: 1.095  loss_mask_5: 0.03551  loss_dice_5: 0.6149  loss_bbox_5: 0.07508  loss_giou_5: 0.344  loss_ce_dn_5: 0.1593  loss_mask_dn_5: 0.03328  loss_dice_dn_5: 0.6289  loss_bbox_dn_5: 0.05719  loss_giou_dn_5: 0.2807  loss_ce_6: 1.034  loss_mask_6: 0.03154  loss_dice_6: 0.7245  loss_bbox_6: 0.06896  loss_giou_6: 0.3756  loss_ce_dn_6: 0.1641  loss_mask_dn_6: 0.03476  loss_dice_dn_6: 0.6903  loss_bbox_dn_6: 0.05659  loss_giou_dn_6: 0.2774  loss_ce_7: 0.964  loss_mask_7: 0.03696  loss_dice_7: 0.8422  loss_bbox_7: 0.08656  loss_giou_7: 0.3693  loss_ce_dn_7: 0.1593  loss_mask_dn_7: 0.03511  loss_dice_dn_7: 0.6665  loss_bbox_dn_7: 0.05556  loss_giou_dn_7: 0.2746  loss_ce_8: 0.9086  loss_mask_8: 0.03354  loss_dice_8: 0.6353  loss_bbox_8: 0.08673  loss_giou_8: 0.339  loss_ce_dn_8: 0.1622  loss_mask_dn_8: 0.03592  loss_dice_dn_8: 0.7127  loss_bbox_dn_8: 0.05551  loss_giou_dn_8: 0.276  loss_ce_interm: 1.136  loss_mask_interm: 0.03848  loss_dice_interm: 0.7227  loss_bbox_interm: 0.1171  loss_giou_interm: 0.4827  time: 1.9541  data_time: 0.1244  lr: 1e-06  max_mem: 6639M\n",
            "[05/20 17:46:43 d2.utils.events]:  eta: 1:23:45  iter: 2639  total_loss: 37.38  loss_ce: 0.8914  loss_mask: 0.0471  loss_dice: 0.4653  loss_bbox: 0.06062  loss_giou: 0.2865  loss_ce_dn: 0.1738  loss_mask_dn: 0.0412  loss_dice_dn: 0.4981  loss_bbox_dn: 0.051  loss_giou_dn: 0.2457  loss_ce_0: 1.135  loss_mask_0: 0.03907  loss_dice_0: 0.4855  loss_bbox_0: 0.07477  loss_giou_0: 0.3417  loss_ce_dn_0: 0.6341  loss_mask_dn_0: 0.1707  loss_dice_dn_0: 2.223  loss_bbox_dn_0: 0.3296  loss_giou_dn_0: 0.853  loss_ce_1: 1.093  loss_mask_1: 0.04326  loss_dice_1: 0.4489  loss_bbox_1: 0.05841  loss_giou_1: 0.3034  loss_ce_dn_1: 0.2551  loss_mask_dn_1: 0.03591  loss_dice_dn_1: 0.5185  loss_bbox_dn_1: 0.07871  loss_giou_dn_1: 0.3238  loss_ce_2: 1.084  loss_mask_2: 0.0424  loss_dice_2: 0.4528  loss_bbox_2: 0.05338  loss_giou_2: 0.2669  loss_ce_dn_2: 0.2082  loss_mask_dn_2: 0.03752  loss_dice_dn_2: 0.5285  loss_bbox_dn_2: 0.06246  loss_giou_dn_2: 0.287  loss_ce_3: 0.9977  loss_mask_3: 0.03892  loss_dice_3: 0.4819  loss_bbox_3: 0.06034  loss_giou_3: 0.2804  loss_ce_dn_3: 0.2016  loss_mask_dn_3: 0.03946  loss_dice_dn_3: 0.5165  loss_bbox_dn_3: 0.05796  loss_giou_dn_3: 0.2627  loss_ce_4: 0.9128  loss_mask_4: 0.03123  loss_dice_4: 0.5065  loss_bbox_4: 0.06143  loss_giou_4: 0.2854  loss_ce_dn_4: 0.1914  loss_mask_dn_4: 0.04294  loss_dice_dn_4: 0.5411  loss_bbox_dn_4: 0.05411  loss_giou_dn_4: 0.2514  loss_ce_5: 0.8589  loss_mask_5: 0.03773  loss_dice_5: 0.4579  loss_bbox_5: 0.06337  loss_giou_5: 0.2879  loss_ce_dn_5: 0.1891  loss_mask_dn_5: 0.04346  loss_dice_dn_5: 0.5203  loss_bbox_dn_5: 0.05012  loss_giou_dn_5: 0.2538  loss_ce_6: 0.9021  loss_mask_6: 0.04226  loss_dice_6: 0.5039  loss_bbox_6: 0.06447  loss_giou_6: 0.2863  loss_ce_dn_6: 0.1793  loss_mask_dn_6: 0.04207  loss_dice_dn_6: 0.5147  loss_bbox_dn_6: 0.04964  loss_giou_dn_6: 0.2515  loss_ce_7: 0.869  loss_mask_7: 0.04908  loss_dice_7: 0.5731  loss_bbox_7: 0.06341  loss_giou_7: 0.2811  loss_ce_dn_7: 0.1828  loss_mask_dn_7: 0.0424  loss_dice_dn_7: 0.5099  loss_bbox_dn_7: 0.04861  loss_giou_dn_7: 0.2502  loss_ce_8: 0.901  loss_mask_8: 0.04214  loss_dice_8: 0.5204  loss_bbox_8: 0.06094  loss_giou_8: 0.2883  loss_ce_dn_8: 0.181  loss_mask_dn_8: 0.04094  loss_dice_dn_8: 0.4852  loss_bbox_dn_8: 0.04994  loss_giou_dn_8: 0.2476  loss_ce_interm: 1.166  loss_mask_interm: 0.04602  loss_dice_interm: 0.5223  loss_bbox_interm: 0.09443  loss_giou_interm: 0.3639  time: 1.9530  data_time: 0.1249  lr: 1e-06  max_mem: 6639M\n",
            "[05/20 17:47:18 d2.utils.events]:  eta: 1:23:13  iter: 2659  total_loss: 39.27  loss_ce: 0.9514  loss_mask: 0.03914  loss_dice: 0.4048  loss_bbox: 0.05548  loss_giou: 0.2647  loss_ce_dn: 0.1706  loss_mask_dn: 0.03325  loss_dice_dn: 0.4863  loss_bbox_dn: 0.03743  loss_giou_dn: 0.248  loss_ce_0: 1.36  loss_mask_0: 0.0379  loss_dice_0: 0.4247  loss_bbox_0: 0.0587  loss_giou_0: 0.3132  loss_ce_dn_0: 0.7617  loss_mask_dn_0: 0.2583  loss_dice_dn_0: 1.957  loss_bbox_dn_0: 0.3861  loss_giou_dn_0: 0.8561  loss_ce_1: 1.261  loss_mask_1: 0.0369  loss_dice_1: 0.4888  loss_bbox_1: 0.05032  loss_giou_1: 0.2419  loss_ce_dn_1: 0.266  loss_mask_dn_1: 0.03544  loss_dice_dn_1: 0.5033  loss_bbox_dn_1: 0.08024  loss_giou_dn_1: 0.3508  loss_ce_2: 1.156  loss_mask_2: 0.04194  loss_dice_2: 0.4583  loss_bbox_2: 0.06353  loss_giou_2: 0.2725  loss_ce_dn_2: 0.2179  loss_mask_dn_2: 0.03382  loss_dice_dn_2: 0.4995  loss_bbox_dn_2: 0.06228  loss_giou_dn_2: 0.2751  loss_ce_3: 1.108  loss_mask_3: 0.03615  loss_dice_3: 0.4638  loss_bbox_3: 0.05181  loss_giou_3: 0.246  loss_ce_dn_3: 0.1853  loss_mask_dn_3: 0.03573  loss_dice_dn_3: 0.4542  loss_bbox_dn_3: 0.04895  loss_giou_dn_3: 0.2429  loss_ce_4: 1.136  loss_mask_4: 0.0365  loss_dice_4: 0.479  loss_bbox_4: 0.05335  loss_giou_4: 0.2456  loss_ce_dn_4: 0.1799  loss_mask_dn_4: 0.03494  loss_dice_dn_4: 0.4537  loss_bbox_dn_4: 0.04546  loss_giou_dn_4: 0.252  loss_ce_5: 0.9622  loss_mask_5: 0.03631  loss_dice_5: 0.3548  loss_bbox_5: 0.05785  loss_giou_5: 0.2667  loss_ce_dn_5: 0.1715  loss_mask_dn_5: 0.03385  loss_dice_dn_5: 0.5049  loss_bbox_dn_5: 0.04222  loss_giou_dn_5: 0.2456  loss_ce_6: 1.034  loss_mask_6: 0.03754  loss_dice_6: 0.4102  loss_bbox_6: 0.05913  loss_giou_6: 0.2669  loss_ce_dn_6: 0.1725  loss_mask_dn_6: 0.03352  loss_dice_dn_6: 0.5036  loss_bbox_dn_6: 0.04116  loss_giou_dn_6: 0.2511  loss_ce_7: 0.9836  loss_mask_7: 0.04146  loss_dice_7: 0.4575  loss_bbox_7: 0.05139  loss_giou_7: 0.2642  loss_ce_dn_7: 0.1712  loss_mask_dn_7: 0.03402  loss_dice_dn_7: 0.4768  loss_bbox_dn_7: 0.0395  loss_giou_dn_7: 0.2471  loss_ce_8: 0.9558  loss_mask_8: 0.03621  loss_dice_8: 0.4016  loss_bbox_8: 0.05918  loss_giou_8: 0.2673  loss_ce_dn_8: 0.1714  loss_mask_dn_8: 0.03284  loss_dice_dn_8: 0.4771  loss_bbox_dn_8: 0.03828  loss_giou_dn_8: 0.2501  loss_ce_interm: 1.35  loss_mask_interm: 0.03833  loss_dice_interm: 0.4403  loss_bbox_interm: 0.1029  loss_giou_interm: 0.4187  time: 1.9511  data_time: 0.1013  lr: 1e-06  max_mem: 6639M\n",
            "[05/20 17:47:51 d2.utils.events]:  eta: 1:22:40  iter: 2679  total_loss: 37.85  loss_ce: 0.9011  loss_mask: 0.02792  loss_dice: 0.4651  loss_bbox: 0.07161  loss_giou: 0.4115  loss_ce_dn: 0.21  loss_mask_dn: 0.02686  loss_dice_dn: 0.5312  loss_bbox_dn: 0.03453  loss_giou_dn: 0.3401  loss_ce_0: 1.21  loss_mask_0: 0.02998  loss_dice_0: 0.6838  loss_bbox_0: 0.06671  loss_giou_0: 0.542  loss_ce_dn_0: 0.7769  loss_mask_dn_0: 0.1384  loss_dice_dn_0: 2.672  loss_bbox_dn_0: 0.2506  loss_giou_dn_0: 0.8515  loss_ce_1: 1.093  loss_mask_1: 0.02999  loss_dice_1: 0.6988  loss_bbox_1: 0.06114  loss_giou_1: 0.4145  loss_ce_dn_1: 0.281  loss_mask_dn_1: 0.02184  loss_dice_dn_1: 0.5846  loss_bbox_dn_1: 0.06642  loss_giou_dn_1: 0.3996  loss_ce_2: 0.9449  loss_mask_2: 0.02495  loss_dice_2: 0.543  loss_bbox_2: 0.0585  loss_giou_2: 0.415  loss_ce_dn_2: 0.2656  loss_mask_dn_2: 0.0235  loss_dice_dn_2: 0.638  loss_bbox_dn_2: 0.04751  loss_giou_dn_2: 0.3623  loss_ce_3: 0.8785  loss_mask_3: 0.02628  loss_dice_3: 0.6492  loss_bbox_3: 0.06104  loss_giou_3: 0.3946  loss_ce_dn_3: 0.2495  loss_mask_dn_3: 0.02565  loss_dice_dn_3: 0.5933  loss_bbox_dn_3: 0.04327  loss_giou_dn_3: 0.3569  loss_ce_4: 0.9181  loss_mask_4: 0.02498  loss_dice_4: 0.5513  loss_bbox_4: 0.07378  loss_giou_4: 0.3738  loss_ce_dn_4: 0.2353  loss_mask_dn_4: 0.02578  loss_dice_dn_4: 0.5165  loss_bbox_dn_4: 0.03874  loss_giou_dn_4: 0.3469  loss_ce_5: 0.798  loss_mask_5: 0.028  loss_dice_5: 0.5287  loss_bbox_5: 0.07109  loss_giou_5: 0.3981  loss_ce_dn_5: 0.2143  loss_mask_dn_5: 0.02608  loss_dice_dn_5: 0.5917  loss_bbox_dn_5: 0.03618  loss_giou_dn_5: 0.3449  loss_ce_6: 0.8547  loss_mask_6: 0.02603  loss_dice_6: 0.6206  loss_bbox_6: 0.07187  loss_giou_6: 0.3969  loss_ce_dn_6: 0.2169  loss_mask_dn_6: 0.02633  loss_dice_dn_6: 0.5465  loss_bbox_dn_6: 0.03514  loss_giou_dn_6: 0.3426  loss_ce_7: 0.8632  loss_mask_7: 0.03114  loss_dice_7: 0.4674  loss_bbox_7: 0.07071  loss_giou_7: 0.3959  loss_ce_dn_7: 0.2074  loss_mask_dn_7: 0.02636  loss_dice_dn_7: 0.5811  loss_bbox_dn_7: 0.03674  loss_giou_dn_7: 0.3405  loss_ce_8: 0.8631  loss_mask_8: 0.02591  loss_dice_8: 0.5493  loss_bbox_8: 0.06929  loss_giou_8: 0.3964  loss_ce_dn_8: 0.2156  loss_mask_dn_8: 0.02672  loss_dice_dn_8: 0.5638  loss_bbox_dn_8: 0.0365  loss_giou_dn_8: 0.3426  loss_ce_interm: 1.071  loss_mask_interm: 0.02628  loss_dice_interm: 0.6992  loss_bbox_interm: 0.09956  loss_giou_interm: 0.5686  time: 1.9489  data_time: 0.0765  lr: 1e-06  max_mem: 6639M\n",
            "[05/20 17:48:26 d2.utils.events]:  eta: 1:22:11  iter: 2699  total_loss: 41.07  loss_ce: 1.051  loss_mask: 0.05484  loss_dice: 0.4823  loss_bbox: 0.07244  loss_giou: 0.3179  loss_ce_dn: 0.1539  loss_mask_dn: 0.05355  loss_dice_dn: 0.5445  loss_bbox_dn: 0.06947  loss_giou_dn: 0.2967  loss_ce_0: 1.295  loss_mask_0: 0.0555  loss_dice_0: 0.4852  loss_bbox_0: 0.06532  loss_giou_0: 0.4505  loss_ce_dn_0: 0.7896  loss_mask_dn_0: 0.2602  loss_dice_dn_0: 2.468  loss_bbox_dn_0: 0.337  loss_giou_dn_0: 0.8565  loss_ce_1: 1.185  loss_mask_1: 0.06721  loss_dice_1: 0.6131  loss_bbox_1: 0.05909  loss_giou_1: 0.4374  loss_ce_dn_1: 0.293  loss_mask_dn_1: 0.05443  loss_dice_dn_1: 0.5823  loss_bbox_dn_1: 0.1036  loss_giou_dn_1: 0.3688  loss_ce_2: 1.257  loss_mask_2: 0.0605  loss_dice_2: 0.5164  loss_bbox_2: 0.07522  loss_giou_2: 0.3725  loss_ce_dn_2: 0.2365  loss_mask_dn_2: 0.05198  loss_dice_dn_2: 0.5454  loss_bbox_dn_2: 0.08589  loss_giou_dn_2: 0.3161  loss_ce_3: 1.274  loss_mask_3: 0.05482  loss_dice_3: 0.4532  loss_bbox_3: 0.05329  loss_giou_3: 0.3557  loss_ce_dn_3: 0.2114  loss_mask_dn_3: 0.05202  loss_dice_dn_3: 0.5569  loss_bbox_dn_3: 0.07235  loss_giou_dn_3: 0.301  loss_ce_4: 1.058  loss_mask_4: 0.05869  loss_dice_4: 0.3983  loss_bbox_4: 0.06318  loss_giou_4: 0.3506  loss_ce_dn_4: 0.1868  loss_mask_dn_4: 0.05623  loss_dice_dn_4: 0.5422  loss_bbox_dn_4: 0.07079  loss_giou_dn_4: 0.2917  loss_ce_5: 1.046  loss_mask_5: 0.06457  loss_dice_5: 0.4165  loss_bbox_5: 0.05949  loss_giou_5: 0.337  loss_ce_dn_5: 0.1789  loss_mask_dn_5: 0.05366  loss_dice_dn_5: 0.5051  loss_bbox_dn_5: 0.07027  loss_giou_dn_5: 0.3022  loss_ce_6: 1.074  loss_mask_6: 0.05684  loss_dice_6: 0.4532  loss_bbox_6: 0.07071  loss_giou_6: 0.3364  loss_ce_dn_6: 0.166  loss_mask_dn_6: 0.05379  loss_dice_dn_6: 0.527  loss_bbox_dn_6: 0.06978  loss_giou_dn_6: 0.2871  loss_ce_7: 1.089  loss_mask_7: 0.05596  loss_dice_7: 0.4449  loss_bbox_7: 0.07034  loss_giou_7: 0.3275  loss_ce_dn_7: 0.1582  loss_mask_dn_7: 0.05465  loss_dice_dn_7: 0.5712  loss_bbox_dn_7: 0.06762  loss_giou_dn_7: 0.297  loss_ce_8: 1.051  loss_mask_8: 0.05511  loss_dice_8: 0.4205  loss_bbox_8: 0.07024  loss_giou_8: 0.3213  loss_ce_dn_8: 0.1554  loss_mask_dn_8: 0.05301  loss_dice_dn_8: 0.5046  loss_bbox_dn_8: 0.06845  loss_giou_dn_8: 0.2893  loss_ce_interm: 1.34  loss_mask_interm: 0.05279  loss_dice_interm: 0.5072  loss_bbox_interm: 0.1321  loss_giou_interm: 0.439  time: 1.9473  data_time: 0.0615  lr: 1e-06  max_mem: 6639M\n",
            "[05/20 17:48:59 d2.utils.events]:  eta: 1:21:33  iter: 2719  total_loss: 34.57  loss_ce: 0.8576  loss_mask: 0.03776  loss_dice: 0.4012  loss_bbox: 0.04712  loss_giou: 0.2725  loss_ce_dn: 0.1791  loss_mask_dn: 0.03622  loss_dice_dn: 0.4249  loss_bbox_dn: 0.04209  loss_giou_dn: 0.2428  loss_ce_0: 1.084  loss_mask_0: 0.0404  loss_dice_0: 0.3697  loss_bbox_0: 0.06385  loss_giou_0: 0.3327  loss_ce_dn_0: 0.7903  loss_mask_dn_0: 0.2956  loss_dice_dn_0: 2.707  loss_bbox_dn_0: 0.3527  loss_giou_dn_0: 0.8538  loss_ce_1: 1.099  loss_mask_1: 0.03752  loss_dice_1: 0.4773  loss_bbox_1: 0.06445  loss_giou_1: 0.3497  loss_ce_dn_1: 0.2991  loss_mask_dn_1: 0.03975  loss_dice_dn_1: 0.4605  loss_bbox_dn_1: 0.07887  loss_giou_dn_1: 0.3334  loss_ce_2: 1.081  loss_mask_2: 0.04142  loss_dice_2: 0.3751  loss_bbox_2: 0.05487  loss_giou_2: 0.2924  loss_ce_dn_2: 0.2467  loss_mask_dn_2: 0.03734  loss_dice_dn_2: 0.4137  loss_bbox_dn_2: 0.05435  loss_giou_dn_2: 0.2659  loss_ce_3: 0.9505  loss_mask_3: 0.03677  loss_dice_3: 0.3221  loss_bbox_3: 0.05658  loss_giou_3: 0.2886  loss_ce_dn_3: 0.2372  loss_mask_dn_3: 0.03705  loss_dice_dn_3: 0.4271  loss_bbox_dn_3: 0.04593  loss_giou_dn_3: 0.2625  loss_ce_4: 0.8775  loss_mask_4: 0.03675  loss_dice_4: 0.4143  loss_bbox_4: 0.04966  loss_giou_4: 0.276  loss_ce_dn_4: 0.1993  loss_mask_dn_4: 0.03836  loss_dice_dn_4: 0.441  loss_bbox_dn_4: 0.04438  loss_giou_dn_4: 0.2442  loss_ce_5: 0.9359  loss_mask_5: 0.0329  loss_dice_5: 0.3861  loss_bbox_5: 0.04642  loss_giou_5: 0.268  loss_ce_dn_5: 0.1779  loss_mask_dn_5: 0.03515  loss_dice_dn_5: 0.4227  loss_bbox_dn_5: 0.04363  loss_giou_dn_5: 0.2429  loss_ce_6: 0.9477  loss_mask_6: 0.03242  loss_dice_6: 0.3619  loss_bbox_6: 0.04706  loss_giou_6: 0.2784  loss_ce_dn_6: 0.1771  loss_mask_dn_6: 0.0367  loss_dice_dn_6: 0.4061  loss_bbox_dn_6: 0.04398  loss_giou_dn_6: 0.2416  loss_ce_7: 0.8759  loss_mask_7: 0.03734  loss_dice_7: 0.3377  loss_bbox_7: 0.0484  loss_giou_7: 0.2699  loss_ce_dn_7: 0.1808  loss_mask_dn_7: 0.03656  loss_dice_dn_7: 0.3923  loss_bbox_dn_7: 0.04372  loss_giou_dn_7: 0.2423  loss_ce_8: 0.8327  loss_mask_8: 0.03628  loss_dice_8: 0.4268  loss_bbox_8: 0.05251  loss_giou_8: 0.2776  loss_ce_dn_8: 0.1803  loss_mask_dn_8: 0.03695  loss_dice_dn_8: 0.4126  loss_bbox_dn_8: 0.04261  loss_giou_dn_8: 0.2456  loss_ce_interm: 1.203  loss_mask_interm: 0.03427  loss_dice_interm: 0.4658  loss_bbox_interm: 0.1027  loss_giou_interm: 0.401  time: 1.9453  data_time: 0.0817  lr: 1e-06  max_mem: 6639M\n",
            "[05/20 17:49:33 d2.utils.events]:  eta: 1:20:57  iter: 2739  total_loss: 40.32  loss_ce: 1.136  loss_mask: 0.03164  loss_dice: 0.4531  loss_bbox: 0.04094  loss_giou: 0.223  loss_ce_dn: 0.2331  loss_mask_dn: 0.03585  loss_dice_dn: 0.5033  loss_bbox_dn: 0.03569  loss_giou_dn: 0.2194  loss_ce_0: 1.375  loss_mask_0: 0.04195  loss_dice_0: 0.5003  loss_bbox_0: 0.04623  loss_giou_0: 0.3119  loss_ce_dn_0: 0.7716  loss_mask_dn_0: 0.2078  loss_dice_dn_0: 2.371  loss_bbox_dn_0: 0.3135  loss_giou_dn_0: 0.8531  loss_ce_1: 1.333  loss_mask_1: 0.0366  loss_dice_1: 0.4651  loss_bbox_1: 0.0428  loss_giou_1: 0.2704  loss_ce_dn_1: 0.3083  loss_mask_dn_1: 0.03434  loss_dice_dn_1: 0.5415  loss_bbox_dn_1: 0.06814  loss_giou_dn_1: 0.3307  loss_ce_2: 1.173  loss_mask_2: 0.03801  loss_dice_2: 0.5465  loss_bbox_2: 0.04226  loss_giou_2: 0.2504  loss_ce_dn_2: 0.2816  loss_mask_dn_2: 0.03471  loss_dice_dn_2: 0.5083  loss_bbox_dn_2: 0.04955  loss_giou_dn_2: 0.2507  loss_ce_3: 1.123  loss_mask_3: 0.03664  loss_dice_3: 0.4095  loss_bbox_3: 0.04224  loss_giou_3: 0.2306  loss_ce_dn_3: 0.2516  loss_mask_dn_3: 0.03551  loss_dice_dn_3: 0.5106  loss_bbox_dn_3: 0.04065  loss_giou_dn_3: 0.2179  loss_ce_4: 1.202  loss_mask_4: 0.03152  loss_dice_4: 0.5119  loss_bbox_4: 0.04294  loss_giou_4: 0.2294  loss_ce_dn_4: 0.2565  loss_mask_dn_4: 0.03517  loss_dice_dn_4: 0.5124  loss_bbox_dn_4: 0.0374  loss_giou_dn_4: 0.2166  loss_ce_5: 1.189  loss_mask_5: 0.03634  loss_dice_5: 0.5755  loss_bbox_5: 0.04199  loss_giou_5: 0.2234  loss_ce_dn_5: 0.2538  loss_mask_dn_5: 0.03407  loss_dice_dn_5: 0.5066  loss_bbox_dn_5: 0.03702  loss_giou_dn_5: 0.2153  loss_ce_6: 1.061  loss_mask_6: 0.03187  loss_dice_6: 0.4569  loss_bbox_6: 0.04078  loss_giou_6: 0.225  loss_ce_dn_6: 0.2514  loss_mask_dn_6: 0.03313  loss_dice_dn_6: 0.4948  loss_bbox_dn_6: 0.03735  loss_giou_dn_6: 0.2159  loss_ce_7: 1.055  loss_mask_7: 0.03368  loss_dice_7: 0.5032  loss_bbox_7: 0.04085  loss_giou_7: 0.2195  loss_ce_dn_7: 0.2426  loss_mask_dn_7: 0.0346  loss_dice_dn_7: 0.4921  loss_bbox_dn_7: 0.03606  loss_giou_dn_7: 0.2135  loss_ce_8: 1.009  loss_mask_8: 0.03438  loss_dice_8: 0.433  loss_bbox_8: 0.04074  loss_giou_8: 0.2129  loss_ce_dn_8: 0.2376  loss_mask_dn_8: 0.03551  loss_dice_dn_8: 0.4994  loss_bbox_dn_8: 0.0357  loss_giou_dn_8: 0.222  loss_ce_interm: 1.399  loss_mask_interm: 0.03592  loss_dice_interm: 0.5834  loss_bbox_interm: 0.08506  loss_giou_interm: 0.3562  time: 1.9436  data_time: 0.1151  lr: 1e-06  max_mem: 6639M\n",
            "[05/20 17:50:07 d2.utils.events]:  eta: 1:20:22  iter: 2759  total_loss: 37.75  loss_ce: 0.9293  loss_mask: 0.027  loss_dice: 0.517  loss_bbox: 0.06194  loss_giou: 0.3931  loss_ce_dn: 0.1789  loss_mask_dn: 0.02474  loss_dice_dn: 0.4874  loss_bbox_dn: 0.03174  loss_giou_dn: 0.2784  loss_ce_0: 1.18  loss_mask_0: 0.03129  loss_dice_0: 0.598  loss_bbox_0: 0.1052  loss_giou_0: 0.4962  loss_ce_dn_0: 0.7763  loss_mask_dn_0: 0.1604  loss_dice_dn_0: 2.03  loss_bbox_dn_0: 0.2465  loss_giou_dn_0: 0.8575  loss_ce_1: 1.059  loss_mask_1: 0.02702  loss_dice_1: 0.5548  loss_bbox_1: 0.07871  loss_giou_1: 0.4057  loss_ce_dn_1: 0.247  loss_mask_dn_1: 0.0265  loss_dice_dn_1: 0.4858  loss_bbox_dn_1: 0.05977  loss_giou_dn_1: 0.3564  loss_ce_2: 1.015  loss_mask_2: 0.03076  loss_dice_2: 0.6542  loss_bbox_2: 0.07833  loss_giou_2: 0.4079  loss_ce_dn_2: 0.2142  loss_mask_dn_2: 0.02255  loss_dice_dn_2: 0.5146  loss_bbox_dn_2: 0.0426  loss_giou_dn_2: 0.3137  loss_ce_3: 0.916  loss_mask_3: 0.02868  loss_dice_3: 0.573  loss_bbox_3: 0.0753  loss_giou_3: 0.4491  loss_ce_dn_3: 0.1976  loss_mask_dn_3: 0.02434  loss_dice_dn_3: 0.4978  loss_bbox_dn_3: 0.03506  loss_giou_dn_3: 0.2899  loss_ce_4: 0.9289  loss_mask_4: 0.02875  loss_dice_4: 0.5438  loss_bbox_4: 0.08315  loss_giou_4: 0.4365  loss_ce_dn_4: 0.1932  loss_mask_dn_4: 0.02445  loss_dice_dn_4: 0.5054  loss_bbox_dn_4: 0.03336  loss_giou_dn_4: 0.2889  loss_ce_5: 0.9801  loss_mask_5: 0.02615  loss_dice_5: 0.537  loss_bbox_5: 0.04883  loss_giou_5: 0.3991  loss_ce_dn_5: 0.1869  loss_mask_dn_5: 0.02494  loss_dice_dn_5: 0.4884  loss_bbox_dn_5: 0.03306  loss_giou_dn_5: 0.2873  loss_ce_6: 0.9559  loss_mask_6: 0.02321  loss_dice_6: 0.4288  loss_bbox_6: 0.04949  loss_giou_6: 0.4063  loss_ce_dn_6: 0.1852  loss_mask_dn_6: 0.02425  loss_dice_dn_6: 0.498  loss_bbox_dn_6: 0.03236  loss_giou_dn_6: 0.2874  loss_ce_7: 0.8857  loss_mask_7: 0.02286  loss_dice_7: 0.5816  loss_bbox_7: 0.05277  loss_giou_7: 0.4014  loss_ce_dn_7: 0.179  loss_mask_dn_7: 0.0256  loss_dice_dn_7: 0.4824  loss_bbox_dn_7: 0.0316  loss_giou_dn_7: 0.2838  loss_ce_8: 0.904  loss_mask_8: 0.02633  loss_dice_8: 0.558  loss_bbox_8: 0.07525  loss_giou_8: 0.4369  loss_ce_dn_8: 0.1856  loss_mask_dn_8: 0.02566  loss_dice_dn_8: 0.5128  loss_bbox_dn_8: 0.03138  loss_giou_dn_8: 0.2817  loss_ce_interm: 1.126  loss_mask_interm: 0.0263  loss_dice_interm: 0.5678  loss_bbox_interm: 0.09051  loss_giou_interm: 0.4933  time: 1.9417  data_time: 0.0841  lr: 1e-06  max_mem: 6639M\n",
            "[05/20 17:50:41 d2.utils.events]:  eta: 1:19:50  iter: 2779  total_loss: 47.74  loss_ce: 1.182  loss_mask: 0.02747  loss_dice: 0.5213  loss_bbox: 0.08276  loss_giou: 0.4528  loss_ce_dn: 0.1929  loss_mask_dn: 0.02473  loss_dice_dn: 0.5766  loss_bbox_dn: 0.03566  loss_giou_dn: 0.3571  loss_ce_0: 1.441  loss_mask_0: 0.03196  loss_dice_0: 0.6244  loss_bbox_0: 0.09148  loss_giou_0: 0.5998  loss_ce_dn_0: 0.7454  loss_mask_dn_0: 0.228  loss_dice_dn_0: 2.518  loss_bbox_dn_0: 0.214  loss_giou_dn_0: 0.8565  loss_ce_1: 1.396  loss_mask_1: 0.04029  loss_dice_1: 0.5385  loss_bbox_1: 0.09477  loss_giou_1: 0.4148  loss_ce_dn_1: 0.2874  loss_mask_dn_1: 0.02616  loss_dice_dn_1: 0.6118  loss_bbox_dn_1: 0.05373  loss_giou_dn_1: 0.42  loss_ce_2: 1.188  loss_mask_2: 0.03487  loss_dice_2: 0.5899  loss_bbox_2: 0.09424  loss_giou_2: 0.4594  loss_ce_dn_2: 0.226  loss_mask_dn_2: 0.02429  loss_dice_dn_2: 0.5672  loss_bbox_dn_2: 0.04575  loss_giou_dn_2: 0.3957  loss_ce_3: 1.179  loss_mask_3: 0.0316  loss_dice_3: 0.4922  loss_bbox_3: 0.09315  loss_giou_3: 0.4398  loss_ce_dn_3: 0.1929  loss_mask_dn_3: 0.02461  loss_dice_dn_3: 0.5875  loss_bbox_dn_3: 0.04073  loss_giou_dn_3: 0.352  loss_ce_4: 1.179  loss_mask_4: 0.02121  loss_dice_4: 0.401  loss_bbox_4: 0.09924  loss_giou_4: 0.438  loss_ce_dn_4: 0.187  loss_mask_dn_4: 0.02381  loss_dice_dn_4: 0.5293  loss_bbox_dn_4: 0.03677  loss_giou_dn_4: 0.345  loss_ce_5: 1.194  loss_mask_5: 0.02946  loss_dice_5: 0.5024  loss_bbox_5: 0.09179  loss_giou_5: 0.4408  loss_ce_dn_5: 0.1939  loss_mask_dn_5: 0.02377  loss_dice_dn_5: 0.5831  loss_bbox_dn_5: 0.03698  loss_giou_dn_5: 0.3514  loss_ce_6: 1.108  loss_mask_6: 0.02867  loss_dice_6: 0.5119  loss_bbox_6: 0.08597  loss_giou_6: 0.441  loss_ce_dn_6: 0.1967  loss_mask_dn_6: 0.02367  loss_dice_dn_6: 0.5279  loss_bbox_dn_6: 0.03609  loss_giou_dn_6: 0.3585  loss_ce_7: 1.209  loss_mask_7: 0.02745  loss_dice_7: 0.5597  loss_bbox_7: 0.09585  loss_giou_7: 0.4546  loss_ce_dn_7: 0.1957  loss_mask_dn_7: 0.0258  loss_dice_dn_7: 0.5004  loss_bbox_dn_7: 0.0354  loss_giou_dn_7: 0.3581  loss_ce_8: 1.172  loss_mask_8: 0.02578  loss_dice_8: 0.4171  loss_bbox_8: 0.08382  loss_giou_8: 0.4535  loss_ce_dn_8: 0.191  loss_mask_dn_8: 0.02491  loss_dice_dn_8: 0.5261  loss_bbox_dn_8: 0.03564  loss_giou_dn_8: 0.3614  loss_ce_interm: 1.327  loss_mask_interm: 0.02488  loss_dice_interm: 0.5062  loss_bbox_interm: 0.0924  loss_giou_interm: 0.5303  time: 1.9400  data_time: 0.1005  lr: 1e-06  max_mem: 6639M\n",
            "[05/20 17:51:15 d2.utils.events]:  eta: 1:19:15  iter: 2799  total_loss: 45.48  loss_ce: 1.269  loss_mask: 0.03723  loss_dice: 0.7189  loss_bbox: 0.07903  loss_giou: 0.2862  loss_ce_dn: 0.2216  loss_mask_dn: 0.03313  loss_dice_dn: 0.6387  loss_bbox_dn: 0.05991  loss_giou_dn: 0.2708  loss_ce_0: 1.358  loss_mask_0: 0.04564  loss_dice_0: 0.6126  loss_bbox_0: 0.1023  loss_giou_0: 0.4278  loss_ce_dn_0: 0.7389  loss_mask_dn_0: 0.3623  loss_dice_dn_0: 2.74  loss_bbox_dn_0: 0.2624  loss_giou_dn_0: 0.8556  loss_ce_1: 1.332  loss_mask_1: 0.04112  loss_dice_1: 0.7071  loss_bbox_1: 0.1001  loss_giou_1: 0.3332  loss_ce_dn_1: 0.2763  loss_mask_dn_1: 0.03739  loss_dice_dn_1: 0.6366  loss_bbox_dn_1: 0.08641  loss_giou_dn_1: 0.3592  loss_ce_2: 1.479  loss_mask_2: 0.0419  loss_dice_2: 0.588  loss_bbox_2: 0.08325  loss_giou_2: 0.3431  loss_ce_dn_2: 0.2687  loss_mask_dn_2: 0.03072  loss_dice_dn_2: 0.6605  loss_bbox_dn_2: 0.07037  loss_giou_dn_2: 0.3042  loss_ce_3: 1.351  loss_mask_3: 0.03981  loss_dice_3: 0.7036  loss_bbox_3: 0.08258  loss_giou_3: 0.2775  loss_ce_dn_3: 0.2517  loss_mask_dn_3: 0.03225  loss_dice_dn_3: 0.6489  loss_bbox_dn_3: 0.0663  loss_giou_dn_3: 0.273  loss_ce_4: 1.345  loss_mask_4: 0.03765  loss_dice_4: 0.5678  loss_bbox_4: 0.08331  loss_giou_4: 0.2919  loss_ce_dn_4: 0.2399  loss_mask_dn_4: 0.03132  loss_dice_dn_4: 0.6248  loss_bbox_dn_4: 0.06538  loss_giou_dn_4: 0.2787  loss_ce_5: 1.284  loss_mask_5: 0.03369  loss_dice_5: 0.6164  loss_bbox_5: 0.07719  loss_giou_5: 0.2679  loss_ce_dn_5: 0.2397  loss_mask_dn_5: 0.03303  loss_dice_dn_5: 0.637  loss_bbox_dn_5: 0.0614  loss_giou_dn_5: 0.2616  loss_ce_6: 1.302  loss_mask_6: 0.03833  loss_dice_6: 0.5948  loss_bbox_6: 0.09336  loss_giou_6: 0.2812  loss_ce_dn_6: 0.2261  loss_mask_dn_6: 0.03298  loss_dice_dn_6: 0.6762  loss_bbox_dn_6: 0.06218  loss_giou_dn_6: 0.2692  loss_ce_7: 1.283  loss_mask_7: 0.03574  loss_dice_7: 0.7814  loss_bbox_7: 0.07958  loss_giou_7: 0.2868  loss_ce_dn_7: 0.2226  loss_mask_dn_7: 0.03367  loss_dice_dn_7: 0.6407  loss_bbox_dn_7: 0.06253  loss_giou_dn_7: 0.2674  loss_ce_8: 1.242  loss_mask_8: 0.03678  loss_dice_8: 0.7687  loss_bbox_8: 0.07758  loss_giou_8: 0.2866  loss_ce_dn_8: 0.2261  loss_mask_dn_8: 0.03359  loss_dice_dn_8: 0.646  loss_bbox_dn_8: 0.06053  loss_giou_dn_8: 0.268  loss_ce_interm: 1.37  loss_mask_interm: 0.04599  loss_dice_interm: 0.7018  loss_bbox_interm: 0.1169  loss_giou_interm: 0.4389  time: 1.9382  data_time: 0.0868  lr: 1e-06  max_mem: 6639M\n",
            "[05/20 17:51:50 d2.utils.events]:  eta: 1:18:38  iter: 2819  total_loss: 42.93  loss_ce: 0.9254  loss_mask: 0.04269  loss_dice: 0.5047  loss_bbox: 0.06314  loss_giou: 0.3451  loss_ce_dn: 0.1932  loss_mask_dn: 0.03396  loss_dice_dn: 0.5896  loss_bbox_dn: 0.03903  loss_giou_dn: 0.2927  loss_ce_0: 1.156  loss_mask_0: 0.04287  loss_dice_0: 0.5741  loss_bbox_0: 0.06019  loss_giou_0: 0.3779  loss_ce_dn_0: 0.7681  loss_mask_dn_0: 0.1542  loss_dice_dn_0: 2.343  loss_bbox_dn_0: 0.3492  loss_giou_dn_0: 0.85  loss_ce_1: 1.172  loss_mask_1: 0.03737  loss_dice_1: 0.6222  loss_bbox_1: 0.05128  loss_giou_1: 0.3304  loss_ce_dn_1: 0.2709  loss_mask_dn_1: 0.03532  loss_dice_dn_1: 0.5703  loss_bbox_dn_1: 0.07339  loss_giou_dn_1: 0.3992  loss_ce_2: 1.034  loss_mask_2: 0.0407  loss_dice_2: 0.5239  loss_bbox_2: 0.04809  loss_giou_2: 0.281  loss_ce_dn_2: 0.2321  loss_mask_dn_2: 0.03348  loss_dice_dn_2: 0.565  loss_bbox_dn_2: 0.05541  loss_giou_dn_2: 0.3179  loss_ce_3: 0.9428  loss_mask_3: 0.03909  loss_dice_3: 0.5562  loss_bbox_3: 0.04506  loss_giou_3: 0.2806  loss_ce_dn_3: 0.2018  loss_mask_dn_3: 0.03621  loss_dice_dn_3: 0.5658  loss_bbox_dn_3: 0.04954  loss_giou_dn_3: 0.3001  loss_ce_4: 0.9544  loss_mask_4: 0.03414  loss_dice_4: 0.5358  loss_bbox_4: 0.04772  loss_giou_4: 0.3013  loss_ce_dn_4: 0.2013  loss_mask_dn_4: 0.03598  loss_dice_dn_4: 0.5764  loss_bbox_dn_4: 0.04574  loss_giou_dn_4: 0.2907  loss_ce_5: 0.9085  loss_mask_5: 0.03651  loss_dice_5: 0.4887  loss_bbox_5: 0.05333  loss_giou_5: 0.3336  loss_ce_dn_5: 0.2029  loss_mask_dn_5: 0.03571  loss_dice_dn_5: 0.5602  loss_bbox_dn_5: 0.0397  loss_giou_dn_5: 0.2896  loss_ce_6: 0.9057  loss_mask_6: 0.03538  loss_dice_6: 0.5523  loss_bbox_6: 0.05215  loss_giou_6: 0.3611  loss_ce_dn_6: 0.1935  loss_mask_dn_6: 0.03489  loss_dice_dn_6: 0.5798  loss_bbox_dn_6: 0.04208  loss_giou_dn_6: 0.2918  loss_ce_7: 0.8927  loss_mask_7: 0.03716  loss_dice_7: 0.6159  loss_bbox_7: 0.0462  loss_giou_7: 0.3378  loss_ce_dn_7: 0.1883  loss_mask_dn_7: 0.03491  loss_dice_dn_7: 0.59  loss_bbox_dn_7: 0.03921  loss_giou_dn_7: 0.2932  loss_ce_8: 0.9353  loss_mask_8: 0.04072  loss_dice_8: 0.592  loss_bbox_8: 0.06156  loss_giou_8: 0.3282  loss_ce_dn_8: 0.1954  loss_mask_dn_8: 0.03462  loss_dice_dn_8: 0.5884  loss_bbox_dn_8: 0.03981  loss_giou_dn_8: 0.2945  loss_ce_interm: 1.221  loss_mask_interm: 0.04142  loss_dice_interm: 0.5919  loss_bbox_interm: 0.08981  loss_giou_interm: 0.4512  time: 1.9367  data_time: 0.1242  lr: 1e-06  max_mem: 6639M\n",
            "[05/20 17:52:25 d2.utils.events]:  eta: 1:18:06  iter: 2839  total_loss: 40.84  loss_ce: 0.9076  loss_mask: 0.04305  loss_dice: 0.5293  loss_bbox: 0.07409  loss_giou: 0.4554  loss_ce_dn: 0.207  loss_mask_dn: 0.04185  loss_dice_dn: 0.5368  loss_bbox_dn: 0.03929  loss_giou_dn: 0.3403  loss_ce_0: 1.413  loss_mask_0: 0.04248  loss_dice_0: 0.5957  loss_bbox_0: 0.07353  loss_giou_0: 0.4739  loss_ce_dn_0: 0.7994  loss_mask_dn_0: 0.2043  loss_dice_dn_0: 2.338  loss_bbox_dn_0: 0.2836  loss_giou_dn_0: 0.8572  loss_ce_1: 1.267  loss_mask_1: 0.05336  loss_dice_1: 0.5149  loss_bbox_1: 0.07985  loss_giou_1: 0.4917  loss_ce_dn_1: 0.3078  loss_mask_dn_1: 0.04354  loss_dice_dn_1: 0.5625  loss_bbox_dn_1: 0.0713  loss_giou_dn_1: 0.4237  loss_ce_2: 1.203  loss_mask_2: 0.03954  loss_dice_2: 0.5066  loss_bbox_2: 0.07073  loss_giou_2: 0.4304  loss_ce_dn_2: 0.2527  loss_mask_dn_2: 0.04168  loss_dice_dn_2: 0.571  loss_bbox_dn_2: 0.05598  loss_giou_dn_2: 0.363  loss_ce_3: 1.094  loss_mask_3: 0.04898  loss_dice_3: 0.5967  loss_bbox_3: 0.07091  loss_giou_3: 0.4193  loss_ce_dn_3: 0.2549  loss_mask_dn_3: 0.04615  loss_dice_dn_3: 0.5819  loss_bbox_dn_3: 0.04499  loss_giou_dn_3: 0.3599  loss_ce_4: 1.105  loss_mask_4: 0.04994  loss_dice_4: 0.5468  loss_bbox_4: 0.06491  loss_giou_4: 0.4098  loss_ce_dn_4: 0.2256  loss_mask_dn_4: 0.04521  loss_dice_dn_4: 0.5813  loss_bbox_dn_4: 0.03877  loss_giou_dn_4: 0.3455  loss_ce_5: 0.973  loss_mask_5: 0.03777  loss_dice_5: 0.5404  loss_bbox_5: 0.06466  loss_giou_5: 0.4339  loss_ce_dn_5: 0.222  loss_mask_dn_5: 0.0439  loss_dice_dn_5: 0.5556  loss_bbox_dn_5: 0.03827  loss_giou_dn_5: 0.3304  loss_ce_6: 1.051  loss_mask_6: 0.04346  loss_dice_6: 0.5571  loss_bbox_6: 0.06556  loss_giou_6: 0.4307  loss_ce_dn_6: 0.2102  loss_mask_dn_6: 0.04216  loss_dice_dn_6: 0.5716  loss_bbox_dn_6: 0.0393  loss_giou_dn_6: 0.3365  loss_ce_7: 0.9743  loss_mask_7: 0.0472  loss_dice_7: 0.5998  loss_bbox_7: 0.06397  loss_giou_7: 0.4224  loss_ce_dn_7: 0.2084  loss_mask_dn_7: 0.04397  loss_dice_dn_7: 0.5517  loss_bbox_dn_7: 0.03902  loss_giou_dn_7: 0.3386  loss_ce_8: 0.9128  loss_mask_8: 0.04253  loss_dice_8: 0.48  loss_bbox_8: 0.0739  loss_giou_8: 0.4528  loss_ce_dn_8: 0.2061  loss_mask_dn_8: 0.0444  loss_dice_dn_8: 0.5667  loss_bbox_dn_8: 0.03909  loss_giou_dn_8: 0.3427  loss_ce_interm: 1.359  loss_mask_interm: 0.04828  loss_dice_interm: 0.6428  loss_bbox_interm: 0.09436  loss_giou_interm: 0.4868  time: 1.9356  data_time: 0.1476  lr: 1e-06  max_mem: 6639M\n",
            "[05/20 17:52:59 d2.utils.events]:  eta: 1:17:34  iter: 2859  total_loss: 52.99  loss_ce: 1.237  loss_mask: 0.05014  loss_dice: 0.727  loss_bbox: 0.05193  loss_giou: 0.4627  loss_ce_dn: 0.2152  loss_mask_dn: 0.04078  loss_dice_dn: 0.7922  loss_bbox_dn: 0.04644  loss_giou_dn: 0.3561  loss_ce_0: 1.505  loss_mask_0: 0.04694  loss_dice_0: 1.124  loss_bbox_0: 0.06325  loss_giou_0: 0.6246  loss_ce_dn_0: 0.786  loss_mask_dn_0: 0.1439  loss_dice_dn_0: 2.454  loss_bbox_dn_0: 0.2142  loss_giou_dn_0: 0.8616  loss_ce_1: 1.524  loss_mask_1: 0.04587  loss_dice_1: 0.8997  loss_bbox_1: 0.05527  loss_giou_1: 0.5349  loss_ce_dn_1: 0.2873  loss_mask_dn_1: 0.04033  loss_dice_dn_1: 0.7773  loss_bbox_dn_1: 0.07634  loss_giou_dn_1: 0.4596  loss_ce_2: 1.345  loss_mask_2: 0.05174  loss_dice_2: 0.7815  loss_bbox_2: 0.05764  loss_giou_2: 0.4934  loss_ce_dn_2: 0.247  loss_mask_dn_2: 0.03681  loss_dice_dn_2: 0.8388  loss_bbox_dn_2: 0.05908  loss_giou_dn_2: 0.3979  loss_ce_3: 1.261  loss_mask_3: 0.05137  loss_dice_3: 0.9266  loss_bbox_3: 0.05519  loss_giou_3: 0.4718  loss_ce_dn_3: 0.2331  loss_mask_dn_3: 0.03882  loss_dice_dn_3: 0.826  loss_bbox_dn_3: 0.05364  loss_giou_dn_3: 0.3696  loss_ce_4: 1.343  loss_mask_4: 0.05421  loss_dice_4: 0.8561  loss_bbox_4: 0.05471  loss_giou_4: 0.4653  loss_ce_dn_4: 0.2229  loss_mask_dn_4: 0.03751  loss_dice_dn_4: 0.7569  loss_bbox_dn_4: 0.05045  loss_giou_dn_4: 0.36  loss_ce_5: 1.291  loss_mask_5: 0.05275  loss_dice_5: 0.7527  loss_bbox_5: 0.05568  loss_giou_5: 0.4771  loss_ce_dn_5: 0.2274  loss_mask_dn_5: 0.03841  loss_dice_dn_5: 0.7722  loss_bbox_dn_5: 0.04795  loss_giou_dn_5: 0.3596  loss_ce_6: 1.298  loss_mask_6: 0.04863  loss_dice_6: 0.6467  loss_bbox_6: 0.05331  loss_giou_6: 0.4748  loss_ce_dn_6: 0.2102  loss_mask_dn_6: 0.0394  loss_dice_dn_6: 0.8149  loss_bbox_dn_6: 0.04862  loss_giou_dn_6: 0.3657  loss_ce_7: 1.276  loss_mask_7: 0.04626  loss_dice_7: 0.578  loss_bbox_7: 0.05086  loss_giou_7: 0.4683  loss_ce_dn_7: 0.211  loss_mask_dn_7: 0.04055  loss_dice_dn_7: 0.7659  loss_bbox_dn_7: 0.04614  loss_giou_dn_7: 0.3533  loss_ce_8: 1.258  loss_mask_8: 0.04891  loss_dice_8: 0.7517  loss_bbox_8: 0.0515  loss_giou_8: 0.4703  loss_ce_dn_8: 0.2089  loss_mask_dn_8: 0.03968  loss_dice_dn_8: 0.763  loss_bbox_dn_8: 0.04708  loss_giou_dn_8: 0.3656  loss_ce_interm: 1.589  loss_mask_interm: 0.04778  loss_dice_interm: 0.9148  loss_bbox_interm: 0.1367  loss_giou_interm: 0.6066  time: 1.9340  data_time: 0.0835  lr: 1e-06  max_mem: 6639M\n",
            "[05/20 17:53:35 d2.utils.events]:  eta: 1:16:55  iter: 2879  total_loss: 36.33  loss_ce: 0.6726  loss_mask: 0.03454  loss_dice: 0.5137  loss_bbox: 0.04414  loss_giou: 0.317  loss_ce_dn: 0.1713  loss_mask_dn: 0.03704  loss_dice_dn: 0.5663  loss_bbox_dn: 0.03835  loss_giou_dn: 0.2588  loss_ce_0: 1.055  loss_mask_0: 0.03134  loss_dice_0: 0.5068  loss_bbox_0: 0.05018  loss_giou_0: 0.3086  loss_ce_dn_0: 0.7386  loss_mask_dn_0: 0.1812  loss_dice_dn_0: 1.745  loss_bbox_dn_0: 0.2487  loss_giou_dn_0: 0.8487  loss_ce_1: 0.9151  loss_mask_1: 0.0366  loss_dice_1: 0.537  loss_bbox_1: 0.05392  loss_giou_1: 0.3034  loss_ce_dn_1: 0.3014  loss_mask_dn_1: 0.03526  loss_dice_dn_1: 0.5344  loss_bbox_dn_1: 0.06295  loss_giou_dn_1: 0.3445  loss_ce_2: 0.9579  loss_mask_2: 0.03058  loss_dice_2: 0.5899  loss_bbox_2: 0.04584  loss_giou_2: 0.2901  loss_ce_dn_2: 0.2679  loss_mask_dn_2: 0.03056  loss_dice_dn_2: 0.5638  loss_bbox_dn_2: 0.0512  loss_giou_dn_2: 0.3077  loss_ce_3: 0.7077  loss_mask_3: 0.02897  loss_dice_3: 0.5423  loss_bbox_3: 0.04486  loss_giou_3: 0.2961  loss_ce_dn_3: 0.2252  loss_mask_dn_3: 0.03055  loss_dice_dn_3: 0.4982  loss_bbox_dn_3: 0.04128  loss_giou_dn_3: 0.2909  loss_ce_4: 0.6404  loss_mask_4: 0.03259  loss_dice_4: 0.4218  loss_bbox_4: 0.04678  loss_giou_4: 0.3018  loss_ce_dn_4: 0.1962  loss_mask_dn_4: 0.03431  loss_dice_dn_4: 0.5647  loss_bbox_dn_4: 0.04008  loss_giou_dn_4: 0.2743  loss_ce_5: 0.6858  loss_mask_5: 0.03455  loss_dice_5: 0.5393  loss_bbox_5: 0.05143  loss_giou_5: 0.3341  loss_ce_dn_5: 0.1859  loss_mask_dn_5: 0.03286  loss_dice_dn_5: 0.5746  loss_bbox_dn_5: 0.03859  loss_giou_dn_5: 0.2702  loss_ce_6: 0.6504  loss_mask_6: 0.03328  loss_dice_6: 0.4498  loss_bbox_6: 0.0478  loss_giou_6: 0.3158  loss_ce_dn_6: 0.1769  loss_mask_dn_6: 0.03333  loss_dice_dn_6: 0.548  loss_bbox_dn_6: 0.03788  loss_giou_dn_6: 0.2643  loss_ce_7: 0.6574  loss_mask_7: 0.04022  loss_dice_7: 0.4788  loss_bbox_7: 0.04604  loss_giou_7: 0.3136  loss_ce_dn_7: 0.1729  loss_mask_dn_7: 0.03662  loss_dice_dn_7: 0.5713  loss_bbox_dn_7: 0.03797  loss_giou_dn_7: 0.2648  loss_ce_8: 0.6724  loss_mask_8: 0.03248  loss_dice_8: 0.5245  loss_bbox_8: 0.04351  loss_giou_8: 0.3134  loss_ce_dn_8: 0.1698  loss_mask_dn_8: 0.03555  loss_dice_dn_8: 0.5756  loss_bbox_dn_8: 0.03835  loss_giou_dn_8: 0.2604  loss_ce_interm: 1.098  loss_mask_interm: 0.03078  loss_dice_interm: 0.4516  loss_bbox_interm: 0.08899  loss_giou_interm: 0.3944  time: 1.9322  data_time: 0.0485  lr: 1e-06  max_mem: 6639M\n",
            "[05/20 17:54:08 d2.utils.events]:  eta: 1:16:16  iter: 2899  total_loss: 46.9  loss_ce: 0.9967  loss_mask: 0.02846  loss_dice: 0.6467  loss_bbox: 0.06813  loss_giou: 0.4252  loss_ce_dn: 0.1573  loss_mask_dn: 0.02812  loss_dice_dn: 0.6151  loss_bbox_dn: 0.0326  loss_giou_dn: 0.3378  loss_ce_0: 1.363  loss_mask_0: 0.02413  loss_dice_0: 0.9704  loss_bbox_0: 0.08735  loss_giou_0: 0.6277  loss_ce_dn_0: 0.6652  loss_mask_dn_0: 0.07052  loss_dice_dn_0: 2.529  loss_bbox_dn_0: 0.1446  loss_giou_dn_0: 0.8541  loss_ce_1: 1.184  loss_mask_1: 0.03279  loss_dice_1: 0.7894  loss_bbox_1: 0.07758  loss_giou_1: 0.5271  loss_ce_dn_1: 0.2422  loss_mask_dn_1: 0.02887  loss_dice_dn_1: 0.6626  loss_bbox_dn_1: 0.05074  loss_giou_dn_1: 0.4326  loss_ce_2: 1.224  loss_mask_2: 0.02241  loss_dice_2: 0.5489  loss_bbox_2: 0.06273  loss_giou_2: 0.446  loss_ce_dn_2: 0.2258  loss_mask_dn_2: 0.02534  loss_dice_dn_2: 0.6487  loss_bbox_dn_2: 0.04149  loss_giou_dn_2: 0.3813  loss_ce_3: 1.023  loss_mask_3: 0.03112  loss_dice_3: 0.7401  loss_bbox_3: 0.06512  loss_giou_3: 0.4567  loss_ce_dn_3: 0.1951  loss_mask_dn_3: 0.02547  loss_dice_dn_3: 0.6398  loss_bbox_dn_3: 0.04459  loss_giou_dn_3: 0.3629  loss_ce_4: 1.037  loss_mask_4: 0.02597  loss_dice_4: 0.6768  loss_bbox_4: 0.06585  loss_giou_4: 0.4099  loss_ce_dn_4: 0.1846  loss_mask_dn_4: 0.02814  loss_dice_dn_4: 0.6446  loss_bbox_dn_4: 0.04066  loss_giou_dn_4: 0.3554  loss_ce_5: 1.019  loss_mask_5: 0.02656  loss_dice_5: 0.5649  loss_bbox_5: 0.06577  loss_giou_5: 0.4205  loss_ce_dn_5: 0.1748  loss_mask_dn_5: 0.02668  loss_dice_dn_5: 0.6244  loss_bbox_dn_5: 0.036  loss_giou_dn_5: 0.3492  loss_ce_6: 1.033  loss_mask_6: 0.02503  loss_dice_6: 0.4988  loss_bbox_6: 0.06593  loss_giou_6: 0.4423  loss_ce_dn_6: 0.1602  loss_mask_dn_6: 0.02783  loss_dice_dn_6: 0.6302  loss_bbox_dn_6: 0.03529  loss_giou_dn_6: 0.3466  loss_ce_7: 0.9153  loss_mask_7: 0.02489  loss_dice_7: 0.4578  loss_bbox_7: 0.07003  loss_giou_7: 0.4565  loss_ce_dn_7: 0.1615  loss_mask_dn_7: 0.02909  loss_dice_dn_7: 0.627  loss_bbox_dn_7: 0.03525  loss_giou_dn_7: 0.3333  loss_ce_8: 1.021  loss_mask_8: 0.02781  loss_dice_8: 0.715  loss_bbox_8: 0.0712  loss_giou_8: 0.4062  loss_ce_dn_8: 0.1559  loss_mask_dn_8: 0.02877  loss_dice_dn_8: 0.6424  loss_bbox_dn_8: 0.03446  loss_giou_dn_8: 0.3368  loss_ce_interm: 1.317  loss_mask_interm: 0.02914  loss_dice_interm: 0.8222  loss_bbox_interm: 0.07428  loss_giou_interm: 0.5484  time: 1.9303  data_time: 0.0595  lr: 1e-06  max_mem: 6639M\n",
            "[05/20 17:54:43 d2.utils.events]:  eta: 1:15:40  iter: 2919  total_loss: 45.24  loss_ce: 0.9235  loss_mask: 0.05289  loss_dice: 0.7087  loss_bbox: 0.06464  loss_giou: 0.3792  loss_ce_dn: 0.1862  loss_mask_dn: 0.04737  loss_dice_dn: 0.678  loss_bbox_dn: 0.04585  loss_giou_dn: 0.2993  loss_ce_0: 1.376  loss_mask_0: 0.05514  loss_dice_0: 0.7581  loss_bbox_0: 0.076  loss_giou_0: 0.5339  loss_ce_dn_0: 0.7887  loss_mask_dn_0: 0.2351  loss_dice_dn_0: 3.268  loss_bbox_dn_0: 0.2723  loss_giou_dn_0: 0.868  loss_ce_1: 1.32  loss_mask_1: 0.06038  loss_dice_1: 0.7502  loss_bbox_1: 0.05976  loss_giou_1: 0.3741  loss_ce_dn_1: 0.2747  loss_mask_dn_1: 0.06336  loss_dice_dn_1: 0.7981  loss_bbox_dn_1: 0.08285  loss_giou_dn_1: 0.4295  loss_ce_2: 1.237  loss_mask_2: 0.057  loss_dice_2: 0.5589  loss_bbox_2: 0.06563  loss_giou_2: 0.4011  loss_ce_dn_2: 0.2361  loss_mask_dn_2: 0.05238  loss_dice_dn_2: 0.7444  loss_bbox_dn_2: 0.05644  loss_giou_dn_2: 0.3681  loss_ce_3: 1.149  loss_mask_3: 0.05347  loss_dice_3: 0.6957  loss_bbox_3: 0.06095  loss_giou_3: 0.3556  loss_ce_dn_3: 0.2127  loss_mask_dn_3: 0.04827  loss_dice_dn_3: 0.6623  loss_bbox_dn_3: 0.05062  loss_giou_dn_3: 0.3354  loss_ce_4: 1.053  loss_mask_4: 0.05249  loss_dice_4: 0.7509  loss_bbox_4: 0.06646  loss_giou_4: 0.3637  loss_ce_dn_4: 0.1997  loss_mask_dn_4: 0.04752  loss_dice_dn_4: 0.7301  loss_bbox_dn_4: 0.0463  loss_giou_dn_4: 0.3188  loss_ce_5: 1.007  loss_mask_5: 0.05842  loss_dice_5: 0.6824  loss_bbox_5: 0.05994  loss_giou_5: 0.3578  loss_ce_dn_5: 0.2001  loss_mask_dn_5: 0.04819  loss_dice_dn_5: 0.6826  loss_bbox_dn_5: 0.04702  loss_giou_dn_5: 0.298  loss_ce_6: 0.9692  loss_mask_6: 0.05773  loss_dice_6: 0.6274  loss_bbox_6: 0.05931  loss_giou_6: 0.375  loss_ce_dn_6: 0.1928  loss_mask_dn_6: 0.04774  loss_dice_dn_6: 0.6273  loss_bbox_dn_6: 0.04616  loss_giou_dn_6: 0.3001  loss_ce_7: 1.004  loss_mask_7: 0.04976  loss_dice_7: 0.5966  loss_bbox_7: 0.06494  loss_giou_7: 0.3736  loss_ce_dn_7: 0.1936  loss_mask_dn_7: 0.04745  loss_dice_dn_7: 0.6506  loss_bbox_dn_7: 0.0459  loss_giou_dn_7: 0.3029  loss_ce_8: 1.033  loss_mask_8: 0.05474  loss_dice_8: 0.5951  loss_bbox_8: 0.06478  loss_giou_8: 0.38  loss_ce_dn_8: 0.1908  loss_mask_dn_8: 0.04767  loss_dice_dn_8: 0.6739  loss_bbox_dn_8: 0.04621  loss_giou_dn_8: 0.2989  loss_ce_interm: 1.336  loss_mask_interm: 0.04863  loss_dice_interm: 0.7679  loss_bbox_interm: 0.1067  loss_giou_interm: 0.5069  time: 1.9291  data_time: 0.1018  lr: 1e-06  max_mem: 6639M\n",
            "[05/20 17:55:18 d2.utils.events]:  eta: 1:15:11  iter: 2939  total_loss: 33.55  loss_ce: 0.7729  loss_mask: 0.0311  loss_dice: 0.421  loss_bbox: 0.04774  loss_giou: 0.2233  loss_ce_dn: 0.1503  loss_mask_dn: 0.03421  loss_dice_dn: 0.5123  loss_bbox_dn: 0.04503  loss_giou_dn: 0.2169  loss_ce_0: 1.053  loss_mask_0: 0.03536  loss_dice_0: 0.5406  loss_bbox_0: 0.04483  loss_giou_0: 0.2669  loss_ce_dn_0: 0.7126  loss_mask_dn_0: 0.1686  loss_dice_dn_0: 2.398  loss_bbox_dn_0: 0.2951  loss_giou_dn_0: 0.8502  loss_ce_1: 1.092  loss_mask_1: 0.02996  loss_dice_1: 0.435  loss_bbox_1: 0.04256  loss_giou_1: 0.2396  loss_ce_dn_1: 0.2534  loss_mask_dn_1: 0.02775  loss_dice_dn_1: 0.5465  loss_bbox_dn_1: 0.07719  loss_giou_dn_1: 0.3495  loss_ce_2: 1.012  loss_mask_2: 0.03191  loss_dice_2: 0.4853  loss_bbox_2: 0.04633  loss_giou_2: 0.2162  loss_ce_dn_2: 0.211  loss_mask_dn_2: 0.02881  loss_dice_dn_2: 0.5114  loss_bbox_dn_2: 0.05469  loss_giou_dn_2: 0.2793  loss_ce_3: 0.9495  loss_mask_3: 0.0416  loss_dice_3: 0.4497  loss_bbox_3: 0.04665  loss_giou_3: 0.2575  loss_ce_dn_3: 0.1893  loss_mask_dn_3: 0.03201  loss_dice_dn_3: 0.5443  loss_bbox_dn_3: 0.05021  loss_giou_dn_3: 0.239  loss_ce_4: 0.8723  loss_mask_4: 0.02992  loss_dice_4: 0.5587  loss_bbox_4: 0.04933  loss_giou_4: 0.234  loss_ce_dn_4: 0.1714  loss_mask_dn_4: 0.03558  loss_dice_dn_4: 0.5412  loss_bbox_dn_4: 0.04889  loss_giou_dn_4: 0.2424  loss_ce_5: 0.8634  loss_mask_5: 0.03679  loss_dice_5: 0.4364  loss_bbox_5: 0.04741  loss_giou_5: 0.2314  loss_ce_dn_5: 0.1526  loss_mask_dn_5: 0.03385  loss_dice_dn_5: 0.52  loss_bbox_dn_5: 0.04731  loss_giou_dn_5: 0.2369  loss_ce_6: 0.8554  loss_mask_6: 0.033  loss_dice_6: 0.4847  loss_bbox_6: 0.04936  loss_giou_6: 0.2283  loss_ce_dn_6: 0.1437  loss_mask_dn_6: 0.03365  loss_dice_dn_6: 0.504  loss_bbox_dn_6: 0.04744  loss_giou_dn_6: 0.2372  loss_ce_7: 0.775  loss_mask_7: 0.03112  loss_dice_7: 0.439  loss_bbox_7: 0.04766  loss_giou_7: 0.2473  loss_ce_dn_7: 0.1399  loss_mask_dn_7: 0.03451  loss_dice_dn_7: 0.5457  loss_bbox_dn_7: 0.04664  loss_giou_dn_7: 0.2206  loss_ce_8: 0.7854  loss_mask_8: 0.0286  loss_dice_8: 0.5358  loss_bbox_8: 0.04661  loss_giou_8: 0.2285  loss_ce_dn_8: 0.1451  loss_mask_dn_8: 0.03412  loss_dice_dn_8: 0.5532  loss_bbox_dn_8: 0.04583  loss_giou_dn_8: 0.218  loss_ce_interm: 1.03  loss_mask_interm: 0.03745  loss_dice_interm: 0.5367  loss_bbox_interm: 0.08684  loss_giou_interm: 0.3533  time: 1.9278  data_time: 0.1116  lr: 1e-06  max_mem: 6639M\n",
            "[05/20 17:55:54 d2.utils.events]:  eta: 1:14:39  iter: 2959  total_loss: 54.83  loss_ce: 1.255  loss_mask: 0.04648  loss_dice: 0.8855  loss_bbox: 0.131  loss_giou: 0.6067  loss_ce_dn: 0.2277  loss_mask_dn: 0.04379  loss_dice_dn: 0.7117  loss_bbox_dn: 0.0519  loss_giou_dn: 0.3524  loss_ce_0: 1.385  loss_mask_0: 0.04387  loss_dice_0: 0.881  loss_bbox_0: 0.1917  loss_giou_0: 0.7876  loss_ce_dn_0: 0.8249  loss_mask_dn_0: 0.1996  loss_dice_dn_0: 2.764  loss_bbox_dn_0: 0.3211  loss_giou_dn_0: 0.8624  loss_ce_1: 1.481  loss_mask_1: 0.05034  loss_dice_1: 0.7166  loss_bbox_1: 0.1317  loss_giou_1: 0.7624  loss_ce_dn_1: 0.2858  loss_mask_dn_1: 0.0506  loss_dice_dn_1: 0.7659  loss_bbox_dn_1: 0.1038  loss_giou_dn_1: 0.4073  loss_ce_2: 1.335  loss_mask_2: 0.04475  loss_dice_2: 0.8476  loss_bbox_2: 0.1083  loss_giou_2: 0.7546  loss_ce_dn_2: 0.2633  loss_mask_dn_2: 0.04494  loss_dice_dn_2: 0.7341  loss_bbox_dn_2: 0.06404  loss_giou_dn_2: 0.374  loss_ce_3: 1.33  loss_mask_3: 0.05118  loss_dice_3: 0.6475  loss_bbox_3: 0.1004  loss_giou_3: 0.6395  loss_ce_dn_3: 0.2705  loss_mask_dn_3: 0.04664  loss_dice_dn_3: 0.7348  loss_bbox_dn_3: 0.06367  loss_giou_dn_3: 0.3528  loss_ce_4: 1.291  loss_mask_4: 0.05196  loss_dice_4: 0.5805  loss_bbox_4: 0.1327  loss_giou_4: 0.6311  loss_ce_dn_4: 0.2562  loss_mask_dn_4: 0.04667  loss_dice_dn_4: 0.7124  loss_bbox_dn_4: 0.05867  loss_giou_dn_4: 0.3506  loss_ce_5: 1.332  loss_mask_5: 0.05007  loss_dice_5: 0.6754  loss_bbox_5: 0.1123  loss_giou_5: 0.6145  loss_ce_dn_5: 0.2413  loss_mask_dn_5: 0.0415  loss_dice_dn_5: 0.7676  loss_bbox_dn_5: 0.05511  loss_giou_dn_5: 0.3477  loss_ce_6: 1.231  loss_mask_6: 0.04803  loss_dice_6: 0.664  loss_bbox_6: 0.1312  loss_giou_6: 0.6102  loss_ce_dn_6: 0.2309  loss_mask_dn_6: 0.04291  loss_dice_dn_6: 0.7558  loss_bbox_dn_6: 0.05437  loss_giou_dn_6: 0.3441  loss_ce_7: 1.211  loss_mask_7: 0.05177  loss_dice_7: 0.7906  loss_bbox_7: 0.1447  loss_giou_7: 0.6034  loss_ce_dn_7: 0.2165  loss_mask_dn_7: 0.04275  loss_dice_dn_7: 0.764  loss_bbox_dn_7: 0.05191  loss_giou_dn_7: 0.3477  loss_ce_8: 1.243  loss_mask_8: 0.03955  loss_dice_8: 0.8036  loss_bbox_8: 0.1318  loss_giou_8: 0.5567  loss_ce_dn_8: 0.2253  loss_mask_dn_8: 0.044  loss_dice_dn_8: 0.7607  loss_bbox_dn_8: 0.05177  loss_giou_dn_8: 0.3514  loss_ce_interm: 1.389  loss_mask_interm: 0.0472  loss_dice_interm: 0.7581  loss_bbox_interm: 0.1352  loss_giou_interm: 0.691  time: 1.9267  data_time: 0.1294  lr: 1e-06  max_mem: 6639M\n",
            "[05/20 17:56:27 d2.utils.events]:  eta: 1:13:41  iter: 2979  total_loss: 39.29  loss_ce: 0.9372  loss_mask: 0.04845  loss_dice: 0.5048  loss_bbox: 0.05599  loss_giou: 0.2862  loss_ce_dn: 0.243  loss_mask_dn: 0.04716  loss_dice_dn: 0.5864  loss_bbox_dn: 0.04329  loss_giou_dn: 0.2804  loss_ce_0: 1.307  loss_mask_0: 0.04577  loss_dice_0: 0.5514  loss_bbox_0: 0.06925  loss_giou_0: 0.345  loss_ce_dn_0: 0.7285  loss_mask_dn_0: 0.3329  loss_dice_dn_0: 2.655  loss_bbox_dn_0: 0.3307  loss_giou_dn_0: 0.8569  loss_ce_1: 1.222  loss_mask_1: 0.05016  loss_dice_1: 0.5727  loss_bbox_1: 0.0637  loss_giou_1: 0.3123  loss_ce_dn_1: 0.3189  loss_mask_dn_1: 0.04956  loss_dice_dn_1: 0.5736  loss_bbox_dn_1: 0.08133  loss_giou_dn_1: 0.382  loss_ce_2: 1.08  loss_mask_2: 0.05013  loss_dice_2: 0.6856  loss_bbox_2: 0.06126  loss_giou_2: 0.3119  loss_ce_dn_2: 0.2687  loss_mask_dn_2: 0.04473  loss_dice_dn_2: 0.5716  loss_bbox_dn_2: 0.05739  loss_giou_dn_2: 0.3192  loss_ce_3: 0.9688  loss_mask_3: 0.04839  loss_dice_3: 0.5332  loss_bbox_3: 0.06747  loss_giou_3: 0.2869  loss_ce_dn_3: 0.2493  loss_mask_dn_3: 0.0446  loss_dice_dn_3: 0.5773  loss_bbox_dn_3: 0.04779  loss_giou_dn_3: 0.2927  loss_ce_4: 0.9766  loss_mask_4: 0.04591  loss_dice_4: 0.5417  loss_bbox_4: 0.06768  loss_giou_4: 0.2949  loss_ce_dn_4: 0.2417  loss_mask_dn_4: 0.04377  loss_dice_dn_4: 0.5579  loss_bbox_dn_4: 0.04702  loss_giou_dn_4: 0.2791  loss_ce_5: 0.9911  loss_mask_5: 0.04438  loss_dice_5: 0.5421  loss_bbox_5: 0.04987  loss_giou_5: 0.275  loss_ce_dn_5: 0.2367  loss_mask_dn_5: 0.0448  loss_dice_dn_5: 0.5979  loss_bbox_dn_5: 0.04363  loss_giou_dn_5: 0.2705  loss_ce_6: 0.8962  loss_mask_6: 0.05047  loss_dice_6: 0.6025  loss_bbox_6: 0.05769  loss_giou_6: 0.2894  loss_ce_dn_6: 0.226  loss_mask_dn_6: 0.04584  loss_dice_dn_6: 0.5922  loss_bbox_dn_6: 0.04357  loss_giou_dn_6: 0.2801  loss_ce_7: 0.9671  loss_mask_7: 0.05113  loss_dice_7: 0.5613  loss_bbox_7: 0.05426  loss_giou_7: 0.2914  loss_ce_dn_7: 0.2375  loss_mask_dn_7: 0.04545  loss_dice_dn_7: 0.5967  loss_bbox_dn_7: 0.04255  loss_giou_dn_7: 0.2767  loss_ce_8: 0.9359  loss_mask_8: 0.04706  loss_dice_8: 0.5649  loss_bbox_8: 0.05449  loss_giou_8: 0.2807  loss_ce_dn_8: 0.2343  loss_mask_dn_8: 0.0457  loss_dice_dn_8: 0.5894  loss_bbox_dn_8: 0.04272  loss_giou_dn_8: 0.28  loss_ce_interm: 1.278  loss_mask_interm: 0.05121  loss_dice_interm: 0.5481  loss_bbox_interm: 0.09978  loss_giou_interm: 0.3953  time: 1.9251  data_time: 0.0661  lr: 1e-06  max_mem: 6639M\n",
            "[05/20 17:57:01 d2.data.datasets.coco]: Loaded 150 images in COCO format from /content/TACO-expl/data/annotations_off_0_resval.json\n",
            "[05/20 17:57:01 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "[05/20 17:57:01 d2.data.common]: Serializing 150 elements to byte tensors and concatenating them all ...\n",
            "[05/20 17:57:01 d2.data.common]: Serialized dataset takes 0.21 MiB\n",
            "WARNING [05/20 17:57:01 d2.evaluation.coco_evaluation]: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
            "[05/20 17:57:01 d2.evaluation.evaluator]: Start inference on 150 batches\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1066, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1066, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1066, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1066])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 17:57:11 d2.evaluation.evaluator]: Inference done 11/150. Dataloading: 0.0019 s/iter. Inference: 0.3128 s/iter. Eval: 0.5170 s/iter. Total: 0.8317 s/iter. ETA=0:01:55\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 608])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 608])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 608])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1200])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 750])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 17:57:16 d2.evaluation.evaluator]: Inference done 18/150. Dataloading: 0.0022 s/iter. Inference: 0.2947 s/iter. Eval: 0.4862 s/iter. Total: 0.7833 s/iter. ETA=0:01:43\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 750])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([750, 1333])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 17:57:21 d2.evaluation.evaluator]: Inference done 24/150. Dataloading: 0.0039 s/iter. Inference: 0.3048 s/iter. Eval: 0.5199 s/iter. Total: 0.8288 s/iter. ETA=0:01:44\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 750])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([750, 1333])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 750])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 17:57:27 d2.evaluation.evaluator]: Inference done 30/150. Dataloading: 0.0038 s/iter. Inference: 0.3096 s/iter. Eval: 0.5319 s/iter. Total: 0.8456 s/iter. ETA=0:01:41\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 750])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 17:57:32 d2.evaluation.evaluator]: Inference done 37/150. Dataloading: 0.0035 s/iter. Inference: 0.3060 s/iter. Eval: 0.5153 s/iter. Total: 0.8251 s/iter. ETA=0:01:33\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 17:57:37 d2.evaluation.evaluator]: Inference done 43/150. Dataloading: 0.0041 s/iter. Inference: 0.3069 s/iter. Eval: 0.5238 s/iter. Total: 0.8352 s/iter. ETA=0:01:29\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 17:57:43 d2.evaluation.evaluator]: Inference done 49/150. Dataloading: 0.0052 s/iter. Inference: 0.3101 s/iter. Eval: 0.5264 s/iter. Total: 0.8421 s/iter. ETA=0:01:25\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 17:57:48 d2.evaluation.evaluator]: Inference done 56/150. Dataloading: 0.0049 s/iter. Inference: 0.3069 s/iter. Eval: 0.5161 s/iter. Total: 0.8283 s/iter. ETA=0:01:17\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 17:57:54 d2.evaluation.evaluator]: Inference done 63/150. Dataloading: 0.0048 s/iter. Inference: 0.3069 s/iter. Eval: 0.5173 s/iter. Total: 0.8293 s/iter. ETA=0:01:12\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 17:57:59 d2.evaluation.evaluator]: Inference done 69/150. Dataloading: 0.0047 s/iter. Inference: 0.3096 s/iter. Eval: 0.5223 s/iter. Total: 0.8370 s/iter. ETA=0:01:07\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 17:58:04 d2.evaluation.evaluator]: Inference done 76/150. Dataloading: 0.0046 s/iter. Inference: 0.3068 s/iter. Eval: 0.5150 s/iter. Total: 0.8268 s/iter. ETA=0:01:01\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([852, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 17:58:10 d2.evaluation.evaluator]: Inference done 83/150. Dataloading: 0.0046 s/iter. Inference: 0.3054 s/iter. Eval: 0.5125 s/iter. Total: 0.8230 s/iter. ETA=0:00:55\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 17:58:15 d2.evaluation.evaluator]: Inference done 89/150. Dataloading: 0.0046 s/iter. Inference: 0.3065 s/iter. Eval: 0.5181 s/iter. Total: 0.8296 s/iter. ETA=0:00:50\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 17:58:20 d2.evaluation.evaluator]: Inference done 96/150. Dataloading: 0.0044 s/iter. Inference: 0.3045 s/iter. Eval: 0.5126 s/iter. Total: 0.8219 s/iter. ETA=0:00:44\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 17:58:26 d2.evaluation.evaluator]: Inference done 103/150. Dataloading: 0.0043 s/iter. Inference: 0.3033 s/iter. Eval: 0.5111 s/iter. Total: 0.8191 s/iter. ETA=0:00:38\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 17:58:31 d2.evaluation.evaluator]: Inference done 109/150. Dataloading: 0.0045 s/iter. Inference: 0.3047 s/iter. Eval: 0.5162 s/iter. Total: 0.8258 s/iter. ETA=0:00:33\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 17:58:37 d2.evaluation.evaluator]: Inference done 116/150. Dataloading: 0.0044 s/iter. Inference: 0.3034 s/iter. Eval: 0.5122 s/iter. Total: 0.8203 s/iter. ETA=0:00:27\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 17:58:42 d2.evaluation.evaluator]: Inference done 123/150. Dataloading: 0.0044 s/iter. Inference: 0.3024 s/iter. Eval: 0.5103 s/iter. Total: 0.8175 s/iter. ETA=0:00:22\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 17:58:48 d2.evaluation.evaluator]: Inference done 129/150. Dataloading: 0.0048 s/iter. Inference: 0.3038 s/iter. Eval: 0.5164 s/iter. Total: 0.8255 s/iter. ETA=0:00:17\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 750])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 17:58:54 d2.evaluation.evaluator]: Inference done 136/150. Dataloading: 0.0047 s/iter. Inference: 0.3060 s/iter. Eval: 0.5136 s/iter. Total: 0.8247 s/iter. ETA=0:00:11\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 750])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 750])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 17:58:59 d2.evaluation.evaluator]: Inference done 143/150. Dataloading: 0.0047 s/iter. Inference: 0.3056 s/iter. Eval: 0.5128 s/iter. Total: 0.8235 s/iter. ETA=0:00:05\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 608])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 608])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 608])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 17:59:05 d2.evaluation.evaluator]: Inference done 149/150. Dataloading: 0.0051 s/iter. Inference: 0.3068 s/iter. Eval: 0.5164 s/iter. Total: 0.8287 s/iter. ETA=0:00:00\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 608])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[05/20 17:59:06 d2.evaluation.evaluator]: Total inference time: 0:02:00.235165 (0.829208 s / iter per device, on 1 devices)\n",
            "[05/20 17:59:06 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:44 (0.307077 s / iter per device, on 1 devices)\n",
            "[05/20 17:59:06 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...\n",
            "[05/20 17:59:06 d2.evaluation.coco_evaluation]: Saving results to /content/output/chkpt/inference/coco_instances_results.json\n",
            "[05/20 17:59:06 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "[05/20 17:59:06 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*\n",
            "[05/20 17:59:06 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.16 seconds.\n",
            "[05/20 17:59:06 d2.evaluation.fast_eval_api]: Accumulating evaluation results...\n",
            "[05/20 17:59:06 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.07 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.243\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.409\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.245\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.056\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.242\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.414\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.321\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.436\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.446\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.106\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.485\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.791\n",
            "[05/20 17:59:06 d2.evaluation.coco_evaluation]: Evaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
            "| 24.261 | 40.922 | 24.489 | 5.619 | 24.224 | 41.438 |\n",
            "[05/20 17:59:06 d2.evaluation.coco_evaluation]: Per-category bbox AP: \n",
            "| category   | AP     | category              | AP     | category   | AP     |\n",
            "|:-----------|:-------|:----------------------|:-------|:-----------|:-------|\n",
            "| Bottle     | 53.436 | Bottle cap            | 12.042 | Can        | 42.685 |\n",
            "| Cigarette  | 1.681  | Cup                   | 30.963 | Lid        | 35.457 |\n",
            "| Other      | 20.332 | Plastic bag & wrapper | 22.049 | Pop tab    | 8.931  |\n",
            "| Straw      | 15.031 |                       |        |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.17s)\n",
            "creating index...\n",
            "index created!\n",
            "[05/20 17:59:07 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*\n",
            "[05/20 17:59:07 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.28 seconds.\n",
            "[05/20 17:59:07 d2.evaluation.fast_eval_api]: Accumulating evaluation results...\n",
            "[05/20 17:59:07 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.06 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.386\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.500\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.394\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.212\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.465\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.522\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.454\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.644\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.661\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.413\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.751\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.839\n",
            "[05/20 17:59:07 d2.evaluation.coco_evaluation]: Evaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 38.583 | 50.029 | 39.371 | 21.202 | 46.469 | 52.203 |\n",
            "[05/20 17:59:07 d2.evaluation.coco_evaluation]: Per-category segm AP: \n",
            "| category   | AP     | category              | AP     | category   | AP     |\n",
            "|:-----------|:-------|:----------------------|:-------|:-----------|:-------|\n",
            "| Bottle     | 72.849 | Bottle cap            | 39.471 | Can        | 55.259 |\n",
            "| Cigarette  | 20.291 | Cup                   | 43.334 | Lid        | 44.494 |\n",
            "| Other      | 30.713 | Plastic bag & wrapper | 35.190 | Pop tab    | 25.600 |\n",
            "| Straw      | 18.627 |                       |        |            |        |\n",
            "[05/20 17:59:07 d2.engine.defaults]: Evaluation results for TACO_val in csv format:\n",
            "[05/20 17:59:07 d2.evaluation.testing]: copypaste: Task: bbox\n",
            "[05/20 17:59:07 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl\n",
            "[05/20 17:59:07 d2.evaluation.testing]: copypaste: 24.2606,40.9225,24.4893,5.6191,24.2244,41.4377\n",
            "[05/20 17:59:07 d2.evaluation.testing]: copypaste: Task: segm\n",
            "[05/20 17:59:07 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl\n",
            "[05/20 17:59:07 d2.evaluation.testing]: copypaste: 38.5828,50.0292,39.3714,21.2024,46.4694,52.2034\n",
            "[05/20 17:59:07 d2.utils.events]:  eta: 1:12:59  iter: 2999  total_loss: 49.62  loss_ce: 1.082  loss_mask: 0.02063  loss_dice: 0.7744  loss_bbox: 0.08613  loss_giou: 0.6116  loss_ce_dn: 0.138  loss_mask_dn: 0.02084  loss_dice_dn: 0.6457  loss_bbox_dn: 0.03671  loss_giou_dn: 0.4208  loss_ce_0: 1.295  loss_mask_0: 0.02586  loss_dice_0: 0.8443  loss_bbox_0: 0.08443  loss_giou_0: 0.7251  loss_ce_dn_0: 0.6728  loss_mask_dn_0: 0.1245  loss_dice_dn_0: 2.804  loss_bbox_dn_0: 0.17  loss_giou_dn_0: 0.8692  loss_ce_1: 1.289  loss_mask_1: 0.02444  loss_dice_1: 0.8523  loss_bbox_1: 0.07576  loss_giou_1: 0.6199  loss_ce_dn_1: 0.2522  loss_mask_dn_1: 0.01836  loss_dice_dn_1: 0.7403  loss_bbox_dn_1: 0.05114  loss_giou_dn_1: 0.4821  loss_ce_2: 1.174  loss_mask_2: 0.02323  loss_dice_2: 0.6021  loss_bbox_2: 0.06522  loss_giou_2: 0.5725  loss_ce_dn_2: 0.2291  loss_mask_dn_2: 0.01785  loss_dice_dn_2: 0.6759  loss_bbox_dn_2: 0.0421  loss_giou_dn_2: 0.4395  loss_ce_3: 1.103  loss_mask_3: 0.02371  loss_dice_3: 0.7275  loss_bbox_3: 0.06294  loss_giou_3: 0.583  loss_ce_dn_3: 0.2095  loss_mask_dn_3: 0.01986  loss_dice_dn_3: 0.6595  loss_bbox_dn_3: 0.03819  loss_giou_dn_3: 0.4172  loss_ce_4: 1.116  loss_mask_4: 0.02204  loss_dice_4: 0.7811  loss_bbox_4: 0.07483  loss_giou_4: 0.6315  loss_ce_dn_4: 0.1757  loss_mask_dn_4: 0.0214  loss_dice_dn_4: 0.6736  loss_bbox_dn_4: 0.03527  loss_giou_dn_4: 0.4119  loss_ce_5: 1.107  loss_mask_5: 0.02425  loss_dice_5: 0.7703  loss_bbox_5: 0.07932  loss_giou_5: 0.5785  loss_ce_dn_5: 0.1693  loss_mask_dn_5: 0.01923  loss_dice_dn_5: 0.6635  loss_bbox_dn_5: 0.03679  loss_giou_dn_5: 0.4145  loss_ce_6: 1.064  loss_mask_6: 0.02125  loss_dice_6: 0.7685  loss_bbox_6: 0.08829  loss_giou_6: 0.6198  loss_ce_dn_6: 0.1499  loss_mask_dn_6: 0.01993  loss_dice_dn_6: 0.6591  loss_bbox_dn_6: 0.03663  loss_giou_dn_6: 0.4114  loss_ce_7: 1.201  loss_mask_7: 0.02048  loss_dice_7: 0.7965  loss_bbox_7: 0.06905  loss_giou_7: 0.5768  loss_ce_dn_7: 0.1454  loss_mask_dn_7: 0.01828  loss_dice_dn_7: 0.6483  loss_bbox_dn_7: 0.03751  loss_giou_dn_7: 0.4127  loss_ce_8: 1.103  loss_mask_8: 0.02257  loss_dice_8: 0.8369  loss_bbox_8: 0.06362  loss_giou_8: 0.6044  loss_ce_dn_8: 0.1424  loss_mask_dn_8: 0.0209  loss_dice_dn_8: 0.7059  loss_bbox_dn_8: 0.0374  loss_giou_dn_8: 0.4207  loss_ce_interm: 1.291  loss_mask_interm: 0.02137  loss_dice_interm: 0.6383  loss_bbox_interm: 0.09065  loss_giou_interm: 0.6642  time: 1.9233  data_time: 0.0665  lr: 1e-06  max_mem: 6639M\n",
            "[05/20 17:59:43 d2.utils.events]:  eta: 1:12:34  iter: 3019  total_loss: 42.99  loss_ce: 0.8311  loss_mask: 0.037  loss_dice: 0.65  loss_bbox: 0.08726  loss_giou: 0.3048  loss_ce_dn: 0.1674  loss_mask_dn: 0.03867  loss_dice_dn: 0.6571  loss_bbox_dn: 0.04771  loss_giou_dn: 0.2916  loss_ce_0: 1.38  loss_mask_0: 0.04257  loss_dice_0: 0.6302  loss_bbox_0: 0.08766  loss_giou_0: 0.4736  loss_ce_dn_0: 0.7751  loss_mask_dn_0: 0.1974  loss_dice_dn_0: 2.544  loss_bbox_dn_0: 0.2746  loss_giou_dn_0: 0.8548  loss_ce_1: 1.271  loss_mask_1: 0.03965  loss_dice_1: 0.7162  loss_bbox_1: 0.0868  loss_giou_1: 0.3393  loss_ce_dn_1: 0.2745  loss_mask_dn_1: 0.03909  loss_dice_dn_1: 0.7384  loss_bbox_dn_1: 0.09314  loss_giou_dn_1: 0.3993  loss_ce_2: 1.209  loss_mask_2: 0.03888  loss_dice_2: 0.6955  loss_bbox_2: 0.08513  loss_giou_2: 0.3793  loss_ce_dn_2: 0.2294  loss_mask_dn_2: 0.03722  loss_dice_dn_2: 0.6755  loss_bbox_dn_2: 0.06961  loss_giou_dn_2: 0.3431  loss_ce_3: 1.047  loss_mask_3: 0.03682  loss_dice_3: 0.7818  loss_bbox_3: 0.08012  loss_giou_3: 0.3451  loss_ce_dn_3: 0.2002  loss_mask_dn_3: 0.03696  loss_dice_dn_3: 0.6747  loss_bbox_dn_3: 0.05708  loss_giou_dn_3: 0.302  loss_ce_4: 0.9711  loss_mask_4: 0.03709  loss_dice_4: 0.6837  loss_bbox_4: 0.0957  loss_giou_4: 0.3446  loss_ce_dn_4: 0.1913  loss_mask_dn_4: 0.04025  loss_dice_dn_4: 0.6736  loss_bbox_dn_4: 0.05182  loss_giou_dn_4: 0.2963  loss_ce_5: 0.9091  loss_mask_5: 0.0384  loss_dice_5: 0.643  loss_bbox_5: 0.09833  loss_giou_5: 0.3256  loss_ce_dn_5: 0.1874  loss_mask_dn_5: 0.0409  loss_dice_dn_5: 0.6695  loss_bbox_dn_5: 0.05081  loss_giou_dn_5: 0.292  loss_ce_6: 0.9329  loss_mask_6: 0.04092  loss_dice_6: 0.6416  loss_bbox_6: 0.1006  loss_giou_6: 0.38  loss_ce_dn_6: 0.1772  loss_mask_dn_6: 0.03903  loss_dice_dn_6: 0.6577  loss_bbox_dn_6: 0.05095  loss_giou_dn_6: 0.2902  loss_ce_7: 0.8452  loss_mask_7: 0.04062  loss_dice_7: 0.6197  loss_bbox_7: 0.09286  loss_giou_7: 0.3063  loss_ce_dn_7: 0.1636  loss_mask_dn_7: 0.04063  loss_dice_dn_7: 0.655  loss_bbox_dn_7: 0.04869  loss_giou_dn_7: 0.2898  loss_ce_8: 0.8709  loss_mask_8: 0.03748  loss_dice_8: 0.6523  loss_bbox_8: 0.08953  loss_giou_8: 0.3018  loss_ce_dn_8: 0.1695  loss_mask_dn_8: 0.0393  loss_dice_dn_8: 0.6546  loss_bbox_dn_8: 0.04799  loss_giou_dn_8: 0.289  loss_ce_interm: 1.414  loss_mask_interm: 0.03794  loss_dice_interm: 0.6674  loss_bbox_interm: 0.1277  loss_giou_interm: 0.4773  time: 1.9223  data_time: 0.0750  lr: 1e-06  max_mem: 6639M\n",
            "[05/20 18:00:17 d2.utils.events]:  eta: 1:12:05  iter: 3039  total_loss: 50.13  loss_ce: 1.075  loss_mask: 0.05046  loss_dice: 0.8369  loss_bbox: 0.07566  loss_giou: 0.4537  loss_ce_dn: 0.202  loss_mask_dn: 0.04021  loss_dice_dn: 0.7537  loss_bbox_dn: 0.05172  loss_giou_dn: 0.3387  loss_ce_0: 1.473  loss_mask_0: 0.04851  loss_dice_0: 0.8318  loss_bbox_0: 0.09682  loss_giou_0: 0.5174  loss_ce_dn_0: 0.7728  loss_mask_dn_0: 0.2041  loss_dice_dn_0: 3.018  loss_bbox_dn_0: 0.3033  loss_giou_dn_0: 0.8488  loss_ce_1: 1.361  loss_mask_1: 0.05014  loss_dice_1: 0.8794  loss_bbox_1: 0.07832  loss_giou_1: 0.4256  loss_ce_dn_1: 0.2803  loss_mask_dn_1: 0.04332  loss_dice_dn_1: 0.792  loss_bbox_dn_1: 0.08682  loss_giou_dn_1: 0.4153  loss_ce_2: 1.291  loss_mask_2: 0.04375  loss_dice_2: 0.731  loss_bbox_2: 0.08007  loss_giou_2: 0.446  loss_ce_dn_2: 0.2304  loss_mask_dn_2: 0.04174  loss_dice_dn_2: 0.831  loss_bbox_dn_2: 0.0676  loss_giou_dn_2: 0.3829  loss_ce_3: 1.206  loss_mask_3: 0.04857  loss_dice_3: 0.8872  loss_bbox_3: 0.07723  loss_giou_3: 0.4223  loss_ce_dn_3: 0.2248  loss_mask_dn_3: 0.04301  loss_dice_dn_3: 0.8266  loss_bbox_dn_3: 0.05614  loss_giou_dn_3: 0.3522  loss_ce_4: 1.098  loss_mask_4: 0.05012  loss_dice_4: 0.7404  loss_bbox_4: 0.07624  loss_giou_4: 0.4239  loss_ce_dn_4: 0.219  loss_mask_dn_4: 0.04358  loss_dice_dn_4: 0.828  loss_bbox_dn_4: 0.05849  loss_giou_dn_4: 0.3463  loss_ce_5: 1.014  loss_mask_5: 0.0461  loss_dice_5: 0.8388  loss_bbox_5: 0.07642  loss_giou_5: 0.4332  loss_ce_dn_5: 0.2025  loss_mask_dn_5: 0.04262  loss_dice_dn_5: 0.839  loss_bbox_dn_5: 0.05247  loss_giou_dn_5: 0.3395  loss_ce_6: 1.068  loss_mask_6: 0.04716  loss_dice_6: 0.8361  loss_bbox_6: 0.07594  loss_giou_6: 0.4305  loss_ce_dn_6: 0.2022  loss_mask_dn_6: 0.04029  loss_dice_dn_6: 0.7819  loss_bbox_dn_6: 0.0515  loss_giou_dn_6: 0.3376  loss_ce_7: 1.1  loss_mask_7: 0.04597  loss_dice_7: 0.7989  loss_bbox_7: 0.0769  loss_giou_7: 0.4424  loss_ce_dn_7: 0.2031  loss_mask_dn_7: 0.03994  loss_dice_dn_7: 0.7538  loss_bbox_dn_7: 0.05157  loss_giou_dn_7: 0.3439  loss_ce_8: 1.07  loss_mask_8: 0.04488  loss_dice_8: 0.7382  loss_bbox_8: 0.07595  loss_giou_8: 0.459  loss_ce_dn_8: 0.2016  loss_mask_dn_8: 0.03984  loss_dice_dn_8: 0.7535  loss_bbox_dn_8: 0.05205  loss_giou_dn_8: 0.3444  loss_ce_interm: 1.513  loss_mask_interm: 0.04832  loss_dice_interm: 0.9299  loss_bbox_interm: 0.08205  loss_giou_interm: 0.5755  time: 1.9208  data_time: 0.0850  lr: 1e-06  max_mem: 6639M\n",
            "[05/20 18:00:51 d2.utils.events]:  eta: 1:11:24  iter: 3059  total_loss: 38.33  loss_ce: 0.9109  loss_mask: 0.04113  loss_dice: 0.7077  loss_bbox: 0.04932  loss_giou: 0.3092  loss_ce_dn: 0.1715  loss_mask_dn: 0.03606  loss_dice_dn: 0.5166  loss_bbox_dn: 0.04187  loss_giou_dn: 0.2694  loss_ce_0: 1.12  loss_mask_0: 0.03343  loss_dice_0: 0.4509  loss_bbox_0: 0.05726  loss_giou_0: 0.4236  loss_ce_dn_0: 0.6706  loss_mask_dn_0: 0.1903  loss_dice_dn_0: 2.551  loss_bbox_dn_0: 0.2451  loss_giou_dn_0: 0.8558  loss_ce_1: 1.032  loss_mask_1: 0.04146  loss_dice_1: 0.6438  loss_bbox_1: 0.05861  loss_giou_1: 0.3346  loss_ce_dn_1: 0.2815  loss_mask_dn_1: 0.0366  loss_dice_dn_1: 0.5676  loss_bbox_dn_1: 0.07181  loss_giou_dn_1: 0.3525  loss_ce_2: 1.052  loss_mask_2: 0.03815  loss_dice_2: 0.5016  loss_bbox_2: 0.05736  loss_giou_2: 0.3463  loss_ce_dn_2: 0.2223  loss_mask_dn_2: 0.03485  loss_dice_dn_2: 0.5669  loss_bbox_dn_2: 0.05223  loss_giou_dn_2: 0.3023  loss_ce_3: 0.9395  loss_mask_3: 0.0399  loss_dice_3: 0.4857  loss_bbox_3: 0.05456  loss_giou_3: 0.3268  loss_ce_dn_3: 0.2092  loss_mask_dn_3: 0.03589  loss_dice_dn_3: 0.5844  loss_bbox_dn_3: 0.0476  loss_giou_dn_3: 0.2762  loss_ce_4: 0.9517  loss_mask_4: 0.03375  loss_dice_4: 0.5127  loss_bbox_4: 0.04925  loss_giou_4: 0.3101  loss_ce_dn_4: 0.2084  loss_mask_dn_4: 0.03466  loss_dice_dn_4: 0.5247  loss_bbox_dn_4: 0.04579  loss_giou_dn_4: 0.274  loss_ce_5: 0.95  loss_mask_5: 0.03582  loss_dice_5: 0.5609  loss_bbox_5: 0.05382  loss_giou_5: 0.303  loss_ce_dn_5: 0.1735  loss_mask_dn_5: 0.03525  loss_dice_dn_5: 0.5268  loss_bbox_dn_5: 0.04136  loss_giou_dn_5: 0.2715  loss_ce_6: 0.9083  loss_mask_6: 0.036  loss_dice_6: 0.6202  loss_bbox_6: 0.0495  loss_giou_6: 0.3011  loss_ce_dn_6: 0.1695  loss_mask_dn_6: 0.03449  loss_dice_dn_6: 0.5443  loss_bbox_dn_6: 0.04222  loss_giou_dn_6: 0.2758  loss_ce_7: 0.861  loss_mask_7: 0.03829  loss_dice_7: 0.5548  loss_bbox_7: 0.05001  loss_giou_7: 0.298  loss_ce_dn_7: 0.1762  loss_mask_dn_7: 0.03608  loss_dice_dn_7: 0.5475  loss_bbox_dn_7: 0.0432  loss_giou_dn_7: 0.2782  loss_ce_8: 0.8977  loss_mask_8: 0.03661  loss_dice_8: 0.5446  loss_bbox_8: 0.04998  loss_giou_8: 0.307  loss_ce_dn_8: 0.1722  loss_mask_dn_8: 0.03673  loss_dice_dn_8: 0.5474  loss_bbox_dn_8: 0.04367  loss_giou_dn_8: 0.2711  loss_ce_interm: 1.06  loss_mask_interm: 0.04215  loss_dice_interm: 0.516  loss_bbox_interm: 0.08407  loss_giou_interm: 0.4583  time: 1.9193  data_time: 0.0660  lr: 1e-06  max_mem: 6639M\n",
            "[05/20 18:01:24 d2.utils.events]:  eta: 1:10:44  iter: 3079  total_loss: 60.22  loss_ce: 1.388  loss_mask: 0.02698  loss_dice: 0.7324  loss_bbox: 0.06769  loss_giou: 0.4702  loss_ce_dn: 0.1986  loss_mask_dn: 0.01889  loss_dice_dn: 0.7471  loss_bbox_dn: 0.03391  loss_giou_dn: 0.3599  loss_ce_0: 1.639  loss_mask_0: 0.03077  loss_dice_0: 0.819  loss_bbox_0: 0.08345  loss_giou_0: 0.4677  loss_ce_dn_0: 0.7863  loss_mask_dn_0: 0.1269  loss_dice_dn_0: 2.963  loss_bbox_dn_0: 0.198  loss_giou_dn_0: 0.8621  loss_ce_1: 1.687  loss_mask_1: 0.03105  loss_dice_1: 0.8045  loss_bbox_1: 0.07551  loss_giou_1: 0.4132  loss_ce_dn_1: 0.2869  loss_mask_dn_1: 0.03099  loss_dice_dn_1: 0.7897  loss_bbox_dn_1: 0.05007  loss_giou_dn_1: 0.4465  loss_ce_2: 1.546  loss_mask_2: 0.02665  loss_dice_2: 0.7855  loss_bbox_2: 0.07741  loss_giou_2: 0.4246  loss_ce_dn_2: 0.235  loss_mask_dn_2: 0.02114  loss_dice_dn_2: 0.7697  loss_bbox_dn_2: 0.04109  loss_giou_dn_2: 0.3955  loss_ce_3: 1.496  loss_mask_3: 0.02361  loss_dice_3: 0.8142  loss_bbox_3: 0.07332  loss_giou_3: 0.4001  loss_ce_dn_3: 0.2227  loss_mask_dn_3: 0.02064  loss_dice_dn_3: 0.8113  loss_bbox_dn_3: 0.03478  loss_giou_dn_3: 0.3714  loss_ce_4: 1.466  loss_mask_4: 0.02265  loss_dice_4: 0.9353  loss_bbox_4: 0.07552  loss_giou_4: 0.3939  loss_ce_dn_4: 0.2142  loss_mask_dn_4: 0.01898  loss_dice_dn_4: 0.7885  loss_bbox_dn_4: 0.03546  loss_giou_dn_4: 0.361  loss_ce_5: 1.454  loss_mask_5: 0.02863  loss_dice_5: 0.7642  loss_bbox_5: 0.07053  loss_giou_5: 0.3822  loss_ce_dn_5: 0.1889  loss_mask_dn_5: 0.01824  loss_dice_dn_5: 0.7685  loss_bbox_dn_5: 0.03456  loss_giou_dn_5: 0.358  loss_ce_6: 1.378  loss_mask_6: 0.02329  loss_dice_6: 0.8252  loss_bbox_6: 0.06669  loss_giou_6: 0.4162  loss_ce_dn_6: 0.1951  loss_mask_dn_6: 0.01746  loss_dice_dn_6: 0.6982  loss_bbox_dn_6: 0.0349  loss_giou_dn_6: 0.3597  loss_ce_7: 1.393  loss_mask_7: 0.02646  loss_dice_7: 0.6002  loss_bbox_7: 0.06831  loss_giou_7: 0.4226  loss_ce_dn_7: 0.1973  loss_mask_dn_7: 0.01817  loss_dice_dn_7: 0.7191  loss_bbox_dn_7: 0.03358  loss_giou_dn_7: 0.3606  loss_ce_8: 1.405  loss_mask_8: 0.03028  loss_dice_8: 0.7729  loss_bbox_8: 0.0649  loss_giou_8: 0.4111  loss_ce_dn_8: 0.1968  loss_mask_dn_8: 0.01801  loss_dice_dn_8: 0.7406  loss_bbox_dn_8: 0.03377  loss_giou_dn_8: 0.3569  loss_ce_interm: 1.642  loss_mask_interm: 0.02939  loss_dice_interm: 0.9109  loss_bbox_interm: 0.08787  loss_giou_interm: 0.4726  time: 1.9177  data_time: 0.0706  lr: 1e-06  max_mem: 6639M\n",
            "[05/20 18:01:57 d2.utils.events]:  eta: 1:10:10  iter: 3099  total_loss: 38.45  loss_ce: 0.9428  loss_mask: 0.02478  loss_dice: 0.3746  loss_bbox: 0.07326  loss_giou: 0.2708  loss_ce_dn: 0.2524  loss_mask_dn: 0.02598  loss_dice_dn: 0.4042  loss_bbox_dn: 0.0422  loss_giou_dn: 0.241  loss_ce_0: 1.243  loss_mask_0: 0.02913  loss_dice_0: 0.4738  loss_bbox_0: 0.09489  loss_giou_0: 0.4009  loss_ce_dn_0: 0.7143  loss_mask_dn_0: 0.2295  loss_dice_dn_0: 2.148  loss_bbox_dn_0: 0.235  loss_giou_dn_0: 0.8604  loss_ce_1: 1.178  loss_mask_1: 0.02901  loss_dice_1: 0.4546  loss_bbox_1: 0.09044  loss_giou_1: 0.3285  loss_ce_dn_1: 0.3136  loss_mask_dn_1: 0.02753  loss_dice_dn_1: 0.4416  loss_bbox_dn_1: 0.06916  loss_giou_dn_1: 0.3321  loss_ce_2: 1.122  loss_mask_2: 0.03099  loss_dice_2: 0.4293  loss_bbox_2: 0.09189  loss_giou_2: 0.2854  loss_ce_dn_2: 0.2773  loss_mask_dn_2: 0.02684  loss_dice_dn_2: 0.4442  loss_bbox_dn_2: 0.05378  loss_giou_dn_2: 0.2869  loss_ce_3: 1.026  loss_mask_3: 0.02614  loss_dice_3: 0.4234  loss_bbox_3: 0.07625  loss_giou_3: 0.2937  loss_ce_dn_3: 0.2571  loss_mask_dn_3: 0.02551  loss_dice_dn_3: 0.4189  loss_bbox_dn_3: 0.04587  loss_giou_dn_3: 0.2642  loss_ce_4: 1.001  loss_mask_4: 0.02717  loss_dice_4: 0.439  loss_bbox_4: 0.08888  loss_giou_4: 0.2906  loss_ce_dn_4: 0.2333  loss_mask_dn_4: 0.02505  loss_dice_dn_4: 0.406  loss_bbox_dn_4: 0.04064  loss_giou_dn_4: 0.2628  loss_ce_5: 0.927  loss_mask_5: 0.02936  loss_dice_5: 0.4537  loss_bbox_5: 0.07348  loss_giou_5: 0.2787  loss_ce_dn_5: 0.2297  loss_mask_dn_5: 0.02631  loss_dice_dn_5: 0.4061  loss_bbox_dn_5: 0.04178  loss_giou_dn_5: 0.2522  loss_ce_6: 0.9015  loss_mask_6: 0.02482  loss_dice_6: 0.4172  loss_bbox_6: 0.08526  loss_giou_6: 0.2796  loss_ce_dn_6: 0.2262  loss_mask_dn_6: 0.02584  loss_dice_dn_6: 0.4048  loss_bbox_dn_6: 0.04302  loss_giou_dn_6: 0.2454  loss_ce_7: 0.926  loss_mask_7: 0.02389  loss_dice_7: 0.4398  loss_bbox_7: 0.07414  loss_giou_7: 0.2721  loss_ce_dn_7: 0.2479  loss_mask_dn_7: 0.02661  loss_dice_dn_7: 0.4073  loss_bbox_dn_7: 0.04298  loss_giou_dn_7: 0.2461  loss_ce_8: 0.934  loss_mask_8: 0.0266  loss_dice_8: 0.5389  loss_bbox_8: 0.07382  loss_giou_8: 0.2766  loss_ce_dn_8: 0.2484  loss_mask_dn_8: 0.02621  loss_dice_dn_8: 0.3975  loss_bbox_dn_8: 0.04193  loss_giou_dn_8: 0.2456  loss_ce_interm: 1.224  loss_mask_interm: 0.03021  loss_dice_interm: 0.4199  loss_bbox_interm: 0.1021  loss_giou_interm: 0.3882  time: 1.9159  data_time: 0.0374  lr: 1e-06  max_mem: 6639M\n",
            "[05/20 18:02:31 d2.utils.events]:  eta: 1:09:54  iter: 3119  total_loss: 43.21  loss_ce: 0.9627  loss_mask: 0.04677  loss_dice: 0.5438  loss_bbox: 0.07106  loss_giou: 0.2437  loss_ce_dn: 0.1853  loss_mask_dn: 0.05051  loss_dice_dn: 0.5629  loss_bbox_dn: 0.05397  loss_giou_dn: 0.2669  loss_ce_0: 1.277  loss_mask_0: 0.05245  loss_dice_0: 0.5365  loss_bbox_0: 0.07252  loss_giou_0: 0.3146  loss_ce_dn_0: 0.6925  loss_mask_dn_0: 0.0976  loss_dice_dn_0: 2.783  loss_bbox_dn_0: 0.3477  loss_giou_dn_0: 0.8558  loss_ce_1: 1.21  loss_mask_1: 0.05174  loss_dice_1: 0.6002  loss_bbox_1: 0.06883  loss_giou_1: 0.3249  loss_ce_dn_1: 0.2913  loss_mask_dn_1: 0.05278  loss_dice_dn_1: 0.6707  loss_bbox_dn_1: 0.07931  loss_giou_dn_1: 0.4259  loss_ce_2: 1.14  loss_mask_2: 0.04723  loss_dice_2: 0.5929  loss_bbox_2: 0.07716  loss_giou_2: 0.3138  loss_ce_dn_2: 0.2513  loss_mask_dn_2: 0.04909  loss_dice_dn_2: 0.635  loss_bbox_dn_2: 0.06802  loss_giou_dn_2: 0.3265  loss_ce_3: 1.013  loss_mask_3: 0.0505  loss_dice_3: 0.5412  loss_bbox_3: 0.07125  loss_giou_3: 0.2825  loss_ce_dn_3: 0.2227  loss_mask_dn_3: 0.04958  loss_dice_dn_3: 0.6211  loss_bbox_dn_3: 0.05819  loss_giou_dn_3: 0.2943  loss_ce_4: 0.985  loss_mask_4: 0.04958  loss_dice_4: 0.5493  loss_bbox_4: 0.07049  loss_giou_4: 0.2843  loss_ce_dn_4: 0.2056  loss_mask_dn_4: 0.04836  loss_dice_dn_4: 0.5982  loss_bbox_dn_4: 0.06141  loss_giou_dn_4: 0.2719  loss_ce_5: 0.9251  loss_mask_5: 0.04445  loss_dice_5: 0.4633  loss_bbox_5: 0.06549  loss_giou_5: 0.2791  loss_ce_dn_5: 0.2043  loss_mask_dn_5: 0.04753  loss_dice_dn_5: 0.5597  loss_bbox_dn_5: 0.05733  loss_giou_dn_5: 0.2632  loss_ce_6: 0.9516  loss_mask_6: 0.04765  loss_dice_6: 0.5767  loss_bbox_6: 0.06919  loss_giou_6: 0.2716  loss_ce_dn_6: 0.1905  loss_mask_dn_6: 0.04892  loss_dice_dn_6: 0.5603  loss_bbox_dn_6: 0.05578  loss_giou_dn_6: 0.2626  loss_ce_7: 0.9392  loss_mask_7: 0.04922  loss_dice_7: 0.5428  loss_bbox_7: 0.06073  loss_giou_7: 0.251  loss_ce_dn_7: 0.1893  loss_mask_dn_7: 0.05049  loss_dice_dn_7: 0.5853  loss_bbox_dn_7: 0.05241  loss_giou_dn_7: 0.2622  loss_ce_8: 0.9751  loss_mask_8: 0.05012  loss_dice_8: 0.5957  loss_bbox_8: 0.06191  loss_giou_8: 0.2434  loss_ce_dn_8: 0.1868  loss_mask_dn_8: 0.04993  loss_dice_dn_8: 0.5666  loss_bbox_dn_8: 0.05644  loss_giou_dn_8: 0.2658  loss_ce_interm: 1.238  loss_mask_interm: 0.05125  loss_dice_interm: 0.5651  loss_bbox_interm: 0.1266  loss_giou_interm: 0.4356  time: 1.9144  data_time: 0.0614  lr: 1e-06  max_mem: 6639M\n",
            "[05/20 18:03:06 d2.utils.events]:  eta: 1:09:27  iter: 3139  total_loss: 41.38  loss_ce: 0.9484  loss_mask: 0.04857  loss_dice: 0.3913  loss_bbox: 0.08178  loss_giou: 0.3974  loss_ce_dn: 0.1277  loss_mask_dn: 0.03963  loss_dice_dn: 0.5043  loss_bbox_dn: 0.04122  loss_giou_dn: 0.302  loss_ce_0: 1.105  loss_mask_0: 0.05075  loss_dice_0: 0.5771  loss_bbox_0: 0.07602  loss_giou_0: 0.4174  loss_ce_dn_0: 0.6798  loss_mask_dn_0: 0.1872  loss_dice_dn_0: 2.442  loss_bbox_dn_0: 0.3239  loss_giou_dn_0: 0.8533  loss_ce_1: 1.14  loss_mask_1: 0.05677  loss_dice_1: 0.5617  loss_bbox_1: 0.07641  loss_giou_1: 0.4086  loss_ce_dn_1: 0.2475  loss_mask_dn_1: 0.045  loss_dice_dn_1: 0.586  loss_bbox_dn_1: 0.07447  loss_giou_dn_1: 0.3838  loss_ce_2: 1.086  loss_mask_2: 0.04542  loss_dice_2: 0.5039  loss_bbox_2: 0.07769  loss_giou_2: 0.3991  loss_ce_dn_2: 0.1963  loss_mask_dn_2: 0.04502  loss_dice_dn_2: 0.5221  loss_bbox_dn_2: 0.05682  loss_giou_dn_2: 0.3613  loss_ce_3: 0.9474  loss_mask_3: 0.053  loss_dice_3: 0.6034  loss_bbox_3: 0.0785  loss_giou_3: 0.3919  loss_ce_dn_3: 0.1738  loss_mask_dn_3: 0.04445  loss_dice_dn_3: 0.5266  loss_bbox_dn_3: 0.04991  loss_giou_dn_3: 0.3376  loss_ce_4: 0.9283  loss_mask_4: 0.05112  loss_dice_4: 0.4536  loss_bbox_4: 0.08208  loss_giou_4: 0.399  loss_ce_dn_4: 0.1602  loss_mask_dn_4: 0.04059  loss_dice_dn_4: 0.4982  loss_bbox_dn_4: 0.04636  loss_giou_dn_4: 0.3232  loss_ce_5: 0.9799  loss_mask_5: 0.05782  loss_dice_5: 0.4023  loss_bbox_5: 0.08333  loss_giou_5: 0.3987  loss_ce_dn_5: 0.1458  loss_mask_dn_5: 0.04105  loss_dice_dn_5: 0.4797  loss_bbox_dn_5: 0.04332  loss_giou_dn_5: 0.3137  loss_ce_6: 0.9482  loss_mask_6: 0.04241  loss_dice_6: 0.351  loss_bbox_6: 0.08399  loss_giou_6: 0.3987  loss_ce_dn_6: 0.1378  loss_mask_dn_6: 0.04208  loss_dice_dn_6: 0.5657  loss_bbox_dn_6: 0.04245  loss_giou_dn_6: 0.3115  loss_ce_7: 0.8837  loss_mask_7: 0.05218  loss_dice_7: 0.5578  loss_bbox_7: 0.07977  loss_giou_7: 0.3853  loss_ce_dn_7: 0.1369  loss_mask_dn_7: 0.03983  loss_dice_dn_7: 0.4771  loss_bbox_dn_7: 0.04171  loss_giou_dn_7: 0.3055  loss_ce_8: 0.8746  loss_mask_8: 0.04548  loss_dice_8: 0.4408  loss_bbox_8: 0.07717  loss_giou_8: 0.3761  loss_ce_dn_8: 0.1321  loss_mask_dn_8: 0.03941  loss_dice_dn_8: 0.4824  loss_bbox_dn_8: 0.04157  loss_giou_dn_8: 0.3045  loss_ce_interm: 1.181  loss_mask_interm: 0.06236  loss_dice_interm: 0.5299  loss_bbox_interm: 0.09911  loss_giou_interm: 0.4636  time: 1.9133  data_time: 0.0850  lr: 1e-06  max_mem: 6639M\n",
            "[05/20 18:03:41 d2.utils.events]:  eta: 1:08:59  iter: 3159  total_loss: 45.67  loss_ce: 1.175  loss_mask: 0.03141  loss_dice: 0.9084  loss_bbox: 0.07976  loss_giou: 0.3921  loss_ce_dn: 0.2127  loss_mask_dn: 0.02667  loss_dice_dn: 0.7176  loss_bbox_dn: 0.03507  loss_giou_dn: 0.3143  loss_ce_0: 1.302  loss_mask_0: 0.02922  loss_dice_0: 0.8224  loss_bbox_0: 0.07566  loss_giou_0: 0.4516  loss_ce_dn_0: 0.7551  loss_mask_dn_0: 0.1102  loss_dice_dn_0: 2.805  loss_bbox_dn_0: 0.2054  loss_giou_dn_0: 0.8624  loss_ce_1: 1.255  loss_mask_1: 0.03175  loss_dice_1: 0.7854  loss_bbox_1: 0.07926  loss_giou_1: 0.4063  loss_ce_dn_1: 0.2582  loss_mask_dn_1: 0.02919  loss_dice_dn_1: 0.7432  loss_bbox_dn_1: 0.05134  loss_giou_dn_1: 0.4206  loss_ce_2: 1.242  loss_mask_2: 0.03471  loss_dice_2: 0.824  loss_bbox_2: 0.08163  loss_giou_2: 0.4221  loss_ce_dn_2: 0.2351  loss_mask_dn_2: 0.02376  loss_dice_dn_2: 0.7304  loss_bbox_dn_2: 0.04108  loss_giou_dn_2: 0.3497  loss_ce_3: 1.081  loss_mask_3: 0.02977  loss_dice_3: 0.9767  loss_bbox_3: 0.0825  loss_giou_3: 0.4107  loss_ce_dn_3: 0.2294  loss_mask_dn_3: 0.02443  loss_dice_dn_3: 0.7308  loss_bbox_dn_3: 0.03729  loss_giou_dn_3: 0.3194  loss_ce_4: 1.076  loss_mask_4: 0.03389  loss_dice_4: 0.8343  loss_bbox_4: 0.07646  loss_giou_4: 0.4158  loss_ce_dn_4: 0.2062  loss_mask_dn_4: 0.02765  loss_dice_dn_4: 0.7061  loss_bbox_dn_4: 0.0356  loss_giou_dn_4: 0.3176  loss_ce_5: 1.231  loss_mask_5: 0.03306  loss_dice_5: 0.6971  loss_bbox_5: 0.08173  loss_giou_5: 0.412  loss_ce_dn_5: 0.2039  loss_mask_dn_5: 0.0274  loss_dice_dn_5: 0.7326  loss_bbox_dn_5: 0.03474  loss_giou_dn_5: 0.3157  loss_ce_6: 1.056  loss_mask_6: 0.0278  loss_dice_6: 0.7982  loss_bbox_6: 0.08142  loss_giou_6: 0.413  loss_ce_dn_6: 0.2126  loss_mask_dn_6: 0.02718  loss_dice_dn_6: 0.7126  loss_bbox_dn_6: 0.03474  loss_giou_dn_6: 0.3226  loss_ce_7: 1.037  loss_mask_7: 0.03087  loss_dice_7: 0.7022  loss_bbox_7: 0.08313  loss_giou_7: 0.4039  loss_ce_dn_7: 0.2027  loss_mask_dn_7: 0.0268  loss_dice_dn_7: 0.7077  loss_bbox_dn_7: 0.03495  loss_giou_dn_7: 0.3168  loss_ce_8: 1.173  loss_mask_8: 0.03199  loss_dice_8: 0.6491  loss_bbox_8: 0.08099  loss_giou_8: 0.3979  loss_ce_dn_8: 0.2094  loss_mask_dn_8: 0.02642  loss_dice_dn_8: 0.7093  loss_bbox_dn_8: 0.03464  loss_giou_dn_8: 0.3153  loss_ce_interm: 1.336  loss_mask_interm: 0.03261  loss_dice_interm: 0.7862  loss_bbox_interm: 0.07467  loss_giou_interm: 0.4478  time: 1.9123  data_time: 0.0991  lr: 1e-06  max_mem: 6639M\n",
            "[05/20 18:04:16 d2.utils.events]:  eta: 1:08:25  iter: 3179  total_loss: 43.27  loss_ce: 0.9577  loss_mask: 0.05618  loss_dice: 0.4803  loss_bbox: 0.08713  loss_giou: 0.2621  loss_ce_dn: 0.1993  loss_mask_dn: 0.04906  loss_dice_dn: 0.4658  loss_bbox_dn: 0.04548  loss_giou_dn: 0.2486  loss_ce_0: 1.237  loss_mask_0: 0.04655  loss_dice_0: 0.5485  loss_bbox_0: 0.08062  loss_giou_0: 0.2999  loss_ce_dn_0: 0.7676  loss_mask_dn_0: 0.2668  loss_dice_dn_0: 2.219  loss_bbox_dn_0: 0.4672  loss_giou_dn_0: 0.8583  loss_ce_1: 1.175  loss_mask_1: 0.05825  loss_dice_1: 0.6138  loss_bbox_1: 0.0776  loss_giou_1: 0.2425  loss_ce_dn_1: 0.3017  loss_mask_dn_1: 0.05348  loss_dice_dn_1: 0.5545  loss_bbox_dn_1: 0.101  loss_giou_dn_1: 0.3777  loss_ce_2: 1.163  loss_mask_2: 0.05013  loss_dice_2: 0.5887  loss_bbox_2: 0.07597  loss_giou_2: 0.2632  loss_ce_dn_2: 0.259  loss_mask_dn_2: 0.04853  loss_dice_dn_2: 0.4997  loss_bbox_dn_2: 0.06491  loss_giou_dn_2: 0.2837  loss_ce_3: 1.023  loss_mask_3: 0.05147  loss_dice_3: 0.572  loss_bbox_3: 0.07807  loss_giou_3: 0.2371  loss_ce_dn_3: 0.2244  loss_mask_dn_3: 0.05035  loss_dice_dn_3: 0.4999  loss_bbox_dn_3: 0.05341  loss_giou_dn_3: 0.2624  loss_ce_4: 0.9504  loss_mask_4: 0.04809  loss_dice_4: 0.5826  loss_bbox_4: 0.08045  loss_giou_4: 0.2197  loss_ce_dn_4: 0.2111  loss_mask_dn_4: 0.04945  loss_dice_dn_4: 0.4488  loss_bbox_dn_4: 0.05401  loss_giou_dn_4: 0.2511  loss_ce_5: 0.9675  loss_mask_5: 0.0546  loss_dice_5: 0.5059  loss_bbox_5: 0.08279  loss_giou_5: 0.2187  loss_ce_dn_5: 0.2157  loss_mask_dn_5: 0.04789  loss_dice_dn_5: 0.4511  loss_bbox_dn_5: 0.05225  loss_giou_dn_5: 0.2513  loss_ce_6: 0.97  loss_mask_6: 0.05346  loss_dice_6: 0.5906  loss_bbox_6: 0.08379  loss_giou_6: 0.2271  loss_ce_dn_6: 0.2071  loss_mask_dn_6: 0.05041  loss_dice_dn_6: 0.4541  loss_bbox_dn_6: 0.05219  loss_giou_dn_6: 0.2475  loss_ce_7: 0.9503  loss_mask_7: 0.05488  loss_dice_7: 0.4902  loss_bbox_7: 0.0842  loss_giou_7: 0.2214  loss_ce_dn_7: 0.2045  loss_mask_dn_7: 0.0508  loss_dice_dn_7: 0.4641  loss_bbox_dn_7: 0.05116  loss_giou_dn_7: 0.2469  loss_ce_8: 0.9107  loss_mask_8: 0.055  loss_dice_8: 0.4764  loss_bbox_8: 0.08528  loss_giou_8: 0.2219  loss_ce_dn_8: 0.1992  loss_mask_dn_8: 0.04972  loss_dice_dn_8: 0.4586  loss_bbox_dn_8: 0.04677  loss_giou_dn_8: 0.2479  loss_ce_interm: 1.253  loss_mask_interm: 0.04843  loss_dice_interm: 0.5803  loss_bbox_interm: 0.1245  loss_giou_interm: 0.3893  time: 1.9114  data_time: 0.1216  lr: 1e-06  max_mem: 6639M\n",
            "[05/20 18:04:50 d2.utils.events]:  eta: 1:07:51  iter: 3199  total_loss: 45.8  loss_ce: 0.9203  loss_mask: 0.05314  loss_dice: 0.7014  loss_bbox: 0.0683  loss_giou: 0.3729  loss_ce_dn: 0.2059  loss_mask_dn: 0.04843  loss_dice_dn: 0.7363  loss_bbox_dn: 0.04849  loss_giou_dn: 0.3303  loss_ce_0: 1.221  loss_mask_0: 0.05234  loss_dice_0: 0.7311  loss_bbox_0: 0.07135  loss_giou_0: 0.4885  loss_ce_dn_0: 0.6722  loss_mask_dn_0: 0.1294  loss_dice_dn_0: 2.47  loss_bbox_dn_0: 0.2357  loss_giou_dn_0: 0.8592  loss_ce_1: 1.126  loss_mask_1: 0.05152  loss_dice_1: 0.8333  loss_bbox_1: 0.06675  loss_giou_1: 0.3895  loss_ce_dn_1: 0.3015  loss_mask_dn_1: 0.04486  loss_dice_dn_1: 0.7931  loss_bbox_dn_1: 0.07578  loss_giou_dn_1: 0.3923  loss_ce_2: 1.092  loss_mask_2: 0.05109  loss_dice_2: 0.7073  loss_bbox_2: 0.07543  loss_giou_2: 0.4226  loss_ce_dn_2: 0.2694  loss_mask_dn_2: 0.0409  loss_dice_dn_2: 0.8198  loss_bbox_dn_2: 0.06548  loss_giou_dn_2: 0.3462  loss_ce_3: 0.9738  loss_mask_3: 0.04944  loss_dice_3: 0.7755  loss_bbox_3: 0.06528  loss_giou_3: 0.4001  loss_ce_dn_3: 0.2389  loss_mask_dn_3: 0.04556  loss_dice_dn_3: 0.8466  loss_bbox_dn_3: 0.05889  loss_giou_dn_3: 0.3179  loss_ce_4: 0.897  loss_mask_4: 0.0538  loss_dice_4: 0.9104  loss_bbox_4: 0.07088  loss_giou_4: 0.3751  loss_ce_dn_4: 0.2102  loss_mask_dn_4: 0.04675  loss_dice_dn_4: 0.7648  loss_bbox_dn_4: 0.0503  loss_giou_dn_4: 0.343  loss_ce_5: 0.9381  loss_mask_5: 0.05381  loss_dice_5: 0.7276  loss_bbox_5: 0.06476  loss_giou_5: 0.3782  loss_ce_dn_5: 0.1995  loss_mask_dn_5: 0.0454  loss_dice_dn_5: 0.7886  loss_bbox_dn_5: 0.05168  loss_giou_dn_5: 0.3257  loss_ce_6: 0.9481  loss_mask_6: 0.05384  loss_dice_6: 0.8327  loss_bbox_6: 0.06451  loss_giou_6: 0.3707  loss_ce_dn_6: 0.1956  loss_mask_dn_6: 0.04479  loss_dice_dn_6: 0.7658  loss_bbox_dn_6: 0.04879  loss_giou_dn_6: 0.3152  loss_ce_7: 0.9516  loss_mask_7: 0.05309  loss_dice_7: 0.9505  loss_bbox_7: 0.0554  loss_giou_7: 0.3724  loss_ce_dn_7: 0.2026  loss_mask_dn_7: 0.04834  loss_dice_dn_7: 0.7708  loss_bbox_dn_7: 0.049  loss_giou_dn_7: 0.32  loss_ce_8: 0.8962  loss_mask_8: 0.04807  loss_dice_8: 0.8313  loss_bbox_8: 0.06667  loss_giou_8: 0.3758  loss_ce_dn_8: 0.2028  loss_mask_dn_8: 0.04878  loss_dice_dn_8: 0.7911  loss_bbox_dn_8: 0.04886  loss_giou_dn_8: 0.3305  loss_ce_interm: 1.216  loss_mask_interm: 0.05973  loss_dice_interm: 0.7453  loss_bbox_interm: 0.132  loss_giou_interm: 0.5335  time: 1.9100  data_time: 0.0985  lr: 1e-06  max_mem: 6639M\n",
            "[05/20 18:05:25 d2.utils.events]:  eta: 1:07:18  iter: 3219  total_loss: 44.47  loss_ce: 1.088  loss_mask: 0.0387  loss_dice: 0.6577  loss_bbox: 0.06522  loss_giou: 0.391  loss_ce_dn: 0.204  loss_mask_dn: 0.04157  loss_dice_dn: 0.6402  loss_bbox_dn: 0.03715  loss_giou_dn: 0.3023  loss_ce_0: 1.31  loss_mask_0: 0.05429  loss_dice_0: 0.7039  loss_bbox_0: 0.07491  loss_giou_0: 0.4628  loss_ce_dn_0: 0.7467  loss_mask_dn_0: 0.1669  loss_dice_dn_0: 2.632  loss_bbox_dn_0: 0.2582  loss_giou_dn_0: 0.8635  loss_ce_1: 1.285  loss_mask_1: 0.05735  loss_dice_1: 0.6783  loss_bbox_1: 0.07271  loss_giou_1: 0.4425  loss_ce_dn_1: 0.3125  loss_mask_dn_1: 0.04268  loss_dice_dn_1: 0.6134  loss_bbox_dn_1: 0.07699  loss_giou_dn_1: 0.4235  loss_ce_2: 1.25  loss_mask_2: 0.04646  loss_dice_2: 0.7193  loss_bbox_2: 0.0729  loss_giou_2: 0.453  loss_ce_dn_2: 0.2565  loss_mask_dn_2: 0.04109  loss_dice_dn_2: 0.6198  loss_bbox_dn_2: 0.05646  loss_giou_dn_2: 0.373  loss_ce_3: 1.159  loss_mask_3: 0.0422  loss_dice_3: 0.7445  loss_bbox_3: 0.0705  loss_giou_3: 0.4381  loss_ce_dn_3: 0.2466  loss_mask_dn_3: 0.04215  loss_dice_dn_3: 0.6226  loss_bbox_dn_3: 0.04628  loss_giou_dn_3: 0.341  loss_ce_4: 1.068  loss_mask_4: 0.05075  loss_dice_4: 0.7368  loss_bbox_4: 0.06962  loss_giou_4: 0.448  loss_ce_dn_4: 0.2301  loss_mask_dn_4: 0.04071  loss_dice_dn_4: 0.6319  loss_bbox_dn_4: 0.04425  loss_giou_dn_4: 0.3288  loss_ce_5: 1.115  loss_mask_5: 0.04667  loss_dice_5: 0.6268  loss_bbox_5: 0.06554  loss_giou_5: 0.4366  loss_ce_dn_5: 0.2037  loss_mask_dn_5: 0.03876  loss_dice_dn_5: 0.5895  loss_bbox_dn_5: 0.03727  loss_giou_dn_5: 0.3144  loss_ce_6: 1.116  loss_mask_6: 0.03231  loss_dice_6: 0.6726  loss_bbox_6: 0.06709  loss_giou_6: 0.3922  loss_ce_dn_6: 0.1972  loss_mask_dn_6: 0.0385  loss_dice_dn_6: 0.5571  loss_bbox_dn_6: 0.03847  loss_giou_dn_6: 0.3088  loss_ce_7: 1.116  loss_mask_7: 0.04343  loss_dice_7: 0.7755  loss_bbox_7: 0.05667  loss_giou_7: 0.4021  loss_ce_dn_7: 0.2036  loss_mask_dn_7: 0.04062  loss_dice_dn_7: 0.5434  loss_bbox_dn_7: 0.0386  loss_giou_dn_7: 0.3058  loss_ce_8: 1.084  loss_mask_8: 0.05307  loss_dice_8: 0.6581  loss_bbox_8: 0.05576  loss_giou_8: 0.3926  loss_ce_dn_8: 0.2037  loss_mask_dn_8: 0.04226  loss_dice_dn_8: 0.54  loss_bbox_dn_8: 0.03755  loss_giou_dn_8: 0.3018  loss_ce_interm: 1.413  loss_mask_interm: 0.04969  loss_dice_interm: 0.5747  loss_bbox_interm: 0.1072  loss_giou_interm: 0.5771  time: 1.9090  data_time: 0.1352  lr: 1e-06  max_mem: 6639M\n",
            "[05/20 18:05:59 d2.utils.events]:  eta: 1:06:43  iter: 3239  total_loss: 42.16  loss_ce: 0.8585  loss_mask: 0.03527  loss_dice: 0.51  loss_bbox: 0.05636  loss_giou: 0.2835  loss_ce_dn: 0.1704  loss_mask_dn: 0.03215  loss_dice_dn: 0.5284  loss_bbox_dn: 0.04001  loss_giou_dn: 0.247  loss_ce_0: 1.185  loss_mask_0: 0.03663  loss_dice_0: 0.5324  loss_bbox_0: 0.07252  loss_giou_0: 0.4281  loss_ce_dn_0: 0.8179  loss_mask_dn_0: 0.1133  loss_dice_dn_0: 2.372  loss_bbox_dn_0: 0.2699  loss_giou_dn_0: 0.8633  loss_ce_1: 1.187  loss_mask_1: 0.03436  loss_dice_1: 0.5214  loss_bbox_1: 0.0479  loss_giou_1: 0.304  loss_ce_dn_1: 0.2714  loss_mask_dn_1: 0.03569  loss_dice_dn_1: 0.6037  loss_bbox_dn_1: 0.07843  loss_giou_dn_1: 0.3553  loss_ce_2: 1.143  loss_mask_2: 0.03726  loss_dice_2: 0.4933  loss_bbox_2: 0.04973  loss_giou_2: 0.3103  loss_ce_dn_2: 0.2091  loss_mask_dn_2: 0.03151  loss_dice_dn_2: 0.5492  loss_bbox_dn_2: 0.04781  loss_giou_dn_2: 0.2911  loss_ce_3: 0.8805  loss_mask_3: 0.04126  loss_dice_3: 0.5261  loss_bbox_3: 0.04463  loss_giou_3: 0.2726  loss_ce_dn_3: 0.2008  loss_mask_dn_3: 0.03266  loss_dice_dn_3: 0.5917  loss_bbox_dn_3: 0.04316  loss_giou_dn_3: 0.2701  loss_ce_4: 0.8557  loss_mask_4: 0.04234  loss_dice_4: 0.4999  loss_bbox_4: 0.05128  loss_giou_4: 0.2937  loss_ce_dn_4: 0.1852  loss_mask_dn_4: 0.0332  loss_dice_dn_4: 0.5638  loss_bbox_dn_4: 0.03917  loss_giou_dn_4: 0.2572  loss_ce_5: 0.8764  loss_mask_5: 0.03213  loss_dice_5: 0.4848  loss_bbox_5: 0.05785  loss_giou_5: 0.2901  loss_ce_dn_5: 0.1834  loss_mask_dn_5: 0.03264  loss_dice_dn_5: 0.5582  loss_bbox_dn_5: 0.04198  loss_giou_dn_5: 0.2539  loss_ce_6: 0.9103  loss_mask_6: 0.04098  loss_dice_6: 0.6312  loss_bbox_6: 0.05375  loss_giou_6: 0.2881  loss_ce_dn_6: 0.1829  loss_mask_dn_6: 0.03225  loss_dice_dn_6: 0.543  loss_bbox_dn_6: 0.04253  loss_giou_dn_6: 0.262  loss_ce_7: 0.8706  loss_mask_7: 0.03327  loss_dice_7: 0.4668  loss_bbox_7: 0.05244  loss_giou_7: 0.2839  loss_ce_dn_7: 0.1736  loss_mask_dn_7: 0.03384  loss_dice_dn_7: 0.5245  loss_bbox_dn_7: 0.04083  loss_giou_dn_7: 0.254  loss_ce_8: 0.8467  loss_mask_8: 0.03899  loss_dice_8: 0.5815  loss_bbox_8: 0.06046  loss_giou_8: 0.3061  loss_ce_dn_8: 0.1764  loss_mask_dn_8: 0.03205  loss_dice_dn_8: 0.521  loss_bbox_dn_8: 0.04149  loss_giou_dn_8: 0.2479  loss_ce_interm: 1.213  loss_mask_interm: 0.03344  loss_dice_interm: 0.6364  loss_bbox_interm: 0.08524  loss_giou_interm: 0.4652  time: 1.9077  data_time: 0.0943  lr: 1e-06  max_mem: 6639M\n",
            "[05/20 18:06:35 d2.utils.events]:  eta: 1:06:05  iter: 3259  total_loss: 41.79  loss_ce: 0.8706  loss_mask: 0.04245  loss_dice: 0.4894  loss_bbox: 0.06744  loss_giou: 0.2857  loss_ce_dn: 0.1541  loss_mask_dn: 0.04226  loss_dice_dn: 0.6122  loss_bbox_dn: 0.04976  loss_giou_dn: 0.27  loss_ce_0: 0.966  loss_mask_0: 0.0434  loss_dice_0: 0.7025  loss_bbox_0: 0.05607  loss_giou_0: 0.3318  loss_ce_dn_0: 0.698  loss_mask_dn_0: 0.2706  loss_dice_dn_0: 2.484  loss_bbox_dn_0: 0.3293  loss_giou_dn_0: 0.8612  loss_ce_1: 1.057  loss_mask_1: 0.04433  loss_dice_1: 0.6259  loss_bbox_1: 0.06827  loss_giou_1: 0.3626  loss_ce_dn_1: 0.237  loss_mask_dn_1: 0.0392  loss_dice_dn_1: 0.6363  loss_bbox_dn_1: 0.0823  loss_giou_dn_1: 0.3607  loss_ce_2: 1.131  loss_mask_2: 0.04082  loss_dice_2: 0.6544  loss_bbox_2: 0.07557  loss_giou_2: 0.3484  loss_ce_dn_2: 0.2021  loss_mask_dn_2: 0.03767  loss_dice_dn_2: 0.6389  loss_bbox_dn_2: 0.06487  loss_giou_dn_2: 0.3112  loss_ce_3: 0.9085  loss_mask_3: 0.04586  loss_dice_3: 0.6691  loss_bbox_3: 0.08099  loss_giou_3: 0.3181  loss_ce_dn_3: 0.1842  loss_mask_dn_3: 0.03981  loss_dice_dn_3: 0.6164  loss_bbox_dn_3: 0.04854  loss_giou_dn_3: 0.295  loss_ce_4: 0.8049  loss_mask_4: 0.04139  loss_dice_4: 0.6077  loss_bbox_4: 0.05878  loss_giou_4: 0.2887  loss_ce_dn_4: 0.1686  loss_mask_dn_4: 0.03907  loss_dice_dn_4: 0.6286  loss_bbox_dn_4: 0.05264  loss_giou_dn_4: 0.2755  loss_ce_5: 0.8959  loss_mask_5: 0.04151  loss_dice_5: 0.5558  loss_bbox_5: 0.06125  loss_giou_5: 0.2925  loss_ce_dn_5: 0.1586  loss_mask_dn_5: 0.03822  loss_dice_dn_5: 0.6187  loss_bbox_dn_5: 0.05009  loss_giou_dn_5: 0.271  loss_ce_6: 0.9372  loss_mask_6: 0.0455  loss_dice_6: 0.5342  loss_bbox_6: 0.06901  loss_giou_6: 0.2911  loss_ce_dn_6: 0.1552  loss_mask_dn_6: 0.03994  loss_dice_dn_6: 0.6094  loss_bbox_dn_6: 0.04919  loss_giou_dn_6: 0.2676  loss_ce_7: 0.8382  loss_mask_7: 0.04601  loss_dice_7: 0.5939  loss_bbox_7: 0.07077  loss_giou_7: 0.3139  loss_ce_dn_7: 0.1561  loss_mask_dn_7: 0.03933  loss_dice_dn_7: 0.5836  loss_bbox_dn_7: 0.05043  loss_giou_dn_7: 0.2636  loss_ce_8: 0.8606  loss_mask_8: 0.03822  loss_dice_8: 0.5877  loss_bbox_8: 0.07024  loss_giou_8: 0.2852  loss_ce_dn_8: 0.1558  loss_mask_dn_8: 0.04137  loss_dice_dn_8: 0.6165  loss_bbox_dn_8: 0.04884  loss_giou_dn_8: 0.267  loss_ce_interm: 1.193  loss_mask_interm: 0.04129  loss_dice_interm: 0.7409  loss_bbox_interm: 0.09134  loss_giou_interm: 0.4078  time: 1.9071  data_time: 0.1263  lr: 1e-06  max_mem: 6639M\n",
            "[05/20 18:07:10 d2.utils.events]:  eta: 1:05:28  iter: 3279  total_loss: 32.23  loss_ce: 0.6575  loss_mask: 0.04321  loss_dice: 0.374  loss_bbox: 0.04694  loss_giou: 0.2289  loss_ce_dn: 0.1649  loss_mask_dn: 0.04089  loss_dice_dn: 0.3689  loss_bbox_dn: 0.03214  loss_giou_dn: 0.1843  loss_ce_0: 1.115  loss_mask_0: 0.05152  loss_dice_0: 0.3898  loss_bbox_0: 0.04859  loss_giou_0: 0.2656  loss_ce_dn_0: 0.7355  loss_mask_dn_0: 0.3171  loss_dice_dn_0: 2.387  loss_bbox_dn_0: 0.3611  loss_giou_dn_0: 0.8589  loss_ce_1: 1.019  loss_mask_1: 0.05044  loss_dice_1: 0.3721  loss_bbox_1: 0.04987  loss_giou_1: 0.2149  loss_ce_dn_1: 0.2404  loss_mask_dn_1: 0.04424  loss_dice_dn_1: 0.3913  loss_bbox_dn_1: 0.07649  loss_giou_dn_1: 0.269  loss_ce_2: 0.9213  loss_mask_2: 0.04645  loss_dice_2: 0.4183  loss_bbox_2: 0.05189  loss_giou_2: 0.2427  loss_ce_dn_2: 0.2082  loss_mask_dn_2: 0.04133  loss_dice_dn_2: 0.3951  loss_bbox_dn_2: 0.05215  loss_giou_dn_2: 0.232  loss_ce_3: 0.7644  loss_mask_3: 0.04129  loss_dice_3: 0.2938  loss_bbox_3: 0.05033  loss_giou_3: 0.2363  loss_ce_dn_3: 0.1845  loss_mask_dn_3: 0.04434  loss_dice_dn_3: 0.3702  loss_bbox_dn_3: 0.0432  loss_giou_dn_3: 0.2045  loss_ce_4: 0.6047  loss_mask_4: 0.04213  loss_dice_4: 0.4204  loss_bbox_4: 0.05646  loss_giou_4: 0.2612  loss_ce_dn_4: 0.172  loss_mask_dn_4: 0.04558  loss_dice_dn_4: 0.3942  loss_bbox_dn_4: 0.03947  loss_giou_dn_4: 0.1953  loss_ce_5: 0.6672  loss_mask_5: 0.03849  loss_dice_5: 0.3405  loss_bbox_5: 0.05179  loss_giou_5: 0.2271  loss_ce_dn_5: 0.1705  loss_mask_dn_5: 0.04024  loss_dice_dn_5: 0.3733  loss_bbox_dn_5: 0.03584  loss_giou_dn_5: 0.1924  loss_ce_6: 0.6174  loss_mask_6: 0.04051  loss_dice_6: 0.3411  loss_bbox_6: 0.05076  loss_giou_6: 0.2224  loss_ce_dn_6: 0.1633  loss_mask_dn_6: 0.04029  loss_dice_dn_6: 0.3745  loss_bbox_dn_6: 0.03529  loss_giou_dn_6: 0.1861  loss_ce_7: 0.602  loss_mask_7: 0.03918  loss_dice_7: 0.3877  loss_bbox_7: 0.05252  loss_giou_7: 0.2491  loss_ce_dn_7: 0.1586  loss_mask_dn_7: 0.04074  loss_dice_dn_7: 0.3868  loss_bbox_dn_7: 0.03482  loss_giou_dn_7: 0.186  loss_ce_8: 0.6942  loss_mask_8: 0.04063  loss_dice_8: 0.4356  loss_bbox_8: 0.04863  loss_giou_8: 0.226  loss_ce_dn_8: 0.1634  loss_mask_dn_8: 0.04208  loss_dice_dn_8: 0.3883  loss_bbox_dn_8: 0.03298  loss_giou_dn_8: 0.1811  loss_ce_interm: 1.045  loss_mask_interm: 0.0564  loss_dice_interm: 0.44  loss_bbox_interm: 0.1117  loss_giou_interm: 0.3428  time: 1.9060  data_time: 0.1079  lr: 1e-06  max_mem: 6639M\n",
            "[05/20 18:07:45 d2.utils.events]:  eta: 1:05:07  iter: 3299  total_loss: 47.81  loss_ce: 1.016  loss_mask: 0.04689  loss_dice: 0.6591  loss_bbox: 0.09609  loss_giou: 0.3567  loss_ce_dn: 0.1569  loss_mask_dn: 0.03789  loss_dice_dn: 0.6375  loss_bbox_dn: 0.05209  loss_giou_dn: 0.2896  loss_ce_0: 1.561  loss_mask_0: 0.06353  loss_dice_0: 0.6737  loss_bbox_0: 0.1063  loss_giou_0: 0.437  loss_ce_dn_0: 0.7492  loss_mask_dn_0: 0.1766  loss_dice_dn_0: 2.863  loss_bbox_dn_0: 0.2887  loss_giou_dn_0: 0.8653  loss_ce_1: 1.253  loss_mask_1: 0.08018  loss_dice_1: 0.7258  loss_bbox_1: 0.1067  loss_giou_1: 0.5411  loss_ce_dn_1: 0.2451  loss_mask_dn_1: 0.05205  loss_dice_dn_1: 0.6467  loss_bbox_dn_1: 0.09556  loss_giou_dn_1: 0.4075  loss_ce_2: 1.235  loss_mask_2: 0.06065  loss_dice_2: 0.5737  loss_bbox_2: 0.08339  loss_giou_2: 0.3513  loss_ce_dn_2: 0.2298  loss_mask_dn_2: 0.04712  loss_dice_dn_2: 0.6327  loss_bbox_dn_2: 0.0668  loss_giou_dn_2: 0.3516  loss_ce_3: 1.064  loss_mask_3: 0.04108  loss_dice_3: 0.5264  loss_bbox_3: 0.09045  loss_giou_3: 0.3524  loss_ce_dn_3: 0.2043  loss_mask_dn_3: 0.04103  loss_dice_dn_3: 0.6295  loss_bbox_dn_3: 0.05892  loss_giou_dn_3: 0.296  loss_ce_4: 1.061  loss_mask_4: 0.04571  loss_dice_4: 0.6238  loss_bbox_4: 0.08154  loss_giou_4: 0.3553  loss_ce_dn_4: 0.1829  loss_mask_dn_4: 0.04202  loss_dice_dn_4: 0.6927  loss_bbox_dn_4: 0.05529  loss_giou_dn_4: 0.2907  loss_ce_5: 1.109  loss_mask_5: 0.04021  loss_dice_5: 0.7699  loss_bbox_5: 0.08686  loss_giou_5: 0.3484  loss_ce_dn_5: 0.1763  loss_mask_dn_5: 0.03842  loss_dice_dn_5: 0.6705  loss_bbox_dn_5: 0.05283  loss_giou_dn_5: 0.2842  loss_ce_6: 1.022  loss_mask_6: 0.04458  loss_dice_6: 0.5578  loss_bbox_6: 0.0943  loss_giou_6: 0.357  loss_ce_dn_6: 0.1599  loss_mask_dn_6: 0.03981  loss_dice_dn_6: 0.5878  loss_bbox_dn_6: 0.05188  loss_giou_dn_6: 0.2859  loss_ce_7: 1.007  loss_mask_7: 0.04572  loss_dice_7: 0.6273  loss_bbox_7: 0.09945  loss_giou_7: 0.3596  loss_ce_dn_7: 0.154  loss_mask_dn_7: 0.03993  loss_dice_dn_7: 0.5917  loss_bbox_dn_7: 0.053  loss_giou_dn_7: 0.2873  loss_ce_8: 1.015  loss_mask_8: 0.03966  loss_dice_8: 0.6852  loss_bbox_8: 0.09805  loss_giou_8: 0.3651  loss_ce_dn_8: 0.1552  loss_mask_dn_8: 0.03837  loss_dice_dn_8: 0.6271  loss_bbox_dn_8: 0.05262  loss_giou_dn_8: 0.2939  loss_ce_interm: 1.16  loss_mask_interm: 0.06023  loss_dice_interm: 0.7173  loss_bbox_interm: 0.1325  loss_giou_interm: 0.5103  time: 1.9049  data_time: 0.1255  lr: 1e-06  max_mem: 6639M\n",
            "[05/20 18:08:19 d2.utils.events]:  eta: 1:04:29  iter: 3319  total_loss: 46.2  loss_ce: 1.282  loss_mask: 0.02451  loss_dice: 0.6957  loss_bbox: 0.05324  loss_giou: 0.4549  loss_ce_dn: 0.2215  loss_mask_dn: 0.02679  loss_dice_dn: 0.6314  loss_bbox_dn: 0.0366  loss_giou_dn: 0.3578  loss_ce_0: 1.493  loss_mask_0: 0.02633  loss_dice_0: 0.8521  loss_bbox_0: 0.05527  loss_giou_0: 0.5059  loss_ce_dn_0: 0.7334  loss_mask_dn_0: 0.1081  loss_dice_dn_0: 2.621  loss_bbox_dn_0: 0.2128  loss_giou_dn_0: 0.8618  loss_ce_1: 1.448  loss_mask_1: 0.02643  loss_dice_1: 0.8951  loss_bbox_1: 0.06017  loss_giou_1: 0.4254  loss_ce_dn_1: 0.2785  loss_mask_dn_1: 0.0259  loss_dice_dn_1: 0.6608  loss_bbox_dn_1: 0.05689  loss_giou_dn_1: 0.4319  loss_ce_2: 1.35  loss_mask_2: 0.02687  loss_dice_2: 0.5529  loss_bbox_2: 0.05418  loss_giou_2: 0.4313  loss_ce_dn_2: 0.2528  loss_mask_dn_2: 0.02549  loss_dice_dn_2: 0.7142  loss_bbox_dn_2: 0.0434  loss_giou_dn_2: 0.3849  loss_ce_3: 1.335  loss_mask_3: 0.02409  loss_dice_3: 0.6684  loss_bbox_3: 0.05203  loss_giou_3: 0.4131  loss_ce_dn_3: 0.246  loss_mask_dn_3: 0.02704  loss_dice_dn_3: 0.6513  loss_bbox_dn_3: 0.0389  loss_giou_dn_3: 0.354  loss_ce_4: 1.271  loss_mask_4: 0.02854  loss_dice_4: 0.7202  loss_bbox_4: 0.05873  loss_giou_4: 0.4125  loss_ce_dn_4: 0.2357  loss_mask_dn_4: 0.02723  loss_dice_dn_4: 0.6505  loss_bbox_dn_4: 0.03774  loss_giou_dn_4: 0.3325  loss_ce_5: 1.266  loss_mask_5: 0.0269  loss_dice_5: 0.8908  loss_bbox_5: 0.05572  loss_giou_5: 0.4386  loss_ce_dn_5: 0.2431  loss_mask_dn_5: 0.02667  loss_dice_dn_5: 0.6722  loss_bbox_dn_5: 0.03689  loss_giou_dn_5: 0.3519  loss_ce_6: 1.279  loss_mask_6: 0.02811  loss_dice_6: 0.6163  loss_bbox_6: 0.05644  loss_giou_6: 0.4251  loss_ce_dn_6: 0.232  loss_mask_dn_6: 0.02759  loss_dice_dn_6: 0.6724  loss_bbox_dn_6: 0.0372  loss_giou_dn_6: 0.3458  loss_ce_7: 1.299  loss_mask_7: 0.02828  loss_dice_7: 0.7309  loss_bbox_7: 0.05569  loss_giou_7: 0.4507  loss_ce_dn_7: 0.2251  loss_mask_dn_7: 0.02707  loss_dice_dn_7: 0.6742  loss_bbox_dn_7: 0.03811  loss_giou_dn_7: 0.3557  loss_ce_8: 1.294  loss_mask_8: 0.02426  loss_dice_8: 0.7072  loss_bbox_8: 0.05487  loss_giou_8: 0.4545  loss_ce_dn_8: 0.2245  loss_mask_dn_8: 0.02698  loss_dice_dn_8: 0.6628  loss_bbox_dn_8: 0.03748  loss_giou_dn_8: 0.3529  loss_ce_interm: 1.486  loss_mask_interm: 0.02429  loss_dice_interm: 0.8395  loss_bbox_interm: 0.0884  loss_giou_interm: 0.6173  time: 1.9036  data_time: 0.0713  lr: 1e-06  max_mem: 6639M\n",
            "[05/20 18:08:52 d2.utils.events]:  eta: 1:03:52  iter: 3339  total_loss: 53.83  loss_ce: 1.362  loss_mask: 0.02967  loss_dice: 0.7182  loss_bbox: 0.07456  loss_giou: 0.558  loss_ce_dn: 0.2429  loss_mask_dn: 0.02926  loss_dice_dn: 0.7538  loss_bbox_dn: 0.04128  loss_giou_dn: 0.3748  loss_ce_0: 1.436  loss_mask_0: 0.03255  loss_dice_0: 0.8966  loss_bbox_0: 0.08239  loss_giou_0: 0.6759  loss_ce_dn_0: 0.7966  loss_mask_dn_0: 0.1197  loss_dice_dn_0: 2.539  loss_bbox_dn_0: 0.1855  loss_giou_dn_0: 0.8584  loss_ce_1: 1.409  loss_mask_1: 0.03218  loss_dice_1: 0.9364  loss_bbox_1: 0.08454  loss_giou_1: 0.5889  loss_ce_dn_1: 0.3204  loss_mask_dn_1: 0.02922  loss_dice_dn_1: 0.7976  loss_bbox_dn_1: 0.06999  loss_giou_dn_1: 0.4559  loss_ce_2: 1.404  loss_mask_2: 0.03239  loss_dice_2: 0.9602  loss_bbox_2: 0.07357  loss_giou_2: 0.5742  loss_ce_dn_2: 0.3065  loss_mask_dn_2: 0.02979  loss_dice_dn_2: 0.7412  loss_bbox_dn_2: 0.05019  loss_giou_dn_2: 0.4059  loss_ce_3: 1.325  loss_mask_3: 0.03667  loss_dice_3: 0.7604  loss_bbox_3: 0.06798  loss_giou_3: 0.507  loss_ce_dn_3: 0.2853  loss_mask_dn_3: 0.03125  loss_dice_dn_3: 0.7708  loss_bbox_dn_3: 0.04701  loss_giou_dn_3: 0.3965  loss_ce_4: 1.362  loss_mask_4: 0.0302  loss_dice_4: 0.8947  loss_bbox_4: 0.07151  loss_giou_4: 0.5368  loss_ce_dn_4: 0.2733  loss_mask_dn_4: 0.02928  loss_dice_dn_4: 0.6944  loss_bbox_dn_4: 0.04626  loss_giou_dn_4: 0.3834  loss_ce_5: 1.252  loss_mask_5: 0.0369  loss_dice_5: 0.8821  loss_bbox_5: 0.071  loss_giou_5: 0.5463  loss_ce_dn_5: 0.2454  loss_mask_dn_5: 0.03025  loss_dice_dn_5: 0.7311  loss_bbox_dn_5: 0.04429  loss_giou_dn_5: 0.3739  loss_ce_6: 1.331  loss_mask_6: 0.03601  loss_dice_6: 0.9532  loss_bbox_6: 0.07334  loss_giou_6: 0.5457  loss_ce_dn_6: 0.2487  loss_mask_dn_6: 0.03166  loss_dice_dn_6: 0.7358  loss_bbox_dn_6: 0.04397  loss_giou_dn_6: 0.3715  loss_ce_7: 1.346  loss_mask_7: 0.03047  loss_dice_7: 0.7741  loss_bbox_7: 0.07501  loss_giou_7: 0.5471  loss_ce_dn_7: 0.2476  loss_mask_dn_7: 0.03017  loss_dice_dn_7: 0.6719  loss_bbox_dn_7: 0.04202  loss_giou_dn_7: 0.3773  loss_ce_8: 1.338  loss_mask_8: 0.03182  loss_dice_8: 0.6952  loss_bbox_8: 0.07337  loss_giou_8: 0.5563  loss_ce_dn_8: 0.241  loss_mask_dn_8: 0.02961  loss_dice_dn_8: 0.7031  loss_bbox_dn_8: 0.04161  loss_giou_dn_8: 0.376  loss_ce_interm: 1.425  loss_mask_interm: 0.03338  loss_dice_interm: 0.8225  loss_bbox_interm: 0.1176  loss_giou_interm: 0.6522  time: 1.9022  data_time: 0.0866  lr: 1e-06  max_mem: 6639M\n",
            "[05/20 18:09:29 d2.utils.events]:  eta: 1:03:33  iter: 3359  total_loss: 33.47  loss_ce: 0.7412  loss_mask: 0.03919  loss_dice: 0.4384  loss_bbox: 0.05584  loss_giou: 0.3081  loss_ce_dn: 0.1194  loss_mask_dn: 0.05164  loss_dice_dn: 0.4914  loss_bbox_dn: 0.04821  loss_giou_dn: 0.2835  loss_ce_0: 1.128  loss_mask_0: 0.04088  loss_dice_0: 0.4918  loss_bbox_0: 0.1053  loss_giou_0: 0.5371  loss_ce_dn_0: 0.7066  loss_mask_dn_0: 0.1201  loss_dice_dn_0: 2.184  loss_bbox_dn_0: 0.2444  loss_giou_dn_0: 0.8591  loss_ce_1: 1.16  loss_mask_1: 0.04517  loss_dice_1: 0.4333  loss_bbox_1: 0.06403  loss_giou_1: 0.352  loss_ce_dn_1: 0.2282  loss_mask_dn_1: 0.04826  loss_dice_dn_1: 0.5228  loss_bbox_dn_1: 0.08343  loss_giou_dn_1: 0.3842  loss_ce_2: 0.9748  loss_mask_2: 0.0402  loss_dice_2: 0.4704  loss_bbox_2: 0.05928  loss_giou_2: 0.3044  loss_ce_dn_2: 0.181  loss_mask_dn_2: 0.04818  loss_dice_dn_2: 0.4942  loss_bbox_dn_2: 0.06567  loss_giou_dn_2: 0.3136  loss_ce_3: 0.7692  loss_mask_3: 0.0449  loss_dice_3: 0.3868  loss_bbox_3: 0.05492  loss_giou_3: 0.2951  loss_ce_dn_3: 0.1593  loss_mask_dn_3: 0.04944  loss_dice_dn_3: 0.4796  loss_bbox_dn_3: 0.05497  loss_giou_dn_3: 0.2916  loss_ce_4: 0.7593  loss_mask_4: 0.05211  loss_dice_4: 0.4249  loss_bbox_4: 0.0637  loss_giou_4: 0.2963  loss_ce_dn_4: 0.1463  loss_mask_dn_4: 0.05021  loss_dice_dn_4: 0.4983  loss_bbox_dn_4: 0.05131  loss_giou_dn_4: 0.2969  loss_ce_5: 0.7678  loss_mask_5: 0.04142  loss_dice_5: 0.4285  loss_bbox_5: 0.05872  loss_giou_5: 0.2942  loss_ce_dn_5: 0.1338  loss_mask_dn_5: 0.04988  loss_dice_dn_5: 0.4845  loss_bbox_dn_5: 0.04924  loss_giou_dn_5: 0.2936  loss_ce_6: 0.7398  loss_mask_6: 0.04321  loss_dice_6: 0.3848  loss_bbox_6: 0.05924  loss_giou_6: 0.2957  loss_ce_dn_6: 0.1293  loss_mask_dn_6: 0.0538  loss_dice_dn_6: 0.4792  loss_bbox_dn_6: 0.04886  loss_giou_dn_6: 0.2886  loss_ce_7: 0.7344  loss_mask_7: 0.04399  loss_dice_7: 0.4844  loss_bbox_7: 0.05906  loss_giou_7: 0.2971  loss_ce_dn_7: 0.1245  loss_mask_dn_7: 0.05101  loss_dice_dn_7: 0.4817  loss_bbox_dn_7: 0.04933  loss_giou_dn_7: 0.2808  loss_ce_8: 0.7273  loss_mask_8: 0.04327  loss_dice_8: 0.4272  loss_bbox_8: 0.05799  loss_giou_8: 0.3032  loss_ce_dn_8: 0.1218  loss_mask_dn_8: 0.05041  loss_dice_dn_8: 0.4712  loss_bbox_dn_8: 0.04782  loss_giou_dn_8: 0.2842  loss_ce_interm: 0.9977  loss_mask_interm: 0.04087  loss_dice_interm: 0.4749  loss_bbox_interm: 0.107  loss_giou_interm: 0.3845  time: 1.9015  data_time: 0.1275  lr: 1e-06  max_mem: 6663M\n",
            "[05/20 18:10:04 d2.utils.events]:  eta: 1:02:59  iter: 3379  total_loss: 33.37  loss_ce: 0.7506  loss_mask: 0.0306  loss_dice: 0.4189  loss_bbox: 0.04126  loss_giou: 0.2304  loss_ce_dn: 0.1877  loss_mask_dn: 0.03059  loss_dice_dn: 0.4821  loss_bbox_dn: 0.03778  loss_giou_dn: 0.1945  loss_ce_0: 1.104  loss_mask_0: 0.03135  loss_dice_0: 0.4076  loss_bbox_0: 0.04748  loss_giou_0: 0.2503  loss_ce_dn_0: 0.6358  loss_mask_dn_0: 0.1633  loss_dice_dn_0: 1.781  loss_bbox_dn_0: 0.377  loss_giou_dn_0: 0.8564  loss_ce_1: 1.078  loss_mask_1: 0.03798  loss_dice_1: 0.388  loss_bbox_1: 0.04286  loss_giou_1: 0.245  loss_ce_dn_1: 0.2831  loss_mask_dn_1: 0.02958  loss_dice_dn_1: 0.4419  loss_bbox_dn_1: 0.07829  loss_giou_dn_1: 0.2935  loss_ce_2: 1.02  loss_mask_2: 0.03046  loss_dice_2: 0.359  loss_bbox_2: 0.03794  loss_giou_2: 0.2333  loss_ce_dn_2: 0.2248  loss_mask_dn_2: 0.02835  loss_dice_dn_2: 0.3926  loss_bbox_dn_2: 0.05764  loss_giou_dn_2: 0.2449  loss_ce_3: 0.8478  loss_mask_3: 0.03097  loss_dice_3: 0.3792  loss_bbox_3: 0.03897  loss_giou_3: 0.2214  loss_ce_dn_3: 0.2155  loss_mask_dn_3: 0.02916  loss_dice_dn_3: 0.4106  loss_bbox_dn_3: 0.04587  loss_giou_dn_3: 0.2196  loss_ce_4: 0.8543  loss_mask_4: 0.03934  loss_dice_4: 0.4951  loss_bbox_4: 0.04237  loss_giou_4: 0.2301  loss_ce_dn_4: 0.2064  loss_mask_dn_4: 0.03002  loss_dice_dn_4: 0.467  loss_bbox_dn_4: 0.03852  loss_giou_dn_4: 0.2026  loss_ce_5: 0.8195  loss_mask_5: 0.03133  loss_dice_5: 0.3653  loss_bbox_5: 0.0425  loss_giou_5: 0.2267  loss_ce_dn_5: 0.2025  loss_mask_dn_5: 0.03027  loss_dice_dn_5: 0.4265  loss_bbox_dn_5: 0.03985  loss_giou_dn_5: 0.2009  loss_ce_6: 0.7328  loss_mask_6: 0.03533  loss_dice_6: 0.3622  loss_bbox_6: 0.04147  loss_giou_6: 0.2215  loss_ce_dn_6: 0.2007  loss_mask_dn_6: 0.02879  loss_dice_dn_6: 0.455  loss_bbox_dn_6: 0.03958  loss_giou_dn_6: 0.1961  loss_ce_7: 0.7503  loss_mask_7: 0.02987  loss_dice_7: 0.3826  loss_bbox_7: 0.04244  loss_giou_7: 0.2308  loss_ce_dn_7: 0.1908  loss_mask_dn_7: 0.0306  loss_dice_dn_7: 0.4709  loss_bbox_dn_7: 0.03929  loss_giou_dn_7: 0.1961  loss_ce_8: 0.7699  loss_mask_8: 0.03013  loss_dice_8: 0.4013  loss_bbox_8: 0.04088  loss_giou_8: 0.2268  loss_ce_dn_8: 0.188  loss_mask_dn_8: 0.02981  loss_dice_dn_8: 0.4526  loss_bbox_dn_8: 0.03816  loss_giou_dn_8: 0.1918  loss_ce_interm: 1.073  loss_mask_interm: 0.03942  loss_dice_interm: 0.3795  loss_bbox_interm: 0.1084  loss_giou_interm: 0.4155  time: 1.9005  data_time: 0.0546  lr: 1e-06  max_mem: 6663M\n",
            "[05/20 18:10:38 d2.utils.events]:  eta: 1:02:27  iter: 3399  total_loss: 38.77  loss_ce: 1.09  loss_mask: 0.02061  loss_dice: 0.4656  loss_bbox: 0.04064  loss_giou: 0.3087  loss_ce_dn: 0.2032  loss_mask_dn: 0.02155  loss_dice_dn: 0.5002  loss_bbox_dn: 0.03325  loss_giou_dn: 0.2658  loss_ce_0: 1.241  loss_mask_0: 0.02324  loss_dice_0: 0.5109  loss_bbox_0: 0.05544  loss_giou_0: 0.4444  loss_ce_dn_0: 0.7651  loss_mask_dn_0: 0.1229  loss_dice_dn_0: 2.296  loss_bbox_dn_0: 0.1912  loss_giou_dn_0: 0.8563  loss_ce_1: 1.277  loss_mask_1: 0.02926  loss_dice_1: 0.6076  loss_bbox_1: 0.05422  loss_giou_1: 0.3801  loss_ce_dn_1: 0.2775  loss_mask_dn_1: 0.01925  loss_dice_dn_1: 0.5794  loss_bbox_dn_1: 0.0485  loss_giou_dn_1: 0.3762  loss_ce_2: 1.243  loss_mask_2: 0.02066  loss_dice_2: 0.5447  loss_bbox_2: 0.06049  loss_giou_2: 0.3525  loss_ce_dn_2: 0.2484  loss_mask_dn_2: 0.01919  loss_dice_dn_2: 0.5225  loss_bbox_dn_2: 0.04114  loss_giou_dn_2: 0.3003  loss_ce_3: 1.189  loss_mask_3: 0.01825  loss_dice_3: 0.5304  loss_bbox_3: 0.04565  loss_giou_3: 0.3059  loss_ce_dn_3: 0.2185  loss_mask_dn_3: 0.01979  loss_dice_dn_3: 0.5139  loss_bbox_dn_3: 0.03542  loss_giou_dn_3: 0.2942  loss_ce_4: 1.147  loss_mask_4: 0.02114  loss_dice_4: 0.5455  loss_bbox_4: 0.04588  loss_giou_4: 0.3266  loss_ce_dn_4: 0.2024  loss_mask_dn_4: 0.02181  loss_dice_dn_4: 0.4981  loss_bbox_dn_4: 0.03233  loss_giou_dn_4: 0.2933  loss_ce_5: 1.157  loss_mask_5: 0.01918  loss_dice_5: 0.523  loss_bbox_5: 0.03561  loss_giou_5: 0.3218  loss_ce_dn_5: 0.1924  loss_mask_dn_5: 0.02131  loss_dice_dn_5: 0.5167  loss_bbox_dn_5: 0.03207  loss_giou_dn_5: 0.2817  loss_ce_6: 1.104  loss_mask_6: 0.01919  loss_dice_6: 0.56  loss_bbox_6: 0.03727  loss_giou_6: 0.3062  loss_ce_dn_6: 0.1962  loss_mask_dn_6: 0.02094  loss_dice_dn_6: 0.4876  loss_bbox_dn_6: 0.03409  loss_giou_dn_6: 0.2659  loss_ce_7: 1.075  loss_mask_7: 0.01808  loss_dice_7: 0.4886  loss_bbox_7: 0.05444  loss_giou_7: 0.3093  loss_ce_dn_7: 0.2001  loss_mask_dn_7: 0.0209  loss_dice_dn_7: 0.4953  loss_bbox_dn_7: 0.03381  loss_giou_dn_7: 0.2666  loss_ce_8: 1.09  loss_mask_8: 0.02363  loss_dice_8: 0.6573  loss_bbox_8: 0.05542  loss_giou_8: 0.309  loss_ce_dn_8: 0.2013  loss_mask_dn_8: 0.02085  loss_dice_dn_8: 0.5  loss_bbox_dn_8: 0.03292  loss_giou_dn_8: 0.2684  loss_ce_interm: 1.221  loss_mask_interm: 0.02043  loss_dice_interm: 0.5322  loss_bbox_interm: 0.07624  loss_giou_interm: 0.4369  time: 1.8993  data_time: 0.0832  lr: 1e-06  max_mem: 6663M\n",
            "[05/20 18:11:13 d2.utils.events]:  eta: 1:01:44  iter: 3419  total_loss: 33.85  loss_ce: 0.9511  loss_mask: 0.03151  loss_dice: 0.3261  loss_bbox: 0.04932  loss_giou: 0.2202  loss_ce_dn: 0.2068  loss_mask_dn: 0.02726  loss_dice_dn: 0.4113  loss_bbox_dn: 0.03675  loss_giou_dn: 0.2067  loss_ce_0: 1.162  loss_mask_0: 0.03537  loss_dice_0: 0.4246  loss_bbox_0: 0.07514  loss_giou_0: 0.3251  loss_ce_dn_0: 0.718  loss_mask_dn_0: 0.1911  loss_dice_dn_0: 2.311  loss_bbox_dn_0: 0.2914  loss_giou_dn_0: 0.856  loss_ce_1: 1.151  loss_mask_1: 0.03674  loss_dice_1: 0.3547  loss_bbox_1: 0.05911  loss_giou_1: 0.2753  loss_ce_dn_1: 0.2952  loss_mask_dn_1: 0.02922  loss_dice_dn_1: 0.4339  loss_bbox_dn_1: 0.0666  loss_giou_dn_1: 0.3091  loss_ce_2: 1.015  loss_mask_2: 0.03537  loss_dice_2: 0.4451  loss_bbox_2: 0.05799  loss_giou_2: 0.2221  loss_ce_dn_2: 0.2511  loss_mask_dn_2: 0.02691  loss_dice_dn_2: 0.4004  loss_bbox_dn_2: 0.04562  loss_giou_dn_2: 0.2442  loss_ce_3: 0.922  loss_mask_3: 0.02826  loss_dice_3: 0.3916  loss_bbox_3: 0.049  loss_giou_3: 0.2107  loss_ce_dn_3: 0.2245  loss_mask_dn_3: 0.02721  loss_dice_dn_3: 0.4027  loss_bbox_dn_3: 0.04045  loss_giou_dn_3: 0.2275  loss_ce_4: 0.8806  loss_mask_4: 0.03565  loss_dice_4: 0.3761  loss_bbox_4: 0.05081  loss_giou_4: 0.2339  loss_ce_dn_4: 0.2109  loss_mask_dn_4: 0.02752  loss_dice_dn_4: 0.4266  loss_bbox_dn_4: 0.03683  loss_giou_dn_4: 0.2144  loss_ce_5: 0.9007  loss_mask_5: 0.03286  loss_dice_5: 0.4188  loss_bbox_5: 0.04945  loss_giou_5: 0.2253  loss_ce_dn_5: 0.2045  loss_mask_dn_5: 0.0271  loss_dice_dn_5: 0.4257  loss_bbox_dn_5: 0.03769  loss_giou_dn_5: 0.2149  loss_ce_6: 0.9145  loss_mask_6: 0.02657  loss_dice_6: 0.512  loss_bbox_6: 0.04952  loss_giou_6: 0.2263  loss_ce_dn_6: 0.1997  loss_mask_dn_6: 0.02773  loss_dice_dn_6: 0.4043  loss_bbox_dn_6: 0.03792  loss_giou_dn_6: 0.2155  loss_ce_7: 0.9226  loss_mask_7: 0.0321  loss_dice_7: 0.3848  loss_bbox_7: 0.0496  loss_giou_7: 0.2172  loss_ce_dn_7: 0.2031  loss_mask_dn_7: 0.02671  loss_dice_dn_7: 0.4345  loss_bbox_dn_7: 0.03821  loss_giou_dn_7: 0.2062  loss_ce_8: 0.9654  loss_mask_8: 0.02473  loss_dice_8: 0.3546  loss_bbox_8: 0.04819  loss_giou_8: 0.2161  loss_ce_dn_8: 0.2061  loss_mask_dn_8: 0.02634  loss_dice_dn_8: 0.3803  loss_bbox_dn_8: 0.0369  loss_giou_dn_8: 0.2046  loss_ce_interm: 1.114  loss_mask_interm: 0.03477  loss_dice_interm: 0.4112  loss_bbox_interm: 0.06271  loss_giou_interm: 0.3308  time: 1.8983  data_time: 0.0828  lr: 1e-06  max_mem: 6663M\n",
            "[05/20 18:11:47 d2.utils.events]:  eta: 1:01:21  iter: 3439  total_loss: 46.85  loss_ce: 1.232  loss_mask: 0.04245  loss_dice: 0.5936  loss_bbox: 0.05963  loss_giou: 0.3811  loss_ce_dn: 0.1693  loss_mask_dn: 0.04421  loss_dice_dn: 0.6222  loss_bbox_dn: 0.04197  loss_giou_dn: 0.3247  loss_ce_0: 1.511  loss_mask_0: 0.04223  loss_dice_0: 0.6035  loss_bbox_0: 0.1353  loss_giou_0: 0.5528  loss_ce_dn_0: 0.7493  loss_mask_dn_0: 0.1588  loss_dice_dn_0: 2.488  loss_bbox_dn_0: 0.3837  loss_giou_dn_0: 0.8626  loss_ce_1: 1.456  loss_mask_1: 0.03973  loss_dice_1: 0.594  loss_bbox_1: 0.0711  loss_giou_1: 0.4479  loss_ce_dn_1: 0.297  loss_mask_dn_1: 0.04451  loss_dice_dn_1: 0.627  loss_bbox_dn_1: 0.09983  loss_giou_dn_1: 0.3942  loss_ce_2: 1.255  loss_mask_2: 0.0401  loss_dice_2: 0.6773  loss_bbox_2: 0.07163  loss_giou_2: 0.4036  loss_ce_dn_2: 0.2633  loss_mask_dn_2: 0.03939  loss_dice_dn_2: 0.6144  loss_bbox_dn_2: 0.06394  loss_giou_dn_2: 0.34  loss_ce_3: 1.282  loss_mask_3: 0.04184  loss_dice_3: 0.656  loss_bbox_3: 0.0626  loss_giou_3: 0.3901  loss_ce_dn_3: 0.2326  loss_mask_dn_3: 0.03969  loss_dice_dn_3: 0.6001  loss_bbox_dn_3: 0.05015  loss_giou_dn_3: 0.3261  loss_ce_4: 1.272  loss_mask_4: 0.03687  loss_dice_4: 0.5942  loss_bbox_4: 0.08044  loss_giou_4: 0.3944  loss_ce_dn_4: 0.1998  loss_mask_dn_4: 0.03867  loss_dice_dn_4: 0.6575  loss_bbox_dn_4: 0.0455  loss_giou_dn_4: 0.3207  loss_ce_5: 1.191  loss_mask_5: 0.03929  loss_dice_5: 0.6375  loss_bbox_5: 0.05975  loss_giou_5: 0.4042  loss_ce_dn_5: 0.1924  loss_mask_dn_5: 0.04029  loss_dice_dn_5: 0.6352  loss_bbox_dn_5: 0.04164  loss_giou_dn_5: 0.324  loss_ce_6: 1.115  loss_mask_6: 0.03587  loss_dice_6: 0.5514  loss_bbox_6: 0.06786  loss_giou_6: 0.3879  loss_ce_dn_6: 0.1764  loss_mask_dn_6: 0.04241  loss_dice_dn_6: 0.624  loss_bbox_dn_6: 0.04245  loss_giou_dn_6: 0.3194  loss_ce_7: 1.109  loss_mask_7: 0.04332  loss_dice_7: 0.6524  loss_bbox_7: 0.06181  loss_giou_7: 0.385  loss_ce_dn_7: 0.1745  loss_mask_dn_7: 0.0412  loss_dice_dn_7: 0.638  loss_bbox_dn_7: 0.04263  loss_giou_dn_7: 0.3214  loss_ce_8: 1.202  loss_mask_8: 0.04176  loss_dice_8: 0.6486  loss_bbox_8: 0.06081  loss_giou_8: 0.3846  loss_ce_dn_8: 0.1717  loss_mask_dn_8: 0.04164  loss_dice_dn_8: 0.6283  loss_bbox_dn_8: 0.04302  loss_giou_dn_8: 0.3212  loss_ce_interm: 1.478  loss_mask_interm: 0.04506  loss_dice_interm: 0.5797  loss_bbox_interm: 0.1048  loss_giou_interm: 0.4308  time: 1.8974  data_time: 0.0850  lr: 1e-06  max_mem: 6663M\n",
            "[05/20 18:12:21 d2.utils.events]:  eta: 1:00:51  iter: 3459  total_loss: 47.15  loss_ce: 1.085  loss_mask: 0.04754  loss_dice: 0.6652  loss_bbox: 0.06857  loss_giou: 0.3955  loss_ce_dn: 0.2683  loss_mask_dn: 0.03594  loss_dice_dn: 0.676  loss_bbox_dn: 0.04233  loss_giou_dn: 0.318  loss_ce_0: 1.498  loss_mask_0: 0.05967  loss_dice_0: 0.5455  loss_bbox_0: 0.08188  loss_giou_0: 0.6373  loss_ce_dn_0: 0.8209  loss_mask_dn_0: 0.1936  loss_dice_dn_0: 2.947  loss_bbox_dn_0: 0.2585  loss_giou_dn_0: 0.8551  loss_ce_1: 1.507  loss_mask_1: 0.04307  loss_dice_1: 0.8102  loss_bbox_1: 0.06704  loss_giou_1: 0.4702  loss_ce_dn_1: 0.3502  loss_mask_dn_1: 0.03682  loss_dice_dn_1: 0.6749  loss_bbox_dn_1: 0.06686  loss_giou_dn_1: 0.3844  loss_ce_2: 1.246  loss_mask_2: 0.05132  loss_dice_2: 0.8424  loss_bbox_2: 0.08301  loss_giou_2: 0.4386  loss_ce_dn_2: 0.3255  loss_mask_dn_2: 0.03401  loss_dice_dn_2: 0.6671  loss_bbox_dn_2: 0.05466  loss_giou_dn_2: 0.3377  loss_ce_3: 1.175  loss_mask_3: 0.04398  loss_dice_3: 0.7062  loss_bbox_3: 0.06496  loss_giou_3: 0.4144  loss_ce_dn_3: 0.3009  loss_mask_dn_3: 0.03413  loss_dice_dn_3: 0.6415  loss_bbox_dn_3: 0.04916  loss_giou_dn_3: 0.3283  loss_ce_4: 1.111  loss_mask_4: 0.03909  loss_dice_4: 0.6217  loss_bbox_4: 0.06679  loss_giou_4: 0.4181  loss_ce_dn_4: 0.2742  loss_mask_dn_4: 0.03269  loss_dice_dn_4: 0.6237  loss_bbox_dn_4: 0.04624  loss_giou_dn_4: 0.3222  loss_ce_5: 1.151  loss_mask_5: 0.04637  loss_dice_5: 0.5721  loss_bbox_5: 0.07987  loss_giou_5: 0.3859  loss_ce_dn_5: 0.2653  loss_mask_dn_5: 0.03458  loss_dice_dn_5: 0.6456  loss_bbox_dn_5: 0.04445  loss_giou_dn_5: 0.3144  loss_ce_6: 1.128  loss_mask_6: 0.04125  loss_dice_6: 0.7499  loss_bbox_6: 0.07579  loss_giou_6: 0.3996  loss_ce_dn_6: 0.2738  loss_mask_dn_6: 0.03395  loss_dice_dn_6: 0.6447  loss_bbox_dn_6: 0.0441  loss_giou_dn_6: 0.3254  loss_ce_7: 1.127  loss_mask_7: 0.03624  loss_dice_7: 0.6457  loss_bbox_7: 0.07021  loss_giou_7: 0.4293  loss_ce_dn_7: 0.2778  loss_mask_dn_7: 0.0363  loss_dice_dn_7: 0.624  loss_bbox_dn_7: 0.04315  loss_giou_dn_7: 0.3223  loss_ce_8: 1.109  loss_mask_8: 0.04007  loss_dice_8: 0.653  loss_bbox_8: 0.06912  loss_giou_8: 0.4039  loss_ce_dn_8: 0.2711  loss_mask_dn_8: 0.03625  loss_dice_dn_8: 0.6345  loss_bbox_dn_8: 0.04256  loss_giou_dn_8: 0.3213  loss_ce_interm: 1.512  loss_mask_interm: 0.04519  loss_dice_interm: 0.7402  loss_bbox_interm: 0.1098  loss_giou_interm: 0.5259  time: 1.8962  data_time: 0.0910  lr: 1e-06  max_mem: 6663M\n",
            "[05/20 18:12:56 d2.utils.events]:  eta: 1:00:13  iter: 3479  total_loss: 45.33  loss_ce: 1.042  loss_mask: 0.03968  loss_dice: 0.6925  loss_bbox: 0.06582  loss_giou: 0.3827  loss_ce_dn: 0.1767  loss_mask_dn: 0.03682  loss_dice_dn: 0.6958  loss_bbox_dn: 0.04698  loss_giou_dn: 0.353  loss_ce_0: 1.182  loss_mask_0: 0.0384  loss_dice_0: 0.5825  loss_bbox_0: 0.08253  loss_giou_0: 0.4158  loss_ce_dn_0: 0.7342  loss_mask_dn_0: 0.2087  loss_dice_dn_0: 2.553  loss_bbox_dn_0: 0.2392  loss_giou_dn_0: 0.8568  loss_ce_1: 1.134  loss_mask_1: 0.03805  loss_dice_1: 0.7275  loss_bbox_1: 0.06968  loss_giou_1: 0.4058  loss_ce_dn_1: 0.2517  loss_mask_dn_1: 0.03624  loss_dice_dn_1: 0.8348  loss_bbox_dn_1: 0.08218  loss_giou_dn_1: 0.4495  loss_ce_2: 1.165  loss_mask_2: 0.04031  loss_dice_2: 0.7129  loss_bbox_2: 0.07007  loss_giou_2: 0.4139  loss_ce_dn_2: 0.2116  loss_mask_dn_2: 0.03494  loss_dice_dn_2: 0.7196  loss_bbox_dn_2: 0.06116  loss_giou_dn_2: 0.396  loss_ce_3: 1.065  loss_mask_3: 0.03866  loss_dice_3: 0.6859  loss_bbox_3: 0.05481  loss_giou_3: 0.3868  loss_ce_dn_3: 0.2003  loss_mask_dn_3: 0.03573  loss_dice_dn_3: 0.7181  loss_bbox_dn_3: 0.05379  loss_giou_dn_3: 0.371  loss_ce_4: 1.079  loss_mask_4: 0.03682  loss_dice_4: 0.8114  loss_bbox_4: 0.05469  loss_giou_4: 0.3837  loss_ce_dn_4: 0.1873  loss_mask_dn_4: 0.03571  loss_dice_dn_4: 0.7228  loss_bbox_dn_4: 0.04652  loss_giou_dn_4: 0.3598  loss_ce_5: 1.039  loss_mask_5: 0.03907  loss_dice_5: 0.7241  loss_bbox_5: 0.0689  loss_giou_5: 0.3776  loss_ce_dn_5: 0.182  loss_mask_dn_5: 0.03703  loss_dice_dn_5: 0.719  loss_bbox_dn_5: 0.04729  loss_giou_dn_5: 0.3491  loss_ce_6: 1.038  loss_mask_6: 0.03564  loss_dice_6: 0.6193  loss_bbox_6: 0.06742  loss_giou_6: 0.3771  loss_ce_dn_6: 0.1774  loss_mask_dn_6: 0.03678  loss_dice_dn_6: 0.7086  loss_bbox_dn_6: 0.04782  loss_giou_dn_6: 0.3526  loss_ce_7: 1.031  loss_mask_7: 0.03993  loss_dice_7: 0.7785  loss_bbox_7: 0.06087  loss_giou_7: 0.3775  loss_ce_dn_7: 0.1793  loss_mask_dn_7: 0.03668  loss_dice_dn_7: 0.6375  loss_bbox_dn_7: 0.04779  loss_giou_dn_7: 0.3524  loss_ce_8: 0.9825  loss_mask_8: 0.04008  loss_dice_8: 0.6294  loss_bbox_8: 0.06246  loss_giou_8: 0.3829  loss_ce_dn_8: 0.1822  loss_mask_dn_8: 0.03589  loss_dice_dn_8: 0.6686  loss_bbox_dn_8: 0.04628  loss_giou_dn_8: 0.3539  loss_ce_interm: 1.215  loss_mask_interm: 0.03768  loss_dice_interm: 0.5904  loss_bbox_interm: 0.08707  loss_giou_interm: 0.3982  time: 1.8951  data_time: 0.0551  lr: 1e-06  max_mem: 6663M\n",
            "[05/20 18:13:30 d2.data.datasets.coco]: Loaded 150 images in COCO format from /content/TACO-expl/data/annotations_off_0_resval.json\n",
            "[05/20 18:13:30 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "[05/20 18:13:30 d2.data.common]: Serializing 150 elements to byte tensors and concatenating them all ...\n",
            "[05/20 18:13:30 d2.data.common]: Serialized dataset takes 0.21 MiB\n",
            "WARNING [05/20 18:13:30 d2.evaluation.coco_evaluation]: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
            "[05/20 18:13:30 d2.evaluation.evaluator]: Start inference on 150 batches\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1066, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1066, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1066, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1066])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 18:13:39 d2.evaluation.evaluator]: Inference done 11/150. Dataloading: 0.0018 s/iter. Inference: 0.2883 s/iter. Eval: 0.4460 s/iter. Total: 0.7362 s/iter. ETA=0:01:42\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 608])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 608])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 608])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1200])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 750])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 18:13:44 d2.evaluation.evaluator]: Inference done 17/150. Dataloading: 0.0057 s/iter. Inference: 0.2921 s/iter. Eval: 0.4914 s/iter. Total: 0.7894 s/iter. ETA=0:01:44\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 750])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 18:13:50 d2.evaluation.evaluator]: Inference done 23/150. Dataloading: 0.0068 s/iter. Inference: 0.3111 s/iter. Eval: 0.5324 s/iter. Total: 0.8509 s/iter. ETA=0:01:48\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([750, 1333])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 750])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([750, 1333])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 750])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 18:13:55 d2.evaluation.evaluator]: Inference done 30/150. Dataloading: 0.0057 s/iter. Inference: 0.3091 s/iter. Eval: 0.5219 s/iter. Total: 0.8372 s/iter. ETA=0:01:40\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 750])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 18:14:01 d2.evaluation.evaluator]: Inference done 37/150. Dataloading: 0.0058 s/iter. Inference: 0.3084 s/iter. Eval: 0.5225 s/iter. Total: 0.8372 s/iter. ETA=0:01:34\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 18:14:07 d2.evaluation.evaluator]: Inference done 43/150. Dataloading: 0.0063 s/iter. Inference: 0.3136 s/iter. Eval: 0.5305 s/iter. Total: 0.8508 s/iter. ETA=0:01:31\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 18:14:12 d2.evaluation.evaluator]: Inference done 50/150. Dataloading: 0.0057 s/iter. Inference: 0.3099 s/iter. Eval: 0.5188 s/iter. Total: 0.8348 s/iter. ETA=0:01:23\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 18:14:18 d2.evaluation.evaluator]: Inference done 57/150. Dataloading: 0.0052 s/iter. Inference: 0.3084 s/iter. Eval: 0.5154 s/iter. Total: 0.8295 s/iter. ETA=0:01:17\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 18:14:23 d2.evaluation.evaluator]: Inference done 63/150. Dataloading: 0.0051 s/iter. Inference: 0.3098 s/iter. Eval: 0.5212 s/iter. Total: 0.8366 s/iter. ETA=0:01:12\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 18:14:28 d2.evaluation.evaluator]: Inference done 70/150. Dataloading: 0.0048 s/iter. Inference: 0.3073 s/iter. Eval: 0.5135 s/iter. Total: 0.8261 s/iter. ETA=0:01:06\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 18:14:33 d2.evaluation.evaluator]: Inference done 76/150. Dataloading: 0.0049 s/iter. Inference: 0.3085 s/iter. Eval: 0.5161 s/iter. Total: 0.8300 s/iter. ETA=0:01:01\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([852, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 18:14:39 d2.evaluation.evaluator]: Inference done 82/150. Dataloading: 0.0052 s/iter. Inference: 0.3102 s/iter. Eval: 0.5261 s/iter. Total: 0.8420 s/iter. ETA=0:00:57\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 18:14:44 d2.evaluation.evaluator]: Inference done 89/150. Dataloading: 0.0050 s/iter. Inference: 0.3080 s/iter. Eval: 0.5196 s/iter. Total: 0.8331 s/iter. ETA=0:00:50\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 18:14:50 d2.evaluation.evaluator]: Inference done 96/150. Dataloading: 0.0048 s/iter. Inference: 0.3064 s/iter. Eval: 0.5148 s/iter. Total: 0.8265 s/iter. ETA=0:00:44\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 18:14:55 d2.evaluation.evaluator]: Inference done 102/150. Dataloading: 0.0049 s/iter. Inference: 0.3079 s/iter. Eval: 0.5217 s/iter. Total: 0.8350 s/iter. ETA=0:00:40\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 18:15:01 d2.evaluation.evaluator]: Inference done 109/150. Dataloading: 0.0047 s/iter. Inference: 0.3065 s/iter. Eval: 0.5170 s/iter. Total: 0.8288 s/iter. ETA=0:00:33\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 18:15:06 d2.evaluation.evaluator]: Inference done 116/150. Dataloading: 0.0046 s/iter. Inference: 0.3049 s/iter. Eval: 0.5132 s/iter. Total: 0.8232 s/iter. ETA=0:00:27\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 18:15:12 d2.evaluation.evaluator]: Inference done 122/150. Dataloading: 0.0050 s/iter. Inference: 0.3069 s/iter. Eval: 0.5191 s/iter. Total: 0.8315 s/iter. ETA=0:00:23\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 18:15:17 d2.evaluation.evaluator]: Inference done 129/150. Dataloading: 0.0048 s/iter. Inference: 0.3055 s/iter. Eval: 0.5154 s/iter. Total: 0.8262 s/iter. ETA=0:00:17\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 750])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 18:15:22 d2.evaluation.evaluator]: Inference done 136/150. Dataloading: 0.0048 s/iter. Inference: 0.3041 s/iter. Eval: 0.5137 s/iter. Total: 0.8230 s/iter. ETA=0:00:11\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 750])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 750])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 18:15:27 d2.evaluation.evaluator]: Inference done 141/150. Dataloading: 0.0050 s/iter. Inference: 0.3059 s/iter. Eval: 0.5196 s/iter. Total: 0.8311 s/iter. ETA=0:00:07\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 608])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 608])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 18:15:33 d2.evaluation.evaluator]: Inference done 148/150. Dataloading: 0.0050 s/iter. Inference: 0.3053 s/iter. Eval: 0.5166 s/iter. Total: 0.8275 s/iter. ETA=0:00:01\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 608])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 608])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[05/20 18:15:34 d2.evaluation.evaluator]: Total inference time: 0:01:59.837439 (0.826465 s / iter per device, on 1 devices)\n",
            "[05/20 18:15:34 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:44 (0.304862 s / iter per device, on 1 devices)\n",
            "[05/20 18:15:34 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...\n",
            "[05/20 18:15:34 d2.evaluation.coco_evaluation]: Saving results to /content/output/chkpt/inference/coco_instances_results.json\n",
            "[05/20 18:15:35 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "[05/20 18:15:35 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*\n",
            "[05/20 18:15:35 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.15 seconds.\n",
            "[05/20 18:15:35 d2.evaluation.fast_eval_api]: Accumulating evaluation results...\n",
            "[05/20 18:15:35 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.07 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.240\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.409\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.243\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.067\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.246\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.413\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.320\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.432\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.445\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.110\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.485\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.790\n",
            "[05/20 18:15:35 d2.evaluation.coco_evaluation]: Evaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
            "| 24.050 | 40.936 | 24.268 | 6.688 | 24.571 | 41.291 |\n",
            "[05/20 18:15:35 d2.evaluation.coco_evaluation]: Per-category bbox AP: \n",
            "| category   | AP     | category              | AP     | category   | AP     |\n",
            "|:-----------|:-------|:----------------------|:-------|:-----------|:-------|\n",
            "| Bottle     | 53.191 | Bottle cap            | 12.090 | Can        | 42.582 |\n",
            "| Cigarette  | 1.719  | Cup                   | 30.818 | Lid        | 33.391 |\n",
            "| Other      | 20.027 | Plastic bag & wrapper | 22.304 | Pop tab    | 9.121  |\n",
            "| Straw      | 15.254 |                       |        |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.17s)\n",
            "creating index...\n",
            "index created!\n",
            "[05/20 18:15:35 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*\n",
            "[05/20 18:15:36 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.26 seconds.\n",
            "[05/20 18:15:36 d2.evaluation.fast_eval_api]: Accumulating evaluation results...\n",
            "[05/20 18:15:36 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.06 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.387\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.501\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.395\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.220\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.475\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.519\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.452\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.646\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.664\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.419\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.751\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.838\n",
            "[05/20 18:15:36 d2.evaluation.coco_evaluation]: Evaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 38.663 | 50.084 | 39.510 | 21.993 | 47.466 | 51.939 |\n",
            "[05/20 18:15:36 d2.evaluation.coco_evaluation]: Per-category segm AP: \n",
            "| category   | AP     | category              | AP     | category   | AP     |\n",
            "|:-----------|:-------|:----------------------|:-------|:-----------|:-------|\n",
            "| Bottle     | 73.263 | Bottle cap            | 39.321 | Can        | 55.320 |\n",
            "| Cigarette  | 20.706 | Cup                   | 43.359 | Lid        | 43.883 |\n",
            "| Other      | 30.323 | Plastic bag & wrapper | 35.660 | Pop tab    | 26.053 |\n",
            "| Straw      | 18.741 |                       |        |            |        |\n",
            "[05/20 18:15:36 d2.engine.defaults]: Evaluation results for TACO_val in csv format:\n",
            "[05/20 18:15:36 d2.evaluation.testing]: copypaste: Task: bbox\n",
            "[05/20 18:15:36 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl\n",
            "[05/20 18:15:36 d2.evaluation.testing]: copypaste: 24.0496,40.9362,24.2683,6.6879,24.5714,41.2910\n",
            "[05/20 18:15:36 d2.evaluation.testing]: copypaste: Task: segm\n",
            "[05/20 18:15:36 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl\n",
            "[05/20 18:15:36 d2.evaluation.testing]: copypaste: 38.6628,50.0843,39.5095,21.9926,47.4659,51.9388\n",
            "[05/20 18:15:36 d2.utils.events]:  eta: 0:59:45  iter: 3499  total_loss: 51.63  loss_ce: 1.154  loss_mask: 0.03925  loss_dice: 0.6991  loss_bbox: 0.06786  loss_giou: 0.4095  loss_ce_dn: 0.1809  loss_mask_dn: 0.03807  loss_dice_dn: 0.7135  loss_bbox_dn: 0.05001  loss_giou_dn: 0.3231  loss_ce_0: 1.351  loss_mask_0: 0.03258  loss_dice_0: 0.7546  loss_bbox_0: 0.08871  loss_giou_0: 0.5212  loss_ce_dn_0: 0.7457  loss_mask_dn_0: 0.2536  loss_dice_dn_0: 2.801  loss_bbox_dn_0: 0.3211  loss_giou_dn_0: 0.8532  loss_ce_1: 1.363  loss_mask_1: 0.04148  loss_dice_1: 0.6705  loss_bbox_1: 0.08845  loss_giou_1: 0.4248  loss_ce_dn_1: 0.2665  loss_mask_dn_1: 0.03709  loss_dice_dn_1: 0.8644  loss_bbox_dn_1: 0.07778  loss_giou_dn_1: 0.425  loss_ce_2: 1.3  loss_mask_2: 0.04027  loss_dice_2: 0.7454  loss_bbox_2: 0.07792  loss_giou_2: 0.4411  loss_ce_dn_2: 0.2224  loss_mask_dn_2: 0.03792  loss_dice_dn_2: 0.7635  loss_bbox_dn_2: 0.05686  loss_giou_dn_2: 0.3793  loss_ce_3: 1.253  loss_mask_3: 0.03393  loss_dice_3: 0.6588  loss_bbox_3: 0.07883  loss_giou_3: 0.3857  loss_ce_dn_3: 0.214  loss_mask_dn_3: 0.03614  loss_dice_dn_3: 0.7535  loss_bbox_dn_3: 0.05299  loss_giou_dn_3: 0.3475  loss_ce_4: 1.215  loss_mask_4: 0.0436  loss_dice_4: 0.7081  loss_bbox_4: 0.1028  loss_giou_4: 0.4222  loss_ce_dn_4: 0.1918  loss_mask_dn_4: 0.03695  loss_dice_dn_4: 0.7265  loss_bbox_dn_4: 0.05499  loss_giou_dn_4: 0.3504  loss_ce_5: 1.207  loss_mask_5: 0.03504  loss_dice_5: 0.7332  loss_bbox_5: 0.09581  loss_giou_5: 0.3794  loss_ce_dn_5: 0.1977  loss_mask_dn_5: 0.03776  loss_dice_dn_5: 0.7315  loss_bbox_dn_5: 0.05125  loss_giou_dn_5: 0.3349  loss_ce_6: 1.169  loss_mask_6: 0.03219  loss_dice_6: 0.6431  loss_bbox_6: 0.07775  loss_giou_6: 0.3792  loss_ce_dn_6: 0.1891  loss_mask_dn_6: 0.0368  loss_dice_dn_6: 0.7126  loss_bbox_dn_6: 0.05144  loss_giou_dn_6: 0.3314  loss_ce_7: 1.169  loss_mask_7: 0.03091  loss_dice_7: 0.666  loss_bbox_7: 0.07703  loss_giou_7: 0.4058  loss_ce_dn_7: 0.1808  loss_mask_dn_7: 0.03701  loss_dice_dn_7: 0.7273  loss_bbox_dn_7: 0.05115  loss_giou_dn_7: 0.3256  loss_ce_8: 1.159  loss_mask_8: 0.03613  loss_dice_8: 0.5527  loss_bbox_8: 0.08242  loss_giou_8: 0.4297  loss_ce_dn_8: 0.1773  loss_mask_dn_8: 0.03805  loss_dice_dn_8: 0.7035  loss_bbox_dn_8: 0.05126  loss_giou_dn_8: 0.3244  loss_ce_interm: 1.351  loss_mask_interm: 0.04247  loss_dice_interm: 0.7146  loss_bbox_interm: 0.08975  loss_giou_interm: 0.5303  time: 1.8941  data_time: 0.0755  lr: 1e-06  max_mem: 6663M\n",
            "[05/20 18:16:10 d2.utils.events]:  eta: 0:59:09  iter: 3519  total_loss: 49.6  loss_ce: 0.9373  loss_mask: 0.03556  loss_dice: 0.626  loss_bbox: 0.0701  loss_giou: 0.4078  loss_ce_dn: 0.1727  loss_mask_dn: 0.03909  loss_dice_dn: 0.5873  loss_bbox_dn: 0.03671  loss_giou_dn: 0.329  loss_ce_0: 1.294  loss_mask_0: 0.04731  loss_dice_0: 0.7157  loss_bbox_0: 0.08732  loss_giou_0: 0.5024  loss_ce_dn_0: 0.731  loss_mask_dn_0: 0.1313  loss_dice_dn_0: 1.836  loss_bbox_dn_0: 0.2305  loss_giou_dn_0: 0.872  loss_ce_1: 1.156  loss_mask_1: 0.0464  loss_dice_1: 0.6287  loss_bbox_1: 0.1013  loss_giou_1: 0.4597  loss_ce_dn_1: 0.2818  loss_mask_dn_1: 0.03465  loss_dice_dn_1: 0.6137  loss_bbox_dn_1: 0.06112  loss_giou_dn_1: 0.4139  loss_ce_2: 1.049  loss_mask_2: 0.04142  loss_dice_2: 0.4887  loss_bbox_2: 0.1024  loss_giou_2: 0.447  loss_ce_dn_2: 0.2506  loss_mask_dn_2: 0.03775  loss_dice_dn_2: 0.5845  loss_bbox_dn_2: 0.0482  loss_giou_dn_2: 0.3576  loss_ce_3: 1.1  loss_mask_3: 0.04781  loss_dice_3: 0.6774  loss_bbox_3: 0.09771  loss_giou_3: 0.4549  loss_ce_dn_3: 0.22  loss_mask_dn_3: 0.03806  loss_dice_dn_3: 0.5148  loss_bbox_dn_3: 0.03981  loss_giou_dn_3: 0.3523  loss_ce_4: 1.072  loss_mask_4: 0.03935  loss_dice_4: 0.5874  loss_bbox_4: 0.09451  loss_giou_4: 0.4474  loss_ce_dn_4: 0.1946  loss_mask_dn_4: 0.03798  loss_dice_dn_4: 0.5936  loss_bbox_dn_4: 0.04054  loss_giou_dn_4: 0.3386  loss_ce_5: 1.033  loss_mask_5: 0.0484  loss_dice_5: 0.6008  loss_bbox_5: 0.08772  loss_giou_5: 0.412  loss_ce_dn_5: 0.1802  loss_mask_dn_5: 0.03894  loss_dice_dn_5: 0.5827  loss_bbox_dn_5: 0.03806  loss_giou_dn_5: 0.3318  loss_ce_6: 0.9967  loss_mask_6: 0.04608  loss_dice_6: 0.6098  loss_bbox_6: 0.08226  loss_giou_6: 0.4169  loss_ce_dn_6: 0.1598  loss_mask_dn_6: 0.03914  loss_dice_dn_6: 0.5887  loss_bbox_dn_6: 0.03777  loss_giou_dn_6: 0.3315  loss_ce_7: 1.058  loss_mask_7: 0.04049  loss_dice_7: 0.6061  loss_bbox_7: 0.07282  loss_giou_7: 0.3559  loss_ce_dn_7: 0.1727  loss_mask_dn_7: 0.03938  loss_dice_dn_7: 0.6197  loss_bbox_dn_7: 0.03641  loss_giou_dn_7: 0.3309  loss_ce_8: 1.016  loss_mask_8: 0.04069  loss_dice_8: 0.448  loss_bbox_8: 0.07128  loss_giou_8: 0.3502  loss_ce_dn_8: 0.1738  loss_mask_dn_8: 0.04055  loss_dice_dn_8: 0.5977  loss_bbox_dn_8: 0.03631  loss_giou_dn_8: 0.3267  loss_ce_interm: 1.169  loss_mask_interm: 0.04057  loss_dice_interm: 0.7537  loss_bbox_interm: 0.1292  loss_giou_interm: 0.4467  time: 1.8929  data_time: 0.0737  lr: 1e-06  max_mem: 6663M\n",
            "[05/20 18:16:44 d2.utils.events]:  eta: 0:58:37  iter: 3539  total_loss: 38.11  loss_ce: 0.9337  loss_mask: 0.02463  loss_dice: 0.5571  loss_bbox: 0.04243  loss_giou: 0.3826  loss_ce_dn: 0.1838  loss_mask_dn: 0.02594  loss_dice_dn: 0.5561  loss_bbox_dn: 0.03477  loss_giou_dn: 0.3042  loss_ce_0: 1.297  loss_mask_0: 0.02621  loss_dice_0: 0.5633  loss_bbox_0: 0.05854  loss_giou_0: 0.5582  loss_ce_dn_0: 0.7837  loss_mask_dn_0: 0.07847  loss_dice_dn_0: 2.418  loss_bbox_dn_0: 0.1977  loss_giou_dn_0: 0.863  loss_ce_1: 1.323  loss_mask_1: 0.02734  loss_dice_1: 0.7528  loss_bbox_1: 0.05137  loss_giou_1: 0.4126  loss_ce_dn_1: 0.2593  loss_mask_dn_1: 0.02696  loss_dice_dn_1: 0.631  loss_bbox_dn_1: 0.05532  loss_giou_dn_1: 0.4027  loss_ce_2: 1.143  loss_mask_2: 0.02223  loss_dice_2: 0.5844  loss_bbox_2: 0.04628  loss_giou_2: 0.4516  loss_ce_dn_2: 0.2251  loss_mask_dn_2: 0.02499  loss_dice_dn_2: 0.5746  loss_bbox_dn_2: 0.04449  loss_giou_dn_2: 0.3569  loss_ce_3: 1.162  loss_mask_3: 0.0256  loss_dice_3: 0.6495  loss_bbox_3: 0.04128  loss_giou_3: 0.4013  loss_ce_dn_3: 0.2174  loss_mask_dn_3: 0.02545  loss_dice_dn_3: 0.5215  loss_bbox_dn_3: 0.03696  loss_giou_dn_3: 0.3259  loss_ce_4: 1  loss_mask_4: 0.02261  loss_dice_4: 0.4776  loss_bbox_4: 0.04556  loss_giou_4: 0.3907  loss_ce_dn_4: 0.2091  loss_mask_dn_4: 0.02514  loss_dice_dn_4: 0.5601  loss_bbox_dn_4: 0.03933  loss_giou_dn_4: 0.3306  loss_ce_5: 0.9901  loss_mask_5: 0.02078  loss_dice_5: 0.5748  loss_bbox_5: 0.04371  loss_giou_5: 0.364  loss_ce_dn_5: 0.1982  loss_mask_dn_5: 0.02455  loss_dice_dn_5: 0.5523  loss_bbox_dn_5: 0.03588  loss_giou_dn_5: 0.3171  loss_ce_6: 1.051  loss_mask_6: 0.02636  loss_dice_6: 0.3743  loss_bbox_6: 0.04597  loss_giou_6: 0.4025  loss_ce_dn_6: 0.1855  loss_mask_dn_6: 0.02451  loss_dice_dn_6: 0.558  loss_bbox_dn_6: 0.03429  loss_giou_dn_6: 0.3105  loss_ce_7: 0.9885  loss_mask_7: 0.02406  loss_dice_7: 0.438  loss_bbox_7: 0.04386  loss_giou_7: 0.3682  loss_ce_dn_7: 0.1876  loss_mask_dn_7: 0.02557  loss_dice_dn_7: 0.5283  loss_bbox_dn_7: 0.03468  loss_giou_dn_7: 0.311  loss_ce_8: 0.9337  loss_mask_8: 0.0251  loss_dice_8: 0.4575  loss_bbox_8: 0.04352  loss_giou_8: 0.3925  loss_ce_dn_8: 0.1857  loss_mask_dn_8: 0.02571  loss_dice_dn_8: 0.5306  loss_bbox_dn_8: 0.03522  loss_giou_dn_8: 0.3058  loss_ce_interm: 1.172  loss_mask_interm: 0.02848  loss_dice_interm: 0.492  loss_bbox_interm: 0.06887  loss_giou_interm: 0.5311  time: 1.8919  data_time: 0.0752  lr: 1e-06  max_mem: 6663M\n",
            "[05/20 18:17:21 d2.utils.events]:  eta: 0:58:02  iter: 3559  total_loss: 41.33  loss_ce: 1.024  loss_mask: 0.02964  loss_dice: 0.4677  loss_bbox: 0.05838  loss_giou: 0.2744  loss_ce_dn: 0.2069  loss_mask_dn: 0.0345  loss_dice_dn: 0.4779  loss_bbox_dn: 0.0414  loss_giou_dn: 0.2397  loss_ce_0: 1.353  loss_mask_0: 0.04304  loss_dice_0: 0.6398  loss_bbox_0: 0.06632  loss_giou_0: 0.3953  loss_ce_dn_0: 0.6794  loss_mask_dn_0: 0.1791  loss_dice_dn_0: 2.583  loss_bbox_dn_0: 0.2295  loss_giou_dn_0: 0.8526  loss_ce_1: 1.422  loss_mask_1: 0.0334  loss_dice_1: 0.56  loss_bbox_1: 0.06854  loss_giou_1: 0.3316  loss_ce_dn_1: 0.2898  loss_mask_dn_1: 0.03662  loss_dice_dn_1: 0.5026  loss_bbox_dn_1: 0.05599  loss_giou_dn_1: 0.3162  loss_ce_2: 1.364  loss_mask_2: 0.03149  loss_dice_2: 0.4539  loss_bbox_2: 0.05084  loss_giou_2: 0.2664  loss_ce_dn_2: 0.2745  loss_mask_dn_2: 0.03245  loss_dice_dn_2: 0.5417  loss_bbox_dn_2: 0.05395  loss_giou_dn_2: 0.2839  loss_ce_3: 1.221  loss_mask_3: 0.03607  loss_dice_3: 0.4049  loss_bbox_3: 0.05547  loss_giou_3: 0.276  loss_ce_dn_3: 0.2335  loss_mask_dn_3: 0.03536  loss_dice_dn_3: 0.5182  loss_bbox_dn_3: 0.04351  loss_giou_dn_3: 0.2579  loss_ce_4: 1.226  loss_mask_4: 0.03079  loss_dice_4: 0.3207  loss_bbox_4: 0.05644  loss_giou_4: 0.2846  loss_ce_dn_4: 0.2301  loss_mask_dn_4: 0.03294  loss_dice_dn_4: 0.5047  loss_bbox_dn_4: 0.0434  loss_giou_dn_4: 0.2642  loss_ce_5: 1.077  loss_mask_5: 0.02589  loss_dice_5: 0.4001  loss_bbox_5: 0.05538  loss_giou_5: 0.2769  loss_ce_dn_5: 0.2118  loss_mask_dn_5: 0.03249  loss_dice_dn_5: 0.4956  loss_bbox_dn_5: 0.04242  loss_giou_dn_5: 0.2425  loss_ce_6: 1.019  loss_mask_6: 0.0346  loss_dice_6: 0.3833  loss_bbox_6: 0.05745  loss_giou_6: 0.2743  loss_ce_dn_6: 0.2093  loss_mask_dn_6: 0.03342  loss_dice_dn_6: 0.502  loss_bbox_dn_6: 0.04268  loss_giou_dn_6: 0.2358  loss_ce_7: 1.022  loss_mask_7: 0.03326  loss_dice_7: 0.4307  loss_bbox_7: 0.05766  loss_giou_7: 0.2642  loss_ce_dn_7: 0.2039  loss_mask_dn_7: 0.03571  loss_dice_dn_7: 0.5083  loss_bbox_dn_7: 0.04167  loss_giou_dn_7: 0.2353  loss_ce_8: 0.9948  loss_mask_8: 0.02839  loss_dice_8: 0.499  loss_bbox_8: 0.06145  loss_giou_8: 0.2704  loss_ce_dn_8: 0.2071  loss_mask_dn_8: 0.03531  loss_dice_dn_8: 0.5003  loss_bbox_dn_8: 0.04125  loss_giou_dn_8: 0.2335  loss_ce_interm: 1.435  loss_mask_interm: 0.05119  loss_dice_interm: 0.4917  loss_bbox_interm: 0.1004  loss_giou_interm: 0.3762  time: 1.8916  data_time: 0.1512  lr: 1e-06  max_mem: 6663M\n",
            "[05/20 18:17:55 d2.utils.events]:  eta: 0:57:30  iter: 3579  total_loss: 42.59  loss_ce: 1.012  loss_mask: 0.04692  loss_dice: 0.6062  loss_bbox: 0.04674  loss_giou: 0.3073  loss_ce_dn: 0.2264  loss_mask_dn: 0.04617  loss_dice_dn: 0.6934  loss_bbox_dn: 0.04485  loss_giou_dn: 0.3077  loss_ce_0: 1.195  loss_mask_0: 0.05461  loss_dice_0: 0.6863  loss_bbox_0: 0.06375  loss_giou_0: 0.4057  loss_ce_dn_0: 0.7621  loss_mask_dn_0: 0.2541  loss_dice_dn_0: 3.028  loss_bbox_dn_0: 0.2688  loss_giou_dn_0: 0.8522  loss_ce_1: 1.236  loss_mask_1: 0.05525  loss_dice_1: 0.7913  loss_bbox_1: 0.0574  loss_giou_1: 0.4079  loss_ce_dn_1: 0.3037  loss_mask_dn_1: 0.05827  loss_dice_dn_1: 0.7902  loss_bbox_dn_1: 0.06682  loss_giou_dn_1: 0.3872  loss_ce_2: 1.19  loss_mask_2: 0.05915  loss_dice_2: 0.715  loss_bbox_2: 0.05498  loss_giou_2: 0.3815  loss_ce_dn_2: 0.2697  loss_mask_dn_2: 0.04962  loss_dice_dn_2: 0.6981  loss_bbox_dn_2: 0.05107  loss_giou_dn_2: 0.3437  loss_ce_3: 0.9596  loss_mask_3: 0.06334  loss_dice_3: 0.8057  loss_bbox_3: 0.0604  loss_giou_3: 0.3386  loss_ce_dn_3: 0.2471  loss_mask_dn_3: 0.04956  loss_dice_dn_3: 0.6838  loss_bbox_dn_3: 0.04674  loss_giou_dn_3: 0.318  loss_ce_4: 1.051  loss_mask_4: 0.04675  loss_dice_4: 0.671  loss_bbox_4: 0.05102  loss_giou_4: 0.3857  loss_ce_dn_4: 0.2541  loss_mask_dn_4: 0.04837  loss_dice_dn_4: 0.6777  loss_bbox_dn_4: 0.04659  loss_giou_dn_4: 0.3137  loss_ce_5: 1.027  loss_mask_5: 0.04807  loss_dice_5: 0.685  loss_bbox_5: 0.05108  loss_giou_5: 0.3087  loss_ce_dn_5: 0.2307  loss_mask_dn_5: 0.04858  loss_dice_dn_5: 0.6937  loss_bbox_dn_5: 0.04483  loss_giou_dn_5: 0.3055  loss_ce_6: 0.9411  loss_mask_6: 0.0447  loss_dice_6: 0.676  loss_bbox_6: 0.04826  loss_giou_6: 0.3134  loss_ce_dn_6: 0.2248  loss_mask_dn_6: 0.04782  loss_dice_dn_6: 0.6728  loss_bbox_dn_6: 0.04476  loss_giou_dn_6: 0.3078  loss_ce_7: 0.9081  loss_mask_7: 0.05128  loss_dice_7: 0.6628  loss_bbox_7: 0.05179  loss_giou_7: 0.267  loss_ce_dn_7: 0.226  loss_mask_dn_7: 0.04721  loss_dice_dn_7: 0.6596  loss_bbox_dn_7: 0.04389  loss_giou_dn_7: 0.3057  loss_ce_8: 1.007  loss_mask_8: 0.04886  loss_dice_8: 0.6322  loss_bbox_8: 0.05331  loss_giou_8: 0.2695  loss_ce_dn_8: 0.2324  loss_mask_dn_8: 0.04839  loss_dice_dn_8: 0.7063  loss_bbox_dn_8: 0.04449  loss_giou_dn_8: 0.3032  loss_ce_interm: 1.121  loss_mask_interm: 0.06005  loss_dice_interm: 0.8077  loss_bbox_interm: 0.08352  loss_giou_interm: 0.4339  time: 1.8906  data_time: 0.1190  lr: 1e-06  max_mem: 6663M\n",
            "[05/20 18:18:30 d2.utils.events]:  eta: 0:57:02  iter: 3599  total_loss: 46.57  loss_ce: 1.092  loss_mask: 0.03696  loss_dice: 0.7765  loss_bbox: 0.04483  loss_giou: 0.3546  loss_ce_dn: 0.2013  loss_mask_dn: 0.02619  loss_dice_dn: 0.7099  loss_bbox_dn: 0.03294  loss_giou_dn: 0.3141  loss_ce_0: 1.281  loss_mask_0: 0.04347  loss_dice_0: 0.6246  loss_bbox_0: 0.06  loss_giou_0: 0.4823  loss_ce_dn_0: 0.7981  loss_mask_dn_0: 0.195  loss_dice_dn_0: 2.536  loss_bbox_dn_0: 0.278  loss_giou_dn_0: 0.863  loss_ce_1: 1.118  loss_mask_1: 0.02726  loss_dice_1: 0.6746  loss_bbox_1: 0.05299  loss_giou_1: 0.4238  loss_ce_dn_1: 0.2902  loss_mask_dn_1: 0.037  loss_dice_dn_1: 0.8414  loss_bbox_dn_1: 0.0679  loss_giou_dn_1: 0.3685  loss_ce_2: 1.245  loss_mask_2: 0.03307  loss_dice_2: 0.6863  loss_bbox_2: 0.0471  loss_giou_2: 0.3713  loss_ce_dn_2: 0.2437  loss_mask_dn_2: 0.03089  loss_dice_dn_2: 0.7642  loss_bbox_dn_2: 0.05547  loss_giou_dn_2: 0.3191  loss_ce_3: 0.9849  loss_mask_3: 0.03354  loss_dice_3: 0.7915  loss_bbox_3: 0.04707  loss_giou_3: 0.3532  loss_ce_dn_3: 0.2136  loss_mask_dn_3: 0.02994  loss_dice_dn_3: 0.6843  loss_bbox_dn_3: 0.03697  loss_giou_dn_3: 0.3107  loss_ce_4: 1.009  loss_mask_4: 0.03216  loss_dice_4: 0.6649  loss_bbox_4: 0.04886  loss_giou_4: 0.3638  loss_ce_dn_4: 0.1975  loss_mask_dn_4: 0.02793  loss_dice_dn_4: 0.6783  loss_bbox_dn_4: 0.03421  loss_giou_dn_4: 0.3192  loss_ce_5: 1.109  loss_mask_5: 0.04038  loss_dice_5: 0.7819  loss_bbox_5: 0.04673  loss_giou_5: 0.3714  loss_ce_dn_5: 0.1907  loss_mask_dn_5: 0.028  loss_dice_dn_5: 0.7387  loss_bbox_dn_5: 0.0327  loss_giou_dn_5: 0.32  loss_ce_6: 1.122  loss_mask_6: 0.04079  loss_dice_6: 0.6154  loss_bbox_6: 0.04578  loss_giou_6: 0.3635  loss_ce_dn_6: 0.1832  loss_mask_dn_6: 0.02553  loss_dice_dn_6: 0.6965  loss_bbox_dn_6: 0.03369  loss_giou_dn_6: 0.3144  loss_ce_7: 1.144  loss_mask_7: 0.034  loss_dice_7: 0.7235  loss_bbox_7: 0.04566  loss_giou_7: 0.349  loss_ce_dn_7: 0.1961  loss_mask_dn_7: 0.02592  loss_dice_dn_7: 0.7389  loss_bbox_dn_7: 0.03273  loss_giou_dn_7: 0.3122  loss_ce_8: 1.14  loss_mask_8: 0.03654  loss_dice_8: 0.7166  loss_bbox_8: 0.04508  loss_giou_8: 0.3472  loss_ce_dn_8: 0.1995  loss_mask_dn_8: 0.02601  loss_dice_dn_8: 0.7442  loss_bbox_dn_8: 0.03266  loss_giou_dn_8: 0.313  loss_ce_interm: 1.275  loss_mask_interm: 0.05258  loss_dice_interm: 0.6852  loss_bbox_interm: 0.08978  loss_giou_interm: 0.4392  time: 1.8897  data_time: 0.0577  lr: 1e-06  max_mem: 6663M\n",
            "[05/20 18:19:05 d2.utils.events]:  eta: 0:56:36  iter: 3619  total_loss: 34.54  loss_ce: 0.8905  loss_mask: 0.03017  loss_dice: 0.3329  loss_bbox: 0.03662  loss_giou: 0.257  loss_ce_dn: 0.1677  loss_mask_dn: 0.0235  loss_dice_dn: 0.4757  loss_bbox_dn: 0.03393  loss_giou_dn: 0.2265  loss_ce_0: 0.9453  loss_mask_0: 0.03438  loss_dice_0: 0.5182  loss_bbox_0: 0.05447  loss_giou_0: 0.4421  loss_ce_dn_0: 0.685  loss_mask_dn_0: 0.1431  loss_dice_dn_0: 2.365  loss_bbox_dn_0: 0.2513  loss_giou_dn_0: 0.8537  loss_ce_1: 0.9589  loss_mask_1: 0.02882  loss_dice_1: 0.436  loss_bbox_1: 0.04689  loss_giou_1: 0.3243  loss_ce_dn_1: 0.2848  loss_mask_dn_1: 0.02697  loss_dice_dn_1: 0.4944  loss_bbox_dn_1: 0.06207  loss_giou_dn_1: 0.2735  loss_ce_2: 0.8859  loss_mask_2: 0.03459  loss_dice_2: 0.5927  loss_bbox_2: 0.04995  loss_giou_2: 0.3237  loss_ce_dn_2: 0.2252  loss_mask_dn_2: 0.02716  loss_dice_dn_2: 0.5171  loss_bbox_dn_2: 0.04273  loss_giou_dn_2: 0.2502  loss_ce_3: 0.9283  loss_mask_3: 0.03527  loss_dice_3: 0.5085  loss_bbox_3: 0.04047  loss_giou_3: 0.2861  loss_ce_dn_3: 0.2023  loss_mask_dn_3: 0.02806  loss_dice_dn_3: 0.5664  loss_bbox_dn_3: 0.03842  loss_giou_dn_3: 0.2365  loss_ce_4: 0.8925  loss_mask_4: 0.03707  loss_dice_4: 0.5498  loss_bbox_4: 0.03833  loss_giou_4: 0.2758  loss_ce_dn_4: 0.1902  loss_mask_dn_4: 0.02514  loss_dice_dn_4: 0.4922  loss_bbox_dn_4: 0.03659  loss_giou_dn_4: 0.2382  loss_ce_5: 0.8025  loss_mask_5: 0.02803  loss_dice_5: 0.4061  loss_bbox_5: 0.04013  loss_giou_5: 0.2678  loss_ce_dn_5: 0.1736  loss_mask_dn_5: 0.02425  loss_dice_dn_5: 0.4885  loss_bbox_dn_5: 0.03652  loss_giou_dn_5: 0.2249  loss_ce_6: 0.8248  loss_mask_6: 0.0294  loss_dice_6: 0.4034  loss_bbox_6: 0.04676  loss_giou_6: 0.2613  loss_ce_dn_6: 0.1721  loss_mask_dn_6: 0.0242  loss_dice_dn_6: 0.5188  loss_bbox_dn_6: 0.03719  loss_giou_dn_6: 0.223  loss_ce_7: 0.8142  loss_mask_7: 0.02571  loss_dice_7: 0.5374  loss_bbox_7: 0.03803  loss_giou_7: 0.258  loss_ce_dn_7: 0.1709  loss_mask_dn_7: 0.0236  loss_dice_dn_7: 0.4913  loss_bbox_dn_7: 0.03603  loss_giou_dn_7: 0.2244  loss_ce_8: 0.8374  loss_mask_8: 0.0254  loss_dice_8: 0.3483  loss_bbox_8: 0.03686  loss_giou_8: 0.2647  loss_ce_dn_8: 0.1653  loss_mask_dn_8: 0.02211  loss_dice_dn_8: 0.5062  loss_bbox_dn_8: 0.0344  loss_giou_dn_8: 0.2296  loss_ce_interm: 0.9371  loss_mask_interm: 0.02387  loss_dice_interm: 0.5261  loss_bbox_interm: 0.07623  loss_giou_interm: 0.3556  time: 1.8889  data_time: 0.0992  lr: 1e-06  max_mem: 6663M\n",
            "[05/20 18:19:38 d2.utils.events]:  eta: 0:55:55  iter: 3639  total_loss: 38.63  loss_ce: 0.7539  loss_mask: 0.03905  loss_dice: 0.447  loss_bbox: 0.05659  loss_giou: 0.3021  loss_ce_dn: 0.1185  loss_mask_dn: 0.0326  loss_dice_dn: 0.6046  loss_bbox_dn: 0.03742  loss_giou_dn: 0.2378  loss_ce_0: 1.244  loss_mask_0: 0.03856  loss_dice_0: 0.5404  loss_bbox_0: 0.07362  loss_giou_0: 0.4248  loss_ce_dn_0: 0.7353  loss_mask_dn_0: 0.2901  loss_dice_dn_0: 2.661  loss_bbox_dn_0: 0.3047  loss_giou_dn_0: 0.8496  loss_ce_1: 1.141  loss_mask_1: 0.03382  loss_dice_1: 0.7363  loss_bbox_1: 0.08111  loss_giou_1: 0.362  loss_ce_dn_1: 0.2406  loss_mask_dn_1: 0.03384  loss_dice_dn_1: 0.5877  loss_bbox_dn_1: 0.05921  loss_giou_dn_1: 0.3556  loss_ce_2: 1.014  loss_mask_2: 0.03272  loss_dice_2: 0.4351  loss_bbox_2: 0.05478  loss_giou_2: 0.34  loss_ce_dn_2: 0.2032  loss_mask_dn_2: 0.02858  loss_dice_dn_2: 0.5886  loss_bbox_dn_2: 0.05129  loss_giou_dn_2: 0.3141  loss_ce_3: 0.8786  loss_mask_3: 0.03738  loss_dice_3: 0.7052  loss_bbox_3: 0.07442  loss_giou_3: 0.303  loss_ce_dn_3: 0.173  loss_mask_dn_3: 0.03057  loss_dice_dn_3: 0.5635  loss_bbox_dn_3: 0.04542  loss_giou_dn_3: 0.2884  loss_ce_4: 0.8322  loss_mask_4: 0.03494  loss_dice_4: 0.4721  loss_bbox_4: 0.05229  loss_giou_4: 0.3072  loss_ce_dn_4: 0.1599  loss_mask_dn_4: 0.03191  loss_dice_dn_4: 0.5505  loss_bbox_dn_4: 0.03679  loss_giou_dn_4: 0.2539  loss_ce_5: 0.884  loss_mask_5: 0.03753  loss_dice_5: 0.576  loss_bbox_5: 0.05301  loss_giou_5: 0.3196  loss_ce_dn_5: 0.1417  loss_mask_dn_5: 0.03102  loss_dice_dn_5: 0.5819  loss_bbox_dn_5: 0.03658  loss_giou_dn_5: 0.2479  loss_ce_6: 0.7667  loss_mask_6: 0.03362  loss_dice_6: 0.597  loss_bbox_6: 0.05361  loss_giou_6: 0.3021  loss_ce_dn_6: 0.1289  loss_mask_dn_6: 0.0311  loss_dice_dn_6: 0.5607  loss_bbox_dn_6: 0.03613  loss_giou_dn_6: 0.2437  loss_ce_7: 0.7819  loss_mask_7: 0.03597  loss_dice_7: 0.3771  loss_bbox_7: 0.05456  loss_giou_7: 0.3085  loss_ce_dn_7: 0.1208  loss_mask_dn_7: 0.0329  loss_dice_dn_7: 0.5506  loss_bbox_dn_7: 0.03726  loss_giou_dn_7: 0.2444  loss_ce_8: 0.7527  loss_mask_8: 0.03446  loss_dice_8: 0.422  loss_bbox_8: 0.05682  loss_giou_8: 0.3017  loss_ce_dn_8: 0.1191  loss_mask_dn_8: 0.03252  loss_dice_dn_8: 0.5372  loss_bbox_dn_8: 0.03728  loss_giou_dn_8: 0.238  loss_ce_interm: 1.247  loss_mask_interm: 0.04049  loss_dice_interm: 0.7392  loss_bbox_interm: 0.1027  loss_giou_interm: 0.3731  time: 1.8877  data_time: 0.0641  lr: 1e-06  max_mem: 6663M\n",
            "[05/20 18:20:14 d2.utils.events]:  eta: 0:55:22  iter: 3659  total_loss: 46.44  loss_ce: 0.9947  loss_mask: 0.06522  loss_dice: 0.5989  loss_bbox: 0.05378  loss_giou: 0.3474  loss_ce_dn: 0.1652  loss_mask_dn: 0.037  loss_dice_dn: 0.5364  loss_bbox_dn: 0.04953  loss_giou_dn: 0.2863  loss_ce_0: 1.301  loss_mask_0: 0.05979  loss_dice_0: 0.5848  loss_bbox_0: 0.06515  loss_giou_0: 0.4213  loss_ce_dn_0: 0.6968  loss_mask_dn_0: 0.3773  loss_dice_dn_0: 3.014  loss_bbox_dn_0: 0.3462  loss_giou_dn_0: 0.8587  loss_ce_1: 1.269  loss_mask_1: 0.06847  loss_dice_1: 0.5756  loss_bbox_1: 0.05962  loss_giou_1: 0.3775  loss_ce_dn_1: 0.2534  loss_mask_dn_1: 0.04826  loss_dice_dn_1: 0.5997  loss_bbox_dn_1: 0.0965  loss_giou_dn_1: 0.3837  loss_ce_2: 1.155  loss_mask_2: 0.06482  loss_dice_2: 0.6295  loss_bbox_2: 0.05623  loss_giou_2: 0.3931  loss_ce_dn_2: 0.2178  loss_mask_dn_2: 0.04228  loss_dice_dn_2: 0.576  loss_bbox_dn_2: 0.07436  loss_giou_dn_2: 0.3427  loss_ce_3: 1.123  loss_mask_3: 0.0637  loss_dice_3: 0.5763  loss_bbox_3: 0.05641  loss_giou_3: 0.3605  loss_ce_dn_3: 0.2132  loss_mask_dn_3: 0.04425  loss_dice_dn_3: 0.5856  loss_bbox_dn_3: 0.06739  loss_giou_dn_3: 0.3188  loss_ce_4: 1.023  loss_mask_4: 0.05574  loss_dice_4: 0.539  loss_bbox_4: 0.05254  loss_giou_4: 0.3526  loss_ce_dn_4: 0.1897  loss_mask_dn_4: 0.04284  loss_dice_dn_4: 0.5784  loss_bbox_dn_4: 0.05952  loss_giou_dn_4: 0.3078  loss_ce_5: 0.9954  loss_mask_5: 0.05525  loss_dice_5: 0.536  loss_bbox_5: 0.05504  loss_giou_5: 0.3473  loss_ce_dn_5: 0.1814  loss_mask_dn_5: 0.03745  loss_dice_dn_5: 0.5568  loss_bbox_dn_5: 0.05386  loss_giou_dn_5: 0.2932  loss_ce_6: 1.022  loss_mask_6: 0.05806  loss_dice_6: 0.5525  loss_bbox_6: 0.0563  loss_giou_6: 0.3578  loss_ce_dn_6: 0.1679  loss_mask_dn_6: 0.03773  loss_dice_dn_6: 0.5576  loss_bbox_dn_6: 0.04971  loss_giou_dn_6: 0.2917  loss_ce_7: 1.005  loss_mask_7: 0.05125  loss_dice_7: 0.5556  loss_bbox_7: 0.05596  loss_giou_7: 0.3529  loss_ce_dn_7: 0.1713  loss_mask_dn_7: 0.03557  loss_dice_dn_7: 0.5414  loss_bbox_dn_7: 0.0504  loss_giou_dn_7: 0.2921  loss_ce_8: 1  loss_mask_8: 0.05649  loss_dice_8: 0.5416  loss_bbox_8: 0.05701  loss_giou_8: 0.3485  loss_ce_dn_8: 0.1678  loss_mask_dn_8: 0.03582  loss_dice_dn_8: 0.5484  loss_bbox_dn_8: 0.0511  loss_giou_dn_8: 0.2896  loss_ce_interm: 1.298  loss_mask_interm: 0.06259  loss_dice_interm: 0.575  loss_bbox_interm: 0.1378  loss_giou_interm: 0.4879  time: 1.8871  data_time: 0.1523  lr: 1e-06  max_mem: 6663M\n",
            "[05/20 18:20:48 d2.utils.events]:  eta: 0:54:39  iter: 3679  total_loss: 41.6  loss_ce: 0.833  loss_mask: 0.03705  loss_dice: 0.7151  loss_bbox: 0.06547  loss_giou: 0.3583  loss_ce_dn: 0.1807  loss_mask_dn: 0.0342  loss_dice_dn: 0.675  loss_bbox_dn: 0.04292  loss_giou_dn: 0.2942  loss_ce_0: 1.213  loss_mask_0: 0.04164  loss_dice_0: 0.7316  loss_bbox_0: 0.0695  loss_giou_0: 0.4434  loss_ce_dn_0: 0.8074  loss_mask_dn_0: 0.1831  loss_dice_dn_0: 2.799  loss_bbox_dn_0: 0.3071  loss_giou_dn_0: 0.8535  loss_ce_1: 1.198  loss_mask_1: 0.03959  loss_dice_1: 0.8233  loss_bbox_1: 0.07741  loss_giou_1: 0.3998  loss_ce_dn_1: 0.2489  loss_mask_dn_1: 0.03557  loss_dice_dn_1: 0.7075  loss_bbox_dn_1: 0.09007  loss_giou_dn_1: 0.3808  loss_ce_2: 1.059  loss_mask_2: 0.04492  loss_dice_2: 0.8331  loss_bbox_2: 0.09404  loss_giou_2: 0.3708  loss_ce_dn_2: 0.215  loss_mask_dn_2: 0.03025  loss_dice_dn_2: 0.6883  loss_bbox_dn_2: 0.05848  loss_giou_dn_2: 0.3377  loss_ce_3: 0.9104  loss_mask_3: 0.0474  loss_dice_3: 0.7431  loss_bbox_3: 0.07208  loss_giou_3: 0.4123  loss_ce_dn_3: 0.2091  loss_mask_dn_3: 0.03025  loss_dice_dn_3: 0.6878  loss_bbox_dn_3: 0.04677  loss_giou_dn_3: 0.3164  loss_ce_4: 0.8589  loss_mask_4: 0.04218  loss_dice_4: 0.7859  loss_bbox_4: 0.06476  loss_giou_4: 0.4013  loss_ce_dn_4: 0.1923  loss_mask_dn_4: 0.03138  loss_dice_dn_4: 0.6847  loss_bbox_dn_4: 0.0486  loss_giou_dn_4: 0.315  loss_ce_5: 0.9002  loss_mask_5: 0.04678  loss_dice_5: 0.7395  loss_bbox_5: 0.07057  loss_giou_5: 0.4031  loss_ce_dn_5: 0.1886  loss_mask_dn_5: 0.03069  loss_dice_dn_5: 0.6771  loss_bbox_dn_5: 0.0473  loss_giou_dn_5: 0.3146  loss_ce_6: 0.8956  loss_mask_6: 0.0352  loss_dice_6: 0.7313  loss_bbox_6: 0.07096  loss_giou_6: 0.3843  loss_ce_dn_6: 0.1827  loss_mask_dn_6: 0.02975  loss_dice_dn_6: 0.6945  loss_bbox_dn_6: 0.0458  loss_giou_dn_6: 0.319  loss_ce_7: 0.8553  loss_mask_7: 0.04305  loss_dice_7: 0.8788  loss_bbox_7: 0.0765  loss_giou_7: 0.3708  loss_ce_dn_7: 0.1861  loss_mask_dn_7: 0.03143  loss_dice_dn_7: 0.6708  loss_bbox_dn_7: 0.04375  loss_giou_dn_7: 0.3031  loss_ce_8: 0.8562  loss_mask_8: 0.03676  loss_dice_8: 0.7897  loss_bbox_8: 0.06773  loss_giou_8: 0.3691  loss_ce_dn_8: 0.1824  loss_mask_dn_8: 0.03307  loss_dice_dn_8: 0.6896  loss_bbox_dn_8: 0.04263  loss_giou_dn_8: 0.2954  loss_ce_interm: 1.152  loss_mask_interm: 0.03785  loss_dice_interm: 0.7395  loss_bbox_interm: 0.1032  loss_giou_interm: 0.4749  time: 1.8860  data_time: 0.0738  lr: 1e-06  max_mem: 6663M\n",
            "[05/20 18:21:23 d2.utils.events]:  eta: 0:54:06  iter: 3699  total_loss: 34.44  loss_ce: 0.8712  loss_mask: 0.03812  loss_dice: 0.3844  loss_bbox: 0.04706  loss_giou: 0.2054  loss_ce_dn: 0.1301  loss_mask_dn: 0.03671  loss_dice_dn: 0.479  loss_bbox_dn: 0.04694  loss_giou_dn: 0.187  loss_ce_0: 1.168  loss_mask_0: 0.03926  loss_dice_0: 0.3764  loss_bbox_0: 0.06463  loss_giou_0: 0.2151  loss_ce_dn_0: 0.6961  loss_mask_dn_0: 0.1503  loss_dice_dn_0: 2.002  loss_bbox_dn_0: 0.3772  loss_giou_dn_0: 0.8588  loss_ce_1: 1.165  loss_mask_1: 0.0464  loss_dice_1: 0.4046  loss_bbox_1: 0.05127  loss_giou_1: 0.2052  loss_ce_dn_1: 0.2469  loss_mask_dn_1: 0.03685  loss_dice_dn_1: 0.4883  loss_bbox_dn_1: 0.1132  loss_giou_dn_1: 0.2985  loss_ce_2: 1.012  loss_mask_2: 0.0344  loss_dice_2: 0.2994  loss_bbox_2: 0.04789  loss_giou_2: 0.1822  loss_ce_dn_2: 0.1985  loss_mask_dn_2: 0.03642  loss_dice_dn_2: 0.477  loss_bbox_dn_2: 0.07079  loss_giou_dn_2: 0.2221  loss_ce_3: 0.9852  loss_mask_3: 0.0349  loss_dice_3: 0.3466  loss_bbox_3: 0.04689  loss_giou_3: 0.1812  loss_ce_dn_3: 0.18  loss_mask_dn_3: 0.03814  loss_dice_dn_3: 0.5112  loss_bbox_dn_3: 0.05157  loss_giou_dn_3: 0.2218  loss_ce_4: 0.9415  loss_mask_4: 0.04308  loss_dice_4: 0.456  loss_bbox_4: 0.05596  loss_giou_4: 0.1857  loss_ce_dn_4: 0.1505  loss_mask_dn_4: 0.03864  loss_dice_dn_4: 0.4959  loss_bbox_dn_4: 0.04977  loss_giou_dn_4: 0.2177  loss_ce_5: 0.9034  loss_mask_5: 0.04101  loss_dice_5: 0.367  loss_bbox_5: 0.04752  loss_giou_5: 0.1921  loss_ce_dn_5: 0.1464  loss_mask_dn_5: 0.03761  loss_dice_dn_5: 0.4987  loss_bbox_dn_5: 0.04987  loss_giou_dn_5: 0.189  loss_ce_6: 0.91  loss_mask_6: 0.03739  loss_dice_6: 0.4328  loss_bbox_6: 0.0478  loss_giou_6: 0.179  loss_ce_dn_6: 0.1351  loss_mask_dn_6: 0.03791  loss_dice_dn_6: 0.4733  loss_bbox_dn_6: 0.04871  loss_giou_dn_6: 0.1953  loss_ce_7: 0.8835  loss_mask_7: 0.03847  loss_dice_7: 0.3345  loss_bbox_7: 0.04814  loss_giou_7: 0.2081  loss_ce_dn_7: 0.1286  loss_mask_dn_7: 0.03613  loss_dice_dn_7: 0.4747  loss_bbox_dn_7: 0.04754  loss_giou_dn_7: 0.1863  loss_ce_8: 0.8827  loss_mask_8: 0.03745  loss_dice_8: 0.4895  loss_bbox_8: 0.04646  loss_giou_8: 0.2045  loss_ce_dn_8: 0.1283  loss_mask_dn_8: 0.03838  loss_dice_dn_8: 0.4851  loss_bbox_dn_8: 0.04667  loss_giou_dn_8: 0.191  loss_ce_interm: 1.117  loss_mask_interm: 0.03887  loss_dice_interm: 0.4197  loss_bbox_interm: 0.1199  loss_giou_interm: 0.3266  time: 1.8855  data_time: 0.1151  lr: 1e-06  max_mem: 6663M\n",
            "[05/20 18:21:58 d2.utils.events]:  eta: 0:53:36  iter: 3719  total_loss: 48.28  loss_ce: 1.016  loss_mask: 0.02719  loss_dice: 0.7263  loss_bbox: 0.07558  loss_giou: 0.4392  loss_ce_dn: 0.2096  loss_mask_dn: 0.02274  loss_dice_dn: 0.8403  loss_bbox_dn: 0.03759  loss_giou_dn: 0.3616  loss_ce_0: 1.429  loss_mask_0: 0.03826  loss_dice_0: 0.933  loss_bbox_0: 0.09257  loss_giou_0: 0.5972  loss_ce_dn_0: 0.7453  loss_mask_dn_0: 0.09775  loss_dice_dn_0: 2.69  loss_bbox_dn_0: 0.204  loss_giou_dn_0: 0.8574  loss_ce_1: 1.335  loss_mask_1: 0.02517  loss_dice_1: 0.8311  loss_bbox_1: 0.08624  loss_giou_1: 0.5158  loss_ce_dn_1: 0.2928  loss_mask_dn_1: 0.0229  loss_dice_dn_1: 0.8379  loss_bbox_dn_1: 0.06151  loss_giou_dn_1: 0.4512  loss_ce_2: 1.253  loss_mask_2: 0.03293  loss_dice_2: 0.8542  loss_bbox_2: 0.08639  loss_giou_2: 0.5189  loss_ce_dn_2: 0.2481  loss_mask_dn_2: 0.02196  loss_dice_dn_2: 0.847  loss_bbox_dn_2: 0.04622  loss_giou_dn_2: 0.4151  loss_ce_3: 1.189  loss_mask_3: 0.03231  loss_dice_3: 0.7467  loss_bbox_3: 0.08874  loss_giou_3: 0.4893  loss_ce_dn_3: 0.2261  loss_mask_dn_3: 0.0225  loss_dice_dn_3: 0.8533  loss_bbox_dn_3: 0.04068  loss_giou_dn_3: 0.3887  loss_ce_4: 1.06  loss_mask_4: 0.02901  loss_dice_4: 0.791  loss_bbox_4: 0.1068  loss_giou_4: 0.5656  loss_ce_dn_4: 0.226  loss_mask_dn_4: 0.02253  loss_dice_dn_4: 0.7921  loss_bbox_dn_4: 0.03866  loss_giou_dn_4: 0.3725  loss_ce_5: 1.161  loss_mask_5: 0.0301  loss_dice_5: 0.8175  loss_bbox_5: 0.08183  loss_giou_5: 0.444  loss_ce_dn_5: 0.2064  loss_mask_dn_5: 0.02286  loss_dice_dn_5: 0.8252  loss_bbox_dn_5: 0.03923  loss_giou_dn_5: 0.3643  loss_ce_6: 1.1  loss_mask_6: 0.02832  loss_dice_6: 0.6133  loss_bbox_6: 0.08739  loss_giou_6: 0.538  loss_ce_dn_6: 0.2175  loss_mask_dn_6: 0.02221  loss_dice_dn_6: 0.8167  loss_bbox_dn_6: 0.03941  loss_giou_dn_6: 0.3659  loss_ce_7: 1.025  loss_mask_7: 0.03203  loss_dice_7: 0.9037  loss_bbox_7: 0.0751  loss_giou_7: 0.4725  loss_ce_dn_7: 0.213  loss_mask_dn_7: 0.02289  loss_dice_dn_7: 0.8114  loss_bbox_dn_7: 0.03708  loss_giou_dn_7: 0.3615  loss_ce_8: 1.028  loss_mask_8: 0.02913  loss_dice_8: 0.8718  loss_bbox_8: 0.08239  loss_giou_8: 0.4792  loss_ce_dn_8: 0.2078  loss_mask_dn_8: 0.02272  loss_dice_dn_8: 0.8166  loss_bbox_dn_8: 0.03778  loss_giou_dn_8: 0.3629  loss_ce_interm: 1.422  loss_mask_interm: 0.03744  loss_dice_interm: 0.6979  loss_bbox_interm: 0.08278  loss_giou_interm: 0.6815  time: 1.8846  data_time: 0.0701  lr: 1e-06  max_mem: 6663M\n",
            "[05/20 18:22:32 d2.utils.events]:  eta: 0:53:09  iter: 3739  total_loss: 42.93  loss_ce: 1.055  loss_mask: 0.04374  loss_dice: 0.5941  loss_bbox: 0.07155  loss_giou: 0.3323  loss_ce_dn: 0.1421  loss_mask_dn: 0.04914  loss_dice_dn: 0.5655  loss_bbox_dn: 0.04435  loss_giou_dn: 0.2771  loss_ce_0: 1.309  loss_mask_0: 0.05059  loss_dice_0: 0.5519  loss_bbox_0: 0.07554  loss_giou_0: 0.3801  loss_ce_dn_0: 0.7638  loss_mask_dn_0: 0.3773  loss_dice_dn_0: 2.611  loss_bbox_dn_0: 0.3195  loss_giou_dn_0: 0.8512  loss_ce_1: 1.205  loss_mask_1: 0.04494  loss_dice_1: 0.6978  loss_bbox_1: 0.07362  loss_giou_1: 0.3341  loss_ce_dn_1: 0.2477  loss_mask_dn_1: 0.04725  loss_dice_dn_1: 0.6815  loss_bbox_dn_1: 0.1007  loss_giou_dn_1: 0.3883  loss_ce_2: 1.085  loss_mask_2: 0.03731  loss_dice_2: 0.5034  loss_bbox_2: 0.07706  loss_giou_2: 0.3422  loss_ce_dn_2: 0.1801  loss_mask_dn_2: 0.0467  loss_dice_dn_2: 0.6401  loss_bbox_dn_2: 0.06819  loss_giou_dn_2: 0.331  loss_ce_3: 1.07  loss_mask_3: 0.04011  loss_dice_3: 0.5615  loss_bbox_3: 0.06375  loss_giou_3: 0.318  loss_ce_dn_3: 0.1425  loss_mask_dn_3: 0.04902  loss_dice_dn_3: 0.5984  loss_bbox_dn_3: 0.05622  loss_giou_dn_3: 0.2944  loss_ce_4: 1.002  loss_mask_4: 0.04138  loss_dice_4: 0.7682  loss_bbox_4: 0.06785  loss_giou_4: 0.3217  loss_ce_dn_4: 0.1511  loss_mask_dn_4: 0.04962  loss_dice_dn_4: 0.6026  loss_bbox_dn_4: 0.05321  loss_giou_dn_4: 0.2897  loss_ce_5: 0.9705  loss_mask_5: 0.04263  loss_dice_5: 0.7078  loss_bbox_5: 0.06396  loss_giou_5: 0.3131  loss_ce_dn_5: 0.1472  loss_mask_dn_5: 0.05071  loss_dice_dn_5: 0.6078  loss_bbox_dn_5: 0.04707  loss_giou_dn_5: 0.2766  loss_ce_6: 1.005  loss_mask_6: 0.04198  loss_dice_6: 0.5517  loss_bbox_6: 0.06297  loss_giou_6: 0.3046  loss_ce_dn_6: 0.1352  loss_mask_dn_6: 0.04988  loss_dice_dn_6: 0.6062  loss_bbox_dn_6: 0.04578  loss_giou_dn_6: 0.2726  loss_ce_7: 1.005  loss_mask_7: 0.04062  loss_dice_7: 0.537  loss_bbox_7: 0.07331  loss_giou_7: 0.3226  loss_ce_dn_7: 0.1372  loss_mask_dn_7: 0.05158  loss_dice_dn_7: 0.5909  loss_bbox_dn_7: 0.04643  loss_giou_dn_7: 0.2792  loss_ce_8: 1.005  loss_mask_8: 0.04385  loss_dice_8: 0.6288  loss_bbox_8: 0.07301  loss_giou_8: 0.3182  loss_ce_dn_8: 0.1405  loss_mask_dn_8: 0.04987  loss_dice_dn_8: 0.5699  loss_bbox_dn_8: 0.04637  loss_giou_dn_8: 0.2781  loss_ce_interm: 1.234  loss_mask_interm: 0.0505  loss_dice_interm: 0.6422  loss_bbox_interm: 0.1034  loss_giou_interm: 0.5039  time: 1.8836  data_time: 0.0539  lr: 1e-06  max_mem: 6663M\n",
            "[05/20 18:23:06 d2.utils.events]:  eta: 0:52:37  iter: 3759  total_loss: 46.67  loss_ce: 1.028  loss_mask: 0.03525  loss_dice: 0.6936  loss_bbox: 0.08871  loss_giou: 0.3737  loss_ce_dn: 0.2176  loss_mask_dn: 0.02994  loss_dice_dn: 0.7362  loss_bbox_dn: 0.04025  loss_giou_dn: 0.3531  loss_ce_0: 1.421  loss_mask_0: 0.03179  loss_dice_0: 0.6832  loss_bbox_0: 0.09244  loss_giou_0: 0.4647  loss_ce_dn_0: 0.7364  loss_mask_dn_0: 0.1334  loss_dice_dn_0: 2.582  loss_bbox_dn_0: 0.198  loss_giou_dn_0: 0.8485  loss_ce_1: 1.251  loss_mask_1: 0.03282  loss_dice_1: 0.7734  loss_bbox_1: 0.09664  loss_giou_1: 0.435  loss_ce_dn_1: 0.2804  loss_mask_dn_1: 0.02973  loss_dice_dn_1: 0.7127  loss_bbox_dn_1: 0.07444  loss_giou_dn_1: 0.4693  loss_ce_2: 1.214  loss_mask_2: 0.03041  loss_dice_2: 0.7508  loss_bbox_2: 0.08793  loss_giou_2: 0.4443  loss_ce_dn_2: 0.2505  loss_mask_dn_2: 0.02883  loss_dice_dn_2: 0.6977  loss_bbox_dn_2: 0.05183  loss_giou_dn_2: 0.3913  loss_ce_3: 1.123  loss_mask_3: 0.03407  loss_dice_3: 0.7655  loss_bbox_3: 0.07559  loss_giou_3: 0.4111  loss_ce_dn_3: 0.238  loss_mask_dn_3: 0.03146  loss_dice_dn_3: 0.7257  loss_bbox_dn_3: 0.04411  loss_giou_dn_3: 0.3597  loss_ce_4: 1.027  loss_mask_4: 0.03338  loss_dice_4: 0.757  loss_bbox_4: 0.0875  loss_giou_4: 0.441  loss_ce_dn_4: 0.2374  loss_mask_dn_4: 0.03081  loss_dice_dn_4: 0.702  loss_bbox_dn_4: 0.04138  loss_giou_dn_4: 0.3669  loss_ce_5: 1.065  loss_mask_5: 0.03478  loss_dice_5: 0.744  loss_bbox_5: 0.08716  loss_giou_5: 0.4321  loss_ce_dn_5: 0.2298  loss_mask_dn_5: 0.02989  loss_dice_dn_5: 0.7278  loss_bbox_dn_5: 0.04086  loss_giou_dn_5: 0.3598  loss_ce_6: 1.058  loss_mask_6: 0.0296  loss_dice_6: 0.7491  loss_bbox_6: 0.08737  loss_giou_6: 0.432  loss_ce_dn_6: 0.2318  loss_mask_dn_6: 0.03041  loss_dice_dn_6: 0.7439  loss_bbox_dn_6: 0.04044  loss_giou_dn_6: 0.3578  loss_ce_7: 1.033  loss_mask_7: 0.03514  loss_dice_7: 0.7232  loss_bbox_7: 0.07387  loss_giou_7: 0.3739  loss_ce_dn_7: 0.2124  loss_mask_dn_7: 0.03149  loss_dice_dn_7: 0.7234  loss_bbox_dn_7: 0.04035  loss_giou_dn_7: 0.3588  loss_ce_8: 1.049  loss_mask_8: 0.03247  loss_dice_8: 0.5791  loss_bbox_8: 0.07432  loss_giou_8: 0.377  loss_ce_dn_8: 0.2163  loss_mask_dn_8: 0.03168  loss_dice_dn_8: 0.7318  loss_bbox_dn_8: 0.04066  loss_giou_dn_8: 0.3551  loss_ce_interm: 1.333  loss_mask_interm: 0.02964  loss_dice_interm: 0.6981  loss_bbox_interm: 0.0985  loss_giou_interm: 0.5945  time: 1.8825  data_time: 0.0798  lr: 1e-06  max_mem: 6663M\n",
            "[05/20 18:23:40 d2.utils.events]:  eta: 0:52:05  iter: 3779  total_loss: 49.42  loss_ce: 1.116  loss_mask: 0.02987  loss_dice: 0.7953  loss_bbox: 0.04538  loss_giou: 0.4524  loss_ce_dn: 0.2175  loss_mask_dn: 0.02767  loss_dice_dn: 0.731  loss_bbox_dn: 0.02944  loss_giou_dn: 0.2971  loss_ce_0: 1.312  loss_mask_0: 0.02712  loss_dice_0: 0.8032  loss_bbox_0: 0.05249  loss_giou_0: 0.5682  loss_ce_dn_0: 0.6847  loss_mask_dn_0: 0.06348  loss_dice_dn_0: 2.08  loss_bbox_dn_0: 0.1387  loss_giou_dn_0: 0.8516  loss_ce_1: 1.382  loss_mask_1: 0.03244  loss_dice_1: 0.7678  loss_bbox_1: 0.04635  loss_giou_1: 0.4975  loss_ce_dn_1: 0.2865  loss_mask_dn_1: 0.0276  loss_dice_dn_1: 0.7658  loss_bbox_dn_1: 0.04786  loss_giou_dn_1: 0.3899  loss_ce_2: 1.303  loss_mask_2: 0.02647  loss_dice_2: 0.7445  loss_bbox_2: 0.05229  loss_giou_2: 0.4335  loss_ce_dn_2: 0.2716  loss_mask_dn_2: 0.02588  loss_dice_dn_2: 0.7555  loss_bbox_dn_2: 0.03392  loss_giou_dn_2: 0.3258  loss_ce_3: 1.311  loss_mask_3: 0.03221  loss_dice_3: 0.919  loss_bbox_3: 0.04944  loss_giou_3: 0.4574  loss_ce_dn_3: 0.2753  loss_mask_dn_3: 0.02618  loss_dice_dn_3: 0.7195  loss_bbox_dn_3: 0.03056  loss_giou_dn_3: 0.3047  loss_ce_4: 1.077  loss_mask_4: 0.02667  loss_dice_4: 0.827  loss_bbox_4: 0.05111  loss_giou_4: 0.4707  loss_ce_dn_4: 0.251  loss_mask_dn_4: 0.02497  loss_dice_dn_4: 0.7184  loss_bbox_dn_4: 0.0303  loss_giou_dn_4: 0.3076  loss_ce_5: 1.182  loss_mask_5: 0.03133  loss_dice_5: 0.898  loss_bbox_5: 0.04338  loss_giou_5: 0.4629  loss_ce_dn_5: 0.2284  loss_mask_dn_5: 0.02639  loss_dice_dn_5: 0.6839  loss_bbox_dn_5: 0.02994  loss_giou_dn_5: 0.295  loss_ce_6: 1.173  loss_mask_6: 0.03097  loss_dice_6: 0.8545  loss_bbox_6: 0.04882  loss_giou_6: 0.4617  loss_ce_dn_6: 0.2184  loss_mask_dn_6: 0.02626  loss_dice_dn_6: 0.7309  loss_bbox_dn_6: 0.03036  loss_giou_dn_6: 0.2928  loss_ce_7: 1.118  loss_mask_7: 0.03499  loss_dice_7: 0.8211  loss_bbox_7: 0.04477  loss_giou_7: 0.4465  loss_ce_dn_7: 0.2136  loss_mask_dn_7: 0.0273  loss_dice_dn_7: 0.7472  loss_bbox_dn_7: 0.02965  loss_giou_dn_7: 0.2998  loss_ce_8: 1.106  loss_mask_8: 0.02828  loss_dice_8: 0.8997  loss_bbox_8: 0.04505  loss_giou_8: 0.4534  loss_ce_dn_8: 0.2182  loss_mask_dn_8: 0.02731  loss_dice_dn_8: 0.7156  loss_bbox_dn_8: 0.02943  loss_giou_dn_8: 0.3014  loss_ce_interm: 1.438  loss_mask_interm: 0.02775  loss_dice_interm: 0.5987  loss_bbox_interm: 0.07378  loss_giou_interm: 0.5464  time: 1.8816  data_time: 0.0815  lr: 1e-06  max_mem: 6663M\n",
            "[05/20 18:24:13 d2.utils.events]:  eta: 0:51:40  iter: 3799  total_loss: 51.87  loss_ce: 1.148  loss_mask: 0.03051  loss_dice: 0.7543  loss_bbox: 0.06595  loss_giou: 0.544  loss_ce_dn: 0.2499  loss_mask_dn: 0.03262  loss_dice_dn: 0.6929  loss_bbox_dn: 0.03364  loss_giou_dn: 0.3753  loss_ce_0: 1.393  loss_mask_0: 0.03598  loss_dice_0: 0.784  loss_bbox_0: 0.07149  loss_giou_0: 0.5711  loss_ce_dn_0: 0.691  loss_mask_dn_0: 0.08265  loss_dice_dn_0: 2.916  loss_bbox_dn_0: 0.1962  loss_giou_dn_0: 0.8521  loss_ce_1: 1.309  loss_mask_1: 0.03297  loss_dice_1: 1.015  loss_bbox_1: 0.07194  loss_giou_1: 0.5716  loss_ce_dn_1: 0.3206  loss_mask_dn_1: 0.03096  loss_dice_dn_1: 0.7102  loss_bbox_dn_1: 0.05502  loss_giou_dn_1: 0.4624  loss_ce_2: 1.301  loss_mask_2: 0.03522  loss_dice_2: 0.6319  loss_bbox_2: 0.07193  loss_giou_2: 0.5241  loss_ce_dn_2: 0.2996  loss_mask_dn_2: 0.03124  loss_dice_dn_2: 0.7482  loss_bbox_dn_2: 0.03959  loss_giou_dn_2: 0.4096  loss_ce_3: 1.129  loss_mask_3: 0.03154  loss_dice_3: 0.6449  loss_bbox_3: 0.06777  loss_giou_3: 0.5722  loss_ce_dn_3: 0.2699  loss_mask_dn_3: 0.03151  loss_dice_dn_3: 0.7023  loss_bbox_dn_3: 0.0378  loss_giou_dn_3: 0.4066  loss_ce_4: 1.113  loss_mask_4: 0.03732  loss_dice_4: 0.9328  loss_bbox_4: 0.0583  loss_giou_4: 0.5567  loss_ce_dn_4: 0.2479  loss_mask_dn_4: 0.03338  loss_dice_dn_4: 0.6902  loss_bbox_dn_4: 0.03368  loss_giou_dn_4: 0.3881  loss_ce_5: 1.092  loss_mask_5: 0.03385  loss_dice_5: 0.7065  loss_bbox_5: 0.06449  loss_giou_5: 0.5242  loss_ce_dn_5: 0.2503  loss_mask_dn_5: 0.03195  loss_dice_dn_5: 0.7146  loss_bbox_dn_5: 0.03441  loss_giou_dn_5: 0.3919  loss_ce_6: 1.095  loss_mask_6: 0.03528  loss_dice_6: 0.724  loss_bbox_6: 0.06106  loss_giou_6: 0.5311  loss_ce_dn_6: 0.2348  loss_mask_dn_6: 0.03265  loss_dice_dn_6: 0.7027  loss_bbox_dn_6: 0.03509  loss_giou_dn_6: 0.384  loss_ce_7: 1.153  loss_mask_7: 0.03479  loss_dice_7: 0.9195  loss_bbox_7: 0.05543  loss_giou_7: 0.552  loss_ce_dn_7: 0.2517  loss_mask_dn_7: 0.03355  loss_dice_dn_7: 0.7405  loss_bbox_dn_7: 0.03499  loss_giou_dn_7: 0.3787  loss_ce_8: 1.15  loss_mask_8: 0.03695  loss_dice_8: 0.881  loss_bbox_8: 0.06486  loss_giou_8: 0.5368  loss_ce_dn_8: 0.248  loss_mask_dn_8: 0.03314  loss_dice_dn_8: 0.7526  loss_bbox_dn_8: 0.03436  loss_giou_dn_8: 0.3764  loss_ce_interm: 1.432  loss_mask_interm: 0.03928  loss_dice_interm: 0.7995  loss_bbox_interm: 0.07313  loss_giou_interm: 0.6436  time: 1.8805  data_time: 0.0937  lr: 1e-06  max_mem: 6663M\n",
            "[05/20 18:24:48 d2.utils.events]:  eta: 0:51:07  iter: 3819  total_loss: 49.49  loss_ce: 1.206  loss_mask: 0.02922  loss_dice: 0.599  loss_bbox: 0.06464  loss_giou: 0.3631  loss_ce_dn: 0.1918  loss_mask_dn: 0.03036  loss_dice_dn: 0.6954  loss_bbox_dn: 0.04455  loss_giou_dn: 0.2945  loss_ce_0: 1.459  loss_mask_0: 0.02972  loss_dice_0: 0.775  loss_bbox_0: 0.07738  loss_giou_0: 0.4371  loss_ce_dn_0: 0.8154  loss_mask_dn_0: 0.1886  loss_dice_dn_0: 3.008  loss_bbox_dn_0: 0.215  loss_giou_dn_0: 0.8556  loss_ce_1: 1.505  loss_mask_1: 0.02673  loss_dice_1: 0.6774  loss_bbox_1: 0.06797  loss_giou_1: 0.3911  loss_ce_dn_1: 0.2847  loss_mask_dn_1: 0.02978  loss_dice_dn_1: 0.7844  loss_bbox_dn_1: 0.06224  loss_giou_dn_1: 0.3993  loss_ce_2: 1.384  loss_mask_2: 0.0301  loss_dice_2: 0.7272  loss_bbox_2: 0.06399  loss_giou_2: 0.3819  loss_ce_dn_2: 0.2413  loss_mask_dn_2: 0.02987  loss_dice_dn_2: 0.7461  loss_bbox_dn_2: 0.04823  loss_giou_dn_2: 0.3641  loss_ce_3: 1.247  loss_mask_3: 0.03242  loss_dice_3: 0.7828  loss_bbox_3: 0.06113  loss_giou_3: 0.3733  loss_ce_dn_3: 0.2116  loss_mask_dn_3: 0.03174  loss_dice_dn_3: 0.6961  loss_bbox_dn_3: 0.04274  loss_giou_dn_3: 0.323  loss_ce_4: 1.126  loss_mask_4: 0.03176  loss_dice_4: 0.7293  loss_bbox_4: 0.06979  loss_giou_4: 0.3667  loss_ce_dn_4: 0.1993  loss_mask_dn_4: 0.03189  loss_dice_dn_4: 0.7382  loss_bbox_dn_4: 0.04442  loss_giou_dn_4: 0.3086  loss_ce_5: 1.189  loss_mask_5: 0.03182  loss_dice_5: 0.7204  loss_bbox_5: 0.06889  loss_giou_5: 0.3634  loss_ce_dn_5: 0.2007  loss_mask_dn_5: 0.03025  loss_dice_dn_5: 0.6839  loss_bbox_dn_5: 0.04409  loss_giou_dn_5: 0.2949  loss_ce_6: 1.171  loss_mask_6: 0.03006  loss_dice_6: 0.6677  loss_bbox_6: 0.06631  loss_giou_6: 0.3657  loss_ce_dn_6: 0.205  loss_mask_dn_6: 0.03207  loss_dice_dn_6: 0.6957  loss_bbox_dn_6: 0.04369  loss_giou_dn_6: 0.3018  loss_ce_7: 1.192  loss_mask_7: 0.03039  loss_dice_7: 0.6725  loss_bbox_7: 0.06587  loss_giou_7: 0.358  loss_ce_dn_7: 0.191  loss_mask_dn_7: 0.0307  loss_dice_dn_7: 0.7219  loss_bbox_dn_7: 0.04413  loss_giou_dn_7: 0.2967  loss_ce_8: 1.218  loss_mask_8: 0.02799  loss_dice_8: 0.6976  loss_bbox_8: 0.06523  loss_giou_8: 0.3555  loss_ce_dn_8: 0.1903  loss_mask_dn_8: 0.0304  loss_dice_dn_8: 0.698  loss_bbox_dn_8: 0.04423  loss_giou_dn_8: 0.2912  loss_ce_interm: 1.431  loss_mask_interm: 0.02779  loss_dice_interm: 0.7304  loss_bbox_interm: 0.08364  loss_giou_interm: 0.483  time: 1.8798  data_time: 0.0651  lr: 1e-06  max_mem: 6663M\n",
            "[05/20 18:25:25 d2.utils.events]:  eta: 0:50:34  iter: 3839  total_loss: 39.6  loss_ce: 0.7639  loss_mask: 0.03669  loss_dice: 0.4944  loss_bbox: 0.089  loss_giou: 0.4049  loss_ce_dn: 0.2253  loss_mask_dn: 0.0362  loss_dice_dn: 0.4829  loss_bbox_dn: 0.04459  loss_giou_dn: 0.3004  loss_ce_0: 1.136  loss_mask_0: 0.0447  loss_dice_0: 0.5808  loss_bbox_0: 0.1242  loss_giou_0: 0.4694  loss_ce_dn_0: 0.7371  loss_mask_dn_0: 0.2844  loss_dice_dn_0: 2.74  loss_bbox_dn_0: 0.3152  loss_giou_dn_0: 0.8578  loss_ce_1: 1.13  loss_mask_1: 0.0462  loss_dice_1: 0.5827  loss_bbox_1: 0.08613  loss_giou_1: 0.4609  loss_ce_dn_1: 0.2802  loss_mask_dn_1: 0.03719  loss_dice_dn_1: 0.5604  loss_bbox_dn_1: 0.07793  loss_giou_dn_1: 0.4015  loss_ce_2: 0.9453  loss_mask_2: 0.04456  loss_dice_2: 0.4197  loss_bbox_2: 0.1101  loss_giou_2: 0.4541  loss_ce_dn_2: 0.2568  loss_mask_dn_2: 0.03727  loss_dice_dn_2: 0.5509  loss_bbox_dn_2: 0.0538  loss_giou_dn_2: 0.3464  loss_ce_3: 0.8952  loss_mask_3: 0.04195  loss_dice_3: 0.6191  loss_bbox_3: 0.08875  loss_giou_3: 0.4099  loss_ce_dn_3: 0.2326  loss_mask_dn_3: 0.03611  loss_dice_dn_3: 0.5527  loss_bbox_dn_3: 0.05098  loss_giou_dn_3: 0.3151  loss_ce_4: 0.8353  loss_mask_4: 0.03314  loss_dice_4: 0.5361  loss_bbox_4: 0.0882  loss_giou_4: 0.4119  loss_ce_dn_4: 0.2291  loss_mask_dn_4: 0.03586  loss_dice_dn_4: 0.5283  loss_bbox_dn_4: 0.04891  loss_giou_dn_4: 0.3083  loss_ce_5: 0.8481  loss_mask_5: 0.04044  loss_dice_5: 0.5854  loss_bbox_5: 0.05651  loss_giou_5: 0.3961  loss_ce_dn_5: 0.2208  loss_mask_dn_5: 0.03625  loss_dice_dn_5: 0.5318  loss_bbox_dn_5: 0.04719  loss_giou_dn_5: 0.3044  loss_ce_6: 0.8145  loss_mask_6: 0.04033  loss_dice_6: 0.5455  loss_bbox_6: 0.0714  loss_giou_6: 0.3964  loss_ce_dn_6: 0.2165  loss_mask_dn_6: 0.03494  loss_dice_dn_6: 0.4969  loss_bbox_dn_6: 0.04757  loss_giou_dn_6: 0.3094  loss_ce_7: 0.8094  loss_mask_7: 0.04179  loss_dice_7: 0.4742  loss_bbox_7: 0.06906  loss_giou_7: 0.4092  loss_ce_dn_7: 0.221  loss_mask_dn_7: 0.0353  loss_dice_dn_7: 0.5006  loss_bbox_dn_7: 0.04429  loss_giou_dn_7: 0.3007  loss_ce_8: 0.7931  loss_mask_8: 0.03768  loss_dice_8: 0.6138  loss_bbox_8: 0.08923  loss_giou_8: 0.4088  loss_ce_dn_8: 0.2258  loss_mask_dn_8: 0.03635  loss_dice_dn_8: 0.51  loss_bbox_dn_8: 0.04439  loss_giou_dn_8: 0.3018  loss_ce_interm: 1.18  loss_mask_interm: 0.0466  loss_dice_interm: 0.6204  loss_bbox_interm: 0.1446  loss_giou_interm: 0.5589  time: 1.8791  data_time: 0.0782  lr: 1e-06  max_mem: 6663M\n",
            "[05/20 18:25:59 d2.utils.events]:  eta: 0:49:55  iter: 3859  total_loss: 42.85  loss_ce: 1.065  loss_mask: 0.03534  loss_dice: 0.6943  loss_bbox: 0.07405  loss_giou: 0.4186  loss_ce_dn: 0.2068  loss_mask_dn: 0.03428  loss_dice_dn: 0.6161  loss_bbox_dn: 0.0338  loss_giou_dn: 0.3341  loss_ce_0: 1.417  loss_mask_0: 0.03172  loss_dice_0: 0.7408  loss_bbox_0: 0.07871  loss_giou_0: 0.5158  loss_ce_dn_0: 0.7394  loss_mask_dn_0: 0.1582  loss_dice_dn_0: 2.442  loss_bbox_dn_0: 0.2639  loss_giou_dn_0: 0.8532  loss_ce_1: 1.235  loss_mask_1: 0.02796  loss_dice_1: 0.6296  loss_bbox_1: 0.06386  loss_giou_1: 0.4058  loss_ce_dn_1: 0.2659  loss_mask_dn_1: 0.03526  loss_dice_dn_1: 0.7311  loss_bbox_dn_1: 0.07276  loss_giou_dn_1: 0.4256  loss_ce_2: 1.114  loss_mask_2: 0.03627  loss_dice_2: 0.6574  loss_bbox_2: 0.06876  loss_giou_2: 0.3962  loss_ce_dn_2: 0.2304  loss_mask_dn_2: 0.03335  loss_dice_dn_2: 0.6649  loss_bbox_dn_2: 0.05504  loss_giou_dn_2: 0.3571  loss_ce_3: 1.081  loss_mask_3: 0.03413  loss_dice_3: 0.7625  loss_bbox_3: 0.06203  loss_giou_3: 0.4091  loss_ce_dn_3: 0.2137  loss_mask_dn_3: 0.03297  loss_dice_dn_3: 0.6568  loss_bbox_dn_3: 0.04342  loss_giou_dn_3: 0.3429  loss_ce_4: 1.103  loss_mask_4: 0.03286  loss_dice_4: 0.7816  loss_bbox_4: 0.05915  loss_giou_4: 0.4622  loss_ce_dn_4: 0.2098  loss_mask_dn_4: 0.03531  loss_dice_dn_4: 0.6743  loss_bbox_dn_4: 0.03767  loss_giou_dn_4: 0.3386  loss_ce_5: 1.034  loss_mask_5: 0.03601  loss_dice_5: 0.6856  loss_bbox_5: 0.05957  loss_giou_5: 0.4643  loss_ce_dn_5: 0.206  loss_mask_dn_5: 0.03591  loss_dice_dn_5: 0.6252  loss_bbox_dn_5: 0.03567  loss_giou_dn_5: 0.3407  loss_ce_6: 1.089  loss_mask_6: 0.03126  loss_dice_6: 0.6916  loss_bbox_6: 0.05985  loss_giou_6: 0.4585  loss_ce_dn_6: 0.2027  loss_mask_dn_6: 0.03428  loss_dice_dn_6: 0.6591  loss_bbox_dn_6: 0.03691  loss_giou_dn_6: 0.344  loss_ce_7: 1.119  loss_mask_7: 0.02987  loss_dice_7: 0.5996  loss_bbox_7: 0.05993  loss_giou_7: 0.4447  loss_ce_dn_7: 0.2031  loss_mask_dn_7: 0.03448  loss_dice_dn_7: 0.6608  loss_bbox_dn_7: 0.0346  loss_giou_dn_7: 0.3397  loss_ce_8: 1.08  loss_mask_8: 0.03477  loss_dice_8: 0.6998  loss_bbox_8: 0.05909  loss_giou_8: 0.4247  loss_ce_dn_8: 0.2039  loss_mask_dn_8: 0.03453  loss_dice_dn_8: 0.6316  loss_bbox_dn_8: 0.03485  loss_giou_dn_8: 0.3385  loss_ce_interm: 1.33  loss_mask_interm: 0.03616  loss_dice_interm: 0.7382  loss_bbox_interm: 0.08353  loss_giou_interm: 0.5416  time: 1.8782  data_time: 0.0682  lr: 1e-06  max_mem: 6663M\n",
            "[05/20 18:26:34 d2.utils.events]:  eta: 0:49:31  iter: 3879  total_loss: 32.64  loss_ce: 0.7477  loss_mask: 0.03097  loss_dice: 0.4161  loss_bbox: 0.04614  loss_giou: 0.2148  loss_ce_dn: 0.1617  loss_mask_dn: 0.0251  loss_dice_dn: 0.3965  loss_bbox_dn: 0.02889  loss_giou_dn: 0.2125  loss_ce_0: 1.088  loss_mask_0: 0.02635  loss_dice_0: 0.3492  loss_bbox_0: 0.0492  loss_giou_0: 0.3051  loss_ce_dn_0: 0.6474  loss_mask_dn_0: 0.1789  loss_dice_dn_0: 2.436  loss_bbox_dn_0: 0.2896  loss_giou_dn_0: 0.8648  loss_ce_1: 0.9935  loss_mask_1: 0.03367  loss_dice_1: 0.4233  loss_bbox_1: 0.04285  loss_giou_1: 0.2574  loss_ce_dn_1: 0.2654  loss_mask_dn_1: 0.02521  loss_dice_dn_1: 0.455  loss_bbox_dn_1: 0.05761  loss_giou_dn_1: 0.3037  loss_ce_2: 0.9419  loss_mask_2: 0.03164  loss_dice_2: 0.3976  loss_bbox_2: 0.03494  loss_giou_2: 0.2348  loss_ce_dn_2: 0.2251  loss_mask_dn_2: 0.02355  loss_dice_dn_2: 0.4102  loss_bbox_dn_2: 0.04339  loss_giou_dn_2: 0.2617  loss_ce_3: 0.9315  loss_mask_3: 0.03443  loss_dice_3: 0.3541  loss_bbox_3: 0.03814  loss_giou_3: 0.2361  loss_ce_dn_3: 0.2056  loss_mask_dn_3: 0.02538  loss_dice_dn_3: 0.4146  loss_bbox_dn_3: 0.03292  loss_giou_dn_3: 0.2347  loss_ce_4: 0.7969  loss_mask_4: 0.03064  loss_dice_4: 0.447  loss_bbox_4: 0.04854  loss_giou_4: 0.2252  loss_ce_dn_4: 0.1846  loss_mask_dn_4: 0.02616  loss_dice_dn_4: 0.4086  loss_bbox_dn_4: 0.03005  loss_giou_dn_4: 0.2228  loss_ce_5: 0.7924  loss_mask_5: 0.02549  loss_dice_5: 0.4297  loss_bbox_5: 0.04619  loss_giou_5: 0.2342  loss_ce_dn_5: 0.1725  loss_mask_dn_5: 0.02506  loss_dice_dn_5: 0.3934  loss_bbox_dn_5: 0.02873  loss_giou_dn_5: 0.2178  loss_ce_6: 0.7372  loss_mask_6: 0.03026  loss_dice_6: 0.348  loss_bbox_6: 0.04444  loss_giou_6: 0.2342  loss_ce_dn_6: 0.1726  loss_mask_dn_6: 0.02502  loss_dice_dn_6: 0.4071  loss_bbox_dn_6: 0.02877  loss_giou_dn_6: 0.2178  loss_ce_7: 0.7344  loss_mask_7: 0.03111  loss_dice_7: 0.4474  loss_bbox_7: 0.0459  loss_giou_7: 0.2228  loss_ce_dn_7: 0.1667  loss_mask_dn_7: 0.02386  loss_dice_dn_7: 0.3993  loss_bbox_dn_7: 0.02915  loss_giou_dn_7: 0.2064  loss_ce_8: 0.7549  loss_mask_8: 0.02909  loss_dice_8: 0.4278  loss_bbox_8: 0.04621  loss_giou_8: 0.2169  loss_ce_dn_8: 0.164  loss_mask_dn_8: 0.02478  loss_dice_dn_8: 0.4015  loss_bbox_dn_8: 0.0295  loss_giou_dn_8: 0.2102  loss_ce_interm: 1.101  loss_mask_interm: 0.02725  loss_dice_interm: 0.3846  loss_bbox_interm: 0.06743  loss_giou_interm: 0.3968  time: 1.8775  data_time: 0.1162  lr: 1e-06  max_mem: 6663M\n",
            "[05/20 18:27:10 d2.utils.events]:  eta: 0:49:02  iter: 3899  total_loss: 45.04  loss_ce: 1.01  loss_mask: 0.04864  loss_dice: 0.7598  loss_bbox: 0.07137  loss_giou: 0.3626  loss_ce_dn: 0.2211  loss_mask_dn: 0.04798  loss_dice_dn: 0.6025  loss_bbox_dn: 0.05602  loss_giou_dn: 0.3128  loss_ce_0: 1.333  loss_mask_0: 0.0694  loss_dice_0: 0.6708  loss_bbox_0: 0.118  loss_giou_0: 0.3899  loss_ce_dn_0: 0.7234  loss_mask_dn_0: 0.3202  loss_dice_dn_0: 2.901  loss_bbox_dn_0: 0.2879  loss_giou_dn_0: 0.8476  loss_ce_1: 1.194  loss_mask_1: 0.06395  loss_dice_1: 0.5744  loss_bbox_1: 0.09246  loss_giou_1: 0.3753  loss_ce_dn_1: 0.3349  loss_mask_dn_1: 0.05706  loss_dice_dn_1: 0.7731  loss_bbox_dn_1: 0.07725  loss_giou_dn_1: 0.3892  loss_ce_2: 1.259  loss_mask_2: 0.06942  loss_dice_2: 0.5032  loss_bbox_2: 0.07504  loss_giou_2: 0.3349  loss_ce_dn_2: 0.2913  loss_mask_dn_2: 0.05097  loss_dice_dn_2: 0.6766  loss_bbox_dn_2: 0.0713  loss_giou_dn_2: 0.3281  loss_ce_3: 1.109  loss_mask_3: 0.06134  loss_dice_3: 0.7556  loss_bbox_3: 0.08624  loss_giou_3: 0.3536  loss_ce_dn_3: 0.2407  loss_mask_dn_3: 0.04925  loss_dice_dn_3: 0.667  loss_bbox_dn_3: 0.06932  loss_giou_dn_3: 0.3143  loss_ce_4: 1.067  loss_mask_4: 0.05998  loss_dice_4: 0.6008  loss_bbox_4: 0.08506  loss_giou_4: 0.3412  loss_ce_dn_4: 0.2521  loss_mask_dn_4: 0.04521  loss_dice_dn_4: 0.6372  loss_bbox_dn_4: 0.0673  loss_giou_dn_4: 0.3122  loss_ce_5: 1.034  loss_mask_5: 0.05712  loss_dice_5: 0.6959  loss_bbox_5: 0.07561  loss_giou_5: 0.349  loss_ce_dn_5: 0.2365  loss_mask_dn_5: 0.04805  loss_dice_dn_5: 0.6414  loss_bbox_dn_5: 0.06056  loss_giou_dn_5: 0.3108  loss_ce_6: 1.065  loss_mask_6: 0.05342  loss_dice_6: 0.5407  loss_bbox_6: 0.07228  loss_giou_6: 0.3614  loss_ce_dn_6: 0.2165  loss_mask_dn_6: 0.04413  loss_dice_dn_6: 0.6318  loss_bbox_dn_6: 0.05801  loss_giou_dn_6: 0.3246  loss_ce_7: 1.058  loss_mask_7: 0.05667  loss_dice_7: 0.6418  loss_bbox_7: 0.07284  loss_giou_7: 0.349  loss_ce_dn_7: 0.2236  loss_mask_dn_7: 0.04621  loss_dice_dn_7: 0.6253  loss_bbox_dn_7: 0.05532  loss_giou_dn_7: 0.3132  loss_ce_8: 1.04  loss_mask_8: 0.06204  loss_dice_8: 0.6619  loss_bbox_8: 0.07278  loss_giou_8: 0.3576  loss_ce_dn_8: 0.2227  loss_mask_dn_8: 0.04833  loss_dice_dn_8: 0.6064  loss_bbox_dn_8: 0.05575  loss_giou_dn_8: 0.3156  loss_ce_interm: 1.38  loss_mask_interm: 0.05611  loss_dice_interm: 0.8222  loss_bbox_interm: 0.1421  loss_giou_interm: 0.3834  time: 1.8770  data_time: 0.1153  lr: 1e-06  max_mem: 6663M\n",
            "[05/20 18:27:45 d2.utils.events]:  eta: 0:48:32  iter: 3919  total_loss: 40.12  loss_ce: 0.9758  loss_mask: 0.04503  loss_dice: 0.5529  loss_bbox: 0.09314  loss_giou: 0.3371  loss_ce_dn: 0.1932  loss_mask_dn: 0.04073  loss_dice_dn: 0.5191  loss_bbox_dn: 0.04643  loss_giou_dn: 0.2586  loss_ce_0: 1.239  loss_mask_0: 0.04524  loss_dice_0: 0.5313  loss_bbox_0: 0.106  loss_giou_0: 0.328  loss_ce_dn_0: 0.6893  loss_mask_dn_0: 0.4201  loss_dice_dn_0: 2.744  loss_bbox_dn_0: 0.2873  loss_giou_dn_0: 0.8614  loss_ce_1: 1.344  loss_mask_1: 0.04417  loss_dice_1: 0.4619  loss_bbox_1: 0.08249  loss_giou_1: 0.3023  loss_ce_dn_1: 0.2559  loss_mask_dn_1: 0.05108  loss_dice_dn_1: 0.5846  loss_bbox_dn_1: 0.09647  loss_giou_dn_1: 0.3665  loss_ce_2: 1.052  loss_mask_2: 0.04437  loss_dice_2: 0.4285  loss_bbox_2: 0.09924  loss_giou_2: 0.3207  loss_ce_dn_2: 0.2116  loss_mask_dn_2: 0.04236  loss_dice_dn_2: 0.5387  loss_bbox_dn_2: 0.07167  loss_giou_dn_2: 0.3116  loss_ce_3: 0.9959  loss_mask_3: 0.04192  loss_dice_3: 0.5208  loss_bbox_3: 0.09024  loss_giou_3: 0.3065  loss_ce_dn_3: 0.1982  loss_mask_dn_3: 0.0449  loss_dice_dn_3: 0.5409  loss_bbox_dn_3: 0.05902  loss_giou_dn_3: 0.2763  loss_ce_4: 0.9215  loss_mask_4: 0.04583  loss_dice_4: 0.4756  loss_bbox_4: 0.08273  loss_giou_4: 0.3159  loss_ce_dn_4: 0.1915  loss_mask_dn_4: 0.0439  loss_dice_dn_4: 0.5365  loss_bbox_dn_4: 0.05148  loss_giou_dn_4: 0.258  loss_ce_5: 1.029  loss_mask_5: 0.043  loss_dice_5: 0.5425  loss_bbox_5: 0.08951  loss_giou_5: 0.3075  loss_ce_dn_5: 0.1986  loss_mask_dn_5: 0.04322  loss_dice_dn_5: 0.5347  loss_bbox_dn_5: 0.04661  loss_giou_dn_5: 0.2566  loss_ce_6: 0.9443  loss_mask_6: 0.04591  loss_dice_6: 0.5356  loss_bbox_6: 0.09634  loss_giou_6: 0.3123  loss_ce_dn_6: 0.1946  loss_mask_dn_6: 0.04197  loss_dice_dn_6: 0.5354  loss_bbox_dn_6: 0.04588  loss_giou_dn_6: 0.2569  loss_ce_7: 0.9666  loss_mask_7: 0.04561  loss_dice_7: 0.5242  loss_bbox_7: 0.08671  loss_giou_7: 0.3362  loss_ce_dn_7: 0.193  loss_mask_dn_7: 0.04154  loss_dice_dn_7: 0.5265  loss_bbox_dn_7: 0.04672  loss_giou_dn_7: 0.2569  loss_ce_8: 0.9774  loss_mask_8: 0.04553  loss_dice_8: 0.5165  loss_bbox_8: 0.08022  loss_giou_8: 0.3344  loss_ce_dn_8: 0.1921  loss_mask_dn_8: 0.04239  loss_dice_dn_8: 0.53  loss_bbox_dn_8: 0.04567  loss_giou_dn_8: 0.2554  loss_ce_interm: 1.136  loss_mask_interm: 0.04497  loss_dice_interm: 0.5587  loss_bbox_interm: 0.1137  loss_giou_interm: 0.4475  time: 1.8765  data_time: 0.0980  lr: 1e-06  max_mem: 6663M\n",
            "[05/20 18:28:20 d2.utils.events]:  eta: 0:47:59  iter: 3939  total_loss: 37.11  loss_ce: 0.7901  loss_mask: 0.03032  loss_dice: 0.6082  loss_bbox: 0.04621  loss_giou: 0.3512  loss_ce_dn: 0.1059  loss_mask_dn: 0.02981  loss_dice_dn: 0.4553  loss_bbox_dn: 0.03337  loss_giou_dn: 0.2851  loss_ce_0: 1.13  loss_mask_0: 0.03101  loss_dice_0: 0.5597  loss_bbox_0: 0.05266  loss_giou_0: 0.4741  loss_ce_dn_0: 0.8415  loss_mask_dn_0: 0.104  loss_dice_dn_0: 2.288  loss_bbox_dn_0: 0.2321  loss_giou_dn_0: 0.8488  loss_ce_1: 1.123  loss_mask_1: 0.0311  loss_dice_1: 0.5115  loss_bbox_1: 0.04748  loss_giou_1: 0.4027  loss_ce_dn_1: 0.2603  loss_mask_dn_1: 0.03222  loss_dice_dn_1: 0.6226  loss_bbox_dn_1: 0.06085  loss_giou_dn_1: 0.3671  loss_ce_2: 0.9889  loss_mask_2: 0.03365  loss_dice_2: 0.7154  loss_bbox_2: 0.0501  loss_giou_2: 0.3801  loss_ce_dn_2: 0.2208  loss_mask_dn_2: 0.02916  loss_dice_dn_2: 0.5366  loss_bbox_dn_2: 0.04611  loss_giou_dn_2: 0.3101  loss_ce_3: 0.9137  loss_mask_3: 0.03468  loss_dice_3: 0.4782  loss_bbox_3: 0.04878  loss_giou_3: 0.3782  loss_ce_dn_3: 0.1725  loss_mask_dn_3: 0.03097  loss_dice_dn_3: 0.4781  loss_bbox_dn_3: 0.03984  loss_giou_dn_3: 0.2926  loss_ce_4: 0.8028  loss_mask_4: 0.03131  loss_dice_4: 0.5342  loss_bbox_4: 0.05863  loss_giou_4: 0.3625  loss_ce_dn_4: 0.1536  loss_mask_dn_4: 0.03064  loss_dice_dn_4: 0.4763  loss_bbox_dn_4: 0.03574  loss_giou_dn_4: 0.282  loss_ce_5: 0.7813  loss_mask_5: 0.03161  loss_dice_5: 0.5619  loss_bbox_5: 0.05503  loss_giou_5: 0.3504  loss_ce_dn_5: 0.1345  loss_mask_dn_5: 0.02958  loss_dice_dn_5: 0.4937  loss_bbox_dn_5: 0.03557  loss_giou_dn_5: 0.2828  loss_ce_6: 0.9434  loss_mask_6: 0.02968  loss_dice_6: 0.5549  loss_bbox_6: 0.05311  loss_giou_6: 0.3512  loss_ce_dn_6: 0.1127  loss_mask_dn_6: 0.02769  loss_dice_dn_6: 0.4894  loss_bbox_dn_6: 0.03514  loss_giou_dn_6: 0.2784  loss_ce_7: 0.7929  loss_mask_7: 0.03093  loss_dice_7: 0.5661  loss_bbox_7: 0.04784  loss_giou_7: 0.3486  loss_ce_dn_7: 0.1027  loss_mask_dn_7: 0.02863  loss_dice_dn_7: 0.4661  loss_bbox_dn_7: 0.03415  loss_giou_dn_7: 0.2804  loss_ce_8: 0.7215  loss_mask_8: 0.02993  loss_dice_8: 0.5977  loss_bbox_8: 0.04354  loss_giou_8: 0.3499  loss_ce_dn_8: 0.1018  loss_mask_dn_8: 0.02932  loss_dice_dn_8: 0.5044  loss_bbox_dn_8: 0.03359  loss_giou_dn_8: 0.2829  loss_ce_interm: 1.103  loss_mask_interm: 0.03129  loss_dice_interm: 0.5655  loss_bbox_interm: 0.09441  loss_giou_interm: 0.4489  time: 1.8758  data_time: 0.0858  lr: 1e-06  max_mem: 6663M\n",
            "[05/20 18:28:54 d2.utils.events]:  eta: 0:47:25  iter: 3959  total_loss: 32.3  loss_ce: 0.8236  loss_mask: 0.04817  loss_dice: 0.4342  loss_bbox: 0.09296  loss_giou: 0.266  loss_ce_dn: 0.1686  loss_mask_dn: 0.03899  loss_dice_dn: 0.4022  loss_bbox_dn: 0.05585  loss_giou_dn: 0.2279  loss_ce_0: 1.152  loss_mask_0: 0.05801  loss_dice_0: 0.435  loss_bbox_0: 0.09138  loss_giou_0: 0.2912  loss_ce_dn_0: 0.6839  loss_mask_dn_0: 0.2177  loss_dice_dn_0: 2.03  loss_bbox_dn_0: 0.3516  loss_giou_dn_0: 0.8516  loss_ce_1: 1.232  loss_mask_1: 0.0507  loss_dice_1: 0.4489  loss_bbox_1: 0.08121  loss_giou_1: 0.2048  loss_ce_dn_1: 0.2598  loss_mask_dn_1: 0.0429  loss_dice_dn_1: 0.4307  loss_bbox_dn_1: 0.1069  loss_giou_dn_1: 0.3303  loss_ce_2: 1.049  loss_mask_2: 0.05434  loss_dice_2: 0.428  loss_bbox_2: 0.09262  loss_giou_2: 0.2657  loss_ce_dn_2: 0.2142  loss_mask_dn_2: 0.04324  loss_dice_dn_2: 0.4145  loss_bbox_dn_2: 0.08311  loss_giou_dn_2: 0.2661  loss_ce_3: 0.9042  loss_mask_3: 0.05038  loss_dice_3: 0.3426  loss_bbox_3: 0.0873  loss_giou_3: 0.2611  loss_ce_dn_3: 0.1909  loss_mask_dn_3: 0.04014  loss_dice_dn_3: 0.4118  loss_bbox_dn_3: 0.06918  loss_giou_dn_3: 0.2434  loss_ce_4: 0.9045  loss_mask_4: 0.04659  loss_dice_4: 0.4286  loss_bbox_4: 0.08775  loss_giou_4: 0.2986  loss_ce_dn_4: 0.1932  loss_mask_dn_4: 0.04038  loss_dice_dn_4: 0.396  loss_bbox_dn_4: 0.06649  loss_giou_dn_4: 0.2304  loss_ce_5: 0.8113  loss_mask_5: 0.04194  loss_dice_5: 0.3489  loss_bbox_5: 0.0913  loss_giou_5: 0.2756  loss_ce_dn_5: 0.1756  loss_mask_dn_5: 0.03718  loss_dice_dn_5: 0.426  loss_bbox_dn_5: 0.06624  loss_giou_dn_5: 0.2403  loss_ce_6: 0.8625  loss_mask_6: 0.04862  loss_dice_6: 0.4436  loss_bbox_6: 0.09483  loss_giou_6: 0.2481  loss_ce_dn_6: 0.1579  loss_mask_dn_6: 0.03969  loss_dice_dn_6: 0.4036  loss_bbox_dn_6: 0.06318  loss_giou_dn_6: 0.2325  loss_ce_7: 0.8152  loss_mask_7: 0.03864  loss_dice_7: 0.3496  loss_bbox_7: 0.0838  loss_giou_7: 0.2651  loss_ce_dn_7: 0.1737  loss_mask_dn_7: 0.03813  loss_dice_dn_7: 0.3758  loss_bbox_dn_7: 0.0611  loss_giou_dn_7: 0.2263  loss_ce_8: 0.8024  loss_mask_8: 0.04492  loss_dice_8: 0.3259  loss_bbox_8: 0.09388  loss_giou_8: 0.2743  loss_ce_dn_8: 0.1711  loss_mask_dn_8: 0.03907  loss_dice_dn_8: 0.4121  loss_bbox_dn_8: 0.06222  loss_giou_dn_8: 0.2289  loss_ce_interm: 1.115  loss_mask_interm: 0.04977  loss_dice_interm: 0.4401  loss_bbox_interm: 0.1278  loss_giou_interm: 0.3989  time: 1.8749  data_time: 0.0687  lr: 1e-06  max_mem: 6663M\n",
            "[05/20 18:29:29 d2.utils.events]:  eta: 0:47:00  iter: 3979  total_loss: 33.33  loss_ce: 0.7685  loss_mask: 0.03374  loss_dice: 0.6897  loss_bbox: 0.04449  loss_giou: 0.2581  loss_ce_dn: 0.1705  loss_mask_dn: 0.03305  loss_dice_dn: 0.5366  loss_bbox_dn: 0.03751  loss_giou_dn: 0.2317  loss_ce_0: 1.07  loss_mask_0: 0.04457  loss_dice_0: 0.5009  loss_bbox_0: 0.06262  loss_giou_0: 0.3514  loss_ce_dn_0: 0.6773  loss_mask_dn_0: 0.2018  loss_dice_dn_0: 2.649  loss_bbox_dn_0: 0.2982  loss_giou_dn_0: 0.8556  loss_ce_1: 1.05  loss_mask_1: 0.04397  loss_dice_1: 0.6696  loss_bbox_1: 0.04863  loss_giou_1: 0.2618  loss_ce_dn_1: 0.2344  loss_mask_dn_1: 0.0373  loss_dice_dn_1: 0.5572  loss_bbox_dn_1: 0.06484  loss_giou_dn_1: 0.2948  loss_ce_2: 1.175  loss_mask_2: 0.03874  loss_dice_2: 0.5677  loss_bbox_2: 0.05855  loss_giou_2: 0.3482  loss_ce_dn_2: 0.2041  loss_mask_dn_2: 0.03506  loss_dice_dn_2: 0.5943  loss_bbox_dn_2: 0.04795  loss_giou_dn_2: 0.2693  loss_ce_3: 0.8633  loss_mask_3: 0.03687  loss_dice_3: 0.5173  loss_bbox_3: 0.04423  loss_giou_3: 0.256  loss_ce_dn_3: 0.1854  loss_mask_dn_3: 0.03416  loss_dice_dn_3: 0.566  loss_bbox_dn_3: 0.03787  loss_giou_dn_3: 0.2302  loss_ce_4: 0.8334  loss_mask_4: 0.04371  loss_dice_4: 0.4893  loss_bbox_4: 0.0478  loss_giou_4: 0.279  loss_ce_dn_4: 0.1758  loss_mask_dn_4: 0.03308  loss_dice_dn_4: 0.5478  loss_bbox_dn_4: 0.03682  loss_giou_dn_4: 0.2312  loss_ce_5: 0.7867  loss_mask_5: 0.0385  loss_dice_5: 0.4847  loss_bbox_5: 0.04368  loss_giou_5: 0.2654  loss_ce_dn_5: 0.1644  loss_mask_dn_5: 0.03295  loss_dice_dn_5: 0.5775  loss_bbox_dn_5: 0.03683  loss_giou_dn_5: 0.2307  loss_ce_6: 0.8608  loss_mask_6: 0.04363  loss_dice_6: 0.5666  loss_bbox_6: 0.04422  loss_giou_6: 0.2637  loss_ce_dn_6: 0.1752  loss_mask_dn_6: 0.03254  loss_dice_dn_6: 0.5646  loss_bbox_dn_6: 0.03694  loss_giou_dn_6: 0.2329  loss_ce_7: 0.7574  loss_mask_7: 0.0359  loss_dice_7: 0.5395  loss_bbox_7: 0.04522  loss_giou_7: 0.2531  loss_ce_dn_7: 0.1719  loss_mask_dn_7: 0.03238  loss_dice_dn_7: 0.5876  loss_bbox_dn_7: 0.03649  loss_giou_dn_7: 0.2321  loss_ce_8: 0.8276  loss_mask_8: 0.03356  loss_dice_8: 0.5725  loss_bbox_8: 0.04289  loss_giou_8: 0.2131  loss_ce_dn_8: 0.1728  loss_mask_dn_8: 0.03242  loss_dice_dn_8: 0.5455  loss_bbox_dn_8: 0.0373  loss_giou_dn_8: 0.2331  loss_ce_interm: 1.087  loss_mask_interm: 0.03376  loss_dice_interm: 0.4799  loss_bbox_interm: 0.08555  loss_giou_interm: 0.3177  time: 1.8743  data_time: 0.0781  lr: 1e-06  max_mem: 6663M\n",
            "[05/20 18:30:03 d2.data.datasets.coco]: Loaded 150 images in COCO format from /content/TACO-expl/data/annotations_off_0_resval.json\n",
            "[05/20 18:30:03 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "[05/20 18:30:03 d2.data.common]: Serializing 150 elements to byte tensors and concatenating them all ...\n",
            "[05/20 18:30:03 d2.data.common]: Serialized dataset takes 0.21 MiB\n",
            "WARNING [05/20 18:30:03 d2.evaluation.coco_evaluation]: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
            "[05/20 18:30:03 d2.evaluation.evaluator]: Start inference on 150 batches\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1066, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1066, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1066, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1066])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 18:30:13 d2.evaluation.evaluator]: Inference done 11/150. Dataloading: 0.0021 s/iter. Inference: 0.3045 s/iter. Eval: 0.5068 s/iter. Total: 0.8135 s/iter. ETA=0:01:53\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 608])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 608])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 608])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1200])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 750])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 18:30:18 d2.evaluation.evaluator]: Inference done 18/150. Dataloading: 0.0022 s/iter. Inference: 0.2905 s/iter. Eval: 0.4832 s/iter. Total: 0.7761 s/iter. ETA=0:01:42\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 750])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([750, 1333])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 18:30:24 d2.evaluation.evaluator]: Inference done 24/150. Dataloading: 0.0043 s/iter. Inference: 0.2993 s/iter. Eval: 0.5143 s/iter. Total: 0.8182 s/iter. ETA=0:01:43\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 750])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([750, 1333])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 750])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 18:30:29 d2.evaluation.evaluator]: Inference done 30/150. Dataloading: 0.0043 s/iter. Inference: 0.3070 s/iter. Eval: 0.5300 s/iter. Total: 0.8417 s/iter. ETA=0:01:41\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 750])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 18:30:35 d2.evaluation.evaluator]: Inference done 37/150. Dataloading: 0.0039 s/iter. Inference: 0.3034 s/iter. Eval: 0.5147 s/iter. Total: 0.8223 s/iter. ETA=0:01:32\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 18:30:40 d2.evaluation.evaluator]: Inference done 43/150. Dataloading: 0.0044 s/iter. Inference: 0.3032 s/iter. Eval: 0.5344 s/iter. Total: 0.8425 s/iter. ETA=0:01:30\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 18:30:46 d2.evaluation.evaluator]: Inference done 49/150. Dataloading: 0.0050 s/iter. Inference: 0.3058 s/iter. Eval: 0.5356 s/iter. Total: 0.8469 s/iter. ETA=0:01:25\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 18:30:51 d2.evaluation.evaluator]: Inference done 56/150. Dataloading: 0.0048 s/iter. Inference: 0.3030 s/iter. Eval: 0.5233 s/iter. Total: 0.8315 s/iter. ETA=0:01:18\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 18:30:57 d2.evaluation.evaluator]: Inference done 63/150. Dataloading: 0.0050 s/iter. Inference: 0.3041 s/iter. Eval: 0.5245 s/iter. Total: 0.8340 s/iter. ETA=0:01:12\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 18:31:02 d2.evaluation.evaluator]: Inference done 69/150. Dataloading: 0.0053 s/iter. Inference: 0.3055 s/iter. Eval: 0.5290 s/iter. Total: 0.8403 s/iter. ETA=0:01:08\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 18:31:07 d2.evaluation.evaluator]: Inference done 76/150. Dataloading: 0.0050 s/iter. Inference: 0.3035 s/iter. Eval: 0.5215 s/iter. Total: 0.8304 s/iter. ETA=0:01:01\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([852, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 18:31:13 d2.evaluation.evaluator]: Inference done 83/150. Dataloading: 0.0048 s/iter. Inference: 0.3020 s/iter. Eval: 0.5200 s/iter. Total: 0.8272 s/iter. ETA=0:00:55\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 18:31:18 d2.evaluation.evaluator]: Inference done 89/150. Dataloading: 0.0048 s/iter. Inference: 0.3034 s/iter. Eval: 0.5241 s/iter. Total: 0.8327 s/iter. ETA=0:00:50\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 18:31:23 d2.evaluation.evaluator]: Inference done 96/150. Dataloading: 0.0046 s/iter. Inference: 0.3017 s/iter. Eval: 0.5185 s/iter. Total: 0.8253 s/iter. ETA=0:00:44\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 18:31:29 d2.evaluation.evaluator]: Inference done 103/150. Dataloading: 0.0046 s/iter. Inference: 0.3014 s/iter. Eval: 0.5177 s/iter. Total: 0.8242 s/iter. ETA=0:00:38\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 18:31:35 d2.evaluation.evaluator]: Inference done 109/150. Dataloading: 0.0050 s/iter. Inference: 0.3028 s/iter. Eval: 0.5227 s/iter. Total: 0.8310 s/iter. ETA=0:00:34\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 18:31:40 d2.evaluation.evaluator]: Inference done 116/150. Dataloading: 0.0049 s/iter. Inference: 0.3015 s/iter. Eval: 0.5179 s/iter. Total: 0.8247 s/iter. ETA=0:00:28\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 18:31:45 d2.evaluation.evaluator]: Inference done 123/150. Dataloading: 0.0049 s/iter. Inference: 0.3008 s/iter. Eval: 0.5161 s/iter. Total: 0.8222 s/iter. ETA=0:00:22\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 18:31:51 d2.evaluation.evaluator]: Inference done 129/150. Dataloading: 0.0048 s/iter. Inference: 0.3022 s/iter. Eval: 0.5206 s/iter. Total: 0.8280 s/iter. ETA=0:00:17\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 750])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 18:31:56 d2.evaluation.evaluator]: Inference done 136/150. Dataloading: 0.0046 s/iter. Inference: 0.3010 s/iter. Eval: 0.5176 s/iter. Total: 0.8237 s/iter. ETA=0:00:11\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 750])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 750])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 18:32:02 d2.evaluation.evaluator]: Inference done 143/150. Dataloading: 0.0046 s/iter. Inference: 0.3006 s/iter. Eval: 0.5177 s/iter. Total: 0.8234 s/iter. ETA=0:00:05\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 608])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 608])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 608])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 18:32:07 d2.evaluation.evaluator]: Inference done 149/150. Dataloading: 0.0045 s/iter. Inference: 0.3016 s/iter. Eval: 0.5203 s/iter. Total: 0.8269 s/iter. ETA=0:00:00\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 608])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[05/20 18:32:08 d2.evaluation.evaluator]: Total inference time: 0:01:59.876094 (0.826732 s / iter per device, on 1 devices)\n",
            "[05/20 18:32:08 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:43 (0.301380 s / iter per device, on 1 devices)\n",
            "[05/20 18:32:08 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...\n",
            "[05/20 18:32:08 d2.evaluation.coco_evaluation]: Saving results to /content/output/chkpt/inference/coco_instances_results.json\n",
            "[05/20 18:32:09 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "[05/20 18:32:09 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*\n",
            "[05/20 18:32:09 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.15 seconds.\n",
            "[05/20 18:32:09 d2.evaluation.fast_eval_api]: Accumulating evaluation results...\n",
            "[05/20 18:32:09 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.08 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.243\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.410\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.244\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.065\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.250\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.414\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.316\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.436\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.444\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.102\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.489\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.777\n",
            "[05/20 18:32:09 d2.evaluation.coco_evaluation]: Evaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
            "| 24.285 | 41.001 | 24.350 | 6.468 | 24.970 | 41.437 |\n",
            "[05/20 18:32:09 d2.evaluation.coco_evaluation]: Per-category bbox AP: \n",
            "| category   | AP     | category              | AP     | category   | AP     |\n",
            "|:-----------|:-------|:----------------------|:-------|:-----------|:-------|\n",
            "| Bottle     | 53.490 | Bottle cap            | 12.257 | Can        | 42.717 |\n",
            "| Cigarette  | 1.896  | Cup                   | 30.776 | Lid        | 33.761 |\n",
            "| Other      | 20.069 | Plastic bag & wrapper | 21.884 | Pop tab    | 10.708 |\n",
            "| Straw      | 15.294 |                       |        |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.17s)\n",
            "creating index...\n",
            "index created!\n",
            "[05/20 18:32:09 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*\n",
            "[05/20 18:32:10 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.25 seconds.\n",
            "[05/20 18:32:10 d2.evaluation.fast_eval_api]: Accumulating evaluation results...\n",
            "[05/20 18:32:10 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.06 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.386\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.503\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.398\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.215\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.470\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.524\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.448\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.641\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.659\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.404\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.750\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.838\n",
            "[05/20 18:32:10 d2.evaluation.coco_evaluation]: Evaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 38.634 | 50.302 | 39.796 | 21.460 | 47.024 | 52.374 |\n",
            "[05/20 18:32:10 d2.evaluation.coco_evaluation]: Per-category segm AP: \n",
            "| category   | AP     | category              | AP     | category   | AP     |\n",
            "|:-----------|:-------|:----------------------|:-------|:-----------|:-------|\n",
            "| Bottle     | 73.116 | Bottle cap            | 39.752 | Can        | 55.376 |\n",
            "| Cigarette  | 20.576 | Cup                   | 42.743 | Lid        | 44.270 |\n",
            "| Other      | 30.447 | Plastic bag & wrapper | 35.229 | Pop tab    | 25.720 |\n",
            "| Straw      | 19.111 |                       |        |            |        |\n",
            "[05/20 18:32:10 d2.engine.defaults]: Evaluation results for TACO_val in csv format:\n",
            "[05/20 18:32:10 d2.evaluation.testing]: copypaste: Task: bbox\n",
            "[05/20 18:32:10 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl\n",
            "[05/20 18:32:10 d2.evaluation.testing]: copypaste: 24.2853,41.0012,24.3504,6.4676,24.9704,41.4375\n",
            "[05/20 18:32:10 d2.evaluation.testing]: copypaste: Task: segm\n",
            "[05/20 18:32:10 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl\n",
            "[05/20 18:32:10 d2.evaluation.testing]: copypaste: 38.6341,50.3016,39.7961,21.4597,47.0237,52.3738\n",
            "[05/20 18:32:10 d2.utils.events]:  eta: 0:46:28  iter: 3999  total_loss: 35.79  loss_ce: 0.776  loss_mask: 0.03506  loss_dice: 0.3895  loss_bbox: 0.06383  loss_giou: 0.3273  loss_ce_dn: 0.1534  loss_mask_dn: 0.03133  loss_dice_dn: 0.4432  loss_bbox_dn: 0.049  loss_giou_dn: 0.2742  loss_ce_0: 1.267  loss_mask_0: 0.06435  loss_dice_0: 0.6345  loss_bbox_0: 0.07394  loss_giou_0: 0.3553  loss_ce_dn_0: 0.6757  loss_mask_dn_0: 0.1775  loss_dice_dn_0: 1.962  loss_bbox_dn_0: 0.2398  loss_giou_dn_0: 0.8541  loss_ce_1: 1.114  loss_mask_1: 0.03851  loss_dice_1: 0.4183  loss_bbox_1: 0.06521  loss_giou_1: 0.3066  loss_ce_dn_1: 0.2375  loss_mask_dn_1: 0.03077  loss_dice_dn_1: 0.5242  loss_bbox_dn_1: 0.06818  loss_giou_dn_1: 0.3932  loss_ce_2: 0.9453  loss_mask_2: 0.04482  loss_dice_2: 0.3456  loss_bbox_2: 0.06719  loss_giou_2: 0.3441  loss_ce_dn_2: 0.1954  loss_mask_dn_2: 0.02855  loss_dice_dn_2: 0.4413  loss_bbox_dn_2: 0.05725  loss_giou_dn_2: 0.3392  loss_ce_3: 0.9622  loss_mask_3: 0.03483  loss_dice_3: 0.4814  loss_bbox_3: 0.05919  loss_giou_3: 0.379  loss_ce_dn_3: 0.1947  loss_mask_dn_3: 0.03024  loss_dice_dn_3: 0.4457  loss_bbox_dn_3: 0.04813  loss_giou_dn_3: 0.2984  loss_ce_4: 0.9574  loss_mask_4: 0.03452  loss_dice_4: 0.4484  loss_bbox_4: 0.0591  loss_giou_4: 0.3649  loss_ce_dn_4: 0.1814  loss_mask_dn_4: 0.02998  loss_dice_dn_4: 0.4289  loss_bbox_dn_4: 0.04734  loss_giou_dn_4: 0.2868  loss_ce_5: 0.8265  loss_mask_5: 0.03263  loss_dice_5: 0.3696  loss_bbox_5: 0.06373  loss_giou_5: 0.3223  loss_ce_dn_5: 0.1777  loss_mask_dn_5: 0.02893  loss_dice_dn_5: 0.4307  loss_bbox_dn_5: 0.04794  loss_giou_dn_5: 0.2736  loss_ce_6: 0.7812  loss_mask_6: 0.03068  loss_dice_6: 0.433  loss_bbox_6: 0.06181  loss_giou_6: 0.331  loss_ce_dn_6: 0.1651  loss_mask_dn_6: 0.03185  loss_dice_dn_6: 0.433  loss_bbox_dn_6: 0.04795  loss_giou_dn_6: 0.2796  loss_ce_7: 0.7832  loss_mask_7: 0.03035  loss_dice_7: 0.419  loss_bbox_7: 0.06371  loss_giou_7: 0.3274  loss_ce_dn_7: 0.1596  loss_mask_dn_7: 0.03282  loss_dice_dn_7: 0.4378  loss_bbox_dn_7: 0.04863  loss_giou_dn_7: 0.2756  loss_ce_8: 0.7795  loss_mask_8: 0.03088  loss_dice_8: 0.4008  loss_bbox_8: 0.06361  loss_giou_8: 0.3308  loss_ce_dn_8: 0.1537  loss_mask_dn_8: 0.03163  loss_dice_dn_8: 0.4305  loss_bbox_dn_8: 0.04845  loss_giou_dn_8: 0.2767  loss_ce_interm: 1.164  loss_mask_interm: 0.04897  loss_dice_interm: 0.4274  loss_bbox_interm: 0.08145  loss_giou_interm: 0.4033  time: 1.8734  data_time: 0.1194  lr: 1e-06  max_mem: 6663M\n",
            "[05/20 18:32:45 d2.utils.events]:  eta: 0:45:58  iter: 4019  total_loss: 47.24  loss_ce: 1.014  loss_mask: 0.05061  loss_dice: 0.7528  loss_bbox: 0.09197  loss_giou: 0.5279  loss_ce_dn: 0.2218  loss_mask_dn: 0.04292  loss_dice_dn: 0.6925  loss_bbox_dn: 0.05024  loss_giou_dn: 0.3531  loss_ce_0: 1.219  loss_mask_0: 0.05518  loss_dice_0: 0.6443  loss_bbox_0: 0.1359  loss_giou_0: 0.6916  loss_ce_dn_0: 0.7088  loss_mask_dn_0: 0.2945  loss_dice_dn_0: 3.038  loss_bbox_dn_0: 0.291  loss_giou_dn_0: 0.8517  loss_ce_1: 1.209  loss_mask_1: 0.06516  loss_dice_1: 0.6518  loss_bbox_1: 0.08666  loss_giou_1: 0.5597  loss_ce_dn_1: 0.3044  loss_mask_dn_1: 0.04326  loss_dice_dn_1: 0.7847  loss_bbox_dn_1: 0.06938  loss_giou_dn_1: 0.4203  loss_ce_2: 1.191  loss_mask_2: 0.04464  loss_dice_2: 0.6556  loss_bbox_2: 0.09895  loss_giou_2: 0.5445  loss_ce_dn_2: 0.2644  loss_mask_dn_2: 0.04215  loss_dice_dn_2: 0.7143  loss_bbox_dn_2: 0.05708  loss_giou_dn_2: 0.372  loss_ce_3: 1.081  loss_mask_3: 0.05209  loss_dice_3: 0.8814  loss_bbox_3: 0.07298  loss_giou_3: 0.5474  loss_ce_dn_3: 0.2512  loss_mask_dn_3: 0.04404  loss_dice_dn_3: 0.7127  loss_bbox_dn_3: 0.05225  loss_giou_dn_3: 0.3591  loss_ce_4: 1.076  loss_mask_4: 0.04534  loss_dice_4: 0.7031  loss_bbox_4: 0.06778  loss_giou_4: 0.534  loss_ce_dn_4: 0.2345  loss_mask_dn_4: 0.04012  loss_dice_dn_4: 0.6712  loss_bbox_dn_4: 0.04927  loss_giou_dn_4: 0.3576  loss_ce_5: 1.066  loss_mask_5: 0.04892  loss_dice_5: 0.7255  loss_bbox_5: 0.07452  loss_giou_5: 0.5004  loss_ce_dn_5: 0.2284  loss_mask_dn_5: 0.04133  loss_dice_dn_5: 0.7324  loss_bbox_dn_5: 0.05076  loss_giou_dn_5: 0.3535  loss_ce_6: 1.056  loss_mask_6: 0.045  loss_dice_6: 0.7201  loss_bbox_6: 0.08627  loss_giou_6: 0.541  loss_ce_dn_6: 0.2188  loss_mask_dn_6: 0.04242  loss_dice_dn_6: 0.755  loss_bbox_dn_6: 0.05132  loss_giou_dn_6: 0.3493  loss_ce_7: 1.025  loss_mask_7: 0.05527  loss_dice_7: 0.605  loss_bbox_7: 0.08547  loss_giou_7: 0.5526  loss_ce_dn_7: 0.2173  loss_mask_dn_7: 0.04384  loss_dice_dn_7: 0.7203  loss_bbox_dn_7: 0.05073  loss_giou_dn_7: 0.3515  loss_ce_8: 1.068  loss_mask_8: 0.05036  loss_dice_8: 0.6945  loss_bbox_8: 0.08162  loss_giou_8: 0.5255  loss_ce_dn_8: 0.2189  loss_mask_dn_8: 0.04427  loss_dice_dn_8: 0.6976  loss_bbox_dn_8: 0.05037  loss_giou_dn_8: 0.3551  loss_ce_interm: 1.196  loss_mask_interm: 0.05651  loss_dice_interm: 0.6954  loss_bbox_interm: 0.09672  loss_giou_interm: 0.585  time: 1.8729  data_time: 0.1679  lr: 1e-06  max_mem: 6663M\n",
            "[05/20 18:33:19 d2.utils.events]:  eta: 0:45:24  iter: 4039  total_loss: 49.26  loss_ce: 0.781  loss_mask: 0.04433  loss_dice: 0.6216  loss_bbox: 0.06867  loss_giou: 0.3516  loss_ce_dn: 0.1399  loss_mask_dn: 0.04391  loss_dice_dn: 0.6443  loss_bbox_dn: 0.04688  loss_giou_dn: 0.2821  loss_ce_0: 1.193  loss_mask_0: 0.04621  loss_dice_0: 0.6655  loss_bbox_0: 0.07896  loss_giou_0: 0.4636  loss_ce_dn_0: 0.748  loss_mask_dn_0: 0.2856  loss_dice_dn_0: 3.069  loss_bbox_dn_0: 0.3689  loss_giou_dn_0: 0.8562  loss_ce_1: 1.063  loss_mask_1: 0.04211  loss_dice_1: 0.4167  loss_bbox_1: 0.06022  loss_giou_1: 0.4278  loss_ce_dn_1: 0.244  loss_mask_dn_1: 0.05354  loss_dice_dn_1: 0.6407  loss_bbox_dn_1: 0.08475  loss_giou_dn_1: 0.356  loss_ce_2: 1.063  loss_mask_2: 0.04677  loss_dice_2: 0.5737  loss_bbox_2: 0.06013  loss_giou_2: 0.3338  loss_ce_dn_2: 0.189  loss_mask_dn_2: 0.05085  loss_dice_dn_2: 0.6224  loss_bbox_dn_2: 0.06913  loss_giou_dn_2: 0.3223  loss_ce_3: 0.9146  loss_mask_3: 0.03892  loss_dice_3: 0.5337  loss_bbox_3: 0.0659  loss_giou_3: 0.3583  loss_ce_dn_3: 0.1625  loss_mask_dn_3: 0.04707  loss_dice_dn_3: 0.6343  loss_bbox_dn_3: 0.05953  loss_giou_dn_3: 0.2931  loss_ce_4: 0.9052  loss_mask_4: 0.04845  loss_dice_4: 0.6595  loss_bbox_4: 0.06312  loss_giou_4: 0.3569  loss_ce_dn_4: 0.1529  loss_mask_dn_4: 0.04622  loss_dice_dn_4: 0.6321  loss_bbox_dn_4: 0.05411  loss_giou_dn_4: 0.2909  loss_ce_5: 0.8382  loss_mask_5: 0.04865  loss_dice_5: 0.6627  loss_bbox_5: 0.06076  loss_giou_5: 0.3318  loss_ce_dn_5: 0.144  loss_mask_dn_5: 0.04369  loss_dice_dn_5: 0.6295  loss_bbox_dn_5: 0.04948  loss_giou_dn_5: 0.2814  loss_ce_6: 0.7874  loss_mask_6: 0.05036  loss_dice_6: 0.6585  loss_bbox_6: 0.06103  loss_giou_6: 0.3574  loss_ce_dn_6: 0.1389  loss_mask_dn_6: 0.04531  loss_dice_dn_6: 0.6568  loss_bbox_dn_6: 0.04652  loss_giou_dn_6: 0.2848  loss_ce_7: 0.8073  loss_mask_7: 0.04428  loss_dice_7: 0.6478  loss_bbox_7: 0.06035  loss_giou_7: 0.3518  loss_ce_dn_7: 0.1406  loss_mask_dn_7: 0.0412  loss_dice_dn_7: 0.6634  loss_bbox_dn_7: 0.04597  loss_giou_dn_7: 0.2859  loss_ce_8: 0.7759  loss_mask_8: 0.0428  loss_dice_8: 0.5405  loss_bbox_8: 0.07025  loss_giou_8: 0.3524  loss_ce_dn_8: 0.1402  loss_mask_dn_8: 0.04386  loss_dice_dn_8: 0.6383  loss_bbox_dn_8: 0.04614  loss_giou_dn_8: 0.2837  loss_ce_interm: 1.191  loss_mask_interm: 0.04573  loss_dice_interm: 0.8553  loss_bbox_interm: 0.09997  loss_giou_interm: 0.5515  time: 1.8719  data_time: 0.0665  lr: 1e-06  max_mem: 6663M\n",
            "[05/20 18:33:53 d2.utils.events]:  eta: 0:44:54  iter: 4059  total_loss: 47.88  loss_ce: 1.032  loss_mask: 0.03068  loss_dice: 0.8366  loss_bbox: 0.07654  loss_giou: 0.4679  loss_ce_dn: 0.1571  loss_mask_dn: 0.03073  loss_dice_dn: 0.7264  loss_bbox_dn: 0.03813  loss_giou_dn: 0.3467  loss_ce_0: 1.222  loss_mask_0: 0.03249  loss_dice_0: 0.9318  loss_bbox_0: 0.08676  loss_giou_0: 0.6376  loss_ce_dn_0: 0.8539  loss_mask_dn_0: 0.1396  loss_dice_dn_0: 2.878  loss_bbox_dn_0: 0.2424  loss_giou_dn_0: 0.8639  loss_ce_1: 1.234  loss_mask_1: 0.03663  loss_dice_1: 0.8442  loss_bbox_1: 0.08491  loss_giou_1: 0.6318  loss_ce_dn_1: 0.2714  loss_mask_dn_1: 0.03449  loss_dice_dn_1: 0.7639  loss_bbox_dn_1: 0.07304  loss_giou_dn_1: 0.4288  loss_ce_2: 1.11  loss_mask_2: 0.03051  loss_dice_2: 0.8241  loss_bbox_2: 0.09087  loss_giou_2: 0.5908  loss_ce_dn_2: 0.2194  loss_mask_dn_2: 0.03131  loss_dice_dn_2: 0.7591  loss_bbox_dn_2: 0.0489  loss_giou_dn_2: 0.3673  loss_ce_3: 1.13  loss_mask_3: 0.03149  loss_dice_3: 0.8178  loss_bbox_3: 0.09397  loss_giou_3: 0.4903  loss_ce_dn_3: 0.1699  loss_mask_dn_3: 0.03247  loss_dice_dn_3: 0.7268  loss_bbox_dn_3: 0.04466  loss_giou_dn_3: 0.3632  loss_ce_4: 1.052  loss_mask_4: 0.02549  loss_dice_4: 0.8097  loss_bbox_4: 0.0851  loss_giou_4: 0.5067  loss_ce_dn_4: 0.167  loss_mask_dn_4: 0.02999  loss_dice_dn_4: 0.7129  loss_bbox_dn_4: 0.04139  loss_giou_dn_4: 0.3433  loss_ce_5: 1.103  loss_mask_5: 0.02808  loss_dice_5: 0.7864  loss_bbox_5: 0.08157  loss_giou_5: 0.48  loss_ce_dn_5: 0.1521  loss_mask_dn_5: 0.02832  loss_dice_dn_5: 0.7088  loss_bbox_dn_5: 0.04338  loss_giou_dn_5: 0.3459  loss_ce_6: 1.116  loss_mask_6: 0.02861  loss_dice_6: 0.8315  loss_bbox_6: 0.08548  loss_giou_6: 0.4871  loss_ce_dn_6: 0.1442  loss_mask_dn_6: 0.02917  loss_dice_dn_6: 0.7067  loss_bbox_dn_6: 0.04158  loss_giou_dn_6: 0.3481  loss_ce_7: 1.036  loss_mask_7: 0.03081  loss_dice_7: 0.8064  loss_bbox_7: 0.07487  loss_giou_7: 0.4516  loss_ce_dn_7: 0.1524  loss_mask_dn_7: 0.02938  loss_dice_dn_7: 0.689  loss_bbox_dn_7: 0.03816  loss_giou_dn_7: 0.3504  loss_ce_8: 1.057  loss_mask_8: 0.03051  loss_dice_8: 0.8298  loss_bbox_8: 0.07903  loss_giou_8: 0.4516  loss_ce_dn_8: 0.1547  loss_mask_dn_8: 0.02965  loss_dice_dn_8: 0.7009  loss_bbox_dn_8: 0.03751  loss_giou_dn_8: 0.3449  loss_ce_interm: 1.304  loss_mask_interm: 0.03642  loss_dice_interm: 0.9258  loss_bbox_interm: 0.1013  loss_giou_interm: 0.5832  time: 1.8711  data_time: 0.1216  lr: 1e-06  max_mem: 6663M\n",
            "[05/20 18:34:28 d2.utils.events]:  eta: 0:44:25  iter: 4079  total_loss: 36.43  loss_ce: 0.8054  loss_mask: 0.04837  loss_dice: 0.5206  loss_bbox: 0.05181  loss_giou: 0.267  loss_ce_dn: 0.1918  loss_mask_dn: 0.04682  loss_dice_dn: 0.4911  loss_bbox_dn: 0.04547  loss_giou_dn: 0.2399  loss_ce_0: 1.218  loss_mask_0: 0.05482  loss_dice_0: 0.4883  loss_bbox_0: 0.05962  loss_giou_0: 0.3117  loss_ce_dn_0: 0.8329  loss_mask_dn_0: 0.2144  loss_dice_dn_0: 2.501  loss_bbox_dn_0: 0.3607  loss_giou_dn_0: 0.8552  loss_ce_1: 1.136  loss_mask_1: 0.04892  loss_dice_1: 0.4651  loss_bbox_1: 0.05143  loss_giou_1: 0.2581  loss_ce_dn_1: 0.3327  loss_mask_dn_1: 0.04404  loss_dice_dn_1: 0.4905  loss_bbox_dn_1: 0.07506  loss_giou_dn_1: 0.3486  loss_ce_2: 1.074  loss_mask_2: 0.04727  loss_dice_2: 0.4352  loss_bbox_2: 0.0569  loss_giou_2: 0.2554  loss_ce_dn_2: 0.2452  loss_mask_dn_2: 0.04447  loss_dice_dn_2: 0.52  loss_bbox_dn_2: 0.0606  loss_giou_dn_2: 0.2801  loss_ce_3: 0.9359  loss_mask_3: 0.05271  loss_dice_3: 0.475  loss_bbox_3: 0.05386  loss_giou_3: 0.2717  loss_ce_dn_3: 0.2215  loss_mask_dn_3: 0.04736  loss_dice_dn_3: 0.4974  loss_bbox_dn_3: 0.05005  loss_giou_dn_3: 0.2596  loss_ce_4: 0.9127  loss_mask_4: 0.0478  loss_dice_4: 0.5469  loss_bbox_4: 0.05574  loss_giou_4: 0.2678  loss_ce_dn_4: 0.2015  loss_mask_dn_4: 0.04751  loss_dice_dn_4: 0.5059  loss_bbox_dn_4: 0.0466  loss_giou_dn_4: 0.2557  loss_ce_5: 0.8649  loss_mask_5: 0.05166  loss_dice_5: 0.5226  loss_bbox_5: 0.0554  loss_giou_5: 0.2677  loss_ce_dn_5: 0.2  loss_mask_dn_5: 0.04781  loss_dice_dn_5: 0.5071  loss_bbox_dn_5: 0.04671  loss_giou_dn_5: 0.2496  loss_ce_6: 0.805  loss_mask_6: 0.04567  loss_dice_6: 0.4981  loss_bbox_6: 0.05305  loss_giou_6: 0.2632  loss_ce_dn_6: 0.2013  loss_mask_dn_6: 0.04788  loss_dice_dn_6: 0.4793  loss_bbox_dn_6: 0.04758  loss_giou_dn_6: 0.2508  loss_ce_7: 0.8141  loss_mask_7: 0.04885  loss_dice_7: 0.5708  loss_bbox_7: 0.0524  loss_giou_7: 0.2656  loss_ce_dn_7: 0.1898  loss_mask_dn_7: 0.04546  loss_dice_dn_7: 0.5019  loss_bbox_dn_7: 0.04655  loss_giou_dn_7: 0.2346  loss_ce_8: 0.864  loss_mask_8: 0.04633  loss_dice_8: 0.4551  loss_bbox_8: 0.05346  loss_giou_8: 0.2335  loss_ce_dn_8: 0.186  loss_mask_dn_8: 0.04664  loss_dice_dn_8: 0.5026  loss_bbox_dn_8: 0.0462  loss_giou_dn_8: 0.2419  loss_ce_interm: 1.269  loss_mask_interm: 0.05392  loss_dice_interm: 0.5212  loss_bbox_interm: 0.08673  loss_giou_interm: 0.335  time: 1.8706  data_time: 0.1219  lr: 1e-06  max_mem: 6663M\n",
            "[05/20 18:35:02 d2.utils.events]:  eta: 0:43:54  iter: 4099  total_loss: 54.71  loss_ce: 1.069  loss_mask: 0.03586  loss_dice: 1.029  loss_bbox: 0.1122  loss_giou: 0.6299  loss_ce_dn: 0.1878  loss_mask_dn: 0.03388  loss_dice_dn: 0.8128  loss_bbox_dn: 0.05029  loss_giou_dn: 0.4185  loss_ce_0: 1.478  loss_mask_0: 0.0298  loss_dice_0: 0.7768  loss_bbox_0: 0.08846  loss_giou_0: 0.7175  loss_ce_dn_0: 0.7961  loss_mask_dn_0: 0.09466  loss_dice_dn_0: 2.695  loss_bbox_dn_0: 0.208  loss_giou_dn_0: 0.8603  loss_ce_1: 1.474  loss_mask_1: 0.0313  loss_dice_1: 1.077  loss_bbox_1: 0.1019  loss_giou_1: 0.5689  loss_ce_dn_1: 0.2928  loss_mask_dn_1: 0.03403  loss_dice_dn_1: 0.9499  loss_bbox_dn_1: 0.07292  loss_giou_dn_1: 0.4592  loss_ce_2: 1.344  loss_mask_2: 0.03742  loss_dice_2: 0.931  loss_bbox_2: 0.112  loss_giou_2: 0.6254  loss_ce_dn_2: 0.225  loss_mask_dn_2: 0.03328  loss_dice_dn_2: 0.8379  loss_bbox_dn_2: 0.06241  loss_giou_dn_2: 0.4099  loss_ce_3: 1.308  loss_mask_3: 0.03608  loss_dice_3: 0.8357  loss_bbox_3: 0.09277  loss_giou_3: 0.5874  loss_ce_dn_3: 0.2073  loss_mask_dn_3: 0.03421  loss_dice_dn_3: 0.8214  loss_bbox_dn_3: 0.05948  loss_giou_dn_3: 0.4142  loss_ce_4: 1.225  loss_mask_4: 0.03637  loss_dice_4: 0.9616  loss_bbox_4: 0.1033  loss_giou_4: 0.5998  loss_ce_dn_4: 0.2032  loss_mask_dn_4: 0.03602  loss_dice_dn_4: 0.8745  loss_bbox_dn_4: 0.05618  loss_giou_dn_4: 0.4146  loss_ce_5: 1.13  loss_mask_5: 0.03066  loss_dice_5: 0.8384  loss_bbox_5: 0.1197  loss_giou_5: 0.601  loss_ce_dn_5: 0.1908  loss_mask_dn_5: 0.03683  loss_dice_dn_5: 0.8547  loss_bbox_dn_5: 0.05314  loss_giou_dn_5: 0.4259  loss_ce_6: 1.088  loss_mask_6: 0.03826  loss_dice_6: 0.7004  loss_bbox_6: 0.1219  loss_giou_6: 0.5642  loss_ce_dn_6: 0.1852  loss_mask_dn_6: 0.03545  loss_dice_dn_6: 0.8847  loss_bbox_dn_6: 0.05346  loss_giou_dn_6: 0.4237  loss_ce_7: 1.158  loss_mask_7: 0.03408  loss_dice_7: 0.767  loss_bbox_7: 0.116  loss_giou_7: 0.5816  loss_ce_dn_7: 0.1807  loss_mask_dn_7: 0.03448  loss_dice_dn_7: 0.8798  loss_bbox_dn_7: 0.05316  loss_giou_dn_7: 0.4258  loss_ce_8: 1.079  loss_mask_8: 0.03282  loss_dice_8: 0.9672  loss_bbox_8: 0.1145  loss_giou_8: 0.5756  loss_ce_dn_8: 0.1837  loss_mask_dn_8: 0.03567  loss_dice_dn_8: 0.9376  loss_bbox_dn_8: 0.05091  loss_giou_dn_8: 0.4205  loss_ce_interm: 1.563  loss_mask_interm: 0.02536  loss_dice_interm: 0.7176  loss_bbox_interm: 0.1203  loss_giou_interm: 0.5997  time: 1.8697  data_time: 0.0766  lr: 1e-06  max_mem: 6663M\n",
            "[05/20 18:35:36 d2.utils.events]:  eta: 0:43:17  iter: 4119  total_loss: 36.93  loss_ce: 0.8722  loss_mask: 0.0355  loss_dice: 0.5336  loss_bbox: 0.06191  loss_giou: 0.3229  loss_ce_dn: 0.1707  loss_mask_dn: 0.04039  loss_dice_dn: 0.4241  loss_bbox_dn: 0.04111  loss_giou_dn: 0.2543  loss_ce_0: 1.183  loss_mask_0: 0.03835  loss_dice_0: 0.4601  loss_bbox_0: 0.06371  loss_giou_0: 0.4594  loss_ce_dn_0: 0.7912  loss_mask_dn_0: 0.115  loss_dice_dn_0: 1.914  loss_bbox_dn_0: 0.2341  loss_giou_dn_0: 0.8538  loss_ce_1: 1.202  loss_mask_1: 0.03761  loss_dice_1: 0.6363  loss_bbox_1: 0.06072  loss_giou_1: 0.369  loss_ce_dn_1: 0.2677  loss_mask_dn_1: 0.03933  loss_dice_dn_1: 0.501  loss_bbox_dn_1: 0.06522  loss_giou_dn_1: 0.406  loss_ce_2: 1.181  loss_mask_2: 0.03639  loss_dice_2: 0.3837  loss_bbox_2: 0.05391  loss_giou_2: 0.3497  loss_ce_dn_2: 0.2242  loss_mask_dn_2: 0.03924  loss_dice_dn_2: 0.5102  loss_bbox_dn_2: 0.05437  loss_giou_dn_2: 0.3376  loss_ce_3: 0.9948  loss_mask_3: 0.0378  loss_dice_3: 0.5136  loss_bbox_3: 0.05813  loss_giou_3: 0.3536  loss_ce_dn_3: 0.2083  loss_mask_dn_3: 0.03985  loss_dice_dn_3: 0.4522  loss_bbox_dn_3: 0.05057  loss_giou_dn_3: 0.2895  loss_ce_4: 0.9521  loss_mask_4: 0.0379  loss_dice_4: 0.4407  loss_bbox_4: 0.06403  loss_giou_4: 0.3436  loss_ce_dn_4: 0.2044  loss_mask_dn_4: 0.04236  loss_dice_dn_4: 0.4503  loss_bbox_dn_4: 0.04436  loss_giou_dn_4: 0.2581  loss_ce_5: 0.8658  loss_mask_5: 0.04605  loss_dice_5: 0.4515  loss_bbox_5: 0.06208  loss_giou_5: 0.3318  loss_ce_dn_5: 0.1835  loss_mask_dn_5: 0.04162  loss_dice_dn_5: 0.4306  loss_bbox_dn_5: 0.04108  loss_giou_dn_5: 0.2595  loss_ce_6: 0.8735  loss_mask_6: 0.03684  loss_dice_6: 0.6545  loss_bbox_6: 0.06352  loss_giou_6: 0.3312  loss_ce_dn_6: 0.1734  loss_mask_dn_6: 0.04193  loss_dice_dn_6: 0.4673  loss_bbox_dn_6: 0.04084  loss_giou_dn_6: 0.2634  loss_ce_7: 0.859  loss_mask_7: 0.03541  loss_dice_7: 0.4285  loss_bbox_7: 0.06317  loss_giou_7: 0.3193  loss_ce_dn_7: 0.1718  loss_mask_dn_7: 0.04043  loss_dice_dn_7: 0.4335  loss_bbox_dn_7: 0.03934  loss_giou_dn_7: 0.2567  loss_ce_8: 0.8725  loss_mask_8: 0.04286  loss_dice_8: 0.3572  loss_bbox_8: 0.06473  loss_giou_8: 0.4029  loss_ce_dn_8: 0.1724  loss_mask_dn_8: 0.04052  loss_dice_dn_8: 0.4296  loss_bbox_dn_8: 0.04086  loss_giou_dn_8: 0.2561  loss_ce_interm: 1.258  loss_mask_interm: 0.04213  loss_dice_interm: 0.5023  loss_bbox_interm: 0.09752  loss_giou_interm: 0.4079  time: 1.8688  data_time: 0.0859  lr: 1e-06  max_mem: 6663M\n",
            "[05/20 18:36:10 d2.utils.events]:  eta: 0:42:38  iter: 4139  total_loss: 43.46  loss_ce: 0.8761  loss_mask: 0.05415  loss_dice: 0.6507  loss_bbox: 0.06939  loss_giou: 0.4113  loss_ce_dn: 0.2158  loss_mask_dn: 0.04173  loss_dice_dn: 0.5218  loss_bbox_dn: 0.04136  loss_giou_dn: 0.3112  loss_ce_0: 1.352  loss_mask_0: 0.06701  loss_dice_0: 0.4922  loss_bbox_0: 0.08411  loss_giou_0: 0.4821  loss_ce_dn_0: 0.6548  loss_mask_dn_0: 0.1219  loss_dice_dn_0: 2.026  loss_bbox_dn_0: 0.2563  loss_giou_dn_0: 0.8552  loss_ce_1: 1.21  loss_mask_1: 0.05332  loss_dice_1: 0.6322  loss_bbox_1: 0.07361  loss_giou_1: 0.4409  loss_ce_dn_1: 0.2867  loss_mask_dn_1: 0.05271  loss_dice_dn_1: 0.5598  loss_bbox_dn_1: 0.06727  loss_giou_dn_1: 0.3594  loss_ce_2: 1.075  loss_mask_2: 0.05588  loss_dice_2: 0.501  loss_bbox_2: 0.07658  loss_giou_2: 0.411  loss_ce_dn_2: 0.2528  loss_mask_dn_2: 0.03907  loss_dice_dn_2: 0.5338  loss_bbox_dn_2: 0.05398  loss_giou_dn_2: 0.327  loss_ce_3: 0.9881  loss_mask_3: 0.05073  loss_dice_3: 0.4329  loss_bbox_3: 0.06728  loss_giou_3: 0.3882  loss_ce_dn_3: 0.2391  loss_mask_dn_3: 0.04132  loss_dice_dn_3: 0.5428  loss_bbox_dn_3: 0.04748  loss_giou_dn_3: 0.3147  loss_ce_4: 0.9599  loss_mask_4: 0.05247  loss_dice_4: 0.5832  loss_bbox_4: 0.07169  loss_giou_4: 0.3886  loss_ce_dn_4: 0.2289  loss_mask_dn_4: 0.03805  loss_dice_dn_4: 0.5625  loss_bbox_dn_4: 0.04564  loss_giou_dn_4: 0.3263  loss_ce_5: 0.8845  loss_mask_5: 0.05318  loss_dice_5: 0.6634  loss_bbox_5: 0.07125  loss_giou_5: 0.394  loss_ce_dn_5: 0.2288  loss_mask_dn_5: 0.04011  loss_dice_dn_5: 0.5265  loss_bbox_dn_5: 0.04248  loss_giou_dn_5: 0.3173  loss_ce_6: 0.8639  loss_mask_6: 0.04895  loss_dice_6: 0.5812  loss_bbox_6: 0.07327  loss_giou_6: 0.3951  loss_ce_dn_6: 0.2141  loss_mask_dn_6: 0.04151  loss_dice_dn_6: 0.5229  loss_bbox_dn_6: 0.04203  loss_giou_dn_6: 0.3147  loss_ce_7: 0.8579  loss_mask_7: 0.05137  loss_dice_7: 0.4239  loss_bbox_7: 0.07152  loss_giou_7: 0.422  loss_ce_dn_7: 0.2143  loss_mask_dn_7: 0.03997  loss_dice_dn_7: 0.5253  loss_bbox_dn_7: 0.04174  loss_giou_dn_7: 0.3144  loss_ce_8: 0.8809  loss_mask_8: 0.04924  loss_dice_8: 0.5829  loss_bbox_8: 0.07473  loss_giou_8: 0.4201  loss_ce_dn_8: 0.2178  loss_mask_dn_8: 0.04334  loss_dice_dn_8: 0.541  loss_bbox_dn_8: 0.04165  loss_giou_dn_8: 0.311  loss_ce_interm: 1.475  loss_mask_interm: 0.05894  loss_dice_interm: 0.6834  loss_bbox_interm: 0.118  loss_giou_interm: 0.5176  time: 1.8680  data_time: 0.0659  lr: 1e-06  max_mem: 6663M\n",
            "[05/20 18:36:43 d2.utils.events]:  eta: 0:41:59  iter: 4159  total_loss: 37.41  loss_ce: 0.9327  loss_mask: 0.04356  loss_dice: 0.5159  loss_bbox: 0.04237  loss_giou: 0.2469  loss_ce_dn: 0.1844  loss_mask_dn: 0.04092  loss_dice_dn: 0.5585  loss_bbox_dn: 0.04519  loss_giou_dn: 0.2515  loss_ce_0: 1.194  loss_mask_0: 0.03738  loss_dice_0: 0.5061  loss_bbox_0: 0.06088  loss_giou_0: 0.3612  loss_ce_dn_0: 0.7029  loss_mask_dn_0: 0.1677  loss_dice_dn_0: 2.651  loss_bbox_dn_0: 0.273  loss_giou_dn_0: 0.8538  loss_ce_1: 1.217  loss_mask_1: 0.04828  loss_dice_1: 0.5629  loss_bbox_1: 0.04988  loss_giou_1: 0.3492  loss_ce_dn_1: 0.2572  loss_mask_dn_1: 0.03441  loss_dice_dn_1: 0.5947  loss_bbox_dn_1: 0.08118  loss_giou_dn_1: 0.3532  loss_ce_2: 1.138  loss_mask_2: 0.05008  loss_dice_2: 0.6276  loss_bbox_2: 0.04404  loss_giou_2: 0.2729  loss_ce_dn_2: 0.2241  loss_mask_dn_2: 0.03582  loss_dice_dn_2: 0.5683  loss_bbox_dn_2: 0.06201  loss_giou_dn_2: 0.3004  loss_ce_3: 1.027  loss_mask_3: 0.03578  loss_dice_3: 0.5864  loss_bbox_3: 0.03988  loss_giou_3: 0.2576  loss_ce_dn_3: 0.2009  loss_mask_dn_3: 0.04063  loss_dice_dn_3: 0.5711  loss_bbox_dn_3: 0.05034  loss_giou_dn_3: 0.2745  loss_ce_4: 0.9134  loss_mask_4: 0.0431  loss_dice_4: 0.5321  loss_bbox_4: 0.0404  loss_giou_4: 0.2525  loss_ce_dn_4: 0.1879  loss_mask_dn_4: 0.03986  loss_dice_dn_4: 0.5647  loss_bbox_dn_4: 0.04812  loss_giou_dn_4: 0.2657  loss_ce_5: 0.9035  loss_mask_5: 0.04679  loss_dice_5: 0.4931  loss_bbox_5: 0.04049  loss_giou_5: 0.2571  loss_ce_dn_5: 0.188  loss_mask_dn_5: 0.04087  loss_dice_dn_5: 0.552  loss_bbox_dn_5: 0.04492  loss_giou_dn_5: 0.2487  loss_ce_6: 0.9028  loss_mask_6: 0.0397  loss_dice_6: 0.5027  loss_bbox_6: 0.04269  loss_giou_6: 0.2502  loss_ce_dn_6: 0.1857  loss_mask_dn_6: 0.03926  loss_dice_dn_6: 0.5401  loss_bbox_dn_6: 0.04635  loss_giou_dn_6: 0.258  loss_ce_7: 0.9208  loss_mask_7: 0.03759  loss_dice_7: 0.5912  loss_bbox_7: 0.04367  loss_giou_7: 0.246  loss_ce_dn_7: 0.1798  loss_mask_dn_7: 0.03919  loss_dice_dn_7: 0.5441  loss_bbox_dn_7: 0.04587  loss_giou_dn_7: 0.2508  loss_ce_8: 0.905  loss_mask_8: 0.04482  loss_dice_8: 0.5489  loss_bbox_8: 0.04167  loss_giou_8: 0.2454  loss_ce_dn_8: 0.1809  loss_mask_dn_8: 0.03912  loss_dice_dn_8: 0.5944  loss_bbox_dn_8: 0.04609  loss_giou_dn_8: 0.2509  loss_ce_interm: 1.183  loss_mask_interm: 0.04192  loss_dice_interm: 0.5899  loss_bbox_interm: 0.09803  loss_giou_interm: 0.4337  time: 1.8670  data_time: 0.0867  lr: 1e-06  max_mem: 6663M\n",
            "[05/20 18:37:17 d2.utils.events]:  eta: 0:41:27  iter: 4179  total_loss: 42.18  loss_ce: 0.9584  loss_mask: 0.02818  loss_dice: 0.4459  loss_bbox: 0.05165  loss_giou: 0.2851  loss_ce_dn: 0.1721  loss_mask_dn: 0.02983  loss_dice_dn: 0.548  loss_bbox_dn: 0.04061  loss_giou_dn: 0.2796  loss_ce_0: 1.024  loss_mask_0: 0.03091  loss_dice_0: 0.5246  loss_bbox_0: 0.05468  loss_giou_0: 0.3585  loss_ce_dn_0: 0.6934  loss_mask_dn_0: 0.1575  loss_dice_dn_0: 3.085  loss_bbox_dn_0: 0.2301  loss_giou_dn_0: 0.8575  loss_ce_1: 1.088  loss_mask_1: 0.0322  loss_dice_1: 0.5174  loss_bbox_1: 0.04834  loss_giou_1: 0.3186  loss_ce_dn_1: 0.2339  loss_mask_dn_1: 0.0309  loss_dice_dn_1: 0.5928  loss_bbox_dn_1: 0.06119  loss_giou_dn_1: 0.3536  loss_ce_2: 1.065  loss_mask_2: 0.02878  loss_dice_2: 0.5106  loss_bbox_2: 0.04873  loss_giou_2: 0.3137  loss_ce_dn_2: 0.1973  loss_mask_dn_2: 0.02797  loss_dice_dn_2: 0.5755  loss_bbox_dn_2: 0.05195  loss_giou_dn_2: 0.2801  loss_ce_3: 0.94  loss_mask_3: 0.02663  loss_dice_3: 0.5598  loss_bbox_3: 0.05123  loss_giou_3: 0.3255  loss_ce_dn_3: 0.1796  loss_mask_dn_3: 0.03  loss_dice_dn_3: 0.5374  loss_bbox_dn_3: 0.04313  loss_giou_dn_3: 0.2802  loss_ce_4: 0.9331  loss_mask_4: 0.0313  loss_dice_4: 0.4673  loss_bbox_4: 0.05348  loss_giou_4: 0.3114  loss_ce_dn_4: 0.1853  loss_mask_dn_4: 0.03035  loss_dice_dn_4: 0.5451  loss_bbox_dn_4: 0.04184  loss_giou_dn_4: 0.2756  loss_ce_5: 0.9016  loss_mask_5: 0.0295  loss_dice_5: 0.4712  loss_bbox_5: 0.05017  loss_giou_5: 0.2992  loss_ce_dn_5: 0.1809  loss_mask_dn_5: 0.02872  loss_dice_dn_5: 0.5431  loss_bbox_dn_5: 0.04094  loss_giou_dn_5: 0.2733  loss_ce_6: 0.936  loss_mask_6: 0.02978  loss_dice_6: 0.6012  loss_bbox_6: 0.05952  loss_giou_6: 0.2862  loss_ce_dn_6: 0.166  loss_mask_dn_6: 0.02861  loss_dice_dn_6: 0.5267  loss_bbox_dn_6: 0.04093  loss_giou_dn_6: 0.2684  loss_ce_7: 0.9472  loss_mask_7: 0.02961  loss_dice_7: 0.451  loss_bbox_7: 0.05533  loss_giou_7: 0.2892  loss_ce_dn_7: 0.1716  loss_mask_dn_7: 0.02965  loss_dice_dn_7: 0.5447  loss_bbox_dn_7: 0.0408  loss_giou_dn_7: 0.2731  loss_ce_8: 0.9509  loss_mask_8: 0.02934  loss_dice_8: 0.5704  loss_bbox_8: 0.05567  loss_giou_8: 0.292  loss_ce_dn_8: 0.1774  loss_mask_dn_8: 0.03024  loss_dice_dn_8: 0.5559  loss_bbox_dn_8: 0.04045  loss_giou_dn_8: 0.276  loss_ce_interm: 1.081  loss_mask_interm: 0.02926  loss_dice_interm: 0.5564  loss_bbox_interm: 0.07706  loss_giou_interm: 0.4204  time: 1.8661  data_time: 0.0718  lr: 1e-06  max_mem: 6663M\n",
            "[05/20 18:37:52 d2.utils.events]:  eta: 0:40:55  iter: 4199  total_loss: 42.87  loss_ce: 0.9454  loss_mask: 0.02676  loss_dice: 0.3936  loss_bbox: 0.06866  loss_giou: 0.2174  loss_ce_dn: 0.181  loss_mask_dn: 0.02703  loss_dice_dn: 0.4845  loss_bbox_dn: 0.03444  loss_giou_dn: 0.2466  loss_ce_0: 1.125  loss_mask_0: 0.03198  loss_dice_0: 0.4483  loss_bbox_0: 0.08942  loss_giou_0: 0.3352  loss_ce_dn_0: 0.7521  loss_mask_dn_0: 0.1106  loss_dice_dn_0: 2.399  loss_bbox_dn_0: 0.304  loss_giou_dn_0: 0.8432  loss_ce_1: 1.119  loss_mask_1: 0.03393  loss_dice_1: 0.5268  loss_bbox_1: 0.08097  loss_giou_1: 0.3078  loss_ce_dn_1: 0.3111  loss_mask_dn_1: 0.03602  loss_dice_dn_1: 0.4949  loss_bbox_dn_1: 0.08711  loss_giou_dn_1: 0.334  loss_ce_2: 1.07  loss_mask_2: 0.03197  loss_dice_2: 0.4322  loss_bbox_2: 0.08518  loss_giou_2: 0.2808  loss_ce_dn_2: 0.2561  loss_mask_dn_2: 0.02858  loss_dice_dn_2: 0.5109  loss_bbox_dn_2: 0.0499  loss_giou_dn_2: 0.2711  loss_ce_3: 1.017  loss_mask_3: 0.03239  loss_dice_3: 0.4156  loss_bbox_3: 0.09097  loss_giou_3: 0.3118  loss_ce_dn_3: 0.2332  loss_mask_dn_3: 0.02795  loss_dice_dn_3: 0.4836  loss_bbox_dn_3: 0.04175  loss_giou_dn_3: 0.2681  loss_ce_4: 1.003  loss_mask_4: 0.03196  loss_dice_4: 0.6165  loss_bbox_4: 0.09527  loss_giou_4: 0.2698  loss_ce_dn_4: 0.2039  loss_mask_dn_4: 0.02787  loss_dice_dn_4: 0.4936  loss_bbox_dn_4: 0.03669  loss_giou_dn_4: 0.2551  loss_ce_5: 1.044  loss_mask_5: 0.0265  loss_dice_5: 0.3966  loss_bbox_5: 0.07289  loss_giou_5: 0.2223  loss_ce_dn_5: 0.2039  loss_mask_dn_5: 0.02643  loss_dice_dn_5: 0.4765  loss_bbox_dn_5: 0.03829  loss_giou_dn_5: 0.2521  loss_ce_6: 0.9998  loss_mask_6: 0.02678  loss_dice_6: 0.438  loss_bbox_6: 0.08898  loss_giou_6: 0.2179  loss_ce_dn_6: 0.1885  loss_mask_dn_6: 0.02745  loss_dice_dn_6: 0.5043  loss_bbox_dn_6: 0.03751  loss_giou_dn_6: 0.2477  loss_ce_7: 0.9507  loss_mask_7: 0.02743  loss_dice_7: 0.4347  loss_bbox_7: 0.08851  loss_giou_7: 0.2152  loss_ce_dn_7: 0.1842  loss_mask_dn_7: 0.02894  loss_dice_dn_7: 0.4468  loss_bbox_dn_7: 0.03825  loss_giou_dn_7: 0.2495  loss_ce_8: 0.9537  loss_mask_8: 0.02772  loss_dice_8: 0.3617  loss_bbox_8: 0.07971  loss_giou_8: 0.2029  loss_ce_dn_8: 0.1784  loss_mask_dn_8: 0.02735  loss_dice_dn_8: 0.4661  loss_bbox_dn_8: 0.03719  loss_giou_dn_8: 0.2445  loss_ce_interm: 1.188  loss_mask_interm: 0.02773  loss_dice_interm: 0.5057  loss_bbox_interm: 0.09272  loss_giou_interm: 0.3882  time: 1.8655  data_time: 0.1063  lr: 1e-06  max_mem: 6663M\n",
            "[05/20 18:38:26 d2.utils.events]:  eta: 0:40:24  iter: 4219  total_loss: 59.7  loss_ce: 1.101  loss_mask: 0.03915  loss_dice: 0.8256  loss_bbox: 0.07838  loss_giou: 0.8026  loss_ce_dn: 0.1407  loss_mask_dn: 0.04755  loss_dice_dn: 0.7079  loss_bbox_dn: 0.04756  loss_giou_dn: 0.4587  loss_ce_0: 1.405  loss_mask_0: 0.04068  loss_dice_0: 1.313  loss_bbox_0: 0.11  loss_giou_0: 0.7869  loss_ce_dn_0: 0.7571  loss_mask_dn_0: 0.1732  loss_dice_dn_0: 2.576  loss_bbox_dn_0: 0.2898  loss_giou_dn_0: 0.8587  loss_ce_1: 1.437  loss_mask_1: 0.05633  loss_dice_1: 1.014  loss_bbox_1: 0.08383  loss_giou_1: 0.8929  loss_ce_dn_1: 0.2536  loss_mask_dn_1: 0.049  loss_dice_dn_1: 0.8701  loss_bbox_dn_1: 0.1001  loss_giou_dn_1: 0.5314  loss_ce_2: 1.296  loss_mask_2: 0.04098  loss_dice_2: 1.084  loss_bbox_2: 0.08174  loss_giou_2: 0.7902  loss_ce_dn_2: 0.213  loss_mask_dn_2: 0.03892  loss_dice_dn_2: 0.8375  loss_bbox_dn_2: 0.06954  loss_giou_dn_2: 0.4795  loss_ce_3: 1.103  loss_mask_3: 0.04601  loss_dice_3: 0.6113  loss_bbox_3: 0.07949  loss_giou_3: 0.7582  loss_ce_dn_3: 0.1918  loss_mask_dn_3: 0.0414  loss_dice_dn_3: 0.8235  loss_bbox_dn_3: 0.05333  loss_giou_dn_3: 0.4669  loss_ce_4: 1.104  loss_mask_4: 0.04223  loss_dice_4: 1  loss_bbox_4: 0.08593  loss_giou_4: 0.7641  loss_ce_dn_4: 0.1872  loss_mask_dn_4: 0.04445  loss_dice_dn_4: 0.7864  loss_bbox_dn_4: 0.05101  loss_giou_dn_4: 0.4692  loss_ce_5: 1.141  loss_mask_5: 0.0347  loss_dice_5: 0.9237  loss_bbox_5: 0.08012  loss_giou_5: 0.8234  loss_ce_dn_5: 0.1727  loss_mask_dn_5: 0.04303  loss_dice_dn_5: 0.7487  loss_bbox_dn_5: 0.04938  loss_giou_dn_5: 0.4668  loss_ce_6: 1.011  loss_mask_6: 0.03377  loss_dice_6: 0.6696  loss_bbox_6: 0.07928  loss_giou_6: 0.8576  loss_ce_dn_6: 0.1555  loss_mask_dn_6: 0.04094  loss_dice_dn_6: 0.7378  loss_bbox_dn_6: 0.05019  loss_giou_dn_6: 0.465  loss_ce_7: 1.102  loss_mask_7: 0.03635  loss_dice_7: 0.7894  loss_bbox_7: 0.08795  loss_giou_7: 0.8552  loss_ce_dn_7: 0.1489  loss_mask_dn_7: 0.04602  loss_dice_dn_7: 0.7384  loss_bbox_dn_7: 0.0471  loss_giou_dn_7: 0.4581  loss_ce_8: 1.101  loss_mask_8: 0.04766  loss_dice_8: 0.7056  loss_bbox_8: 0.0903  loss_giou_8: 0.7863  loss_ce_dn_8: 0.1398  loss_mask_dn_8: 0.04582  loss_dice_dn_8: 0.7908  loss_bbox_dn_8: 0.04764  loss_giou_dn_8: 0.4573  loss_ce_interm: 1.418  loss_mask_interm: 0.04449  loss_dice_interm: 1.103  loss_bbox_interm: 0.09807  loss_giou_interm: 0.7908  time: 1.8648  data_time: 0.0791  lr: 1e-06  max_mem: 6663M\n",
            "[05/20 18:39:00 d2.utils.events]:  eta: 0:39:55  iter: 4239  total_loss: 44.4  loss_ce: 1.042  loss_mask: 0.02996  loss_dice: 0.5579  loss_bbox: 0.05221  loss_giou: 0.2938  loss_ce_dn: 0.2363  loss_mask_dn: 0.03221  loss_dice_dn: 0.6337  loss_bbox_dn: 0.04632  loss_giou_dn: 0.297  loss_ce_0: 1.306  loss_mask_0: 0.03228  loss_dice_0: 0.6522  loss_bbox_0: 0.07227  loss_giou_0: 0.3431  loss_ce_dn_0: 0.7858  loss_mask_dn_0: 0.2798  loss_dice_dn_0: 2.979  loss_bbox_dn_0: 0.2869  loss_giou_dn_0: 0.8568  loss_ce_1: 1.28  loss_mask_1: 0.03273  loss_dice_1: 0.6512  loss_bbox_1: 0.06012  loss_giou_1: 0.3155  loss_ce_dn_1: 0.2933  loss_mask_dn_1: 0.03297  loss_dice_dn_1: 0.654  loss_bbox_dn_1: 0.07436  loss_giou_dn_1: 0.4018  loss_ce_2: 1.18  loss_mask_2: 0.03711  loss_dice_2: 0.5804  loss_bbox_2: 0.07086  loss_giou_2: 0.3193  loss_ce_dn_2: 0.2469  loss_mask_dn_2: 0.03214  loss_dice_dn_2: 0.6279  loss_bbox_dn_2: 0.05509  loss_giou_dn_2: 0.3466  loss_ce_3: 1.099  loss_mask_3: 0.03538  loss_dice_3: 0.7092  loss_bbox_3: 0.06662  loss_giou_3: 0.3457  loss_ce_dn_3: 0.2358  loss_mask_dn_3: 0.0323  loss_dice_dn_3: 0.621  loss_bbox_dn_3: 0.05169  loss_giou_dn_3: 0.318  loss_ce_4: 1.127  loss_mask_4: 0.02959  loss_dice_4: 0.7284  loss_bbox_4: 0.05607  loss_giou_4: 0.3381  loss_ce_dn_4: 0.2367  loss_mask_dn_4: 0.03127  loss_dice_dn_4: 0.6185  loss_bbox_dn_4: 0.04814  loss_giou_dn_4: 0.3062  loss_ce_5: 1.032  loss_mask_5: 0.03034  loss_dice_5: 0.6984  loss_bbox_5: 0.05103  loss_giou_5: 0.3139  loss_ce_dn_5: 0.2372  loss_mask_dn_5: 0.03012  loss_dice_dn_5: 0.6407  loss_bbox_dn_5: 0.04481  loss_giou_dn_5: 0.2996  loss_ce_6: 1.03  loss_mask_6: 0.03292  loss_dice_6: 0.7144  loss_bbox_6: 0.05238  loss_giou_6: 0.306  loss_ce_dn_6: 0.2282  loss_mask_dn_6: 0.03001  loss_dice_dn_6: 0.6016  loss_bbox_dn_6: 0.04626  loss_giou_dn_6: 0.2976  loss_ce_7: 1.067  loss_mask_7: 0.03277  loss_dice_7: 0.5319  loss_bbox_7: 0.05252  loss_giou_7: 0.3055  loss_ce_dn_7: 0.2328  loss_mask_dn_7: 0.02962  loss_dice_dn_7: 0.6445  loss_bbox_dn_7: 0.04505  loss_giou_dn_7: 0.2999  loss_ce_8: 1.048  loss_mask_8: 0.03216  loss_dice_8: 0.5837  loss_bbox_8: 0.05263  loss_giou_8: 0.2987  loss_ce_dn_8: 0.2358  loss_mask_dn_8: 0.03172  loss_dice_dn_8: 0.6551  loss_bbox_dn_8: 0.04691  loss_giou_dn_8: 0.2988  loss_ce_interm: 1.345  loss_mask_interm: 0.03264  loss_dice_interm: 0.54  loss_bbox_interm: 0.09143  loss_giou_interm: 0.3834  time: 1.8639  data_time: 0.0562  lr: 1e-06  max_mem: 6663M\n",
            "[05/20 18:39:35 d2.utils.events]:  eta: 0:39:27  iter: 4259  total_loss: 53.38  loss_ce: 1.145  loss_mask: 0.03373  loss_dice: 0.8119  loss_bbox: 0.06486  loss_giou: 0.4876  loss_ce_dn: 0.2311  loss_mask_dn: 0.02982  loss_dice_dn: 0.7463  loss_bbox_dn: 0.03491  loss_giou_dn: 0.3856  loss_ce_0: 1.364  loss_mask_0: 0.03759  loss_dice_0: 0.8461  loss_bbox_0: 0.08622  loss_giou_0: 0.6585  loss_ce_dn_0: 0.7576  loss_mask_dn_0: 0.1167  loss_dice_dn_0: 2.609  loss_bbox_dn_0: 0.1959  loss_giou_dn_0: 0.8622  loss_ce_1: 1.281  loss_mask_1: 0.03753  loss_dice_1: 0.7979  loss_bbox_1: 0.07893  loss_giou_1: 0.537  loss_ce_dn_1: 0.2948  loss_mask_dn_1: 0.0284  loss_dice_dn_1: 0.8468  loss_bbox_dn_1: 0.05713  loss_giou_dn_1: 0.4731  loss_ce_2: 1.236  loss_mask_2: 0.03619  loss_dice_2: 0.8238  loss_bbox_2: 0.06794  loss_giou_2: 0.5406  loss_ce_dn_2: 0.2725  loss_mask_dn_2: 0.02884  loss_dice_dn_2: 0.7951  loss_bbox_dn_2: 0.04371  loss_giou_dn_2: 0.409  loss_ce_3: 1.243  loss_mask_3: 0.04083  loss_dice_3: 0.808  loss_bbox_3: 0.06657  loss_giou_3: 0.5193  loss_ce_dn_3: 0.2584  loss_mask_dn_3: 0.02775  loss_dice_dn_3: 0.7975  loss_bbox_dn_3: 0.038  loss_giou_dn_3: 0.3981  loss_ce_4: 1.11  loss_mask_4: 0.0389  loss_dice_4: 0.725  loss_bbox_4: 0.06752  loss_giou_4: 0.5842  loss_ce_dn_4: 0.2363  loss_mask_dn_4: 0.02884  loss_dice_dn_4: 0.7721  loss_bbox_dn_4: 0.0354  loss_giou_dn_4: 0.3934  loss_ce_5: 1.231  loss_mask_5: 0.03727  loss_dice_5: 0.9148  loss_bbox_5: 0.07027  loss_giou_5: 0.4929  loss_ce_dn_5: 0.2435  loss_mask_dn_5: 0.0297  loss_dice_dn_5: 0.7438  loss_bbox_dn_5: 0.03496  loss_giou_dn_5: 0.392  loss_ce_6: 1.121  loss_mask_6: 0.03578  loss_dice_6: 0.8863  loss_bbox_6: 0.06445  loss_giou_6: 0.4842  loss_ce_dn_6: 0.229  loss_mask_dn_6: 0.03065  loss_dice_dn_6: 0.7907  loss_bbox_dn_6: 0.03496  loss_giou_dn_6: 0.3898  loss_ce_7: 1.109  loss_mask_7: 0.03424  loss_dice_7: 0.841  loss_bbox_7: 0.06672  loss_giou_7: 0.5509  loss_ce_dn_7: 0.2336  loss_mask_dn_7: 0.03048  loss_dice_dn_7: 0.7863  loss_bbox_dn_7: 0.03455  loss_giou_dn_7: 0.3855  loss_ce_8: 1.129  loss_mask_8: 0.03364  loss_dice_8: 0.8926  loss_bbox_8: 0.05933  loss_giou_8: 0.4922  loss_ce_dn_8: 0.2336  loss_mask_dn_8: 0.03015  loss_dice_dn_8: 0.7644  loss_bbox_dn_8: 0.03465  loss_giou_dn_8: 0.3867  loss_ce_interm: 1.416  loss_mask_interm: 0.03112  loss_dice_interm: 0.8165  loss_bbox_interm: 0.0834  loss_giou_interm: 0.6706  time: 1.8634  data_time: 0.0892  lr: 1e-06  max_mem: 6663M\n",
            "[05/20 18:40:09 d2.utils.events]:  eta: 0:38:56  iter: 4279  total_loss: 40.82  loss_ce: 0.9144  loss_mask: 0.03152  loss_dice: 0.4791  loss_bbox: 0.06177  loss_giou: 0.2882  loss_ce_dn: 0.1797  loss_mask_dn: 0.02977  loss_dice_dn: 0.7013  loss_bbox_dn: 0.03588  loss_giou_dn: 0.2523  loss_ce_0: 1.234  loss_mask_0: 0.0355  loss_dice_0: 0.6497  loss_bbox_0: 0.05323  loss_giou_0: 0.3223  loss_ce_dn_0: 0.7651  loss_mask_dn_0: 0.1743  loss_dice_dn_0: 2.084  loss_bbox_dn_0: 0.302  loss_giou_dn_0: 0.8532  loss_ce_1: 1.099  loss_mask_1: 0.03192  loss_dice_1: 0.4449  loss_bbox_1: 0.06114  loss_giou_1: 0.2634  loss_ce_dn_1: 0.2645  loss_mask_dn_1: 0.02942  loss_dice_dn_1: 0.7625  loss_bbox_dn_1: 0.06481  loss_giou_dn_1: 0.3439  loss_ce_2: 1.088  loss_mask_2: 0.03501  loss_dice_2: 0.4968  loss_bbox_2: 0.06335  loss_giou_2: 0.3317  loss_ce_dn_2: 0.2431  loss_mask_dn_2: 0.03156  loss_dice_dn_2: 0.7283  loss_bbox_dn_2: 0.04347  loss_giou_dn_2: 0.2885  loss_ce_3: 0.9436  loss_mask_3: 0.03321  loss_dice_3: 0.5458  loss_bbox_3: 0.05921  loss_giou_3: 0.3569  loss_ce_dn_3: 0.2286  loss_mask_dn_3: 0.03044  loss_dice_dn_3: 0.7004  loss_bbox_dn_3: 0.04097  loss_giou_dn_3: 0.2652  loss_ce_4: 0.932  loss_mask_4: 0.03807  loss_dice_4: 0.5048  loss_bbox_4: 0.05763  loss_giou_4: 0.2947  loss_ce_dn_4: 0.2032  loss_mask_dn_4: 0.03064  loss_dice_dn_4: 0.7295  loss_bbox_dn_4: 0.0396  loss_giou_dn_4: 0.2539  loss_ce_5: 0.9391  loss_mask_5: 0.03647  loss_dice_5: 0.6184  loss_bbox_5: 0.05633  loss_giou_5: 0.2977  loss_ce_dn_5: 0.1931  loss_mask_dn_5: 0.02962  loss_dice_dn_5: 0.7195  loss_bbox_dn_5: 0.03648  loss_giou_dn_5: 0.2591  loss_ce_6: 0.9263  loss_mask_6: 0.0351  loss_dice_6: 0.4643  loss_bbox_6: 0.05648  loss_giou_6: 0.2932  loss_ce_dn_6: 0.1857  loss_mask_dn_6: 0.0298  loss_dice_dn_6: 0.758  loss_bbox_dn_6: 0.03647  loss_giou_dn_6: 0.2533  loss_ce_7: 0.9509  loss_mask_7: 0.03608  loss_dice_7: 0.4489  loss_bbox_7: 0.05877  loss_giou_7: 0.2956  loss_ce_dn_7: 0.181  loss_mask_dn_7: 0.03125  loss_dice_dn_7: 0.7486  loss_bbox_dn_7: 0.0357  loss_giou_dn_7: 0.2537  loss_ce_8: 0.8625  loss_mask_8: 0.03022  loss_dice_8: 0.5048  loss_bbox_8: 0.05717  loss_giou_8: 0.2841  loss_ce_dn_8: 0.1781  loss_mask_dn_8: 0.03048  loss_dice_dn_8: 0.7515  loss_bbox_dn_8: 0.03646  loss_giou_dn_8: 0.2539  loss_ce_interm: 1.145  loss_mask_interm: 0.04113  loss_dice_interm: 0.6378  loss_bbox_interm: 0.08084  loss_giou_interm: 0.3209  time: 1.8625  data_time: 0.0583  lr: 1e-06  max_mem: 6663M\n",
            "[05/20 18:40:42 d2.utils.events]:  eta: 0:38:23  iter: 4299  total_loss: 46.58  loss_ce: 0.958  loss_mask: 0.04809  loss_dice: 0.5754  loss_bbox: 0.08579  loss_giou: 0.3472  loss_ce_dn: 0.17  loss_mask_dn: 0.03878  loss_dice_dn: 0.6629  loss_bbox_dn: 0.0499  loss_giou_dn: 0.2618  loss_ce_0: 1.439  loss_mask_0: 0.04848  loss_dice_0: 0.7298  loss_bbox_0: 0.08533  loss_giou_0: 0.4688  loss_ce_dn_0: 0.6705  loss_mask_dn_0: 0.1692  loss_dice_dn_0: 2.389  loss_bbox_dn_0: 0.321  loss_giou_dn_0: 0.8563  loss_ce_1: 1.382  loss_mask_1: 0.05528  loss_dice_1: 0.6543  loss_bbox_1: 0.08315  loss_giou_1: 0.3783  loss_ce_dn_1: 0.2611  loss_mask_dn_1: 0.03987  loss_dice_dn_1: 0.6529  loss_bbox_dn_1: 0.06932  loss_giou_dn_1: 0.3542  loss_ce_2: 1.271  loss_mask_2: 0.04743  loss_dice_2: 0.7015  loss_bbox_2: 0.08119  loss_giou_2: 0.3682  loss_ce_dn_2: 0.2269  loss_mask_dn_2: 0.038  loss_dice_dn_2: 0.6271  loss_bbox_dn_2: 0.05636  loss_giou_dn_2: 0.3101  loss_ce_3: 1.214  loss_mask_3: 0.04926  loss_dice_3: 0.6566  loss_bbox_3: 0.07995  loss_giou_3: 0.3437  loss_ce_dn_3: 0.2006  loss_mask_dn_3: 0.0423  loss_dice_dn_3: 0.6316  loss_bbox_dn_3: 0.05186  loss_giou_dn_3: 0.2864  loss_ce_4: 1.148  loss_mask_4: 0.041  loss_dice_4: 0.6424  loss_bbox_4: 0.08276  loss_giou_4: 0.3355  loss_ce_dn_4: 0.1814  loss_mask_dn_4: 0.03967  loss_dice_dn_4: 0.6472  loss_bbox_dn_4: 0.05132  loss_giou_dn_4: 0.2896  loss_ce_5: 1.072  loss_mask_5: 0.05198  loss_dice_5: 0.6863  loss_bbox_5: 0.07271  loss_giou_5: 0.3533  loss_ce_dn_5: 0.1781  loss_mask_dn_5: 0.03886  loss_dice_dn_5: 0.6427  loss_bbox_dn_5: 0.05433  loss_giou_dn_5: 0.2748  loss_ce_6: 1.06  loss_mask_6: 0.04519  loss_dice_6: 0.7221  loss_bbox_6: 0.08471  loss_giou_6: 0.3398  loss_ce_dn_6: 0.1724  loss_mask_dn_6: 0.03754  loss_dice_dn_6: 0.6104  loss_bbox_dn_6: 0.05353  loss_giou_dn_6: 0.2734  loss_ce_7: 0.9941  loss_mask_7: 0.05112  loss_dice_7: 0.6115  loss_bbox_7: 0.08298  loss_giou_7: 0.3297  loss_ce_dn_7: 0.1706  loss_mask_dn_7: 0.03751  loss_dice_dn_7: 0.6088  loss_bbox_dn_7: 0.05041  loss_giou_dn_7: 0.2649  loss_ce_8: 0.9482  loss_mask_8: 0.04669  loss_dice_8: 0.6113  loss_bbox_8: 0.08602  loss_giou_8: 0.3426  loss_ce_dn_8: 0.1705  loss_mask_dn_8: 0.03773  loss_dice_dn_8: 0.6466  loss_bbox_dn_8: 0.05051  loss_giou_dn_8: 0.2614  loss_ce_interm: 1.227  loss_mask_interm: 0.04798  loss_dice_interm: 0.7832  loss_bbox_interm: 0.1055  loss_giou_interm: 0.4336  time: 1.8617  data_time: 0.0604  lr: 1e-06  max_mem: 6663M\n",
            "[05/20 18:41:19 d2.utils.events]:  eta: 0:37:54  iter: 4319  total_loss: 42.81  loss_ce: 0.7318  loss_mask: 0.03621  loss_dice: 0.6008  loss_bbox: 0.06265  loss_giou: 0.3266  loss_ce_dn: 0.1364  loss_mask_dn: 0.03661  loss_dice_dn: 0.5098  loss_bbox_dn: 0.03627  loss_giou_dn: 0.2875  loss_ce_0: 1.145  loss_mask_0: 0.03066  loss_dice_0: 0.5146  loss_bbox_0: 0.06962  loss_giou_0: 0.3996  loss_ce_dn_0: 0.7465  loss_mask_dn_0: 0.1329  loss_dice_dn_0: 2.333  loss_bbox_dn_0: 0.2109  loss_giou_dn_0: 0.8523  loss_ce_1: 1.153  loss_mask_1: 0.03434  loss_dice_1: 0.5097  loss_bbox_1: 0.08202  loss_giou_1: 0.3288  loss_ce_dn_1: 0.2875  loss_mask_dn_1: 0.03067  loss_dice_dn_1: 0.5225  loss_bbox_dn_1: 0.05106  loss_giou_dn_1: 0.3912  loss_ce_2: 1.088  loss_mask_2: 0.04131  loss_dice_2: 0.5018  loss_bbox_2: 0.07493  loss_giou_2: 0.3002  loss_ce_dn_2: 0.2293  loss_mask_dn_2: 0.03261  loss_dice_dn_2: 0.5211  loss_bbox_dn_2: 0.04331  loss_giou_dn_2: 0.3515  loss_ce_3: 0.8289  loss_mask_3: 0.03904  loss_dice_3: 0.5316  loss_bbox_3: 0.06896  loss_giou_3: 0.3288  loss_ce_dn_3: 0.1816  loss_mask_dn_3: 0.03592  loss_dice_dn_3: 0.5574  loss_bbox_dn_3: 0.03647  loss_giou_dn_3: 0.3255  loss_ce_4: 0.8199  loss_mask_4: 0.03637  loss_dice_4: 0.4579  loss_bbox_4: 0.06614  loss_giou_4: 0.3305  loss_ce_dn_4: 0.1585  loss_mask_dn_4: 0.03535  loss_dice_dn_4: 0.5214  loss_bbox_dn_4: 0.03617  loss_giou_dn_4: 0.3085  loss_ce_5: 0.7817  loss_mask_5: 0.03914  loss_dice_5: 0.622  loss_bbox_5: 0.05977  loss_giou_5: 0.32  loss_ce_dn_5: 0.1519  loss_mask_dn_5: 0.0346  loss_dice_dn_5: 0.4929  loss_bbox_dn_5: 0.03544  loss_giou_dn_5: 0.2985  loss_ce_6: 0.8667  loss_mask_6: 0.04019  loss_dice_6: 0.5199  loss_bbox_6: 0.07141  loss_giou_6: 0.319  loss_ce_dn_6: 0.1337  loss_mask_dn_6: 0.0342  loss_dice_dn_6: 0.5284  loss_bbox_dn_6: 0.03573  loss_giou_dn_6: 0.2994  loss_ce_7: 0.7045  loss_mask_7: 0.0346  loss_dice_7: 0.5367  loss_bbox_7: 0.06264  loss_giou_7: 0.3247  loss_ce_dn_7: 0.1393  loss_mask_dn_7: 0.03377  loss_dice_dn_7: 0.4919  loss_bbox_dn_7: 0.03596  loss_giou_dn_7: 0.294  loss_ce_8: 0.7316  loss_mask_8: 0.03625  loss_dice_8: 0.5386  loss_bbox_8: 0.06761  loss_giou_8: 0.3294  loss_ce_dn_8: 0.1389  loss_mask_dn_8: 0.03539  loss_dice_dn_8: 0.4748  loss_bbox_dn_8: 0.03603  loss_giou_dn_8: 0.2939  loss_ce_interm: 1.14  loss_mask_interm: 0.03355  loss_dice_interm: 0.6009  loss_bbox_interm: 0.1017  loss_giou_interm: 0.4719  time: 1.8611  data_time: 0.0500  lr: 1e-06  max_mem: 6663M\n",
            "[05/20 18:41:54 d2.utils.events]:  eta: 0:37:24  iter: 4339  total_loss: 43.99  loss_ce: 1.174  loss_mask: 0.03037  loss_dice: 0.7226  loss_bbox: 0.06782  loss_giou: 0.3679  loss_ce_dn: 0.1682  loss_mask_dn: 0.03153  loss_dice_dn: 0.5295  loss_bbox_dn: 0.04229  loss_giou_dn: 0.2993  loss_ce_0: 1.49  loss_mask_0: 0.04108  loss_dice_0: 0.6123  loss_bbox_0: 0.07919  loss_giou_0: 0.5718  loss_ce_dn_0: 0.7435  loss_mask_dn_0: 0.1024  loss_dice_dn_0: 2.311  loss_bbox_dn_0: 0.228  loss_giou_dn_0: 0.86  loss_ce_1: 1.514  loss_mask_1: 0.02688  loss_dice_1: 0.6092  loss_bbox_1: 0.06973  loss_giou_1: 0.4671  loss_ce_dn_1: 0.2735  loss_mask_dn_1: 0.03531  loss_dice_dn_1: 0.6744  loss_bbox_dn_1: 0.06555  loss_giou_dn_1: 0.3947  loss_ce_2: 1.361  loss_mask_2: 0.03205  loss_dice_2: 0.6555  loss_bbox_2: 0.07258  loss_giou_2: 0.3917  loss_ce_dn_2: 0.2654  loss_mask_dn_2: 0.03044  loss_dice_dn_2: 0.5857  loss_bbox_dn_2: 0.05309  loss_giou_dn_2: 0.3496  loss_ce_3: 1.243  loss_mask_3: 0.03644  loss_dice_3: 0.5345  loss_bbox_3: 0.06897  loss_giou_3: 0.344  loss_ce_dn_3: 0.2221  loss_mask_dn_3: 0.03064  loss_dice_dn_3: 0.5612  loss_bbox_dn_3: 0.04834  loss_giou_dn_3: 0.3143  loss_ce_4: 1.17  loss_mask_4: 0.03567  loss_dice_4: 0.5793  loss_bbox_4: 0.07184  loss_giou_4: 0.3474  loss_ce_dn_4: 0.1982  loss_mask_dn_4: 0.02865  loss_dice_dn_4: 0.5618  loss_bbox_dn_4: 0.04791  loss_giou_dn_4: 0.309  loss_ce_5: 1.156  loss_mask_5: 0.03672  loss_dice_5: 0.5306  loss_bbox_5: 0.07752  loss_giou_5: 0.3495  loss_ce_dn_5: 0.176  loss_mask_dn_5: 0.02944  loss_dice_dn_5: 0.5442  loss_bbox_dn_5: 0.04366  loss_giou_dn_5: 0.3036  loss_ce_6: 1.187  loss_mask_6: 0.03257  loss_dice_6: 0.6356  loss_bbox_6: 0.07596  loss_giou_6: 0.3572  loss_ce_dn_6: 0.1594  loss_mask_dn_6: 0.02949  loss_dice_dn_6: 0.5405  loss_bbox_dn_6: 0.04221  loss_giou_dn_6: 0.3003  loss_ce_7: 1.166  loss_mask_7: 0.03255  loss_dice_7: 0.5466  loss_bbox_7: 0.07526  loss_giou_7: 0.3422  loss_ce_dn_7: 0.1591  loss_mask_dn_7: 0.03189  loss_dice_dn_7: 0.5447  loss_bbox_dn_7: 0.04238  loss_giou_dn_7: 0.3034  loss_ce_8: 1.155  loss_mask_8: 0.03747  loss_dice_8: 0.5091  loss_bbox_8: 0.06978  loss_giou_8: 0.3545  loss_ce_dn_8: 0.1657  loss_mask_dn_8: 0.03085  loss_dice_dn_8: 0.5548  loss_bbox_dn_8: 0.0424  loss_giou_dn_8: 0.3017  loss_ce_interm: 1.49  loss_mask_interm: 0.03995  loss_dice_interm: 0.625  loss_bbox_interm: 0.09602  loss_giou_interm: 0.4815  time: 1.8606  data_time: 0.0568  lr: 1e-06  max_mem: 6663M\n",
            "[05/20 18:42:30 d2.utils.events]:  eta: 0:36:51  iter: 4359  total_loss: 42.78  loss_ce: 1.01  loss_mask: 0.03219  loss_dice: 0.5296  loss_bbox: 0.07873  loss_giou: 0.3804  loss_ce_dn: 0.1692  loss_mask_dn: 0.0343  loss_dice_dn: 0.5859  loss_bbox_dn: 0.04529  loss_giou_dn: 0.3323  loss_ce_0: 1.289  loss_mask_0: 0.03514  loss_dice_0: 0.6025  loss_bbox_0: 0.08859  loss_giou_0: 0.4402  loss_ce_dn_0: 0.8105  loss_mask_dn_0: 0.205  loss_dice_dn_0: 2.64  loss_bbox_dn_0: 0.3341  loss_giou_dn_0: 0.8601  loss_ce_1: 1.23  loss_mask_1: 0.03273  loss_dice_1: 0.5087  loss_bbox_1: 0.06939  loss_giou_1: 0.4088  loss_ce_dn_1: 0.3084  loss_mask_dn_1: 0.0378  loss_dice_dn_1: 0.6579  loss_bbox_dn_1: 0.08852  loss_giou_dn_1: 0.4129  loss_ce_2: 1.231  loss_mask_2: 0.03265  loss_dice_2: 0.6022  loss_bbox_2: 0.07378  loss_giou_2: 0.4124  loss_ce_dn_2: 0.2495  loss_mask_dn_2: 0.03427  loss_dice_dn_2: 0.572  loss_bbox_dn_2: 0.06423  loss_giou_dn_2: 0.3669  loss_ce_3: 1.141  loss_mask_3: 0.03558  loss_dice_3: 0.5965  loss_bbox_3: 0.09193  loss_giou_3: 0.383  loss_ce_dn_3: 0.2211  loss_mask_dn_3: 0.0312  loss_dice_dn_3: 0.5535  loss_bbox_dn_3: 0.05305  loss_giou_dn_3: 0.3386  loss_ce_4: 1.1  loss_mask_4: 0.03594  loss_dice_4: 0.537  loss_bbox_4: 0.0951  loss_giou_4: 0.3829  loss_ce_dn_4: 0.2025  loss_mask_dn_4: 0.03102  loss_dice_dn_4: 0.5653  loss_bbox_dn_4: 0.0524  loss_giou_dn_4: 0.33  loss_ce_5: 1.062  loss_mask_5: 0.03614  loss_dice_5: 0.5  loss_bbox_5: 0.08205  loss_giou_5: 0.386  loss_ce_dn_5: 0.195  loss_mask_dn_5: 0.03265  loss_dice_dn_5: 0.5452  loss_bbox_dn_5: 0.04716  loss_giou_dn_5: 0.3355  loss_ce_6: 1.001  loss_mask_6: 0.03304  loss_dice_6: 0.3936  loss_bbox_6: 0.0778  loss_giou_6: 0.3784  loss_ce_dn_6: 0.1823  loss_mask_dn_6: 0.03179  loss_dice_dn_6: 0.5518  loss_bbox_dn_6: 0.04602  loss_giou_dn_6: 0.3263  loss_ce_7: 1.006  loss_mask_7: 0.03404  loss_dice_7: 0.5983  loss_bbox_7: 0.07043  loss_giou_7: 0.3781  loss_ce_dn_7: 0.1645  loss_mask_dn_7: 0.03324  loss_dice_dn_7: 0.5798  loss_bbox_dn_7: 0.04605  loss_giou_dn_7: 0.3282  loss_ce_8: 0.9999  loss_mask_8: 0.03511  loss_dice_8: 0.3994  loss_bbox_8: 0.07868  loss_giou_8: 0.3679  loss_ce_dn_8: 0.1678  loss_mask_dn_8: 0.03348  loss_dice_dn_8: 0.5606  loss_bbox_dn_8: 0.04597  loss_giou_dn_8: 0.33  loss_ce_interm: 1.364  loss_mask_interm: 0.03358  loss_dice_interm: 0.4393  loss_bbox_interm: 0.1047  loss_giou_interm: 0.4493  time: 1.8602  data_time: 0.1332  lr: 1e-06  max_mem: 6663M\n",
            "[05/20 18:43:04 d2.utils.events]:  eta: 0:36:19  iter: 4379  total_loss: 38.72  loss_ce: 0.9589  loss_mask: 0.03733  loss_dice: 0.473  loss_bbox: 0.05921  loss_giou: 0.2586  loss_ce_dn: 0.1774  loss_mask_dn: 0.03468  loss_dice_dn: 0.5087  loss_bbox_dn: 0.03611  loss_giou_dn: 0.2456  loss_ce_0: 1.363  loss_mask_0: 0.03746  loss_dice_0: 0.4268  loss_bbox_0: 0.05062  loss_giou_0: 0.3338  loss_ce_dn_0: 0.822  loss_mask_dn_0: 0.1428  loss_dice_dn_0: 2.492  loss_bbox_dn_0: 0.2166  loss_giou_dn_0: 0.8526  loss_ce_1: 1.166  loss_mask_1: 0.04071  loss_dice_1: 0.5176  loss_bbox_1: 0.04999  loss_giou_1: 0.2754  loss_ce_dn_1: 0.2752  loss_mask_dn_1: 0.03483  loss_dice_dn_1: 0.5005  loss_bbox_dn_1: 0.05813  loss_giou_dn_1: 0.335  loss_ce_2: 1.057  loss_mask_2: 0.0385  loss_dice_2: 0.4909  loss_bbox_2: 0.05331  loss_giou_2: 0.303  loss_ce_dn_2: 0.2411  loss_mask_dn_2: 0.03383  loss_dice_dn_2: 0.4707  loss_bbox_dn_2: 0.04454  loss_giou_dn_2: 0.2728  loss_ce_3: 1.034  loss_mask_3: 0.03538  loss_dice_3: 0.4774  loss_bbox_3: 0.05244  loss_giou_3: 0.2646  loss_ce_dn_3: 0.2148  loss_mask_dn_3: 0.03162  loss_dice_dn_3: 0.5069  loss_bbox_dn_3: 0.0427  loss_giou_dn_3: 0.2513  loss_ce_4: 1.026  loss_mask_4: 0.03296  loss_dice_4: 0.5149  loss_bbox_4: 0.0537  loss_giou_4: 0.3045  loss_ce_dn_4: 0.208  loss_mask_dn_4: 0.03305  loss_dice_dn_4: 0.486  loss_bbox_dn_4: 0.03788  loss_giou_dn_4: 0.2479  loss_ce_5: 1.01  loss_mask_5: 0.03412  loss_dice_5: 0.466  loss_bbox_5: 0.06105  loss_giou_5: 0.2592  loss_ce_dn_5: 0.1976  loss_mask_dn_5: 0.03399  loss_dice_dn_5: 0.5021  loss_bbox_dn_5: 0.0369  loss_giou_dn_5: 0.2417  loss_ce_6: 0.9697  loss_mask_6: 0.03733  loss_dice_6: 0.4543  loss_bbox_6: 0.05872  loss_giou_6: 0.2597  loss_ce_dn_6: 0.1857  loss_mask_dn_6: 0.03268  loss_dice_dn_6: 0.5095  loss_bbox_dn_6: 0.03661  loss_giou_dn_6: 0.2416  loss_ce_7: 0.971  loss_mask_7: 0.03377  loss_dice_7: 0.4374  loss_bbox_7: 0.05892  loss_giou_7: 0.2569  loss_ce_dn_7: 0.1844  loss_mask_dn_7: 0.03398  loss_dice_dn_7: 0.5106  loss_bbox_dn_7: 0.03374  loss_giou_dn_7: 0.2423  loss_ce_8: 0.949  loss_mask_8: 0.03848  loss_dice_8: 0.4863  loss_bbox_8: 0.05844  loss_giou_8: 0.2563  loss_ce_dn_8: 0.1809  loss_mask_dn_8: 0.03593  loss_dice_dn_8: 0.5286  loss_bbox_dn_8: 0.03701  loss_giou_dn_8: 0.2463  loss_ce_interm: 1.325  loss_mask_interm: 0.03943  loss_dice_interm: 0.5061  loss_bbox_interm: 0.07139  loss_giou_interm: 0.4271  time: 1.8595  data_time: 0.0729  lr: 1e-06  max_mem: 6663M\n",
            "[05/20 18:43:38 d2.utils.events]:  eta: 0:35:47  iter: 4399  total_loss: 46.52  loss_ce: 0.8882  loss_mask: 0.02757  loss_dice: 0.4019  loss_bbox: 0.0457  loss_giou: 0.2869  loss_ce_dn: 0.1609  loss_mask_dn: 0.02476  loss_dice_dn: 0.6649  loss_bbox_dn: 0.03202  loss_giou_dn: 0.2877  loss_ce_0: 1.397  loss_mask_0: 0.02168  loss_dice_0: 0.8442  loss_bbox_0: 0.05655  loss_giou_0: 0.4123  loss_ce_dn_0: 0.6208  loss_mask_dn_0: 0.08699  loss_dice_dn_0: 2.089  loss_bbox_dn_0: 0.2071  loss_giou_dn_0: 0.8606  loss_ce_1: 1.329  loss_mask_1: 0.0271  loss_dice_1: 0.8239  loss_bbox_1: 0.04436  loss_giou_1: 0.3375  loss_ce_dn_1: 0.2398  loss_mask_dn_1: 0.02439  loss_dice_dn_1: 0.7125  loss_bbox_dn_1: 0.04886  loss_giou_dn_1: 0.3733  loss_ce_2: 1.162  loss_mask_2: 0.02579  loss_dice_2: 0.5604  loss_bbox_2: 0.07457  loss_giou_2: 0.3147  loss_ce_dn_2: 0.2049  loss_mask_dn_2: 0.02027  loss_dice_dn_2: 0.6718  loss_bbox_dn_2: 0.04218  loss_giou_dn_2: 0.3153  loss_ce_3: 1.121  loss_mask_3: 0.02212  loss_dice_3: 0.7424  loss_bbox_3: 0.04736  loss_giou_3: 0.2889  loss_ce_dn_3: 0.1831  loss_mask_dn_3: 0.02254  loss_dice_dn_3: 0.6724  loss_bbox_dn_3: 0.03247  loss_giou_dn_3: 0.2748  loss_ce_4: 1.078  loss_mask_4: 0.02173  loss_dice_4: 0.7862  loss_bbox_4: 0.04687  loss_giou_4: 0.2928  loss_ce_dn_4: 0.1773  loss_mask_dn_4: 0.02137  loss_dice_dn_4: 0.631  loss_bbox_dn_4: 0.03302  loss_giou_dn_4: 0.2869  loss_ce_5: 1.077  loss_mask_5: 0.02592  loss_dice_5: 0.7107  loss_bbox_5: 0.04385  loss_giou_5: 0.2921  loss_ce_dn_5: 0.1772  loss_mask_dn_5: 0.02449  loss_dice_dn_5: 0.7012  loss_bbox_dn_5: 0.03242  loss_giou_dn_5: 0.2865  loss_ce_6: 0.9908  loss_mask_6: 0.02492  loss_dice_6: 0.4924  loss_bbox_6: 0.04492  loss_giou_6: 0.2959  loss_ce_dn_6: 0.1688  loss_mask_dn_6: 0.02662  loss_dice_dn_6: 0.6258  loss_bbox_dn_6: 0.03253  loss_giou_dn_6: 0.3016  loss_ce_7: 1.022  loss_mask_7: 0.02458  loss_dice_7: 0.7087  loss_bbox_7: 0.04299  loss_giou_7: 0.2964  loss_ce_dn_7: 0.1611  loss_mask_dn_7: 0.02549  loss_dice_dn_7: 0.7044  loss_bbox_dn_7: 0.0323  loss_giou_dn_7: 0.2903  loss_ce_8: 1.004  loss_mask_8: 0.02087  loss_dice_8: 0.5896  loss_bbox_8: 0.044  loss_giou_8: 0.294  loss_ce_dn_8: 0.1609  loss_mask_dn_8: 0.02296  loss_dice_dn_8: 0.6796  loss_bbox_dn_8: 0.03162  loss_giou_dn_8: 0.2842  loss_ce_interm: 1.477  loss_mask_interm: 0.02078  loss_dice_interm: 0.6171  loss_bbox_interm: 0.06475  loss_giou_interm: 0.4231  time: 1.8587  data_time: 0.0711  lr: 1e-06  max_mem: 6663M\n",
            "[05/20 18:44:13 d2.utils.events]:  eta: 0:35:16  iter: 4419  total_loss: 42.31  loss_ce: 0.9301  loss_mask: 0.02212  loss_dice: 0.5702  loss_bbox: 0.04645  loss_giou: 0.3196  loss_ce_dn: 0.1627  loss_mask_dn: 0.0242  loss_dice_dn: 0.6487  loss_bbox_dn: 0.04194  loss_giou_dn: 0.295  loss_ce_0: 0.9518  loss_mask_0: 0.02726  loss_dice_0: 0.5199  loss_bbox_0: 0.06094  loss_giou_0: 0.3967  loss_ce_dn_0: 0.6325  loss_mask_dn_0: 0.09808  loss_dice_dn_0: 2.169  loss_bbox_dn_0: 0.23  loss_giou_dn_0: 0.8503  loss_ce_1: 0.9004  loss_mask_1: 0.02154  loss_dice_1: 0.7205  loss_bbox_1: 0.04916  loss_giou_1: 0.348  loss_ce_dn_1: 0.2222  loss_mask_dn_1: 0.02282  loss_dice_dn_1: 0.7169  loss_bbox_dn_1: 0.06015  loss_giou_dn_1: 0.3659  loss_ce_2: 0.9653  loss_mask_2: 0.02669  loss_dice_2: 0.6736  loss_bbox_2: 0.04529  loss_giou_2: 0.3414  loss_ce_dn_2: 0.1799  loss_mask_dn_2: 0.02295  loss_dice_dn_2: 0.6882  loss_bbox_dn_2: 0.04891  loss_giou_dn_2: 0.3191  loss_ce_3: 0.9803  loss_mask_3: 0.02486  loss_dice_3: 0.6478  loss_bbox_3: 0.04542  loss_giou_3: 0.3457  loss_ce_dn_3: 0.1734  loss_mask_dn_3: 0.02321  loss_dice_dn_3: 0.6908  loss_bbox_dn_3: 0.04275  loss_giou_dn_3: 0.3091  loss_ce_4: 0.9503  loss_mask_4: 0.02816  loss_dice_4: 0.6096  loss_bbox_4: 0.0442  loss_giou_4: 0.3313  loss_ce_dn_4: 0.1622  loss_mask_dn_4: 0.02424  loss_dice_dn_4: 0.6781  loss_bbox_dn_4: 0.04184  loss_giou_dn_4: 0.3042  loss_ce_5: 0.9347  loss_mask_5: 0.02346  loss_dice_5: 0.6501  loss_bbox_5: 0.04596  loss_giou_5: 0.3107  loss_ce_dn_5: 0.1713  loss_mask_dn_5: 0.02383  loss_dice_dn_5: 0.6689  loss_bbox_dn_5: 0.04089  loss_giou_dn_5: 0.3058  loss_ce_6: 0.9254  loss_mask_6: 0.01958  loss_dice_6: 0.6141  loss_bbox_6: 0.04493  loss_giou_6: 0.3094  loss_ce_dn_6: 0.1549  loss_mask_dn_6: 0.02496  loss_dice_dn_6: 0.678  loss_bbox_dn_6: 0.04111  loss_giou_dn_6: 0.3052  loss_ce_7: 0.907  loss_mask_7: 0.02739  loss_dice_7: 0.7458  loss_bbox_7: 0.04575  loss_giou_7: 0.3106  loss_ce_dn_7: 0.1609  loss_mask_dn_7: 0.02437  loss_dice_dn_7: 0.6578  loss_bbox_dn_7: 0.04306  loss_giou_dn_7: 0.296  loss_ce_8: 0.933  loss_mask_8: 0.02286  loss_dice_8: 0.7802  loss_bbox_8: 0.04921  loss_giou_8: 0.3122  loss_ce_dn_8: 0.1618  loss_mask_dn_8: 0.02401  loss_dice_dn_8: 0.6452  loss_bbox_dn_8: 0.04305  loss_giou_dn_8: 0.2962  loss_ce_interm: 1.073  loss_mask_interm: 0.02659  loss_dice_interm: 0.6193  loss_bbox_interm: 0.06703  loss_giou_interm: 0.4887  time: 1.8582  data_time: 0.1101  lr: 1e-06  max_mem: 6663M\n",
            "[05/20 18:44:47 d2.utils.events]:  eta: 0:34:45  iter: 4439  total_loss: 35.17  loss_ce: 0.9671  loss_mask: 0.04424  loss_dice: 0.5959  loss_bbox: 0.04975  loss_giou: 0.2458  loss_ce_dn: 0.1659  loss_mask_dn: 0.03703  loss_dice_dn: 0.4992  loss_bbox_dn: 0.03815  loss_giou_dn: 0.225  loss_ce_0: 1.182  loss_mask_0: 0.04533  loss_dice_0: 0.4773  loss_bbox_0: 0.07142  loss_giou_0: 0.4093  loss_ce_dn_0: 0.7659  loss_mask_dn_0: 0.1001  loss_dice_dn_0: 2.5  loss_bbox_dn_0: 0.2429  loss_giou_dn_0: 0.8552  loss_ce_1: 1.165  loss_mask_1: 0.04223  loss_dice_1: 0.4888  loss_bbox_1: 0.05821  loss_giou_1: 0.3074  loss_ce_dn_1: 0.2447  loss_mask_dn_1: 0.03794  loss_dice_dn_1: 0.5491  loss_bbox_dn_1: 0.05308  loss_giou_dn_1: 0.34  loss_ce_2: 1.095  loss_mask_2: 0.0374  loss_dice_2: 0.4927  loss_bbox_2: 0.05769  loss_giou_2: 0.2511  loss_ce_dn_2: 0.2024  loss_mask_dn_2: 0.03452  loss_dice_dn_2: 0.5049  loss_bbox_dn_2: 0.04375  loss_giou_dn_2: 0.2735  loss_ce_3: 0.9866  loss_mask_3: 0.04038  loss_dice_3: 0.4808  loss_bbox_3: 0.05619  loss_giou_3: 0.2581  loss_ce_dn_3: 0.18  loss_mask_dn_3: 0.0361  loss_dice_dn_3: 0.479  loss_bbox_dn_3: 0.04047  loss_giou_dn_3: 0.2441  loss_ce_4: 0.9872  loss_mask_4: 0.0431  loss_dice_4: 0.459  loss_bbox_4: 0.05564  loss_giou_4: 0.2617  loss_ce_dn_4: 0.1856  loss_mask_dn_4: 0.03454  loss_dice_dn_4: 0.4758  loss_bbox_dn_4: 0.03882  loss_giou_dn_4: 0.2335  loss_ce_5: 0.9524  loss_mask_5: 0.04473  loss_dice_5: 0.483  loss_bbox_5: 0.05319  loss_giou_5: 0.2523  loss_ce_dn_5: 0.1744  loss_mask_dn_5: 0.03644  loss_dice_dn_5: 0.5042  loss_bbox_dn_5: 0.03831  loss_giou_dn_5: 0.2352  loss_ce_6: 0.9648  loss_mask_6: 0.04119  loss_dice_6: 0.557  loss_bbox_6: 0.05173  loss_giou_6: 0.2425  loss_ce_dn_6: 0.1711  loss_mask_dn_6: 0.03671  loss_dice_dn_6: 0.4967  loss_bbox_dn_6: 0.03906  loss_giou_dn_6: 0.2321  loss_ce_7: 0.9612  loss_mask_7: 0.03935  loss_dice_7: 0.4624  loss_bbox_7: 0.04888  loss_giou_7: 0.2419  loss_ce_dn_7: 0.166  loss_mask_dn_7: 0.03701  loss_dice_dn_7: 0.4846  loss_bbox_dn_7: 0.03843  loss_giou_dn_7: 0.228  loss_ce_8: 0.9506  loss_mask_8: 0.03683  loss_dice_8: 0.6081  loss_bbox_8: 0.0483  loss_giou_8: 0.2439  loss_ce_dn_8: 0.1613  loss_mask_dn_8: 0.03749  loss_dice_dn_8: 0.492  loss_bbox_dn_8: 0.03792  loss_giou_dn_8: 0.2277  loss_ce_interm: 1.181  loss_mask_interm: 0.04021  loss_dice_interm: 0.4716  loss_bbox_interm: 0.07348  loss_giou_interm: 0.3171  time: 1.8575  data_time: 0.0833  lr: 1e-06  max_mem: 6663M\n",
            "[05/20 18:45:21 d2.utils.events]:  eta: 0:34:13  iter: 4459  total_loss: 51.14  loss_ce: 1.289  loss_mask: 0.04  loss_dice: 0.4803  loss_bbox: 0.1205  loss_giou: 0.4169  loss_ce_dn: 0.2035  loss_mask_dn: 0.03631  loss_dice_dn: 0.5258  loss_bbox_dn: 0.04655  loss_giou_dn: 0.3037  loss_ce_0: 1.515  loss_mask_0: 0.04613  loss_dice_0: 0.7467  loss_bbox_0: 0.1204  loss_giou_0: 0.5257  loss_ce_dn_0: 0.7448  loss_mask_dn_0: 0.2383  loss_dice_dn_0: 2.728  loss_bbox_dn_0: 0.2602  loss_giou_dn_0: 0.8562  loss_ce_1: 1.506  loss_mask_1: 0.03594  loss_dice_1: 0.4744  loss_bbox_1: 0.09914  loss_giou_1: 0.4163  loss_ce_dn_1: 0.2899  loss_mask_dn_1: 0.03502  loss_dice_dn_1: 0.6517  loss_bbox_dn_1: 0.08489  loss_giou_dn_1: 0.4168  loss_ce_2: 1.378  loss_mask_2: 0.04148  loss_dice_2: 0.5538  loss_bbox_2: 0.1104  loss_giou_2: 0.3724  loss_ce_dn_2: 0.2477  loss_mask_dn_2: 0.034  loss_dice_dn_2: 0.6255  loss_bbox_dn_2: 0.06213  loss_giou_dn_2: 0.3567  loss_ce_3: 1.277  loss_mask_3: 0.04149  loss_dice_3: 0.4337  loss_bbox_3: 0.09829  loss_giou_3: 0.4415  loss_ce_dn_3: 0.2151  loss_mask_dn_3: 0.03571  loss_dice_dn_3: 0.6214  loss_bbox_dn_3: 0.049  loss_giou_dn_3: 0.3244  loss_ce_4: 1.292  loss_mask_4: 0.03901  loss_dice_4: 0.5296  loss_bbox_4: 0.1061  loss_giou_4: 0.3884  loss_ce_dn_4: 0.1998  loss_mask_dn_4: 0.03685  loss_dice_dn_4: 0.5689  loss_bbox_dn_4: 0.04732  loss_giou_dn_4: 0.3132  loss_ce_5: 1.349  loss_mask_5: 0.03751  loss_dice_5: 0.4454  loss_bbox_5: 0.149  loss_giou_5: 0.4173  loss_ce_dn_5: 0.192  loss_mask_dn_5: 0.03748  loss_dice_dn_5: 0.5711  loss_bbox_dn_5: 0.05148  loss_giou_dn_5: 0.3103  loss_ce_6: 1.305  loss_mask_6: 0.03448  loss_dice_6: 0.5631  loss_bbox_6: 0.1129  loss_giou_6: 0.4215  loss_ce_dn_6: 0.1945  loss_mask_dn_6: 0.03562  loss_dice_dn_6: 0.5921  loss_bbox_dn_6: 0.05047  loss_giou_dn_6: 0.3065  loss_ce_7: 1.276  loss_mask_7: 0.03741  loss_dice_7: 0.4362  loss_bbox_7: 0.1524  loss_giou_7: 0.4197  loss_ce_dn_7: 0.1974  loss_mask_dn_7: 0.03691  loss_dice_dn_7: 0.558  loss_bbox_dn_7: 0.04978  loss_giou_dn_7: 0.3018  loss_ce_8: 1.302  loss_mask_8: 0.03731  loss_dice_8: 0.5815  loss_bbox_8: 0.111  loss_giou_8: 0.4176  loss_ce_dn_8: 0.2064  loss_mask_dn_8: 0.03643  loss_dice_dn_8: 0.5363  loss_bbox_dn_8: 0.04669  loss_giou_dn_8: 0.3067  loss_ce_interm: 1.605  loss_mask_interm: 0.04653  loss_dice_interm: 0.6472  loss_bbox_interm: 0.1207  loss_giou_interm: 0.4614  time: 1.8568  data_time: 0.0836  lr: 1e-06  max_mem: 6663M\n",
            "[05/20 18:45:56 d2.utils.events]:  eta: 0:33:41  iter: 4479  total_loss: 48.81  loss_ce: 1.051  loss_mask: 0.04957  loss_dice: 0.7968  loss_bbox: 0.05411  loss_giou: 0.3828  loss_ce_dn: 0.2197  loss_mask_dn: 0.04551  loss_dice_dn: 0.5803  loss_bbox_dn: 0.045  loss_giou_dn: 0.2799  loss_ce_0: 1.435  loss_mask_0: 0.04695  loss_dice_0: 0.672  loss_bbox_0: 0.05452  loss_giou_0: 0.4609  loss_ce_dn_0: 0.7382  loss_mask_dn_0: 0.2023  loss_dice_dn_0: 2.536  loss_bbox_dn_0: 0.4101  loss_giou_dn_0: 0.8589  loss_ce_1: 1.33  loss_mask_1: 0.0484  loss_dice_1: 0.5168  loss_bbox_1: 0.07066  loss_giou_1: 0.392  loss_ce_dn_1: 0.2707  loss_mask_dn_1: 0.04644  loss_dice_dn_1: 0.6726  loss_bbox_dn_1: 0.09057  loss_giou_dn_1: 0.3777  loss_ce_2: 1.193  loss_mask_2: 0.05111  loss_dice_2: 0.6157  loss_bbox_2: 0.04476  loss_giou_2: 0.3243  loss_ce_dn_2: 0.2639  loss_mask_dn_2: 0.04576  loss_dice_dn_2: 0.6472  loss_bbox_dn_2: 0.06155  loss_giou_dn_2: 0.3142  loss_ce_3: 1.162  loss_mask_3: 0.04507  loss_dice_3: 0.6624  loss_bbox_3: 0.04285  loss_giou_3: 0.305  loss_ce_dn_3: 0.247  loss_mask_dn_3: 0.04603  loss_dice_dn_3: 0.6045  loss_bbox_dn_3: 0.04709  loss_giou_dn_3: 0.3055  loss_ce_4: 1.049  loss_mask_4: 0.04478  loss_dice_4: 0.6681  loss_bbox_4: 0.04335  loss_giou_4: 0.3216  loss_ce_dn_4: 0.2349  loss_mask_dn_4: 0.04514  loss_dice_dn_4: 0.609  loss_bbox_dn_4: 0.04447  loss_giou_dn_4: 0.2969  loss_ce_5: 1.02  loss_mask_5: 0.05038  loss_dice_5: 0.6906  loss_bbox_5: 0.04277  loss_giou_5: 0.3035  loss_ce_dn_5: 0.2274  loss_mask_dn_5: 0.04548  loss_dice_dn_5: 0.5698  loss_bbox_dn_5: 0.04538  loss_giou_dn_5: 0.2783  loss_ce_6: 1.046  loss_mask_6: 0.044  loss_dice_6: 0.599  loss_bbox_6: 0.04529  loss_giou_6: 0.3517  loss_ce_dn_6: 0.229  loss_mask_dn_6: 0.04576  loss_dice_dn_6: 0.5948  loss_bbox_dn_6: 0.04516  loss_giou_dn_6: 0.2833  loss_ce_7: 1.028  loss_mask_7: 0.04701  loss_dice_7: 0.6852  loss_bbox_7: 0.04716  loss_giou_7: 0.336  loss_ce_dn_7: 0.227  loss_mask_dn_7: 0.04521  loss_dice_dn_7: 0.5763  loss_bbox_dn_7: 0.04557  loss_giou_dn_7: 0.2862  loss_ce_8: 1.041  loss_mask_8: 0.05049  loss_dice_8: 0.5503  loss_bbox_8: 0.04724  loss_giou_8: 0.3377  loss_ce_dn_8: 0.2176  loss_mask_dn_8: 0.04575  loss_dice_dn_8: 0.5966  loss_bbox_dn_8: 0.04596  loss_giou_dn_8: 0.2839  loss_ce_interm: 1.313  loss_mask_interm: 0.0446  loss_dice_interm: 0.6179  loss_bbox_interm: 0.1314  loss_giou_interm: 0.4855  time: 1.8562  data_time: 0.0907  lr: 1e-06  max_mem: 6663M\n",
            "[05/20 18:46:32 d2.data.datasets.coco]: Loaded 150 images in COCO format from /content/TACO-expl/data/annotations_off_0_resval.json\n",
            "[05/20 18:46:32 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "[05/20 18:46:32 d2.data.common]: Serializing 150 elements to byte tensors and concatenating them all ...\n",
            "[05/20 18:46:32 d2.data.common]: Serialized dataset takes 0.21 MiB\n",
            "WARNING [05/20 18:46:32 d2.evaluation.coco_evaluation]: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
            "[05/20 18:46:32 d2.evaluation.evaluator]: Start inference on 150 batches\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1066, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1066, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1066, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1066])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 18:46:40 d2.evaluation.evaluator]: Inference done 11/150. Dataloading: 0.0019 s/iter. Inference: 0.2878 s/iter. Eval: 0.4557 s/iter. Total: 0.7454 s/iter. ETA=0:01:43\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 608])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 608])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 608])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1200])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 750])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 18:46:46 d2.evaluation.evaluator]: Inference done 17/150. Dataloading: 0.0037 s/iter. Inference: 0.3030 s/iter. Eval: 0.5345 s/iter. Total: 0.8414 s/iter. ETA=0:01:51\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 750])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([750, 1333])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 18:46:52 d2.evaluation.evaluator]: Inference done 24/150. Dataloading: 0.0036 s/iter. Inference: 0.3071 s/iter. Eval: 0.5243 s/iter. Total: 0.8355 s/iter. ETA=0:01:45\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 750])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([750, 1333])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 750])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 18:46:57 d2.evaluation.evaluator]: Inference done 31/150. Dataloading: 0.0033 s/iter. Inference: 0.3040 s/iter. Eval: 0.5109 s/iter. Total: 0.8186 s/iter. ETA=0:01:37\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 750])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 18:47:03 d2.evaluation.evaluator]: Inference done 37/150. Dataloading: 0.0034 s/iter. Inference: 0.3090 s/iter. Eval: 0.5346 s/iter. Total: 0.8474 s/iter. ETA=0:01:35\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 18:47:08 d2.evaluation.evaluator]: Inference done 44/150. Dataloading: 0.0033 s/iter. Inference: 0.3087 s/iter. Eval: 0.5252 s/iter. Total: 0.8377 s/iter. ETA=0:01:28\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 18:47:13 d2.evaluation.evaluator]: Inference done 51/150. Dataloading: 0.0032 s/iter. Inference: 0.3045 s/iter. Eval: 0.5136 s/iter. Total: 0.8219 s/iter. ETA=0:01:21\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 18:47:19 d2.evaluation.evaluator]: Inference done 57/150. Dataloading: 0.0041 s/iter. Inference: 0.3055 s/iter. Eval: 0.5224 s/iter. Total: 0.8324 s/iter. ETA=0:01:17\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 18:47:24 d2.evaluation.evaluator]: Inference done 63/150. Dataloading: 0.0047 s/iter. Inference: 0.3055 s/iter. Eval: 0.5235 s/iter. Total: 0.8342 s/iter. ETA=0:01:12\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 18:47:29 d2.evaluation.evaluator]: Inference done 70/150. Dataloading: 0.0046 s/iter. Inference: 0.3028 s/iter. Eval: 0.5152 s/iter. Total: 0.8231 s/iter. ETA=0:01:05\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([852, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 18:47:35 d2.evaluation.evaluator]: Inference done 77/150. Dataloading: 0.0044 s/iter. Inference: 0.3018 s/iter. Eval: 0.5157 s/iter. Total: 0.8223 s/iter. ETA=0:01:00\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 18:47:40 d2.evaluation.evaluator]: Inference done 83/150. Dataloading: 0.0045 s/iter. Inference: 0.3034 s/iter. Eval: 0.5202 s/iter. Total: 0.8285 s/iter. ETA=0:00:55\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 18:47:45 d2.evaluation.evaluator]: Inference done 90/150. Dataloading: 0.0043 s/iter. Inference: 0.3011 s/iter. Eval: 0.5142 s/iter. Total: 0.8200 s/iter. ETA=0:00:49\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 18:47:51 d2.evaluation.evaluator]: Inference done 97/150. Dataloading: 0.0043 s/iter. Inference: 0.2994 s/iter. Eval: 0.5128 s/iter. Total: 0.8170 s/iter. ETA=0:00:43\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 18:47:56 d2.evaluation.evaluator]: Inference done 103/150. Dataloading: 0.0047 s/iter. Inference: 0.3012 s/iter. Eval: 0.5178 s/iter. Total: 0.8242 s/iter. ETA=0:00:38\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 18:48:01 d2.evaluation.evaluator]: Inference done 110/150. Dataloading: 0.0046 s/iter. Inference: 0.2993 s/iter. Eval: 0.5128 s/iter. Total: 0.8171 s/iter. ETA=0:00:32\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 18:48:07 d2.evaluation.evaluator]: Inference done 117/150. Dataloading: 0.0044 s/iter. Inference: 0.2982 s/iter. Eval: 0.5101 s/iter. Total: 0.8131 s/iter. ETA=0:00:26\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 18:48:12 d2.evaluation.evaluator]: Inference done 123/150. Dataloading: 0.0045 s/iter. Inference: 0.2996 s/iter. Eval: 0.5154 s/iter. Total: 0.8199 s/iter. ETA=0:00:22\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 18:48:18 d2.evaluation.evaluator]: Inference done 130/150. Dataloading: 0.0045 s/iter. Inference: 0.2982 s/iter. Eval: 0.5116 s/iter. Total: 0.8147 s/iter. ETA=0:00:16\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 750])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 750])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 18:48:23 d2.evaluation.evaluator]: Inference done 137/150. Dataloading: 0.0044 s/iter. Inference: 0.2972 s/iter. Eval: 0.5095 s/iter. Total: 0.8115 s/iter. ETA=0:00:10\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 750])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 18:48:29 d2.evaluation.evaluator]: Inference done 143/150. Dataloading: 0.0043 s/iter. Inference: 0.2987 s/iter. Eval: 0.5149 s/iter. Total: 0.8183 s/iter. ETA=0:00:05\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 608])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 608])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 608])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 608])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 18:48:34 d2.evaluation.evaluator]: Total inference time: 0:01:57.969190 (0.813581 s / iter per device, on 1 devices)\n",
            "[05/20 18:48:34 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:43 (0.297540 s / iter per device, on 1 devices)\n",
            "[05/20 18:48:34 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...\n",
            "[05/20 18:48:34 d2.evaluation.coco_evaluation]: Saving results to /content/output/chkpt/inference/coco_instances_results.json\n",
            "[05/20 18:48:34 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "[05/20 18:48:34 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*\n",
            "[05/20 18:48:34 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.17 seconds.\n",
            "[05/20 18:48:34 d2.evaluation.fast_eval_api]: Accumulating evaluation results...\n",
            "[05/20 18:48:34 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.07 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.243\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.411\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.244\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.060\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.246\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.423\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.330\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.436\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.446\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.108\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.484\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.791\n",
            "[05/20 18:48:34 d2.evaluation.coco_evaluation]: Evaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
            "| 24.329 | 41.105 | 24.417 | 5.951 | 24.561 | 42.302 |\n",
            "[05/20 18:48:34 d2.evaluation.coco_evaluation]: Per-category bbox AP: \n",
            "| category   | AP     | category              | AP     | category   | AP     |\n",
            "|:-----------|:-------|:----------------------|:-------|:-----------|:-------|\n",
            "| Bottle     | 53.378 | Bottle cap            | 12.442 | Can        | 42.603 |\n",
            "| Cigarette  | 1.989  | Cup                   | 30.656 | Lid        | 35.624 |\n",
            "| Other      | 20.066 | Plastic bag & wrapper | 22.078 | Pop tab    | 8.921  |\n",
            "| Straw      | 15.529 |                       |        |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.18s)\n",
            "creating index...\n",
            "index created!\n",
            "[05/20 18:48:35 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*\n",
            "[05/20 18:48:36 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.26 seconds.\n",
            "[05/20 18:48:36 d2.evaluation.fast_eval_api]: Accumulating evaluation results...\n",
            "[05/20 18:48:36 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.07 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.388\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.503\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.401\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.217\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.473\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.526\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.462\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.648\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.666\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.425\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.750\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.840\n",
            "[05/20 18:48:36 d2.evaluation.coco_evaluation]: Evaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 38.753 | 50.252 | 40.097 | 21.714 | 47.297 | 52.612 |\n",
            "[05/20 18:48:36 d2.evaluation.coco_evaluation]: Per-category segm AP: \n",
            "| category   | AP     | category              | AP     | category   | AP     |\n",
            "|:-----------|:-------|:----------------------|:-------|:-----------|:-------|\n",
            "| Bottle     | 73.201 | Bottle cap            | 39.682 | Can        | 55.229 |\n",
            "| Cigarette  | 21.388 | Cup                   | 42.800 | Lid        | 45.102 |\n",
            "| Other      | 30.198 | Plastic bag & wrapper | 35.772 | Pop tab    | 24.884 |\n",
            "| Straw      | 19.273 |                       |        |            |        |\n",
            "[05/20 18:48:36 d2.engine.defaults]: Evaluation results for TACO_val in csv format:\n",
            "[05/20 18:48:36 d2.evaluation.testing]: copypaste: Task: bbox\n",
            "[05/20 18:48:36 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl\n",
            "[05/20 18:48:36 d2.evaluation.testing]: copypaste: 24.3287,41.1055,24.4174,5.9510,24.5610,42.3015\n",
            "[05/20 18:48:36 d2.evaluation.testing]: copypaste: Task: segm\n",
            "[05/20 18:48:36 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl\n",
            "[05/20 18:48:36 d2.evaluation.testing]: copypaste: 38.7531,50.2522,40.0969,21.7140,47.2965,52.6117\n",
            "[05/20 18:48:36 d2.utils.events]:  eta: 0:33:10  iter: 4499  total_loss: 49.69  loss_ce: 1.076  loss_mask: 0.04266  loss_dice: 0.7267  loss_bbox: 0.06572  loss_giou: 0.4676  loss_ce_dn: 0.1636  loss_mask_dn: 0.0374  loss_dice_dn: 0.696  loss_bbox_dn: 0.03631  loss_giou_dn: 0.2989  loss_ce_0: 1.524  loss_mask_0: 0.03699  loss_dice_0: 0.5575  loss_bbox_0: 0.1004  loss_giou_0: 0.639  loss_ce_dn_0: 0.6794  loss_mask_dn_0: 0.182  loss_dice_dn_0: 2.66  loss_bbox_dn_0: 0.289  loss_giou_dn_0: 0.8647  loss_ce_1: 1.442  loss_mask_1: 0.03877  loss_dice_1: 0.928  loss_bbox_1: 0.1065  loss_giou_1: 0.554  loss_ce_dn_1: 0.272  loss_mask_dn_1: 0.04123  loss_dice_dn_1: 0.7661  loss_bbox_dn_1: 0.07372  loss_giou_dn_1: 0.4049  loss_ce_2: 1.17  loss_mask_2: 0.03945  loss_dice_2: 0.7847  loss_bbox_2: 0.09762  loss_giou_2: 0.4837  loss_ce_dn_2: 0.2256  loss_mask_dn_2: 0.03759  loss_dice_dn_2: 0.75  loss_bbox_dn_2: 0.05237  loss_giou_dn_2: 0.3404  loss_ce_3: 1.096  loss_mask_3: 0.04273  loss_dice_3: 0.8573  loss_bbox_3: 0.07026  loss_giou_3: 0.474  loss_ce_dn_3: 0.2175  loss_mask_dn_3: 0.03606  loss_dice_dn_3: 0.7414  loss_bbox_dn_3: 0.04665  loss_giou_dn_3: 0.3196  loss_ce_4: 1.106  loss_mask_4: 0.04115  loss_dice_4: 0.8043  loss_bbox_4: 0.07885  loss_giou_4: 0.4812  loss_ce_dn_4: 0.1896  loss_mask_dn_4: 0.03665  loss_dice_dn_4: 0.7217  loss_bbox_dn_4: 0.03952  loss_giou_dn_4: 0.3037  loss_ce_5: 1.178  loss_mask_5: 0.0375  loss_dice_5: 0.8232  loss_bbox_5: 0.08172  loss_giou_5: 0.4088  loss_ce_dn_5: 0.1784  loss_mask_dn_5: 0.03649  loss_dice_dn_5: 0.7127  loss_bbox_dn_5: 0.03776  loss_giou_dn_5: 0.3046  loss_ce_6: 1.1  loss_mask_6: 0.03961  loss_dice_6: 0.7275  loss_bbox_6: 0.05931  loss_giou_6: 0.494  loss_ce_dn_6: 0.1649  loss_mask_dn_6: 0.03612  loss_dice_dn_6: 0.7031  loss_bbox_dn_6: 0.03863  loss_giou_dn_6: 0.3007  loss_ce_7: 1.073  loss_mask_7: 0.03846  loss_dice_7: 0.7706  loss_bbox_7: 0.07944  loss_giou_7: 0.4698  loss_ce_dn_7: 0.1661  loss_mask_dn_7: 0.03829  loss_dice_dn_7: 0.6915  loss_bbox_dn_7: 0.03681  loss_giou_dn_7: 0.2994  loss_ce_8: 1.079  loss_mask_8: 0.04112  loss_dice_8: 0.7777  loss_bbox_8: 0.09188  loss_giou_8: 0.482  loss_ce_dn_8: 0.1661  loss_mask_dn_8: 0.03776  loss_dice_dn_8: 0.7378  loss_bbox_dn_8: 0.03529  loss_giou_dn_8: 0.305  loss_ce_interm: 1.355  loss_mask_interm: 0.03281  loss_dice_interm: 0.8049  loss_bbox_interm: 0.1142  loss_giou_interm: 0.5711  time: 1.8559  data_time: 0.1130  lr: 1e-06  max_mem: 6663M\n",
            "[05/20 18:49:10 d2.utils.events]:  eta: 0:32:42  iter: 4519  total_loss: 43.51  loss_ce: 1.047  loss_mask: 0.03371  loss_dice: 0.4554  loss_bbox: 0.07603  loss_giou: 0.309  loss_ce_dn: 0.1539  loss_mask_dn: 0.03552  loss_dice_dn: 0.4123  loss_bbox_dn: 0.04471  loss_giou_dn: 0.2843  loss_ce_0: 1.389  loss_mask_0: 0.05851  loss_dice_0: 0.4497  loss_bbox_0: 0.1291  loss_giou_0: 0.3988  loss_ce_dn_0: 0.7314  loss_mask_dn_0: 0.1558  loss_dice_dn_0: 2.487  loss_bbox_dn_0: 0.2878  loss_giou_dn_0: 0.8559  loss_ce_1: 1.35  loss_mask_1: 0.03716  loss_dice_1: 0.5145  loss_bbox_1: 0.07776  loss_giou_1: 0.3422  loss_ce_dn_1: 0.2822  loss_mask_dn_1: 0.04971  loss_dice_dn_1: 0.4519  loss_bbox_dn_1: 0.08598  loss_giou_dn_1: 0.341  loss_ce_2: 1.261  loss_mask_2: 0.03959  loss_dice_2: 0.4322  loss_bbox_2: 0.08103  loss_giou_2: 0.3341  loss_ce_dn_2: 0.226  loss_mask_dn_2: 0.03803  loss_dice_dn_2: 0.4303  loss_bbox_dn_2: 0.06216  loss_giou_dn_2: 0.3241  loss_ce_3: 1.216  loss_mask_3: 0.03802  loss_dice_3: 0.4106  loss_bbox_3: 0.08389  loss_giou_3: 0.3281  loss_ce_dn_3: 0.2056  loss_mask_dn_3: 0.03586  loss_dice_dn_3: 0.4409  loss_bbox_dn_3: 0.04936  loss_giou_dn_3: 0.2972  loss_ce_4: 1.183  loss_mask_4: 0.03708  loss_dice_4: 0.4798  loss_bbox_4: 0.08565  loss_giou_4: 0.3244  loss_ce_dn_4: 0.1844  loss_mask_dn_4: 0.03658  loss_dice_dn_4: 0.428  loss_bbox_dn_4: 0.04673  loss_giou_dn_4: 0.3009  loss_ce_5: 1.122  loss_mask_5: 0.0372  loss_dice_5: 0.4001  loss_bbox_5: 0.09165  loss_giou_5: 0.3155  loss_ce_dn_5: 0.1662  loss_mask_dn_5: 0.03537  loss_dice_dn_5: 0.4307  loss_bbox_dn_5: 0.04797  loss_giou_dn_5: 0.2921  loss_ce_6: 1.08  loss_mask_6: 0.03513  loss_dice_6: 0.489  loss_bbox_6: 0.07497  loss_giou_6: 0.3348  loss_ce_dn_6: 0.153  loss_mask_dn_6: 0.03571  loss_dice_dn_6: 0.4324  loss_bbox_dn_6: 0.04618  loss_giou_dn_6: 0.2893  loss_ce_7: 1.083  loss_mask_7: 0.03471  loss_dice_7: 0.4517  loss_bbox_7: 0.07489  loss_giou_7: 0.3247  loss_ce_dn_7: 0.1624  loss_mask_dn_7: 0.03631  loss_dice_dn_7: 0.4284  loss_bbox_dn_7: 0.04805  loss_giou_dn_7: 0.2941  loss_ce_8: 1.08  loss_mask_8: 0.03686  loss_dice_8: 0.42  loss_bbox_8: 0.07461  loss_giou_8: 0.3245  loss_ce_dn_8: 0.1569  loss_mask_dn_8: 0.037  loss_dice_dn_8: 0.4241  loss_bbox_dn_8: 0.04707  loss_giou_dn_8: 0.2897  loss_ce_interm: 1.417  loss_mask_interm: 0.03796  loss_dice_interm: 0.4975  loss_bbox_interm: 0.09744  loss_giou_interm: 0.4174  time: 1.8553  data_time: 0.1557  lr: 1e-06  max_mem: 6663M\n",
            "[05/20 18:49:44 d2.utils.events]:  eta: 0:32:11  iter: 4539  total_loss: 39.47  loss_ce: 0.9145  loss_mask: 0.03395  loss_dice: 0.5054  loss_bbox: 0.04939  loss_giou: 0.4032  loss_ce_dn: 0.1948  loss_mask_dn: 0.03029  loss_dice_dn: 0.6089  loss_bbox_dn: 0.04019  loss_giou_dn: 0.2959  loss_ce_0: 1.145  loss_mask_0: 0.03634  loss_dice_0: 0.6751  loss_bbox_0: 0.04711  loss_giou_0: 0.3716  loss_ce_dn_0: 0.775  loss_mask_dn_0: 0.09914  loss_dice_dn_0: 2.077  loss_bbox_dn_0: 0.2447  loss_giou_dn_0: 0.8537  loss_ce_1: 1.091  loss_mask_1: 0.03438  loss_dice_1: 0.6824  loss_bbox_1: 0.04533  loss_giou_1: 0.3865  loss_ce_dn_1: 0.2595  loss_mask_dn_1: 0.03099  loss_dice_dn_1: 0.6982  loss_bbox_dn_1: 0.06696  loss_giou_dn_1: 0.3981  loss_ce_2: 1.108  loss_mask_2: 0.04166  loss_dice_2: 0.5289  loss_bbox_2: 0.05157  loss_giou_2: 0.3958  loss_ce_dn_2: 0.2142  loss_mask_dn_2: 0.02993  loss_dice_dn_2: 0.663  loss_bbox_dn_2: 0.05406  loss_giou_dn_2: 0.3456  loss_ce_3: 0.8449  loss_mask_3: 0.03969  loss_dice_3: 0.7265  loss_bbox_3: 0.05325  loss_giou_3: 0.4008  loss_ce_dn_3: 0.2127  loss_mask_dn_3: 0.03  loss_dice_dn_3: 0.6299  loss_bbox_dn_3: 0.04334  loss_giou_dn_3: 0.3093  loss_ce_4: 1.003  loss_mask_4: 0.03787  loss_dice_4: 0.584  loss_bbox_4: 0.04953  loss_giou_4: 0.3747  loss_ce_dn_4: 0.2019  loss_mask_dn_4: 0.03067  loss_dice_dn_4: 0.6142  loss_bbox_dn_4: 0.04209  loss_giou_dn_4: 0.3002  loss_ce_5: 0.9902  loss_mask_5: 0.03021  loss_dice_5: 0.505  loss_bbox_5: 0.04979  loss_giou_5: 0.3943  loss_ce_dn_5: 0.1989  loss_mask_dn_5: 0.03152  loss_dice_dn_5: 0.596  loss_bbox_dn_5: 0.03955  loss_giou_dn_5: 0.2925  loss_ce_6: 0.8933  loss_mask_6: 0.03516  loss_dice_6: 0.4903  loss_bbox_6: 0.05341  loss_giou_6: 0.4103  loss_ce_dn_6: 0.203  loss_mask_dn_6: 0.03006  loss_dice_dn_6: 0.6174  loss_bbox_dn_6: 0.04057  loss_giou_dn_6: 0.295  loss_ce_7: 0.9602  loss_mask_7: 0.03277  loss_dice_7: 0.45  loss_bbox_7: 0.04978  loss_giou_7: 0.387  loss_ce_dn_7: 0.2079  loss_mask_dn_7: 0.02936  loss_dice_dn_7: 0.617  loss_bbox_dn_7: 0.04037  loss_giou_dn_7: 0.2943  loss_ce_8: 0.9612  loss_mask_8: 0.03415  loss_dice_8: 0.5552  loss_bbox_8: 0.05216  loss_giou_8: 0.3786  loss_ce_dn_8: 0.1931  loss_mask_dn_8: 0.02987  loss_dice_dn_8: 0.5966  loss_bbox_dn_8: 0.04029  loss_giou_dn_8: 0.2935  loss_ce_interm: 1.153  loss_mask_interm: 0.03601  loss_dice_interm: 0.7298  loss_bbox_interm: 0.1013  loss_giou_interm: 0.5292  time: 1.8546  data_time: 0.0760  lr: 1e-06  max_mem: 6663M\n",
            "[05/20 18:50:17 d2.utils.events]:  eta: 0:31:38  iter: 4559  total_loss: 45.59  loss_ce: 1.029  loss_mask: 0.03209  loss_dice: 0.803  loss_bbox: 0.05798  loss_giou: 0.34  loss_ce_dn: 0.1383  loss_mask_dn: 0.03213  loss_dice_dn: 0.6192  loss_bbox_dn: 0.04485  loss_giou_dn: 0.2845  loss_ce_0: 1.242  loss_mask_0: 0.0436  loss_dice_0: 0.8352  loss_bbox_0: 0.08129  loss_giou_0: 0.471  loss_ce_dn_0: 0.7492  loss_mask_dn_0: 0.2397  loss_dice_dn_0: 2.705  loss_bbox_dn_0: 0.3222  loss_giou_dn_0: 0.8625  loss_ce_1: 1.197  loss_mask_1: 0.03858  loss_dice_1: 0.6439  loss_bbox_1: 0.05944  loss_giou_1: 0.3782  loss_ce_dn_1: 0.2569  loss_mask_dn_1: 0.03527  loss_dice_dn_1: 0.7625  loss_bbox_dn_1: 0.08066  loss_giou_dn_1: 0.3602  loss_ce_2: 1.137  loss_mask_2: 0.0352  loss_dice_2: 0.7308  loss_bbox_2: 0.07375  loss_giou_2: 0.4427  loss_ce_dn_2: 0.2078  loss_mask_dn_2: 0.03325  loss_dice_dn_2: 0.721  loss_bbox_dn_2: 0.06194  loss_giou_dn_2: 0.3262  loss_ce_3: 1.009  loss_mask_3: 0.03389  loss_dice_3: 0.6997  loss_bbox_3: 0.0624  loss_giou_3: 0.3961  loss_ce_dn_3: 0.1924  loss_mask_dn_3: 0.03256  loss_dice_dn_3: 0.6721  loss_bbox_dn_3: 0.05258  loss_giou_dn_3: 0.3024  loss_ce_4: 0.9362  loss_mask_4: 0.03529  loss_dice_4: 0.7985  loss_bbox_4: 0.06076  loss_giou_4: 0.3882  loss_ce_dn_4: 0.1768  loss_mask_dn_4: 0.0321  loss_dice_dn_4: 0.6913  loss_bbox_dn_4: 0.04824  loss_giou_dn_4: 0.285  loss_ce_5: 0.9591  loss_mask_5: 0.03804  loss_dice_5: 0.7302  loss_bbox_5: 0.07089  loss_giou_5: 0.3914  loss_ce_dn_5: 0.1624  loss_mask_dn_5: 0.03076  loss_dice_dn_5: 0.6348  loss_bbox_dn_5: 0.04734  loss_giou_dn_5: 0.2938  loss_ce_6: 0.8455  loss_mask_6: 0.03436  loss_dice_6: 0.6906  loss_bbox_6: 0.07484  loss_giou_6: 0.3926  loss_ce_dn_6: 0.1549  loss_mask_dn_6: 0.03051  loss_dice_dn_6: 0.6867  loss_bbox_dn_6: 0.04498  loss_giou_dn_6: 0.2919  loss_ce_7: 0.86  loss_mask_7: 0.0354  loss_dice_7: 0.8339  loss_bbox_7: 0.06717  loss_giou_7: 0.353  loss_ce_dn_7: 0.1401  loss_mask_dn_7: 0.03073  loss_dice_dn_7: 0.642  loss_bbox_dn_7: 0.04416  loss_giou_dn_7: 0.293  loss_ce_8: 0.9048  loss_mask_8: 0.03342  loss_dice_8: 0.7079  loss_bbox_8: 0.05774  loss_giou_8: 0.377  loss_ce_dn_8: 0.1408  loss_mask_dn_8: 0.0316  loss_dice_dn_8: 0.6572  loss_bbox_dn_8: 0.04454  loss_giou_dn_8: 0.2906  loss_ce_interm: 1.374  loss_mask_interm: 0.03349  loss_dice_interm: 0.7238  loss_bbox_interm: 0.08918  loss_giou_interm: 0.5134  time: 1.8538  data_time: 0.0707  lr: 1e-06  max_mem: 6663M\n",
            "[05/20 18:50:52 d2.utils.events]:  eta: 0:31:06  iter: 4579  total_loss: 34.33  loss_ce: 1.049  loss_mask: 0.03593  loss_dice: 0.4244  loss_bbox: 0.04677  loss_giou: 0.2593  loss_ce_dn: 0.1733  loss_mask_dn: 0.03003  loss_dice_dn: 0.5185  loss_bbox_dn: 0.03907  loss_giou_dn: 0.2653  loss_ce_0: 1.231  loss_mask_0: 0.03653  loss_dice_0: 0.4566  loss_bbox_0: 0.05922  loss_giou_0: 0.3964  loss_ce_dn_0: 0.6457  loss_mask_dn_0: 0.07216  loss_dice_dn_0: 2.268  loss_bbox_dn_0: 0.2077  loss_giou_dn_0: 0.856  loss_ce_1: 1.307  loss_mask_1: 0.03423  loss_dice_1: 0.5198  loss_bbox_1: 0.05805  loss_giou_1: 0.3595  loss_ce_dn_1: 0.2625  loss_mask_dn_1: 0.02956  loss_dice_dn_1: 0.6173  loss_bbox_dn_1: 0.05285  loss_giou_dn_1: 0.3606  loss_ce_2: 1.258  loss_mask_2: 0.03185  loss_dice_2: 0.5299  loss_bbox_2: 0.04995  loss_giou_2: 0.2925  loss_ce_dn_2: 0.2143  loss_mask_dn_2: 0.02722  loss_dice_dn_2: 0.571  loss_bbox_dn_2: 0.04278  loss_giou_dn_2: 0.2986  loss_ce_3: 1.054  loss_mask_3: 0.03224  loss_dice_3: 0.4292  loss_bbox_3: 0.0496  loss_giou_3: 0.2802  loss_ce_dn_3: 0.1937  loss_mask_dn_3: 0.02714  loss_dice_dn_3: 0.5222  loss_bbox_dn_3: 0.04068  loss_giou_dn_3: 0.2864  loss_ce_4: 1.052  loss_mask_4: 0.02868  loss_dice_4: 0.481  loss_bbox_4: 0.0481  loss_giou_4: 0.2721  loss_ce_dn_4: 0.1812  loss_mask_dn_4: 0.02694  loss_dice_dn_4: 0.5514  loss_bbox_dn_4: 0.03971  loss_giou_dn_4: 0.2742  loss_ce_5: 0.9996  loss_mask_5: 0.03027  loss_dice_5: 0.4776  loss_bbox_5: 0.04901  loss_giou_5: 0.2807  loss_ce_dn_5: 0.1852  loss_mask_dn_5: 0.02908  loss_dice_dn_5: 0.5064  loss_bbox_dn_5: 0.03896  loss_giou_dn_5: 0.2678  loss_ce_6: 1.012  loss_mask_6: 0.02998  loss_dice_6: 0.5295  loss_bbox_6: 0.048  loss_giou_6: 0.269  loss_ce_dn_6: 0.1841  loss_mask_dn_6: 0.02958  loss_dice_dn_6: 0.5285  loss_bbox_dn_6: 0.03904  loss_giou_dn_6: 0.2689  loss_ce_7: 1.045  loss_mask_7: 0.02697  loss_dice_7: 0.5333  loss_bbox_7: 0.04788  loss_giou_7: 0.2661  loss_ce_dn_7: 0.1719  loss_mask_dn_7: 0.02924  loss_dice_dn_7: 0.5363  loss_bbox_dn_7: 0.03901  loss_giou_dn_7: 0.2711  loss_ce_8: 1.044  loss_mask_8: 0.02989  loss_dice_8: 0.48  loss_bbox_8: 0.04547  loss_giou_8: 0.2869  loss_ce_dn_8: 0.1781  loss_mask_dn_8: 0.03047  loss_dice_dn_8: 0.5274  loss_bbox_dn_8: 0.03878  loss_giou_dn_8: 0.2741  loss_ce_interm: 1.231  loss_mask_interm: 0.03523  loss_dice_interm: 0.555  loss_bbox_interm: 0.08975  loss_giou_interm: 0.4188  time: 1.8531  data_time: 0.0784  lr: 1e-06  max_mem: 6663M\n",
            "[05/20 18:51:26 d2.utils.events]:  eta: 0:30:34  iter: 4599  total_loss: 50.23  loss_ce: 1.284  loss_mask: 0.04781  loss_dice: 0.7866  loss_bbox: 0.07058  loss_giou: 0.475  loss_ce_dn: 0.169  loss_mask_dn: 0.04022  loss_dice_dn: 0.7402  loss_bbox_dn: 0.04092  loss_giou_dn: 0.3485  loss_ce_0: 1.392  loss_mask_0: 0.04565  loss_dice_0: 0.9009  loss_bbox_0: 0.09318  loss_giou_0: 0.5399  loss_ce_dn_0: 0.6757  loss_mask_dn_0: 0.2256  loss_dice_dn_0: 2.589  loss_bbox_dn_0: 0.2153  loss_giou_dn_0: 0.8585  loss_ce_1: 1.346  loss_mask_1: 0.03963  loss_dice_1: 0.9694  loss_bbox_1: 0.06845  loss_giou_1: 0.4997  loss_ce_dn_1: 0.2378  loss_mask_dn_1: 0.03615  loss_dice_dn_1: 0.7879  loss_bbox_dn_1: 0.06957  loss_giou_dn_1: 0.4228  loss_ce_2: 1.355  loss_mask_2: 0.04145  loss_dice_2: 0.7719  loss_bbox_2: 0.082  loss_giou_2: 0.4978  loss_ce_dn_2: 0.2063  loss_mask_dn_2: 0.03769  loss_dice_dn_2: 0.7633  loss_bbox_dn_2: 0.06274  loss_giou_dn_2: 0.3868  loss_ce_3: 1.245  loss_mask_3: 0.04503  loss_dice_3: 0.9231  loss_bbox_3: 0.08898  loss_giou_3: 0.5193  loss_ce_dn_3: 0.1995  loss_mask_dn_3: 0.0362  loss_dice_dn_3: 0.712  loss_bbox_dn_3: 0.04552  loss_giou_dn_3: 0.3732  loss_ce_4: 1.201  loss_mask_4: 0.04029  loss_dice_4: 0.9619  loss_bbox_4: 0.09281  loss_giou_4: 0.5352  loss_ce_dn_4: 0.1781  loss_mask_dn_4: 0.03747  loss_dice_dn_4: 0.7143  loss_bbox_dn_4: 0.04102  loss_giou_dn_4: 0.3712  loss_ce_5: 1.172  loss_mask_5: 0.04883  loss_dice_5: 0.8678  loss_bbox_5: 0.08377  loss_giou_5: 0.453  loss_ce_dn_5: 0.1676  loss_mask_dn_5: 0.03809  loss_dice_dn_5: 0.7083  loss_bbox_dn_5: 0.04056  loss_giou_dn_5: 0.3551  loss_ce_6: 1.242  loss_mask_6: 0.04307  loss_dice_6: 0.8875  loss_bbox_6: 0.0699  loss_giou_6: 0.4725  loss_ce_dn_6: 0.1713  loss_mask_dn_6: 0.03963  loss_dice_dn_6: 0.7129  loss_bbox_dn_6: 0.04081  loss_giou_dn_6: 0.3524  loss_ce_7: 1.289  loss_mask_7: 0.04269  loss_dice_7: 0.8856  loss_bbox_7: 0.07017  loss_giou_7: 0.4603  loss_ce_dn_7: 0.1703  loss_mask_dn_7: 0.03919  loss_dice_dn_7: 0.693  loss_bbox_dn_7: 0.04033  loss_giou_dn_7: 0.3509  loss_ce_8: 1.273  loss_mask_8: 0.04127  loss_dice_8: 0.856  loss_bbox_8: 0.0698  loss_giou_8: 0.511  loss_ce_dn_8: 0.1739  loss_mask_dn_8: 0.03999  loss_dice_dn_8: 0.7149  loss_bbox_dn_8: 0.04085  loss_giou_dn_8: 0.3514  loss_ce_interm: 1.386  loss_mask_interm: 0.04208  loss_dice_interm: 0.7905  loss_bbox_interm: 0.09346  loss_giou_interm: 0.5064  time: 1.8526  data_time: 0.1252  lr: 1e-06  max_mem: 6663M\n",
            "[05/20 18:52:01 d2.utils.events]:  eta: 0:29:58  iter: 4619  total_loss: 37.39  loss_ce: 0.8305  loss_mask: 0.04672  loss_dice: 0.4451  loss_bbox: 0.04933  loss_giou: 0.2892  loss_ce_dn: 0.1579  loss_mask_dn: 0.03935  loss_dice_dn: 0.4578  loss_bbox_dn: 0.04646  loss_giou_dn: 0.2304  loss_ce_0: 1.123  loss_mask_0: 0.04579  loss_dice_0: 0.5831  loss_bbox_0: 0.05711  loss_giou_0: 0.3341  loss_ce_dn_0: 0.7204  loss_mask_dn_0: 0.1259  loss_dice_dn_0: 2.385  loss_bbox_dn_0: 0.2471  loss_giou_dn_0: 0.8587  loss_ce_1: 1.133  loss_mask_1: 0.05274  loss_dice_1: 0.5326  loss_bbox_1: 0.0549  loss_giou_1: 0.2818  loss_ce_dn_1: 0.2642  loss_mask_dn_1: 0.03746  loss_dice_dn_1: 0.514  loss_bbox_dn_1: 0.06323  loss_giou_dn_1: 0.3472  loss_ce_2: 1.145  loss_mask_2: 0.05164  loss_dice_2: 0.5513  loss_bbox_2: 0.05116  loss_giou_2: 0.3103  loss_ce_dn_2: 0.2255  loss_mask_dn_2: 0.03657  loss_dice_dn_2: 0.479  loss_bbox_dn_2: 0.05217  loss_giou_dn_2: 0.2808  loss_ce_3: 0.9012  loss_mask_3: 0.04988  loss_dice_3: 0.5167  loss_bbox_3: 0.04911  loss_giou_3: 0.3425  loss_ce_dn_3: 0.1977  loss_mask_dn_3: 0.03895  loss_dice_dn_3: 0.4556  loss_bbox_dn_3: 0.0498  loss_giou_dn_3: 0.2533  loss_ce_4: 0.9874  loss_mask_4: 0.03441  loss_dice_4: 0.59  loss_bbox_4: 0.05022  loss_giou_4: 0.2717  loss_ce_dn_4: 0.1734  loss_mask_dn_4: 0.0375  loss_dice_dn_4: 0.4624  loss_bbox_dn_4: 0.04718  loss_giou_dn_4: 0.2446  loss_ce_5: 0.8999  loss_mask_5: 0.04224  loss_dice_5: 0.4837  loss_bbox_5: 0.04826  loss_giou_5: 0.2841  loss_ce_dn_5: 0.1748  loss_mask_dn_5: 0.03781  loss_dice_dn_5: 0.4408  loss_bbox_dn_5: 0.04655  loss_giou_dn_5: 0.2312  loss_ce_6: 0.8147  loss_mask_6: 0.03981  loss_dice_6: 0.4808  loss_bbox_6: 0.05019  loss_giou_6: 0.3009  loss_ce_dn_6: 0.1692  loss_mask_dn_6: 0.03716  loss_dice_dn_6: 0.4406  loss_bbox_dn_6: 0.04695  loss_giou_dn_6: 0.2395  loss_ce_7: 0.8274  loss_mask_7: 0.04091  loss_dice_7: 0.5274  loss_bbox_7: 0.04965  loss_giou_7: 0.2938  loss_ce_dn_7: 0.1641  loss_mask_dn_7: 0.03976  loss_dice_dn_7: 0.4363  loss_bbox_dn_7: 0.04601  loss_giou_dn_7: 0.235  loss_ce_8: 0.8069  loss_mask_8: 0.03874  loss_dice_8: 0.5044  loss_bbox_8: 0.04924  loss_giou_8: 0.2863  loss_ce_dn_8: 0.1583  loss_mask_dn_8: 0.04049  loss_dice_dn_8: 0.4606  loss_bbox_dn_8: 0.04779  loss_giou_dn_8: 0.2294  loss_ce_interm: 1.225  loss_mask_interm: 0.04646  loss_dice_interm: 0.5099  loss_bbox_interm: 0.0844  loss_giou_interm: 0.3961  time: 1.8521  data_time: 0.1096  lr: 1e-06  max_mem: 6663M\n",
            "[05/20 18:52:35 d2.utils.events]:  eta: 0:29:27  iter: 4639  total_loss: 48.63  loss_ce: 1.12  loss_mask: 0.03441  loss_dice: 0.8345  loss_bbox: 0.05244  loss_giou: 0.4611  loss_ce_dn: 0.1804  loss_mask_dn: 0.03087  loss_dice_dn: 0.8138  loss_bbox_dn: 0.03742  loss_giou_dn: 0.3635  loss_ce_0: 1.443  loss_mask_0: 0.04071  loss_dice_0: 0.9751  loss_bbox_0: 0.08171  loss_giou_0: 0.6522  loss_ce_dn_0: 0.7789  loss_mask_dn_0: 0.1187  loss_dice_dn_0: 2.762  loss_bbox_dn_0: 0.2624  loss_giou_dn_0: 0.8486  loss_ce_1: 1.385  loss_mask_1: 0.03383  loss_dice_1: 0.8387  loss_bbox_1: 0.06386  loss_giou_1: 0.5743  loss_ce_dn_1: 0.2626  loss_mask_dn_1: 0.03198  loss_dice_dn_1: 0.8584  loss_bbox_dn_1: 0.06565  loss_giou_dn_1: 0.419  loss_ce_2: 1.27  loss_mask_2: 0.04123  loss_dice_2: 0.9306  loss_bbox_2: 0.06791  loss_giou_2: 0.4653  loss_ce_dn_2: 0.2482  loss_mask_dn_2: 0.02915  loss_dice_dn_2: 0.8068  loss_bbox_dn_2: 0.05241  loss_giou_dn_2: 0.3924  loss_ce_3: 1.191  loss_mask_3: 0.03969  loss_dice_3: 0.6634  loss_bbox_3: 0.05844  loss_giou_3: 0.4565  loss_ce_dn_3: 0.2254  loss_mask_dn_3: 0.03145  loss_dice_dn_3: 0.7899  loss_bbox_dn_3: 0.04217  loss_giou_dn_3: 0.3819  loss_ce_4: 1.091  loss_mask_4: 0.03918  loss_dice_4: 0.7764  loss_bbox_4: 0.05604  loss_giou_4: 0.4421  loss_ce_dn_4: 0.1954  loss_mask_dn_4: 0.03119  loss_dice_dn_4: 0.7432  loss_bbox_dn_4: 0.04285  loss_giou_dn_4: 0.3821  loss_ce_5: 1.123  loss_mask_5: 0.03578  loss_dice_5: 0.8536  loss_bbox_5: 0.05486  loss_giou_5: 0.4389  loss_ce_dn_5: 0.1902  loss_mask_dn_5: 0.03192  loss_dice_dn_5: 0.7709  loss_bbox_dn_5: 0.03802  loss_giou_dn_5: 0.3691  loss_ce_6: 1.103  loss_mask_6: 0.03236  loss_dice_6: 0.7847  loss_bbox_6: 0.05576  loss_giou_6: 0.441  loss_ce_dn_6: 0.1806  loss_mask_dn_6: 0.03125  loss_dice_dn_6: 0.8049  loss_bbox_dn_6: 0.03801  loss_giou_dn_6: 0.3751  loss_ce_7: 1.076  loss_mask_7: 0.03752  loss_dice_7: 0.5301  loss_bbox_7: 0.05256  loss_giou_7: 0.4288  loss_ce_dn_7: 0.1777  loss_mask_dn_7: 0.03269  loss_dice_dn_7: 0.7849  loss_bbox_dn_7: 0.0392  loss_giou_dn_7: 0.3672  loss_ce_8: 1.088  loss_mask_8: 0.03491  loss_dice_8: 0.7558  loss_bbox_8: 0.05296  loss_giou_8: 0.4444  loss_ce_dn_8: 0.1791  loss_mask_dn_8: 0.03155  loss_dice_dn_8: 0.7942  loss_bbox_dn_8: 0.03742  loss_giou_dn_8: 0.3704  loss_ce_interm: 1.461  loss_mask_interm: 0.04438  loss_dice_interm: 0.8774  loss_bbox_interm: 0.09559  loss_giou_interm: 0.5899  time: 1.8513  data_time: 0.0771  lr: 1e-06  max_mem: 6663M\n",
            "[05/20 18:53:08 d2.utils.events]:  eta: 0:28:54  iter: 4659  total_loss: 46  loss_ce: 1.039  loss_mask: 0.03346  loss_dice: 0.6674  loss_bbox: 0.05569  loss_giou: 0.3805  loss_ce_dn: 0.1776  loss_mask_dn: 0.04029  loss_dice_dn: 0.6885  loss_bbox_dn: 0.03981  loss_giou_dn: 0.3191  loss_ce_0: 1.427  loss_mask_0: 0.03349  loss_dice_0: 0.9138  loss_bbox_0: 0.05962  loss_giou_0: 0.4691  loss_ce_dn_0: 0.7264  loss_mask_dn_0: 0.1152  loss_dice_dn_0: 2.008  loss_bbox_dn_0: 0.2308  loss_giou_dn_0: 0.8561  loss_ce_1: 1.342  loss_mask_1: 0.03214  loss_dice_1: 0.7445  loss_bbox_1: 0.05615  loss_giou_1: 0.3413  loss_ce_dn_1: 0.2532  loss_mask_dn_1: 0.0446  loss_dice_dn_1: 0.656  loss_bbox_dn_1: 0.05968  loss_giou_dn_1: 0.414  loss_ce_2: 1.125  loss_mask_2: 0.03783  loss_dice_2: 0.539  loss_bbox_2: 0.07534  loss_giou_2: 0.3457  loss_ce_dn_2: 0.2244  loss_mask_dn_2: 0.04268  loss_dice_dn_2: 0.673  loss_bbox_dn_2: 0.04654  loss_giou_dn_2: 0.3657  loss_ce_3: 0.9909  loss_mask_3: 0.02854  loss_dice_3: 0.7824  loss_bbox_3: 0.05955  loss_giou_3: 0.3614  loss_ce_dn_3: 0.2119  loss_mask_dn_3: 0.04038  loss_dice_dn_3: 0.7052  loss_bbox_dn_3: 0.0437  loss_giou_dn_3: 0.3276  loss_ce_4: 0.9711  loss_mask_4: 0.0338  loss_dice_4: 0.8223  loss_bbox_4: 0.0611  loss_giou_4: 0.3728  loss_ce_dn_4: 0.2138  loss_mask_dn_4: 0.03943  loss_dice_dn_4: 0.6607  loss_bbox_dn_4: 0.03934  loss_giou_dn_4: 0.3288  loss_ce_5: 1.039  loss_mask_5: 0.03694  loss_dice_5: 0.724  loss_bbox_5: 0.05883  loss_giou_5: 0.3562  loss_ce_dn_5: 0.2006  loss_mask_dn_5: 0.03852  loss_dice_dn_5: 0.6896  loss_bbox_dn_5: 0.03916  loss_giou_dn_5: 0.3259  loss_ce_6: 1.075  loss_mask_6: 0.03479  loss_dice_6: 0.7473  loss_bbox_6: 0.08118  loss_giou_6: 0.3658  loss_ce_dn_6: 0.1925  loss_mask_dn_6: 0.03747  loss_dice_dn_6: 0.6854  loss_bbox_dn_6: 0.03859  loss_giou_dn_6: 0.3309  loss_ce_7: 1.003  loss_mask_7: 0.0323  loss_dice_7: 0.791  loss_bbox_7: 0.05542  loss_giou_7: 0.3622  loss_ce_dn_7: 0.1906  loss_mask_dn_7: 0.03912  loss_dice_dn_7: 0.6552  loss_bbox_dn_7: 0.03819  loss_giou_dn_7: 0.31  loss_ce_8: 0.9726  loss_mask_8: 0.03893  loss_dice_8: 0.5289  loss_bbox_8: 0.05767  loss_giou_8: 0.3625  loss_ce_dn_8: 0.1808  loss_mask_dn_8: 0.03982  loss_dice_dn_8: 0.6947  loss_bbox_dn_8: 0.0395  loss_giou_dn_8: 0.3173  loss_ce_interm: 1.279  loss_mask_interm: 0.03002  loss_dice_interm: 0.4659  loss_bbox_interm: 0.08237  loss_giou_interm: 0.5115  time: 1.8505  data_time: 0.0733  lr: 1e-06  max_mem: 6663M\n",
            "[05/20 18:53:40 d2.utils.events]:  eta: 0:28:21  iter: 4679  total_loss: 45.25  loss_ce: 1.093  loss_mask: 0.05501  loss_dice: 0.6896  loss_bbox: 0.06125  loss_giou: 0.4831  loss_ce_dn: 0.1914  loss_mask_dn: 0.04937  loss_dice_dn: 0.7228  loss_bbox_dn: 0.04416  loss_giou_dn: 0.3624  loss_ce_0: 1.373  loss_mask_0: 0.0653  loss_dice_0: 0.6866  loss_bbox_0: 0.0792  loss_giou_0: 0.5204  loss_ce_dn_0: 0.7947  loss_mask_dn_0: 0.1898  loss_dice_dn_0: 2.581  loss_bbox_dn_0: 0.3862  loss_giou_dn_0: 0.8557  loss_ce_1: 1.421  loss_mask_1: 0.05924  loss_dice_1: 0.7575  loss_bbox_1: 0.06985  loss_giou_1: 0.4218  loss_ce_dn_1: 0.2911  loss_mask_dn_1: 0.06434  loss_dice_dn_1: 0.7231  loss_bbox_dn_1: 0.09495  loss_giou_dn_1: 0.4271  loss_ce_2: 1.261  loss_mask_2: 0.05684  loss_dice_2: 0.6341  loss_bbox_2: 0.06798  loss_giou_2: 0.4594  loss_ce_dn_2: 0.2365  loss_mask_dn_2: 0.05912  loss_dice_dn_2: 0.7439  loss_bbox_dn_2: 0.06476  loss_giou_dn_2: 0.3824  loss_ce_3: 1.249  loss_mask_3: 0.0572  loss_dice_3: 0.5835  loss_bbox_3: 0.06919  loss_giou_3: 0.4781  loss_ce_dn_3: 0.2383  loss_mask_dn_3: 0.05512  loss_dice_dn_3: 0.7277  loss_bbox_dn_3: 0.05322  loss_giou_dn_3: 0.3689  loss_ce_4: 1.164  loss_mask_4: 0.06368  loss_dice_4: 0.5774  loss_bbox_4: 0.07189  loss_giou_4: 0.4825  loss_ce_dn_4: 0.2195  loss_mask_dn_4: 0.05726  loss_dice_dn_4: 0.754  loss_bbox_dn_4: 0.05069  loss_giou_dn_4: 0.3652  loss_ce_5: 1.128  loss_mask_5: 0.05541  loss_dice_5: 0.5025  loss_bbox_5: 0.05817  loss_giou_5: 0.477  loss_ce_dn_5: 0.2119  loss_mask_dn_5: 0.05167  loss_dice_dn_5: 0.679  loss_bbox_dn_5: 0.04827  loss_giou_dn_5: 0.364  loss_ce_6: 1.103  loss_mask_6: 0.05474  loss_dice_6: 0.5423  loss_bbox_6: 0.06072  loss_giou_6: 0.4855  loss_ce_dn_6: 0.2016  loss_mask_dn_6: 0.05055  loss_dice_dn_6: 0.705  loss_bbox_dn_6: 0.0476  loss_giou_dn_6: 0.3604  loss_ce_7: 1.113  loss_mask_7: 0.05416  loss_dice_7: 0.485  loss_bbox_7: 0.063  loss_giou_7: 0.4807  loss_ce_dn_7: 0.1927  loss_mask_dn_7: 0.05144  loss_dice_dn_7: 0.7229  loss_bbox_dn_7: 0.04595  loss_giou_dn_7: 0.3607  loss_ce_8: 1.086  loss_mask_8: 0.05388  loss_dice_8: 0.7089  loss_bbox_8: 0.06107  loss_giou_8: 0.4875  loss_ce_dn_8: 0.1921  loss_mask_dn_8: 0.0506  loss_dice_dn_8: 0.6866  loss_bbox_dn_8: 0.04582  loss_giou_dn_8: 0.3589  loss_ce_interm: 1.491  loss_mask_interm: 0.05821  loss_dice_interm: 0.868  loss_bbox_interm: 0.1256  loss_giou_interm: 0.5462  time: 1.8494  data_time: 0.0317  lr: 1e-06  max_mem: 6663M\n",
            "[05/20 18:54:13 d2.utils.events]:  eta: 0:27:49  iter: 4699  total_loss: 50  loss_ce: 1.149  loss_mask: 0.02628  loss_dice: 0.8521  loss_bbox: 0.04991  loss_giou: 0.4134  loss_ce_dn: 0.2036  loss_mask_dn: 0.02649  loss_dice_dn: 0.652  loss_bbox_dn: 0.03534  loss_giou_dn: 0.3211  loss_ce_0: 1.391  loss_mask_0: 0.03617  loss_dice_0: 0.6461  loss_bbox_0: 0.09327  loss_giou_0: 0.6855  loss_ce_dn_0: 0.6976  loss_mask_dn_0: 0.1645  loss_dice_dn_0: 2.801  loss_bbox_dn_0: 0.1796  loss_giou_dn_0: 0.8516  loss_ce_1: 1.38  loss_mask_1: 0.0257  loss_dice_1: 0.8438  loss_bbox_1: 0.0669  loss_giou_1: 0.4796  loss_ce_dn_1: 0.2575  loss_mask_dn_1: 0.02714  loss_dice_dn_1: 0.7477  loss_bbox_dn_1: 0.05991  loss_giou_dn_1: 0.4225  loss_ce_2: 1.277  loss_mask_2: 0.02594  loss_dice_2: 0.6867  loss_bbox_2: 0.06906  loss_giou_2: 0.4959  loss_ce_dn_2: 0.2498  loss_mask_dn_2: 0.02531  loss_dice_dn_2: 0.6396  loss_bbox_dn_2: 0.04467  loss_giou_dn_2: 0.3531  loss_ce_3: 1.244  loss_mask_3: 0.02821  loss_dice_3: 0.6149  loss_bbox_3: 0.05733  loss_giou_3: 0.4955  loss_ce_dn_3: 0.2447  loss_mask_dn_3: 0.02547  loss_dice_dn_3: 0.6949  loss_bbox_dn_3: 0.0381  loss_giou_dn_3: 0.3359  loss_ce_4: 1.144  loss_mask_4: 0.02398  loss_dice_4: 0.7786  loss_bbox_4: 0.07189  loss_giou_4: 0.4453  loss_ce_dn_4: 0.2313  loss_mask_dn_4: 0.02479  loss_dice_dn_4: 0.646  loss_bbox_dn_4: 0.03735  loss_giou_dn_4: 0.3084  loss_ce_5: 1.221  loss_mask_5: 0.02496  loss_dice_5: 0.566  loss_bbox_5: 0.0478  loss_giou_5: 0.418  loss_ce_dn_5: 0.2227  loss_mask_dn_5: 0.02497  loss_dice_dn_5: 0.6805  loss_bbox_dn_5: 0.03582  loss_giou_dn_5: 0.3159  loss_ce_6: 1.111  loss_mask_6: 0.02582  loss_dice_6: 0.7439  loss_bbox_6: 0.06095  loss_giou_6: 0.4191  loss_ce_dn_6: 0.2159  loss_mask_dn_6: 0.02554  loss_dice_dn_6: 0.6593  loss_bbox_dn_6: 0.03547  loss_giou_dn_6: 0.3222  loss_ce_7: 1.235  loss_mask_7: 0.0292  loss_dice_7: 0.9673  loss_bbox_7: 0.05884  loss_giou_7: 0.55  loss_ce_dn_7: 0.2096  loss_mask_dn_7: 0.02615  loss_dice_dn_7: 0.6155  loss_bbox_dn_7: 0.03525  loss_giou_dn_7: 0.321  loss_ce_8: 1.2  loss_mask_8: 0.02415  loss_dice_8: 0.6324  loss_bbox_8: 0.04738  loss_giou_8: 0.4123  loss_ce_dn_8: 0.2106  loss_mask_dn_8: 0.02652  loss_dice_dn_8: 0.6125  loss_bbox_dn_8: 0.03568  loss_giou_dn_8: 0.3229  loss_ce_interm: 1.401  loss_mask_interm: 0.02369  loss_dice_interm: 0.9284  loss_bbox_interm: 0.07562  loss_giou_interm: 0.5178  time: 1.8485  data_time: 0.0612  lr: 1e-06  max_mem: 6663M\n",
            "[05/20 18:54:48 d2.utils.events]:  eta: 0:27:17  iter: 4719  total_loss: 43.95  loss_ce: 1.021  loss_mask: 0.02777  loss_dice: 0.4037  loss_bbox: 0.1027  loss_giou: 0.3872  loss_ce_dn: 0.2524  loss_mask_dn: 0.03039  loss_dice_dn: 0.4688  loss_bbox_dn: 0.03357  loss_giou_dn: 0.3153  loss_ce_0: 1.233  loss_mask_0: 0.03205  loss_dice_0: 0.4791  loss_bbox_0: 0.1393  loss_giou_0: 0.46  loss_ce_dn_0: 0.7446  loss_mask_dn_0: 0.182  loss_dice_dn_0: 2.381  loss_bbox_dn_0: 0.2465  loss_giou_dn_0: 0.8625  loss_ce_1: 1.347  loss_mask_1: 0.03265  loss_dice_1: 0.5616  loss_bbox_1: 0.08866  loss_giou_1: 0.4117  loss_ce_dn_1: 0.3246  loss_mask_dn_1: 0.0325  loss_dice_dn_1: 0.5913  loss_bbox_dn_1: 0.05513  loss_giou_dn_1: 0.381  loss_ce_2: 1.241  loss_mask_2: 0.03494  loss_dice_2: 0.5348  loss_bbox_2: 0.08504  loss_giou_2: 0.3794  loss_ce_dn_2: 0.3134  loss_mask_dn_2: 0.03007  loss_dice_dn_2: 0.4945  loss_bbox_dn_2: 0.04207  loss_giou_dn_2: 0.3334  loss_ce_3: 1.123  loss_mask_3: 0.02851  loss_dice_3: 0.5055  loss_bbox_3: 0.114  loss_giou_3: 0.4263  loss_ce_dn_3: 0.2906  loss_mask_dn_3: 0.03217  loss_dice_dn_3: 0.5038  loss_bbox_dn_3: 0.03394  loss_giou_dn_3: 0.3183  loss_ce_4: 1.15  loss_mask_4: 0.02768  loss_dice_4: 0.4969  loss_bbox_4: 0.08888  loss_giou_4: 0.3824  loss_ce_dn_4: 0.283  loss_mask_dn_4: 0.03132  loss_dice_dn_4: 0.4941  loss_bbox_dn_4: 0.03317  loss_giou_dn_4: 0.3154  loss_ce_5: 1.094  loss_mask_5: 0.02969  loss_dice_5: 0.5199  loss_bbox_5: 0.07949  loss_giou_5: 0.3851  loss_ce_dn_5: 0.2725  loss_mask_dn_5: 0.03121  loss_dice_dn_5: 0.4946  loss_bbox_dn_5: 0.03411  loss_giou_dn_5: 0.3093  loss_ce_6: 1.086  loss_mask_6: 0.03064  loss_dice_6: 0.4564  loss_bbox_6: 0.09246  loss_giou_6: 0.3872  loss_ce_dn_6: 0.2555  loss_mask_dn_6: 0.0314  loss_dice_dn_6: 0.4947  loss_bbox_dn_6: 0.03329  loss_giou_dn_6: 0.3094  loss_ce_7: 1.058  loss_mask_7: 0.03086  loss_dice_7: 0.4117  loss_bbox_7: 0.1005  loss_giou_7: 0.3851  loss_ce_dn_7: 0.2531  loss_mask_dn_7: 0.03165  loss_dice_dn_7: 0.4662  loss_bbox_dn_7: 0.03276  loss_giou_dn_7: 0.317  loss_ce_8: 1.082  loss_mask_8: 0.02514  loss_dice_8: 0.4271  loss_bbox_8: 0.1014  loss_giou_8: 0.3828  loss_ce_dn_8: 0.2597  loss_mask_dn_8: 0.0307  loss_dice_dn_8: 0.4589  loss_bbox_dn_8: 0.03266  loss_giou_dn_8: 0.3155  loss_ce_interm: 1.342  loss_mask_interm: 0.03864  loss_dice_interm: 0.7291  loss_bbox_interm: 0.127  loss_giou_interm: 0.4226  time: 1.8482  data_time: 0.1198  lr: 1e-06  max_mem: 6663M\n",
            "[05/20 18:55:22 d2.utils.events]:  eta: 0:26:44  iter: 4739  total_loss: 40.21  loss_ce: 0.9407  loss_mask: 0.04416  loss_dice: 0.4219  loss_bbox: 0.06324  loss_giou: 0.3104  loss_ce_dn: 0.1066  loss_mask_dn: 0.04605  loss_dice_dn: 0.5317  loss_bbox_dn: 0.03881  loss_giou_dn: 0.2727  loss_ce_0: 1.269  loss_mask_0: 0.04422  loss_dice_0: 0.5967  loss_bbox_0: 0.1017  loss_giou_0: 0.3914  loss_ce_dn_0: 0.7974  loss_mask_dn_0: 0.2121  loss_dice_dn_0: 2.44  loss_bbox_dn_0: 0.2783  loss_giou_dn_0: 0.8527  loss_ce_1: 1.208  loss_mask_1: 0.03868  loss_dice_1: 0.5966  loss_bbox_1: 0.09192  loss_giou_1: 0.3294  loss_ce_dn_1: 0.2501  loss_mask_dn_1: 0.04372  loss_dice_dn_1: 0.6157  loss_bbox_dn_1: 0.0887  loss_giou_dn_1: 0.3808  loss_ce_2: 1.074  loss_mask_2: 0.0412  loss_dice_2: 0.6555  loss_bbox_2: 0.1036  loss_giou_2: 0.3289  loss_ce_dn_2: 0.1766  loss_mask_dn_2: 0.0428  loss_dice_dn_2: 0.5797  loss_bbox_dn_2: 0.05996  loss_giou_dn_2: 0.3099  loss_ce_3: 1.003  loss_mask_3: 0.04933  loss_dice_3: 0.5282  loss_bbox_3: 0.08886  loss_giou_3: 0.3417  loss_ce_dn_3: 0.1544  loss_mask_dn_3: 0.04522  loss_dice_dn_3: 0.5659  loss_bbox_dn_3: 0.04828  loss_giou_dn_3: 0.2869  loss_ce_4: 0.9829  loss_mask_4: 0.05129  loss_dice_4: 0.6175  loss_bbox_4: 0.07925  loss_giou_4: 0.3318  loss_ce_dn_4: 0.1453  loss_mask_dn_4: 0.04499  loss_dice_dn_4: 0.574  loss_bbox_dn_4: 0.04102  loss_giou_dn_4: 0.2719  loss_ce_5: 0.9995  loss_mask_5: 0.04454  loss_dice_5: 0.5341  loss_bbox_5: 0.07027  loss_giou_5: 0.3013  loss_ce_dn_5: 0.1282  loss_mask_dn_5: 0.04235  loss_dice_dn_5: 0.5641  loss_bbox_dn_5: 0.04178  loss_giou_dn_5: 0.2724  loss_ce_6: 0.975  loss_mask_6: 0.04442  loss_dice_6: 0.472  loss_bbox_6: 0.07136  loss_giou_6: 0.3165  loss_ce_dn_6: 0.1137  loss_mask_dn_6: 0.0439  loss_dice_dn_6: 0.5569  loss_bbox_dn_6: 0.04248  loss_giou_dn_6: 0.2738  loss_ce_7: 0.9865  loss_mask_7: 0.05239  loss_dice_7: 0.4741  loss_bbox_7: 0.0622  loss_giou_7: 0.2821  loss_ce_dn_7: 0.1031  loss_mask_dn_7: 0.04515  loss_dice_dn_7: 0.5114  loss_bbox_dn_7: 0.04184  loss_giou_dn_7: 0.2728  loss_ce_8: 1.004  loss_mask_8: 0.04578  loss_dice_8: 0.4617  loss_bbox_8: 0.06123  loss_giou_8: 0.2888  loss_ce_dn_8: 0.1081  loss_mask_dn_8: 0.04522  loss_dice_dn_8: 0.5335  loss_bbox_dn_8: 0.04129  loss_giou_dn_8: 0.269  loss_ce_interm: 1.306  loss_mask_interm: 0.04119  loss_dice_interm: 0.4756  loss_bbox_interm: 0.09993  loss_giou_interm: 0.3809  time: 1.8475  data_time: 0.0671  lr: 1e-06  max_mem: 6663M\n",
            "[05/20 18:55:57 d2.utils.events]:  eta: 0:26:13  iter: 4759  total_loss: 39.27  loss_ce: 0.8758  loss_mask: 0.0375  loss_dice: 0.4909  loss_bbox: 0.06173  loss_giou: 0.3093  loss_ce_dn: 0.1949  loss_mask_dn: 0.04109  loss_dice_dn: 0.382  loss_bbox_dn: 0.05529  loss_giou_dn: 0.2583  loss_ce_0: 1.224  loss_mask_0: 0.04849  loss_dice_0: 0.5097  loss_bbox_0: 0.08162  loss_giou_0: 0.3805  loss_ce_dn_0: 0.7416  loss_mask_dn_0: 0.2284  loss_dice_dn_0: 2.666  loss_bbox_dn_0: 0.3397  loss_giou_dn_0: 0.8488  loss_ce_1: 1.221  loss_mask_1: 0.04568  loss_dice_1: 0.5118  loss_bbox_1: 0.07557  loss_giou_1: 0.3442  loss_ce_dn_1: 0.3092  loss_mask_dn_1: 0.04531  loss_dice_dn_1: 0.3895  loss_bbox_dn_1: 0.1037  loss_giou_dn_1: 0.3702  loss_ce_2: 1.127  loss_mask_2: 0.04176  loss_dice_2: 0.3929  loss_bbox_2: 0.07308  loss_giou_2: 0.3441  loss_ce_dn_2: 0.2588  loss_mask_dn_2: 0.03989  loss_dice_dn_2: 0.3721  loss_bbox_dn_2: 0.07477  loss_giou_dn_2: 0.3168  loss_ce_3: 1.011  loss_mask_3: 0.04616  loss_dice_3: 0.4746  loss_bbox_3: 0.06946  loss_giou_3: 0.3396  loss_ce_dn_3: 0.2439  loss_mask_dn_3: 0.03713  loss_dice_dn_3: 0.368  loss_bbox_dn_3: 0.06581  loss_giou_dn_3: 0.2996  loss_ce_4: 0.9581  loss_mask_4: 0.04229  loss_dice_4: 0.4972  loss_bbox_4: 0.06597  loss_giou_4: 0.3292  loss_ce_dn_4: 0.2356  loss_mask_dn_4: 0.03875  loss_dice_dn_4: 0.3519  loss_bbox_dn_4: 0.05804  loss_giou_dn_4: 0.2771  loss_ce_5: 0.9061  loss_mask_5: 0.03816  loss_dice_5: 0.4507  loss_bbox_5: 0.06419  loss_giou_5: 0.3111  loss_ce_dn_5: 0.2154  loss_mask_dn_5: 0.03777  loss_dice_dn_5: 0.3694  loss_bbox_dn_5: 0.05343  loss_giou_dn_5: 0.2622  loss_ce_6: 0.8595  loss_mask_6: 0.04457  loss_dice_6: 0.4268  loss_bbox_6: 0.06464  loss_giou_6: 0.3162  loss_ce_dn_6: 0.2178  loss_mask_dn_6: 0.03861  loss_dice_dn_6: 0.3732  loss_bbox_dn_6: 0.05392  loss_giou_dn_6: 0.2576  loss_ce_7: 0.8379  loss_mask_7: 0.04017  loss_dice_7: 0.4377  loss_bbox_7: 0.06356  loss_giou_7: 0.3  loss_ce_dn_7: 0.2047  loss_mask_dn_7: 0.03922  loss_dice_dn_7: 0.3805  loss_bbox_dn_7: 0.05335  loss_giou_dn_7: 0.2594  loss_ce_8: 0.8605  loss_mask_8: 0.03673  loss_dice_8: 0.4274  loss_bbox_8: 0.0614  loss_giou_8: 0.3068  loss_ce_dn_8: 0.1989  loss_mask_dn_8: 0.04056  loss_dice_dn_8: 0.3758  loss_bbox_dn_8: 0.05318  loss_giou_dn_8: 0.262  loss_ce_interm: 1.148  loss_mask_interm: 0.05112  loss_dice_interm: 0.3775  loss_bbox_interm: 0.1228  loss_giou_interm: 0.3209  time: 1.8470  data_time: 0.1209  lr: 1e-06  max_mem: 6663M\n",
            "[05/20 18:56:30 d2.utils.events]:  eta: 0:25:42  iter: 4779  total_loss: 34.4  loss_ce: 0.7901  loss_mask: 0.04108  loss_dice: 0.5613  loss_bbox: 0.0475  loss_giou: 0.3261  loss_ce_dn: 0.1842  loss_mask_dn: 0.0387  loss_dice_dn: 0.5636  loss_bbox_dn: 0.0414  loss_giou_dn: 0.2524  loss_ce_0: 1.019  loss_mask_0: 0.04815  loss_dice_0: 0.7005  loss_bbox_0: 0.0862  loss_giou_0: 0.4355  loss_ce_dn_0: 0.7005  loss_mask_dn_0: 0.1295  loss_dice_dn_0: 2.469  loss_bbox_dn_0: 0.2799  loss_giou_dn_0: 0.8569  loss_ce_1: 1.053  loss_mask_1: 0.04799  loss_dice_1: 0.5777  loss_bbox_1: 0.062  loss_giou_1: 0.3748  loss_ce_dn_1: 0.2689  loss_mask_dn_1: 0.04274  loss_dice_dn_1: 0.6029  loss_bbox_dn_1: 0.07184  loss_giou_dn_1: 0.3147  loss_ce_2: 1.138  loss_mask_2: 0.04393  loss_dice_2: 0.6291  loss_bbox_2: 0.04709  loss_giou_2: 0.3272  loss_ce_dn_2: 0.2366  loss_mask_dn_2: 0.04228  loss_dice_dn_2: 0.5589  loss_bbox_dn_2: 0.05932  loss_giou_dn_2: 0.3219  loss_ce_3: 0.9035  loss_mask_3: 0.04468  loss_dice_3: 0.505  loss_bbox_3: 0.05097  loss_giou_3: 0.3365  loss_ce_dn_3: 0.1989  loss_mask_dn_3: 0.04366  loss_dice_dn_3: 0.593  loss_bbox_dn_3: 0.0523  loss_giou_dn_3: 0.2752  loss_ce_4: 0.8569  loss_mask_4: 0.03754  loss_dice_4: 0.5932  loss_bbox_4: 0.05073  loss_giou_4: 0.3358  loss_ce_dn_4: 0.1911  loss_mask_dn_4: 0.04105  loss_dice_dn_4: 0.6426  loss_bbox_dn_4: 0.0466  loss_giou_dn_4: 0.272  loss_ce_5: 0.8334  loss_mask_5: 0.04191  loss_dice_5: 0.5833  loss_bbox_5: 0.05012  loss_giou_5: 0.3345  loss_ce_dn_5: 0.1921  loss_mask_dn_5: 0.03974  loss_dice_dn_5: 0.5691  loss_bbox_dn_5: 0.04592  loss_giou_dn_5: 0.2601  loss_ce_6: 0.8045  loss_mask_6: 0.04269  loss_dice_6: 0.5923  loss_bbox_6: 0.04878  loss_giou_6: 0.3244  loss_ce_dn_6: 0.1825  loss_mask_dn_6: 0.04048  loss_dice_dn_6: 0.6072  loss_bbox_dn_6: 0.04669  loss_giou_dn_6: 0.263  loss_ce_7: 0.8113  loss_mask_7: 0.03851  loss_dice_7: 0.6292  loss_bbox_7: 0.04833  loss_giou_7: 0.3248  loss_ce_dn_7: 0.1849  loss_mask_dn_7: 0.03925  loss_dice_dn_7: 0.558  loss_bbox_dn_7: 0.04294  loss_giou_dn_7: 0.2552  loss_ce_8: 0.7801  loss_mask_8: 0.0428  loss_dice_8: 0.7012  loss_bbox_8: 0.04872  loss_giou_8: 0.3349  loss_ce_dn_8: 0.1792  loss_mask_dn_8: 0.03994  loss_dice_dn_8: 0.583  loss_bbox_dn_8: 0.04269  loss_giou_dn_8: 0.2563  loss_ce_interm: 1.019  loss_mask_interm: 0.04497  loss_dice_interm: 0.6294  loss_bbox_interm: 0.09684  loss_giou_interm: 0.3879  time: 1.8463  data_time: 0.0599  lr: 1e-06  max_mem: 6663M\n",
            "[05/20 18:57:05 d2.utils.events]:  eta: 0:25:09  iter: 4799  total_loss: 45.09  loss_ce: 1.073  loss_mask: 0.03872  loss_dice: 0.6167  loss_bbox: 0.04201  loss_giou: 0.3295  loss_ce_dn: 0.1888  loss_mask_dn: 0.03468  loss_dice_dn: 0.6715  loss_bbox_dn: 0.03552  loss_giou_dn: 0.264  loss_ce_0: 1.303  loss_mask_0: 0.03216  loss_dice_0: 0.5923  loss_bbox_0: 0.04706  loss_giou_0: 0.4324  loss_ce_dn_0: 0.7079  loss_mask_dn_0: 0.4192  loss_dice_dn_0: 2.505  loss_bbox_dn_0: 0.2282  loss_giou_dn_0: 0.8527  loss_ce_1: 1.279  loss_mask_1: 0.04044  loss_dice_1: 0.5653  loss_bbox_1: 0.05323  loss_giou_1: 0.3492  loss_ce_dn_1: 0.2756  loss_mask_dn_1: 0.03832  loss_dice_dn_1: 0.7221  loss_bbox_dn_1: 0.05462  loss_giou_dn_1: 0.3873  loss_ce_2: 1.264  loss_mask_2: 0.03271  loss_dice_2: 0.6424  loss_bbox_2: 0.05229  loss_giou_2: 0.3577  loss_ce_dn_2: 0.2424  loss_mask_dn_2: 0.03453  loss_dice_dn_2: 0.6853  loss_bbox_dn_2: 0.04447  loss_giou_dn_2: 0.3325  loss_ce_3: 1.179  loss_mask_3: 0.03438  loss_dice_3: 0.6971  loss_bbox_3: 0.04304  loss_giou_3: 0.3526  loss_ce_dn_3: 0.2139  loss_mask_dn_3: 0.03448  loss_dice_dn_3: 0.7095  loss_bbox_dn_3: 0.03789  loss_giou_dn_3: 0.3003  loss_ce_4: 1.094  loss_mask_4: 0.03276  loss_dice_4: 0.9528  loss_bbox_4: 0.04981  loss_giou_4: 0.3197  loss_ce_dn_4: 0.2155  loss_mask_dn_4: 0.03518  loss_dice_dn_4: 0.6967  loss_bbox_dn_4: 0.03587  loss_giou_dn_4: 0.28  loss_ce_5: 1.104  loss_mask_5: 0.03893  loss_dice_5: 0.7411  loss_bbox_5: 0.04585  loss_giou_5: 0.3086  loss_ce_dn_5: 0.2091  loss_mask_dn_5: 0.0351  loss_dice_dn_5: 0.6761  loss_bbox_dn_5: 0.03582  loss_giou_dn_5: 0.2665  loss_ce_6: 1.117  loss_mask_6: 0.03124  loss_dice_6: 0.8226  loss_bbox_6: 0.04245  loss_giou_6: 0.3078  loss_ce_dn_6: 0.1977  loss_mask_dn_6: 0.03346  loss_dice_dn_6: 0.6711  loss_bbox_dn_6: 0.03594  loss_giou_dn_6: 0.2686  loss_ce_7: 1.119  loss_mask_7: 0.03548  loss_dice_7: 0.7076  loss_bbox_7: 0.0416  loss_giou_7: 0.3418  loss_ce_dn_7: 0.1975  loss_mask_dn_7: 0.03369  loss_dice_dn_7: 0.6815  loss_bbox_dn_7: 0.03595  loss_giou_dn_7: 0.2591  loss_ce_8: 1.049  loss_mask_8: 0.03753  loss_dice_8: 0.5662  loss_bbox_8: 0.04093  loss_giou_8: 0.3325  loss_ce_dn_8: 0.1884  loss_mask_dn_8: 0.03455  loss_dice_dn_8: 0.6699  loss_bbox_dn_8: 0.03599  loss_giou_dn_8: 0.2602  loss_ce_interm: 1.248  loss_mask_interm: 0.04101  loss_dice_interm: 0.5319  loss_bbox_interm: 0.07578  loss_giou_interm: 0.4027  time: 1.8455  data_time: 0.0509  lr: 1e-06  max_mem: 6663M\n",
            "[05/20 18:57:38 d2.utils.events]:  eta: 0:24:32  iter: 4819  total_loss: 46.79  loss_ce: 0.9309  loss_mask: 0.0754  loss_dice: 0.5885  loss_bbox: 0.07089  loss_giou: 0.2877  loss_ce_dn: 0.1924  loss_mask_dn: 0.07426  loss_dice_dn: 0.5025  loss_bbox_dn: 0.05685  loss_giou_dn: 0.2615  loss_ce_0: 1.434  loss_mask_0: 0.06584  loss_dice_0: 0.6475  loss_bbox_0: 0.06356  loss_giou_0: 0.3451  loss_ce_dn_0: 0.7662  loss_mask_dn_0: 0.3614  loss_dice_dn_0: 2.793  loss_bbox_dn_0: 0.3687  loss_giou_dn_0: 0.8442  loss_ce_1: 1.336  loss_mask_1: 0.07802  loss_dice_1: 0.6146  loss_bbox_1: 0.0546  loss_giou_1: 0.2933  loss_ce_dn_1: 0.2682  loss_mask_dn_1: 0.08206  loss_dice_dn_1: 0.6002  loss_bbox_dn_1: 0.09309  loss_giou_dn_1: 0.3778  loss_ce_2: 1.001  loss_mask_2: 0.08415  loss_dice_2: 0.4868  loss_bbox_2: 0.07218  loss_giou_2: 0.3311  loss_ce_dn_2: 0.2393  loss_mask_dn_2: 0.08004  loss_dice_dn_2: 0.5205  loss_bbox_dn_2: 0.07514  loss_giou_dn_2: 0.2956  loss_ce_3: 1.135  loss_mask_3: 0.0709  loss_dice_3: 0.4639  loss_bbox_3: 0.06908  loss_giou_3: 0.2843  loss_ce_dn_3: 0.228  loss_mask_dn_3: 0.07548  loss_dice_dn_3: 0.4941  loss_bbox_dn_3: 0.06866  loss_giou_dn_3: 0.2699  loss_ce_4: 0.9279  loss_mask_4: 0.08409  loss_dice_4: 0.4675  loss_bbox_4: 0.07353  loss_giou_4: 0.3013  loss_ce_dn_4: 0.2057  loss_mask_dn_4: 0.07662  loss_dice_dn_4: 0.5099  loss_bbox_dn_4: 0.06367  loss_giou_dn_4: 0.2638  loss_ce_5: 0.9809  loss_mask_5: 0.08385  loss_dice_5: 0.683  loss_bbox_5: 0.07451  loss_giou_5: 0.3039  loss_ce_dn_5: 0.203  loss_mask_dn_5: 0.08219  loss_dice_dn_5: 0.4778  loss_bbox_dn_5: 0.05867  loss_giou_dn_5: 0.2565  loss_ce_6: 0.9074  loss_mask_6: 0.08804  loss_dice_6: 0.6042  loss_bbox_6: 0.07536  loss_giou_6: 0.3001  loss_ce_dn_6: 0.2016  loss_mask_dn_6: 0.07287  loss_dice_dn_6: 0.564  loss_bbox_dn_6: 0.05625  loss_giou_dn_6: 0.2562  loss_ce_7: 0.9047  loss_mask_7: 0.07302  loss_dice_7: 0.4965  loss_bbox_7: 0.0713  loss_giou_7: 0.2883  loss_ce_dn_7: 0.2018  loss_mask_dn_7: 0.07418  loss_dice_dn_7: 0.4963  loss_bbox_dn_7: 0.05862  loss_giou_dn_7: 0.2596  loss_ce_8: 0.9611  loss_mask_8: 0.07321  loss_dice_8: 0.6697  loss_bbox_8: 0.07797  loss_giou_8: 0.298  loss_ce_dn_8: 0.1982  loss_mask_dn_8: 0.07445  loss_dice_dn_8: 0.5037  loss_bbox_dn_8: 0.05814  loss_giou_dn_8: 0.2625  loss_ce_interm: 1.391  loss_mask_interm: 0.07941  loss_dice_interm: 0.7134  loss_bbox_interm: 0.1063  loss_giou_interm: 0.3789  time: 1.8447  data_time: 0.0850  lr: 1e-06  max_mem: 6663M\n",
            "[05/20 18:58:12 d2.utils.events]:  eta: 0:24:03  iter: 4839  total_loss: 45.47  loss_ce: 1.134  loss_mask: 0.04201  loss_dice: 0.8797  loss_bbox: 0.1058  loss_giou: 0.4308  loss_ce_dn: 0.2003  loss_mask_dn: 0.03118  loss_dice_dn: 0.8022  loss_bbox_dn: 0.04375  loss_giou_dn: 0.3385  loss_ce_0: 1.29  loss_mask_0: 0.04453  loss_dice_0: 0.8272  loss_bbox_0: 0.1219  loss_giou_0: 0.627  loss_ce_dn_0: 0.8155  loss_mask_dn_0: 0.1584  loss_dice_dn_0: 2.611  loss_bbox_dn_0: 0.2206  loss_giou_dn_0: 0.856  loss_ce_1: 1.345  loss_mask_1: 0.04217  loss_dice_1: 0.8952  loss_bbox_1: 0.1069  loss_giou_1: 0.4508  loss_ce_dn_1: 0.3099  loss_mask_dn_1: 0.03493  loss_dice_dn_1: 0.8112  loss_bbox_dn_1: 0.05831  loss_giou_dn_1: 0.3853  loss_ce_2: 1.228  loss_mask_2: 0.04158  loss_dice_2: 1.004  loss_bbox_2: 0.1218  loss_giou_2: 0.4658  loss_ce_dn_2: 0.2574  loss_mask_dn_2: 0.03244  loss_dice_dn_2: 0.767  loss_bbox_dn_2: 0.05035  loss_giou_dn_2: 0.3507  loss_ce_3: 1.243  loss_mask_3: 0.04273  loss_dice_3: 0.8168  loss_bbox_3: 0.1101  loss_giou_3: 0.418  loss_ce_dn_3: 0.2226  loss_mask_dn_3: 0.03497  loss_dice_dn_3: 0.7651  loss_bbox_dn_3: 0.04651  loss_giou_dn_3: 0.3267  loss_ce_4: 1.264  loss_mask_4: 0.04114  loss_dice_4: 0.7667  loss_bbox_4: 0.1079  loss_giou_4: 0.4387  loss_ce_dn_4: 0.2032  loss_mask_dn_4: 0.03499  loss_dice_dn_4: 0.791  loss_bbox_dn_4: 0.04591  loss_giou_dn_4: 0.3306  loss_ce_5: 1.196  loss_mask_5: 0.0476  loss_dice_5: 0.8664  loss_bbox_5: 0.1172  loss_giou_5: 0.4405  loss_ce_dn_5: 0.1959  loss_mask_dn_5: 0.03122  loss_dice_dn_5: 0.7896  loss_bbox_dn_5: 0.04574  loss_giou_dn_5: 0.3279  loss_ce_6: 1.166  loss_mask_6: 0.04293  loss_dice_6: 0.7874  loss_bbox_6: 0.1127  loss_giou_6: 0.4391  loss_ce_dn_6: 0.2013  loss_mask_dn_6: 0.03183  loss_dice_dn_6: 0.7787  loss_bbox_dn_6: 0.04572  loss_giou_dn_6: 0.3318  loss_ce_7: 1.143  loss_mask_7: 0.03786  loss_dice_7: 0.6933  loss_bbox_7: 0.109  loss_giou_7: 0.4308  loss_ce_dn_7: 0.2083  loss_mask_dn_7: 0.03245  loss_dice_dn_7: 0.7599  loss_bbox_dn_7: 0.0436  loss_giou_dn_7: 0.3301  loss_ce_8: 1.138  loss_mask_8: 0.03725  loss_dice_8: 0.9222  loss_bbox_8: 0.1065  loss_giou_8: 0.4213  loss_ce_dn_8: 0.1996  loss_mask_dn_8: 0.03197  loss_dice_dn_8: 0.7845  loss_bbox_dn_8: 0.04425  loss_giou_dn_8: 0.3365  loss_ce_interm: 1.234  loss_mask_interm: 0.04774  loss_dice_interm: 0.9586  loss_bbox_interm: 0.113  loss_giou_interm: 0.5304  time: 1.8440  data_time: 0.0772  lr: 1e-06  max_mem: 6663M\n",
            "[05/20 18:58:46 d2.utils.events]:  eta: 0:23:33  iter: 4859  total_loss: 45.79  loss_ce: 1.107  loss_mask: 0.05157  loss_dice: 0.5701  loss_bbox: 0.0922  loss_giou: 0.3116  loss_ce_dn: 0.2035  loss_mask_dn: 0.053  loss_dice_dn: 0.6193  loss_bbox_dn: 0.05176  loss_giou_dn: 0.2666  loss_ce_0: 1.28  loss_mask_0: 0.0469  loss_dice_0: 0.7179  loss_bbox_0: 0.1052  loss_giou_0: 0.3719  loss_ce_dn_0: 0.7357  loss_mask_dn_0: 0.2191  loss_dice_dn_0: 2.09  loss_bbox_dn_0: 0.2556  loss_giou_dn_0: 0.8592  loss_ce_1: 1.4  loss_mask_1: 0.0552  loss_dice_1: 0.6379  loss_bbox_1: 0.1023  loss_giou_1: 0.3478  loss_ce_dn_1: 0.2669  loss_mask_dn_1: 0.05722  loss_dice_dn_1: 0.6991  loss_bbox_dn_1: 0.08978  loss_giou_dn_1: 0.4003  loss_ce_2: 1.3  loss_mask_2: 0.05747  loss_dice_2: 0.5466  loss_bbox_2: 0.09222  loss_giou_2: 0.3261  loss_ce_dn_2: 0.2361  loss_mask_dn_2: 0.05612  loss_dice_dn_2: 0.6282  loss_bbox_dn_2: 0.0644  loss_giou_dn_2: 0.3196  loss_ce_3: 1.187  loss_mask_3: 0.05581  loss_dice_3: 0.4847  loss_bbox_3: 0.08942  loss_giou_3: 0.3219  loss_ce_dn_3: 0.211  loss_mask_dn_3: 0.0527  loss_dice_dn_3: 0.6433  loss_bbox_dn_3: 0.06148  loss_giou_dn_3: 0.293  loss_ce_4: 1.137  loss_mask_4: 0.05504  loss_dice_4: 0.5355  loss_bbox_4: 0.0871  loss_giou_4: 0.3253  loss_ce_dn_4: 0.1982  loss_mask_dn_4: 0.0533  loss_dice_dn_4: 0.5686  loss_bbox_dn_4: 0.05742  loss_giou_dn_4: 0.2789  loss_ce_5: 1.148  loss_mask_5: 0.06015  loss_dice_5: 0.7128  loss_bbox_5: 0.08856  loss_giou_5: 0.3124  loss_ce_dn_5: 0.1958  loss_mask_dn_5: 0.0522  loss_dice_dn_5: 0.5906  loss_bbox_dn_5: 0.05645  loss_giou_dn_5: 0.278  loss_ce_6: 1.101  loss_mask_6: 0.05787  loss_dice_6: 0.6892  loss_bbox_6: 0.1012  loss_giou_6: 0.3096  loss_ce_dn_6: 0.2022  loss_mask_dn_6: 0.05162  loss_dice_dn_6: 0.6034  loss_bbox_dn_6: 0.0555  loss_giou_dn_6: 0.274  loss_ce_7: 1.112  loss_mask_7: 0.05294  loss_dice_7: 0.4606  loss_bbox_7: 0.09605  loss_giou_7: 0.3151  loss_ce_dn_7: 0.2005  loss_mask_dn_7: 0.05143  loss_dice_dn_7: 0.619  loss_bbox_dn_7: 0.05184  loss_giou_dn_7: 0.2685  loss_ce_8: 1.108  loss_mask_8: 0.05027  loss_dice_8: 0.5966  loss_bbox_8: 0.09266  loss_giou_8: 0.3145  loss_ce_dn_8: 0.2036  loss_mask_dn_8: 0.05316  loss_dice_dn_8: 0.5964  loss_bbox_dn_8: 0.0519  loss_giou_dn_8: 0.2708  loss_ce_interm: 1.318  loss_mask_interm: 0.05098  loss_dice_interm: 0.7056  loss_bbox_interm: 0.1176  loss_giou_interm: 0.5192  time: 1.8434  data_time: 0.0972  lr: 1e-06  max_mem: 6663M\n",
            "[05/20 18:59:20 d2.utils.events]:  eta: 0:23:01  iter: 4879  total_loss: 43.8  loss_ce: 0.9423  loss_mask: 0.0517  loss_dice: 0.6762  loss_bbox: 0.06576  loss_giou: 0.3428  loss_ce_dn: 0.142  loss_mask_dn: 0.05302  loss_dice_dn: 0.64  loss_bbox_dn: 0.05092  loss_giou_dn: 0.3139  loss_ce_0: 1.156  loss_mask_0: 0.06099  loss_dice_0: 0.6612  loss_bbox_0: 0.09526  loss_giou_0: 0.4353  loss_ce_dn_0: 0.6716  loss_mask_dn_0: 0.2747  loss_dice_dn_0: 2.603  loss_bbox_dn_0: 0.3302  loss_giou_dn_0: 0.8494  loss_ce_1: 1.231  loss_mask_1: 0.05724  loss_dice_1: 0.5969  loss_bbox_1: 0.07292  loss_giou_1: 0.423  loss_ce_dn_1: 0.2254  loss_mask_dn_1: 0.0553  loss_dice_dn_1: 0.6685  loss_bbox_dn_1: 0.09942  loss_giou_dn_1: 0.3885  loss_ce_2: 1.145  loss_mask_2: 0.06117  loss_dice_2: 0.5174  loss_bbox_2: 0.07492  loss_giou_2: 0.3878  loss_ce_dn_2: 0.2026  loss_mask_dn_2: 0.05488  loss_dice_dn_2: 0.6627  loss_bbox_dn_2: 0.0745  loss_giou_dn_2: 0.3375  loss_ce_3: 0.9846  loss_mask_3: 0.05866  loss_dice_3: 0.6567  loss_bbox_3: 0.07185  loss_giou_3: 0.3471  loss_ce_dn_3: 0.1761  loss_mask_dn_3: 0.05658  loss_dice_dn_3: 0.6364  loss_bbox_dn_3: 0.06525  loss_giou_dn_3: 0.3227  loss_ce_4: 1.042  loss_mask_4: 0.06098  loss_dice_4: 0.6148  loss_bbox_4: 0.06413  loss_giou_4: 0.3453  loss_ce_dn_4: 0.1579  loss_mask_dn_4: 0.05153  loss_dice_dn_4: 0.6202  loss_bbox_dn_4: 0.06399  loss_giou_dn_4: 0.3181  loss_ce_5: 1.012  loss_mask_5: 0.04616  loss_dice_5: 0.6161  loss_bbox_5: 0.06082  loss_giou_5: 0.3636  loss_ce_dn_5: 0.1513  loss_mask_dn_5: 0.05135  loss_dice_dn_5: 0.618  loss_bbox_dn_5: 0.05312  loss_giou_dn_5: 0.3156  loss_ce_6: 0.948  loss_mask_6: 0.05426  loss_dice_6: 0.6252  loss_bbox_6: 0.06102  loss_giou_6: 0.364  loss_ce_dn_6: 0.1445  loss_mask_dn_6: 0.0512  loss_dice_dn_6: 0.6124  loss_bbox_dn_6: 0.05426  loss_giou_dn_6: 0.3116  loss_ce_7: 0.9658  loss_mask_7: 0.05727  loss_dice_7: 0.5482  loss_bbox_7: 0.0617  loss_giou_7: 0.3262  loss_ce_dn_7: 0.1479  loss_mask_dn_7: 0.05256  loss_dice_dn_7: 0.6362  loss_bbox_dn_7: 0.05661  loss_giou_dn_7: 0.3165  loss_ce_8: 0.9419  loss_mask_8: 0.05981  loss_dice_8: 0.5456  loss_bbox_8: 0.06277  loss_giou_8: 0.3258  loss_ce_dn_8: 0.1475  loss_mask_dn_8: 0.05398  loss_dice_dn_8: 0.5979  loss_bbox_dn_8: 0.05592  loss_giou_dn_8: 0.3165  loss_ce_interm: 1.134  loss_mask_interm: 0.05969  loss_dice_interm: 0.6851  loss_bbox_interm: 0.1004  loss_giou_interm: 0.4504  time: 1.8429  data_time: 0.1050  lr: 1e-06  max_mem: 6663M\n",
            "[05/20 18:59:54 d2.utils.events]:  eta: 0:22:27  iter: 4899  total_loss: 37.8  loss_ce: 1.005  loss_mask: 0.04011  loss_dice: 0.4878  loss_bbox: 0.09209  loss_giou: 0.2883  loss_ce_dn: 0.1937  loss_mask_dn: 0.02985  loss_dice_dn: 0.5072  loss_bbox_dn: 0.03207  loss_giou_dn: 0.2481  loss_ce_0: 1.353  loss_mask_0: 0.0445  loss_dice_0: 0.5511  loss_bbox_0: 0.09489  loss_giou_0: 0.3569  loss_ce_dn_0: 0.7169  loss_mask_dn_0: 0.1393  loss_dice_dn_0: 1.826  loss_bbox_dn_0: 0.3149  loss_giou_dn_0: 0.8552  loss_ce_1: 1.223  loss_mask_1: 0.04376  loss_dice_1: 0.4535  loss_bbox_1: 0.1031  loss_giou_1: 0.3696  loss_ce_dn_1: 0.2859  loss_mask_dn_1: 0.03376  loss_dice_dn_1: 0.4943  loss_bbox_dn_1: 0.06631  loss_giou_dn_1: 0.3171  loss_ce_2: 1.301  loss_mask_2: 0.0502  loss_dice_2: 0.547  loss_bbox_2: 0.09687  loss_giou_2: 0.348  loss_ce_dn_2: 0.2534  loss_mask_dn_2: 0.03383  loss_dice_dn_2: 0.4602  loss_bbox_dn_2: 0.04652  loss_giou_dn_2: 0.2717  loss_ce_3: 1.099  loss_mask_3: 0.04629  loss_dice_3: 0.4744  loss_bbox_3: 0.09198  loss_giou_3: 0.3139  loss_ce_dn_3: 0.2352  loss_mask_dn_3: 0.03186  loss_dice_dn_3: 0.5178  loss_bbox_dn_3: 0.03415  loss_giou_dn_3: 0.2383  loss_ce_4: 1.011  loss_mask_4: 0.03472  loss_dice_4: 0.4683  loss_bbox_4: 0.08623  loss_giou_4: 0.3159  loss_ce_dn_4: 0.2194  loss_mask_dn_4: 0.03099  loss_dice_dn_4: 0.5171  loss_bbox_dn_4: 0.03491  loss_giou_dn_4: 0.2506  loss_ce_5: 0.9491  loss_mask_5: 0.04107  loss_dice_5: 0.458  loss_bbox_5: 0.08512  loss_giou_5: 0.2928  loss_ce_dn_5: 0.2039  loss_mask_dn_5: 0.03153  loss_dice_dn_5: 0.5087  loss_bbox_dn_5: 0.03427  loss_giou_dn_5: 0.25  loss_ce_6: 0.9859  loss_mask_6: 0.03777  loss_dice_6: 0.4555  loss_bbox_6: 0.08306  loss_giou_6: 0.3065  loss_ce_dn_6: 0.2017  loss_mask_dn_6: 0.03037  loss_dice_dn_6: 0.4836  loss_bbox_dn_6: 0.03235  loss_giou_dn_6: 0.2431  loss_ce_7: 1.001  loss_mask_7: 0.04166  loss_dice_7: 0.4596  loss_bbox_7: 0.08507  loss_giou_7: 0.2967  loss_ce_dn_7: 0.1989  loss_mask_dn_7: 0.0312  loss_dice_dn_7: 0.5205  loss_bbox_dn_7: 0.0324  loss_giou_dn_7: 0.2575  loss_ce_8: 1.006  loss_mask_8: 0.04315  loss_dice_8: 0.4038  loss_bbox_8: 0.08536  loss_giou_8: 0.2937  loss_ce_dn_8: 0.1998  loss_mask_dn_8: 0.03076  loss_dice_dn_8: 0.5055  loss_bbox_dn_8: 0.03212  loss_giou_dn_8: 0.2538  loss_ce_interm: 1.297  loss_mask_interm: 0.04195  loss_dice_interm: 0.4173  loss_bbox_interm: 0.08128  loss_giou_interm: 0.3133  time: 1.8423  data_time: 0.0832  lr: 1e-06  max_mem: 6663M\n",
            "[05/20 19:00:28 d2.utils.events]:  eta: 0:21:58  iter: 4919  total_loss: 36.97  loss_ce: 0.947  loss_mask: 0.03181  loss_dice: 0.5045  loss_bbox: 0.04147  loss_giou: 0.3215  loss_ce_dn: 0.1937  loss_mask_dn: 0.03713  loss_dice_dn: 0.5482  loss_bbox_dn: 0.03961  loss_giou_dn: 0.2889  loss_ce_0: 1.178  loss_mask_0: 0.03784  loss_dice_0: 0.4468  loss_bbox_0: 0.0544  loss_giou_0: 0.4051  loss_ce_dn_0: 0.7547  loss_mask_dn_0: 0.1309  loss_dice_dn_0: 2.386  loss_bbox_dn_0: 0.2452  loss_giou_dn_0: 0.8516  loss_ce_1: 1.121  loss_mask_1: 0.03456  loss_dice_1: 0.428  loss_bbox_1: 0.04535  loss_giou_1: 0.3314  loss_ce_dn_1: 0.2788  loss_mask_dn_1: 0.04079  loss_dice_dn_1: 0.5842  loss_bbox_dn_1: 0.07577  loss_giou_dn_1: 0.3841  loss_ce_2: 1.011  loss_mask_2: 0.03442  loss_dice_2: 0.6206  loss_bbox_2: 0.0478  loss_giou_2: 0.33  loss_ce_dn_2: 0.2439  loss_mask_dn_2: 0.03429  loss_dice_dn_2: 0.5846  loss_bbox_dn_2: 0.05172  loss_giou_dn_2: 0.3333  loss_ce_3: 1.011  loss_mask_3: 0.039  loss_dice_3: 0.6591  loss_bbox_3: 0.04643  loss_giou_3: 0.3045  loss_ce_dn_3: 0.2184  loss_mask_dn_3: 0.03613  loss_dice_dn_3: 0.5858  loss_bbox_dn_3: 0.04426  loss_giou_dn_3: 0.287  loss_ce_4: 0.9233  loss_mask_4: 0.0348  loss_dice_4: 0.5213  loss_bbox_4: 0.04571  loss_giou_4: 0.3026  loss_ce_dn_4: 0.2226  loss_mask_dn_4: 0.03653  loss_dice_dn_4: 0.5204  loss_bbox_dn_4: 0.04071  loss_giou_dn_4: 0.2971  loss_ce_5: 0.8822  loss_mask_5: 0.03403  loss_dice_5: 0.5475  loss_bbox_5: 0.04436  loss_giou_5: 0.3189  loss_ce_dn_5: 0.2094  loss_mask_dn_5: 0.03626  loss_dice_dn_5: 0.5671  loss_bbox_dn_5: 0.03786  loss_giou_dn_5: 0.2881  loss_ce_6: 0.9263  loss_mask_6: 0.03585  loss_dice_6: 0.596  loss_bbox_6: 0.04529  loss_giou_6: 0.3435  loss_ce_dn_6: 0.1961  loss_mask_dn_6: 0.03629  loss_dice_dn_6: 0.5448  loss_bbox_dn_6: 0.0378  loss_giou_dn_6: 0.2977  loss_ce_7: 0.8194  loss_mask_7: 0.03683  loss_dice_7: 0.5807  loss_bbox_7: 0.04254  loss_giou_7: 0.3522  loss_ce_dn_7: 0.1997  loss_mask_dn_7: 0.03588  loss_dice_dn_7: 0.5519  loss_bbox_dn_7: 0.03843  loss_giou_dn_7: 0.2895  loss_ce_8: 0.8026  loss_mask_8: 0.03676  loss_dice_8: 0.5457  loss_bbox_8: 0.04236  loss_giou_8: 0.3507  loss_ce_dn_8: 0.1969  loss_mask_dn_8: 0.03613  loss_dice_dn_8: 0.5054  loss_bbox_dn_8: 0.03924  loss_giou_dn_8: 0.2789  loss_ce_interm: 1.154  loss_mask_interm: 0.03551  loss_dice_interm: 0.4797  loss_bbox_interm: 0.06652  loss_giou_interm: 0.3956  time: 1.8416  data_time: 0.0732  lr: 1e-06  max_mem: 6663M\n",
            "[05/20 19:01:00 d2.utils.events]:  eta: 0:21:22  iter: 4939  total_loss: 40.19  loss_ce: 1.178  loss_mask: 0.02197  loss_dice: 0.4138  loss_bbox: 0.04563  loss_giou: 0.3156  loss_ce_dn: 0.1504  loss_mask_dn: 0.0181  loss_dice_dn: 0.5265  loss_bbox_dn: 0.03104  loss_giou_dn: 0.2722  loss_ce_0: 1.168  loss_mask_0: 0.02106  loss_dice_0: 0.5792  loss_bbox_0: 0.05658  loss_giou_0: 0.42  loss_ce_dn_0: 0.7671  loss_mask_dn_0: 0.1104  loss_dice_dn_0: 2.683  loss_bbox_dn_0: 0.2395  loss_giou_dn_0: 0.8547  loss_ce_1: 1.225  loss_mask_1: 0.02686  loss_dice_1: 0.5099  loss_bbox_1: 0.05072  loss_giou_1: 0.3786  loss_ce_dn_1: 0.2472  loss_mask_dn_1: 0.01971  loss_dice_dn_1: 0.6008  loss_bbox_dn_1: 0.051  loss_giou_dn_1: 0.3873  loss_ce_2: 1.243  loss_mask_2: 0.02713  loss_dice_2: 0.7406  loss_bbox_2: 0.05221  loss_giou_2: 0.3934  loss_ce_dn_2: 0.1903  loss_mask_dn_2: 0.02035  loss_dice_dn_2: 0.5461  loss_bbox_dn_2: 0.04526  loss_giou_dn_2: 0.3293  loss_ce_3: 1.25  loss_mask_3: 0.02533  loss_dice_3: 0.5304  loss_bbox_3: 0.04571  loss_giou_3: 0.3627  loss_ce_dn_3: 0.1749  loss_mask_dn_3: 0.01893  loss_dice_dn_3: 0.5126  loss_bbox_dn_3: 0.035  loss_giou_dn_3: 0.3166  loss_ce_4: 1.282  loss_mask_4: 0.02112  loss_dice_4: 0.6951  loss_bbox_4: 0.04474  loss_giou_4: 0.3324  loss_ce_dn_4: 0.1622  loss_mask_dn_4: 0.01859  loss_dice_dn_4: 0.5547  loss_bbox_dn_4: 0.03499  loss_giou_dn_4: 0.3111  loss_ce_5: 1.074  loss_mask_5: 0.02539  loss_dice_5: 0.6375  loss_bbox_5: 0.04614  loss_giou_5: 0.313  loss_ce_dn_5: 0.1534  loss_mask_dn_5: 0.01777  loss_dice_dn_5: 0.5335  loss_bbox_dn_5: 0.03337  loss_giou_dn_5: 0.2794  loss_ce_6: 1.074  loss_mask_6: 0.02141  loss_dice_6: 0.5647  loss_bbox_6: 0.04729  loss_giou_6: 0.3268  loss_ce_dn_6: 0.1536  loss_mask_dn_6: 0.01941  loss_dice_dn_6: 0.5336  loss_bbox_dn_6: 0.03238  loss_giou_dn_6: 0.2768  loss_ce_7: 1.077  loss_mask_7: 0.02302  loss_dice_7: 0.5193  loss_bbox_7: 0.04884  loss_giou_7: 0.3192  loss_ce_dn_7: 0.1539  loss_mask_dn_7: 0.01942  loss_dice_dn_7: 0.521  loss_bbox_dn_7: 0.03165  loss_giou_dn_7: 0.2757  loss_ce_8: 1.071  loss_mask_8: 0.0208  loss_dice_8: 0.5353  loss_bbox_8: 0.04458  loss_giou_8: 0.3234  loss_ce_dn_8: 0.1527  loss_mask_dn_8: 0.01822  loss_dice_dn_8: 0.5014  loss_bbox_dn_8: 0.03074  loss_giou_dn_8: 0.2776  loss_ce_interm: 1.187  loss_mask_interm: 0.02468  loss_dice_interm: 0.639  loss_bbox_interm: 0.06309  loss_giou_interm: 0.439  time: 1.8407  data_time: 0.0548  lr: 1e-06  max_mem: 6663M\n",
            "[05/20 19:01:34 d2.utils.events]:  eta: 0:20:50  iter: 4959  total_loss: 42.09  loss_ce: 1.064  loss_mask: 0.03052  loss_dice: 0.906  loss_bbox: 0.05134  loss_giou: 0.458  loss_ce_dn: 0.16  loss_mask_dn: 0.02843  loss_dice_dn: 0.6146  loss_bbox_dn: 0.04625  loss_giou_dn: 0.3491  loss_ce_0: 1.392  loss_mask_0: 0.03682  loss_dice_0: 0.8462  loss_bbox_0: 0.05671  loss_giou_0: 0.4913  loss_ce_dn_0: 0.6854  loss_mask_dn_0: 0.1558  loss_dice_dn_0: 2.857  loss_bbox_dn_0: 0.2517  loss_giou_dn_0: 0.8615  loss_ce_1: 1.166  loss_mask_1: 0.03305  loss_dice_1: 0.7806  loss_bbox_1: 0.05184  loss_giou_1: 0.4661  loss_ce_dn_1: 0.2381  loss_mask_dn_1: 0.02815  loss_dice_dn_1: 0.6257  loss_bbox_dn_1: 0.06066  loss_giou_dn_1: 0.421  loss_ce_2: 1.179  loss_mask_2: 0.03975  loss_dice_2: 0.7319  loss_bbox_2: 0.05946  loss_giou_2: 0.5448  loss_ce_dn_2: 0.2083  loss_mask_dn_2: 0.0293  loss_dice_dn_2: 0.6869  loss_bbox_dn_2: 0.05123  loss_giou_dn_2: 0.3674  loss_ce_3: 1.096  loss_mask_3: 0.03742  loss_dice_3: 0.7324  loss_bbox_3: 0.05423  loss_giou_3: 0.5656  loss_ce_dn_3: 0.1908  loss_mask_dn_3: 0.03083  loss_dice_dn_3: 0.6298  loss_bbox_dn_3: 0.0488  loss_giou_dn_3: 0.3585  loss_ce_4: 1.081  loss_mask_4: 0.02902  loss_dice_4: 0.5964  loss_bbox_4: 0.05406  loss_giou_4: 0.5407  loss_ce_dn_4: 0.1862  loss_mask_dn_4: 0.03051  loss_dice_dn_4: 0.6617  loss_bbox_dn_4: 0.04803  loss_giou_dn_4: 0.355  loss_ce_5: 1.04  loss_mask_5: 0.03172  loss_dice_5: 0.6312  loss_bbox_5: 0.05156  loss_giou_5: 0.4884  loss_ce_dn_5: 0.172  loss_mask_dn_5: 0.02933  loss_dice_dn_5: 0.6503  loss_bbox_dn_5: 0.04623  loss_giou_dn_5: 0.35  loss_ce_6: 0.9462  loss_mask_6: 0.03175  loss_dice_6: 0.5743  loss_bbox_6: 0.05198  loss_giou_6: 0.4576  loss_ce_dn_6: 0.1647  loss_mask_dn_6: 0.02757  loss_dice_dn_6: 0.6654  loss_bbox_dn_6: 0.04662  loss_giou_dn_6: 0.3513  loss_ce_7: 1.089  loss_mask_7: 0.0373  loss_dice_7: 0.8647  loss_bbox_7: 0.05191  loss_giou_7: 0.4755  loss_ce_dn_7: 0.1609  loss_mask_dn_7: 0.02744  loss_dice_dn_7: 0.6562  loss_bbox_dn_7: 0.04546  loss_giou_dn_7: 0.3467  loss_ce_8: 1.065  loss_mask_8: 0.0322  loss_dice_8: 0.7881  loss_bbox_8: 0.05024  loss_giou_8: 0.4713  loss_ce_dn_8: 0.1582  loss_mask_dn_8: 0.02833  loss_dice_dn_8: 0.6431  loss_bbox_dn_8: 0.0466  loss_giou_dn_8: 0.3462  loss_ce_interm: 1.415  loss_mask_interm: 0.03281  loss_dice_interm: 0.7868  loss_bbox_interm: 0.103  loss_giou_interm: 0.5819  time: 1.8401  data_time: 0.0875  lr: 1e-06  max_mem: 6663M\n",
            "[05/20 19:02:08 d2.utils.events]:  eta: 0:20:18  iter: 4979  total_loss: 41.63  loss_ce: 1.036  loss_mask: 0.03322  loss_dice: 0.5612  loss_bbox: 0.05832  loss_giou: 0.3857  loss_ce_dn: 0.1713  loss_mask_dn: 0.03636  loss_dice_dn: 0.5633  loss_bbox_dn: 0.04028  loss_giou_dn: 0.3267  loss_ce_0: 1.374  loss_mask_0: 0.03564  loss_dice_0: 0.6697  loss_bbox_0: 0.06903  loss_giou_0: 0.4695  loss_ce_dn_0: 0.7814  loss_mask_dn_0: 0.1738  loss_dice_dn_0: 2.833  loss_bbox_dn_0: 0.2303  loss_giou_dn_0: 0.8501  loss_ce_1: 1.26  loss_mask_1: 0.04116  loss_dice_1: 0.5751  loss_bbox_1: 0.0657  loss_giou_1: 0.4161  loss_ce_dn_1: 0.2767  loss_mask_dn_1: 0.03698  loss_dice_dn_1: 0.6441  loss_bbox_dn_1: 0.06543  loss_giou_dn_1: 0.4083  loss_ce_2: 1.257  loss_mask_2: 0.03696  loss_dice_2: 0.554  loss_bbox_2: 0.06936  loss_giou_2: 0.4398  loss_ce_dn_2: 0.2325  loss_mask_dn_2: 0.03537  loss_dice_dn_2: 0.5529  loss_bbox_dn_2: 0.05376  loss_giou_dn_2: 0.3641  loss_ce_3: 1.148  loss_mask_3: 0.03698  loss_dice_3: 0.6585  loss_bbox_3: 0.0613  loss_giou_3: 0.4099  loss_ce_dn_3: 0.2138  loss_mask_dn_3: 0.03581  loss_dice_dn_3: 0.5108  loss_bbox_dn_3: 0.04721  loss_giou_dn_3: 0.3437  loss_ce_4: 1.138  loss_mask_4: 0.03748  loss_dice_4: 0.4769  loss_bbox_4: 0.0594  loss_giou_4: 0.3948  loss_ce_dn_4: 0.1907  loss_mask_dn_4: 0.03494  loss_dice_dn_4: 0.5904  loss_bbox_dn_4: 0.04316  loss_giou_dn_4: 0.3371  loss_ce_5: 1.123  loss_mask_5: 0.03096  loss_dice_5: 0.4555  loss_bbox_5: 0.06029  loss_giou_5: 0.4098  loss_ce_dn_5: 0.1808  loss_mask_dn_5: 0.03616  loss_dice_dn_5: 0.5843  loss_bbox_dn_5: 0.04241  loss_giou_dn_5: 0.3305  loss_ce_6: 1.069  loss_mask_6: 0.03477  loss_dice_6: 0.5473  loss_bbox_6: 0.06069  loss_giou_6: 0.4132  loss_ce_dn_6: 0.1685  loss_mask_dn_6: 0.03486  loss_dice_dn_6: 0.5426  loss_bbox_dn_6: 0.04193  loss_giou_dn_6: 0.3332  loss_ce_7: 1.134  loss_mask_7: 0.03437  loss_dice_7: 0.5699  loss_bbox_7: 0.06  loss_giou_7: 0.3814  loss_ce_dn_7: 0.1793  loss_mask_dn_7: 0.0369  loss_dice_dn_7: 0.5646  loss_bbox_dn_7: 0.03962  loss_giou_dn_7: 0.3263  loss_ce_8: 1.049  loss_mask_8: 0.03608  loss_dice_8: 0.4471  loss_bbox_8: 0.05788  loss_giou_8: 0.3852  loss_ce_dn_8: 0.1716  loss_mask_dn_8: 0.03629  loss_dice_dn_8: 0.5465  loss_bbox_dn_8: 0.03977  loss_giou_dn_8: 0.3242  loss_ce_interm: 1.374  loss_mask_interm: 0.03853  loss_dice_interm: 0.4165  loss_bbox_interm: 0.08556  loss_giou_interm: 0.4385  time: 1.8394  data_time: 0.0781  lr: 1e-06  max_mem: 6663M\n",
            "[05/20 19:02:41 d2.data.datasets.coco]: Loaded 150 images in COCO format from /content/TACO-expl/data/annotations_off_0_resval.json\n",
            "[05/20 19:02:41 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "[05/20 19:02:41 d2.data.common]: Serializing 150 elements to byte tensors and concatenating them all ...\n",
            "[05/20 19:02:41 d2.data.common]: Serialized dataset takes 0.21 MiB\n",
            "WARNING [05/20 19:02:41 d2.evaluation.coco_evaluation]: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
            "[05/20 19:02:41 d2.evaluation.evaluator]: Start inference on 150 batches\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1066, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1066, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1066, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1066])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 19:02:51 d2.evaluation.evaluator]: Inference done 11/150. Dataloading: 0.0022 s/iter. Inference: 0.3117 s/iter. Eval: 0.5164 s/iter. Total: 0.8303 s/iter. ETA=0:01:55\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 608])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 608])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 608])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1200])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 750])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 19:02:56 d2.evaluation.evaluator]: Inference done 18/150. Dataloading: 0.0023 s/iter. Inference: 0.2924 s/iter. Eval: 0.4806 s/iter. Total: 0.7755 s/iter. ETA=0:01:42\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 750])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([750, 1333])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 19:03:01 d2.evaluation.evaluator]: Inference done 24/150. Dataloading: 0.0033 s/iter. Inference: 0.2974 s/iter. Eval: 0.5046 s/iter. Total: 0.8056 s/iter. ETA=0:01:41\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 750])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([750, 1333])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 750])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 19:03:07 d2.evaluation.evaluator]: Inference done 30/150. Dataloading: 0.0045 s/iter. Inference: 0.3082 s/iter. Eval: 0.5314 s/iter. Total: 0.8446 s/iter. ETA=0:01:41\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 750])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 19:03:12 d2.evaluation.evaluator]: Inference done 37/150. Dataloading: 0.0041 s/iter. Inference: 0.3040 s/iter. Eval: 0.5155 s/iter. Total: 0.8239 s/iter. ETA=0:01:33\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 19:03:18 d2.evaluation.evaluator]: Inference done 44/150. Dataloading: 0.0038 s/iter. Inference: 0.3030 s/iter. Eval: 0.5152 s/iter. Total: 0.8223 s/iter. ETA=0:01:27\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 19:03:23 d2.evaluation.evaluator]: Inference done 50/150. Dataloading: 0.0038 s/iter. Inference: 0.3061 s/iter. Eval: 0.5218 s/iter. Total: 0.8321 s/iter. ETA=0:01:23\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 19:03:28 d2.evaluation.evaluator]: Inference done 57/150. Dataloading: 0.0036 s/iter. Inference: 0.3020 s/iter. Eval: 0.5110 s/iter. Total: 0.8170 s/iter. ETA=0:01:15\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 19:03:34 d2.evaluation.evaluator]: Inference done 64/150. Dataloading: 0.0037 s/iter. Inference: 0.3007 s/iter. Eval: 0.5090 s/iter. Total: 0.8138 s/iter. ETA=0:01:09\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 19:03:39 d2.evaluation.evaluator]: Inference done 70/150. Dataloading: 0.0045 s/iter. Inference: 0.3025 s/iter. Eval: 0.5172 s/iter. Total: 0.8246 s/iter. ETA=0:01:05\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([852, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 19:03:45 d2.evaluation.evaluator]: Inference done 78/150. Dataloading: 0.0043 s/iter. Inference: 0.2990 s/iter. Eval: 0.5076 s/iter. Total: 0.8113 s/iter. ETA=0:00:58\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 19:03:50 d2.evaluation.evaluator]: Inference done 85/150. Dataloading: 0.0043 s/iter. Inference: 0.2974 s/iter. Eval: 0.5067 s/iter. Total: 0.8088 s/iter. ETA=0:00:52\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 19:03:56 d2.evaluation.evaluator]: Inference done 91/150. Dataloading: 0.0042 s/iter. Inference: 0.2991 s/iter. Eval: 0.5125 s/iter. Total: 0.8163 s/iter. ETA=0:00:48\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 19:04:01 d2.evaluation.evaluator]: Inference done 99/150. Dataloading: 0.0041 s/iter. Inference: 0.2969 s/iter. Eval: 0.5062 s/iter. Total: 0.8076 s/iter. ETA=0:00:41\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 19:04:07 d2.evaluation.evaluator]: Inference done 106/150. Dataloading: 0.0040 s/iter. Inference: 0.2963 s/iter. Eval: 0.5048 s/iter. Total: 0.8055 s/iter. ETA=0:00:35\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 19:04:12 d2.evaluation.evaluator]: Inference done 112/150. Dataloading: 0.0039 s/iter. Inference: 0.2973 s/iter. Eval: 0.5096 s/iter. Total: 0.8113 s/iter. ETA=0:00:30\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 19:04:17 d2.evaluation.evaluator]: Inference done 119/150. Dataloading: 0.0038 s/iter. Inference: 0.2959 s/iter. Eval: 0.5056 s/iter. Total: 0.8058 s/iter. ETA=0:00:24\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 19:04:23 d2.evaluation.evaluator]: Inference done 126/150. Dataloading: 0.0038 s/iter. Inference: 0.2950 s/iter. Eval: 0.5040 s/iter. Total: 0.8031 s/iter. ETA=0:00:19\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 19:04:28 d2.evaluation.evaluator]: Inference done 132/150. Dataloading: 0.0040 s/iter. Inference: 0.2958 s/iter. Eval: 0.5093 s/iter. Total: 0.8095 s/iter. ETA=0:00:14\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 750])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 750])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 750])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 19:04:34 d2.evaluation.evaluator]: Inference done 139/150. Dataloading: 0.0039 s/iter. Inference: 0.2956 s/iter. Eval: 0.5079 s/iter. Total: 0.8078 s/iter. ETA=0:00:08\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 19:04:39 d2.evaluation.evaluator]: Inference done 146/150. Dataloading: 0.0038 s/iter. Inference: 0.2946 s/iter. Eval: 0.5049 s/iter. Total: 0.8038 s/iter. ETA=0:00:03\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 608])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 608])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 608])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 608])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[05/20 19:04:43 d2.evaluation.evaluator]: Total inference time: 0:01:57.036553 (0.807149 s / iter per device, on 1 devices)\n",
            "[05/20 19:04:43 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:42 (0.295124 s / iter per device, on 1 devices)\n",
            "[05/20 19:04:43 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...\n",
            "[05/20 19:04:43 d2.evaluation.coco_evaluation]: Saving results to /content/output/chkpt/inference/coco_instances_results.json\n",
            "[05/20 19:04:43 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.03s)\n",
            "creating index...\n",
            "index created!\n",
            "[05/20 19:04:43 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*\n",
            "[05/20 19:04:43 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.22 seconds.\n",
            "[05/20 19:04:43 d2.evaluation.fast_eval_api]: Accumulating evaluation results...\n",
            "[05/20 19:04:44 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.09 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.247\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.417\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.246\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.058\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.248\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.426\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.335\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.438\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.447\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.107\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.491\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.794\n",
            "[05/20 19:04:44 d2.evaluation.coco_evaluation]: Evaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
            "| 24.687 | 41.712 | 24.632 | 5.770 | 24.769 | 42.588 |\n",
            "[05/20 19:04:44 d2.evaluation.coco_evaluation]: Per-category bbox AP: \n",
            "| category   | AP     | category              | AP     | category   | AP     |\n",
            "|:-----------|:-------|:----------------------|:-------|:-----------|:-------|\n",
            "| Bottle     | 53.359 | Bottle cap            | 12.569 | Can        | 42.938 |\n",
            "| Cigarette  | 2.174  | Cup                   | 30.630 | Lid        | 36.259 |\n",
            "| Other      | 20.324 | Plastic bag & wrapper | 22.087 | Pop tab    | 10.575 |\n",
            "| Straw      | 15.957 |                       |        |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.17s)\n",
            "creating index...\n",
            "index created!\n",
            "[05/20 19:04:45 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*\n",
            "[05/20 19:04:45 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.22 seconds.\n",
            "[05/20 19:04:45 d2.evaluation.fast_eval_api]: Accumulating evaluation results...\n",
            "[05/20 19:04:45 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.06 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.392\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.510\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.406\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.212\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.465\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.528\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.468\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.645\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.663\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.416\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.750\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.840\n",
            "[05/20 19:04:45 d2.evaluation.coco_evaluation]: Evaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 39.226 | 50.971 | 40.579 | 21.235 | 46.465 | 52.801 |\n",
            "[05/20 19:04:45 d2.evaluation.coco_evaluation]: Per-category segm AP: \n",
            "| category   | AP     | category              | AP     | category   | AP     |\n",
            "|:-----------|:-------|:----------------------|:-------|:-----------|:-------|\n",
            "| Bottle     | 73.816 | Bottle cap            | 39.927 | Can        | 55.387 |\n",
            "| Cigarette  | 22.077 | Cup                   | 42.843 | Lid        | 46.346 |\n",
            "| Other      | 30.612 | Plastic bag & wrapper | 35.365 | Pop tab    | 25.722 |\n",
            "| Straw      | 20.162 |                       |        |            |        |\n",
            "[05/20 19:04:45 d2.engine.defaults]: Evaluation results for TACO_val in csv format:\n",
            "[05/20 19:04:45 d2.evaluation.testing]: copypaste: Task: bbox\n",
            "[05/20 19:04:45 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl\n",
            "[05/20 19:04:45 d2.evaluation.testing]: copypaste: 24.6870,41.7116,24.6324,5.7705,24.7690,42.5880\n",
            "[05/20 19:04:45 d2.evaluation.testing]: copypaste: Task: segm\n",
            "[05/20 19:04:45 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl\n",
            "[05/20 19:04:45 d2.evaluation.testing]: copypaste: 39.2257,50.9708,40.5790,21.2355,46.4651,52.8014\n",
            "[05/20 19:04:45 d2.utils.events]:  eta: 0:19:46  iter: 4999  total_loss: 41.4  loss_ce: 0.873  loss_mask: 0.03299  loss_dice: 0.6079  loss_bbox: 0.06434  loss_giou: 0.3606  loss_ce_dn: 0.1846  loss_mask_dn: 0.03451  loss_dice_dn: 0.5712  loss_bbox_dn: 0.05321  loss_giou_dn: 0.3433  loss_ce_0: 1.128  loss_mask_0: 0.03655  loss_dice_0: 0.5561  loss_bbox_0: 0.1014  loss_giou_0: 0.4004  loss_ce_dn_0: 0.7572  loss_mask_dn_0: 0.3654  loss_dice_dn_0: 2.336  loss_bbox_dn_0: 0.2611  loss_giou_dn_0: 0.8556  loss_ce_1: 1.112  loss_mask_1: 0.03395  loss_dice_1: 0.5199  loss_bbox_1: 0.1073  loss_giou_1: 0.4122  loss_ce_dn_1: 0.2497  loss_mask_dn_1: 0.03949  loss_dice_dn_1: 0.6409  loss_bbox_dn_1: 0.08152  loss_giou_dn_1: 0.4287  loss_ce_2: 0.96  loss_mask_2: 0.0353  loss_dice_2: 0.5922  loss_bbox_2: 0.09265  loss_giou_2: 0.3496  loss_ce_dn_2: 0.2195  loss_mask_dn_2: 0.03521  loss_dice_dn_2: 0.6135  loss_bbox_dn_2: 0.06597  loss_giou_dn_2: 0.3863  loss_ce_3: 0.8909  loss_mask_3: 0.03836  loss_dice_3: 0.4968  loss_bbox_3: 0.08683  loss_giou_3: 0.3707  loss_ce_dn_3: 0.2082  loss_mask_dn_3: 0.03361  loss_dice_dn_3: 0.6098  loss_bbox_dn_3: 0.05394  loss_giou_dn_3: 0.3543  loss_ce_4: 0.8607  loss_mask_4: 0.04165  loss_dice_4: 0.5458  loss_bbox_4: 0.08066  loss_giou_4: 0.356  loss_ce_dn_4: 0.1828  loss_mask_dn_4: 0.03429  loss_dice_dn_4: 0.6239  loss_bbox_dn_4: 0.05432  loss_giou_dn_4: 0.3539  loss_ce_5: 0.9158  loss_mask_5: 0.03393  loss_dice_5: 0.6032  loss_bbox_5: 0.06533  loss_giou_5: 0.36  loss_ce_dn_5: 0.1863  loss_mask_dn_5: 0.03385  loss_dice_dn_5: 0.5749  loss_bbox_dn_5: 0.05219  loss_giou_dn_5: 0.3448  loss_ce_6: 0.8659  loss_mask_6: 0.03339  loss_dice_6: 0.497  loss_bbox_6: 0.0681  loss_giou_6: 0.3538  loss_ce_dn_6: 0.1865  loss_mask_dn_6: 0.03397  loss_dice_dn_6: 0.5698  loss_bbox_dn_6: 0.05241  loss_giou_dn_6: 0.3456  loss_ce_7: 0.8857  loss_mask_7: 0.0369  loss_dice_7: 0.5671  loss_bbox_7: 0.07223  loss_giou_7: 0.3499  loss_ce_dn_7: 0.186  loss_mask_dn_7: 0.03534  loss_dice_dn_7: 0.5849  loss_bbox_dn_7: 0.05212  loss_giou_dn_7: 0.3418  loss_ce_8: 0.8555  loss_mask_8: 0.03772  loss_dice_8: 0.4621  loss_bbox_8: 0.07391  loss_giou_8: 0.3346  loss_ce_dn_8: 0.19  loss_mask_dn_8: 0.03556  loss_dice_dn_8: 0.5816  loss_bbox_dn_8: 0.0523  loss_giou_dn_8: 0.3436  loss_ce_interm: 1.195  loss_mask_interm: 0.03458  loss_dice_interm: 0.534  loss_bbox_interm: 0.1074  loss_giou_interm: 0.4376  time: 1.8387  data_time: 0.0951  lr: 1e-06  max_mem: 6663M\n",
            "[05/20 19:05:19 d2.utils.events]:  eta: 0:19:14  iter: 5019  total_loss: 37.91  loss_ce: 0.8766  loss_mask: 0.03192  loss_dice: 0.4714  loss_bbox: 0.04907  loss_giou: 0.304  loss_ce_dn: 0.1925  loss_mask_dn: 0.02798  loss_dice_dn: 0.4884  loss_bbox_dn: 0.03729  loss_giou_dn: 0.2552  loss_ce_0: 1.163  loss_mask_0: 0.03471  loss_dice_0: 0.6629  loss_bbox_0: 0.05985  loss_giou_0: 0.3614  loss_ce_dn_0: 0.7435  loss_mask_dn_0: 0.1444  loss_dice_dn_0: 2.737  loss_bbox_dn_0: 0.2186  loss_giou_dn_0: 0.8584  loss_ce_1: 1.139  loss_mask_1: 0.0332  loss_dice_1: 0.6293  loss_bbox_1: 0.04404  loss_giou_1: 0.2929  loss_ce_dn_1: 0.2947  loss_mask_dn_1: 0.02904  loss_dice_dn_1: 0.6133  loss_bbox_dn_1: 0.06124  loss_giou_dn_1: 0.3409  loss_ce_2: 1.047  loss_mask_2: 0.02867  loss_dice_2: 0.6392  loss_bbox_2: 0.05303  loss_giou_2: 0.2946  loss_ce_dn_2: 0.2622  loss_mask_dn_2: 0.02538  loss_dice_dn_2: 0.5343  loss_bbox_dn_2: 0.04694  loss_giou_dn_2: 0.2552  loss_ce_3: 0.9329  loss_mask_3: 0.02962  loss_dice_3: 0.6064  loss_bbox_3: 0.05819  loss_giou_3: 0.3074  loss_ce_dn_3: 0.2203  loss_mask_dn_3: 0.0268  loss_dice_dn_3: 0.4971  loss_bbox_dn_3: 0.03902  loss_giou_dn_3: 0.2649  loss_ce_4: 0.9083  loss_mask_4: 0.02641  loss_dice_4: 0.5525  loss_bbox_4: 0.05697  loss_giou_4: 0.311  loss_ce_dn_4: 0.2189  loss_mask_dn_4: 0.02732  loss_dice_dn_4: 0.486  loss_bbox_dn_4: 0.03922  loss_giou_dn_4: 0.263  loss_ce_5: 0.8666  loss_mask_5: 0.02762  loss_dice_5: 0.5322  loss_bbox_5: 0.05725  loss_giou_5: 0.3109  loss_ce_dn_5: 0.2068  loss_mask_dn_5: 0.02772  loss_dice_dn_5: 0.4907  loss_bbox_dn_5: 0.03889  loss_giou_dn_5: 0.263  loss_ce_6: 0.8633  loss_mask_6: 0.02659  loss_dice_6: 0.5037  loss_bbox_6: 0.05373  loss_giou_6: 0.3099  loss_ce_dn_6: 0.1962  loss_mask_dn_6: 0.02636  loss_dice_dn_6: 0.4879  loss_bbox_dn_6: 0.04014  loss_giou_dn_6: 0.2615  loss_ce_7: 0.8598  loss_mask_7: 0.0269  loss_dice_7: 0.5181  loss_bbox_7: 0.05171  loss_giou_7: 0.3087  loss_ce_dn_7: 0.1925  loss_mask_dn_7: 0.02735  loss_dice_dn_7: 0.499  loss_bbox_dn_7: 0.03688  loss_giou_dn_7: 0.2545  loss_ce_8: 0.8449  loss_mask_8: 0.02619  loss_dice_8: 0.4839  loss_bbox_8: 0.05018  loss_giou_8: 0.3089  loss_ce_dn_8: 0.1929  loss_mask_dn_8: 0.02805  loss_dice_dn_8: 0.4968  loss_bbox_dn_8: 0.03723  loss_giou_dn_8: 0.2602  loss_ce_interm: 1.231  loss_mask_interm: 0.0293  loss_dice_interm: 0.5478  loss_bbox_interm: 0.06384  loss_giou_interm: 0.3657  time: 1.8380  data_time: 0.1125  lr: 1e-06  max_mem: 6663M\n",
            "[05/20 19:05:52 d2.utils.events]:  eta: 0:18:42  iter: 5039  total_loss: 40.93  loss_ce: 1.062  loss_mask: 0.03238  loss_dice: 0.378  loss_bbox: 0.0457  loss_giou: 0.3434  loss_ce_dn: 0.201  loss_mask_dn: 0.02999  loss_dice_dn: 0.5329  loss_bbox_dn: 0.03559  loss_giou_dn: 0.2774  loss_ce_0: 1.398  loss_mask_0: 0.03934  loss_dice_0: 0.5916  loss_bbox_0: 0.06577  loss_giou_0: 0.4359  loss_ce_dn_0: 0.7719  loss_mask_dn_0: 0.168  loss_dice_dn_0: 2.444  loss_bbox_dn_0: 0.2129  loss_giou_dn_0: 0.8635  loss_ce_1: 1.409  loss_mask_1: 0.03603  loss_dice_1: 0.4814  loss_bbox_1: 0.06004  loss_giou_1: 0.3768  loss_ce_dn_1: 0.3259  loss_mask_dn_1: 0.03495  loss_dice_dn_1: 0.593  loss_bbox_dn_1: 0.06563  loss_giou_dn_1: 0.3847  loss_ce_2: 1.305  loss_mask_2: 0.03888  loss_dice_2: 0.698  loss_bbox_2: 0.06298  loss_giou_2: 0.3717  loss_ce_dn_2: 0.2684  loss_mask_dn_2: 0.03059  loss_dice_dn_2: 0.5481  loss_bbox_dn_2: 0.05069  loss_giou_dn_2: 0.3118  loss_ce_3: 1.263  loss_mask_3: 0.0379  loss_dice_3: 0.5154  loss_bbox_3: 0.05024  loss_giou_3: 0.3662  loss_ce_dn_3: 0.2284  loss_mask_dn_3: 0.03002  loss_dice_dn_3: 0.5433  loss_bbox_dn_3: 0.04257  loss_giou_dn_3: 0.2869  loss_ce_4: 1.198  loss_mask_4: 0.03825  loss_dice_4: 0.6026  loss_bbox_4: 0.05138  loss_giou_4: 0.3489  loss_ce_dn_4: 0.218  loss_mask_dn_4: 0.02744  loss_dice_dn_4: 0.5413  loss_bbox_dn_4: 0.03574  loss_giou_dn_4: 0.2711  loss_ce_5: 1.101  loss_mask_5: 0.03216  loss_dice_5: 0.3532  loss_bbox_5: 0.0531  loss_giou_5: 0.372  loss_ce_dn_5: 0.2183  loss_mask_dn_5: 0.02784  loss_dice_dn_5: 0.5127  loss_bbox_dn_5: 0.03563  loss_giou_dn_5: 0.2754  loss_ce_6: 1.079  loss_mask_6: 0.03742  loss_dice_6: 0.6789  loss_bbox_6: 0.04504  loss_giou_6: 0.3573  loss_ce_dn_6: 0.2064  loss_mask_dn_6: 0.02714  loss_dice_dn_6: 0.5686  loss_bbox_dn_6: 0.03563  loss_giou_dn_6: 0.2788  loss_ce_7: 1.067  loss_mask_7: 0.0368  loss_dice_7: 0.7019  loss_bbox_7: 0.06158  loss_giou_7: 0.3554  loss_ce_dn_7: 0.2001  loss_mask_dn_7: 0.02744  loss_dice_dn_7: 0.5368  loss_bbox_dn_7: 0.03583  loss_giou_dn_7: 0.2754  loss_ce_8: 1.052  loss_mask_8: 0.03296  loss_dice_8: 0.4871  loss_bbox_8: 0.04633  loss_giou_8: 0.3449  loss_ce_dn_8: 0.2009  loss_mask_dn_8: 0.02689  loss_dice_dn_8: 0.5495  loss_bbox_dn_8: 0.03549  loss_giou_dn_8: 0.2766  loss_ce_interm: 1.403  loss_mask_interm: 0.03801  loss_dice_interm: 0.5016  loss_bbox_interm: 0.09701  loss_giou_interm: 0.3943  time: 1.8374  data_time: 0.0885  lr: 1e-06  max_mem: 6663M\n",
            "[05/20 19:06:24 d2.utils.events]:  eta: 0:18:10  iter: 5059  total_loss: 45.63  loss_ce: 1.041  loss_mask: 0.03942  loss_dice: 0.7457  loss_bbox: 0.05685  loss_giou: 0.4332  loss_ce_dn: 0.173  loss_mask_dn: 0.03481  loss_dice_dn: 0.5973  loss_bbox_dn: 0.04808  loss_giou_dn: 0.3236  loss_ce_0: 1.238  loss_mask_0: 0.04462  loss_dice_0: 0.62  loss_bbox_0: 0.07971  loss_giou_0: 0.5493  loss_ce_dn_0: 0.7678  loss_mask_dn_0: 0.1404  loss_dice_dn_0: 2.617  loss_bbox_dn_0: 0.1967  loss_giou_dn_0: 0.8633  loss_ce_1: 1.333  loss_mask_1: 0.03691  loss_dice_1: 0.6813  loss_bbox_1: 0.05394  loss_giou_1: 0.5033  loss_ce_dn_1: 0.239  loss_mask_dn_1: 0.03624  loss_dice_dn_1: 0.6336  loss_bbox_dn_1: 0.04989  loss_giou_dn_1: 0.4098  loss_ce_2: 1.205  loss_mask_2: 0.04117  loss_dice_2: 0.7877  loss_bbox_2: 0.06573  loss_giou_2: 0.4476  loss_ce_dn_2: 0.2296  loss_mask_dn_2: 0.03756  loss_dice_dn_2: 0.5626  loss_bbox_dn_2: 0.04594  loss_giou_dn_2: 0.3581  loss_ce_3: 1.197  loss_mask_3: 0.0344  loss_dice_3: 0.7535  loss_bbox_3: 0.05416  loss_giou_3: 0.4229  loss_ce_dn_3: 0.1965  loss_mask_dn_3: 0.03748  loss_dice_dn_3: 0.5935  loss_bbox_dn_3: 0.04314  loss_giou_dn_3: 0.3335  loss_ce_4: 1.102  loss_mask_4: 0.03831  loss_dice_4: 0.7675  loss_bbox_4: 0.05118  loss_giou_4: 0.4156  loss_ce_dn_4: 0.1831  loss_mask_dn_4: 0.03792  loss_dice_dn_4: 0.5764  loss_bbox_dn_4: 0.04685  loss_giou_dn_4: 0.3349  loss_ce_5: 1.105  loss_mask_5: 0.04017  loss_dice_5: 0.7064  loss_bbox_5: 0.05777  loss_giou_5: 0.4163  loss_ce_dn_5: 0.1799  loss_mask_dn_5: 0.02986  loss_dice_dn_5: 0.5597  loss_bbox_dn_5: 0.04758  loss_giou_dn_5: 0.3265  loss_ce_6: 1.04  loss_mask_6: 0.03  loss_dice_6: 0.6446  loss_bbox_6: 0.05602  loss_giou_6: 0.4239  loss_ce_dn_6: 0.175  loss_mask_dn_6: 0.03282  loss_dice_dn_6: 0.6101  loss_bbox_dn_6: 0.04731  loss_giou_dn_6: 0.323  loss_ce_7: 1.064  loss_mask_7: 0.0419  loss_dice_7: 0.5997  loss_bbox_7: 0.06005  loss_giou_7: 0.4214  loss_ce_dn_7: 0.1754  loss_mask_dn_7: 0.03438  loss_dice_dn_7: 0.5698  loss_bbox_dn_7: 0.04823  loss_giou_dn_7: 0.3309  loss_ce_8: 1.076  loss_mask_8: 0.04022  loss_dice_8: 0.6082  loss_bbox_8: 0.06071  loss_giou_8: 0.4424  loss_ce_dn_8: 0.1731  loss_mask_dn_8: 0.03549  loss_dice_dn_8: 0.5751  loss_bbox_dn_8: 0.04766  loss_giou_dn_8: 0.3231  loss_ce_interm: 1.325  loss_mask_interm: 0.04096  loss_dice_interm: 0.7101  loss_bbox_interm: 0.08341  loss_giou_interm: 0.5521  time: 1.8365  data_time: 0.0531  lr: 1e-06  max_mem: 6663M\n",
            "[05/20 19:06:58 d2.utils.events]:  eta: 0:17:38  iter: 5079  total_loss: 40.92  loss_ce: 0.811  loss_mask: 0.03309  loss_dice: 0.683  loss_bbox: 0.05797  loss_giou: 0.3401  loss_ce_dn: 0.1408  loss_mask_dn: 0.03254  loss_dice_dn: 0.6654  loss_bbox_dn: 0.0482  loss_giou_dn: 0.2976  loss_ce_0: 1.142  loss_mask_0: 0.03508  loss_dice_0: 0.8244  loss_bbox_0: 0.06208  loss_giou_0: 0.3946  loss_ce_dn_0: 0.7558  loss_mask_dn_0: 0.1431  loss_dice_dn_0: 2.809  loss_bbox_dn_0: 0.2408  loss_giou_dn_0: 0.8583  loss_ce_1: 1.012  loss_mask_1: 0.03106  loss_dice_1: 0.6622  loss_bbox_1: 0.06689  loss_giou_1: 0.3507  loss_ce_dn_1: 0.278  loss_mask_dn_1: 0.04055  loss_dice_dn_1: 0.7031  loss_bbox_dn_1: 0.0714  loss_giou_dn_1: 0.3925  loss_ce_2: 1.136  loss_mask_2: 0.0344  loss_dice_2: 0.7329  loss_bbox_2: 0.06487  loss_giou_2: 0.3816  loss_ce_dn_2: 0.2397  loss_mask_dn_2: 0.03736  loss_dice_dn_2: 0.6906  loss_bbox_dn_2: 0.06302  loss_giou_dn_2: 0.3536  loss_ce_3: 0.8682  loss_mask_3: 0.03176  loss_dice_3: 0.6507  loss_bbox_3: 0.06619  loss_giou_3: 0.3586  loss_ce_dn_3: 0.1963  loss_mask_dn_3: 0.03732  loss_dice_dn_3: 0.687  loss_bbox_dn_3: 0.05455  loss_giou_dn_3: 0.3228  loss_ce_4: 0.8086  loss_mask_4: 0.03473  loss_dice_4: 0.7246  loss_bbox_4: 0.06902  loss_giou_4: 0.3513  loss_ce_dn_4: 0.1784  loss_mask_dn_4: 0.0371  loss_dice_dn_4: 0.6617  loss_bbox_dn_4: 0.05014  loss_giou_dn_4: 0.3107  loss_ce_5: 0.8411  loss_mask_5: 0.03115  loss_dice_5: 0.5849  loss_bbox_5: 0.07045  loss_giou_5: 0.3278  loss_ce_dn_5: 0.1563  loss_mask_dn_5: 0.03386  loss_dice_dn_5: 0.6712  loss_bbox_dn_5: 0.04998  loss_giou_dn_5: 0.3068  loss_ce_6: 0.8029  loss_mask_6: 0.03034  loss_dice_6: 0.6025  loss_bbox_6: 0.05682  loss_giou_6: 0.3288  loss_ce_dn_6: 0.1469  loss_mask_dn_6: 0.03256  loss_dice_dn_6: 0.6881  loss_bbox_dn_6: 0.0483  loss_giou_dn_6: 0.3021  loss_ce_7: 0.8172  loss_mask_7: 0.03345  loss_dice_7: 0.6824  loss_bbox_7: 0.0574  loss_giou_7: 0.3627  loss_ce_dn_7: 0.1452  loss_mask_dn_7: 0.03164  loss_dice_dn_7: 0.6617  loss_bbox_dn_7: 0.04765  loss_giou_dn_7: 0.3  loss_ce_8: 0.806  loss_mask_8: 0.03274  loss_dice_8: 0.6521  loss_bbox_8: 0.058  loss_giou_8: 0.3648  loss_ce_dn_8: 0.143  loss_mask_dn_8: 0.03441  loss_dice_dn_8: 0.6294  loss_bbox_dn_8: 0.04796  loss_giou_dn_8: 0.2992  loss_ce_interm: 1.106  loss_mask_interm: 0.03154  loss_dice_interm: 0.664  loss_bbox_interm: 0.08459  loss_giou_interm: 0.4376  time: 1.8359  data_time: 0.0971  lr: 1e-06  max_mem: 6663M\n",
            "[05/20 19:07:31 d2.utils.events]:  eta: 0:17:06  iter: 5099  total_loss: 45.78  loss_ce: 1.013  loss_mask: 0.06205  loss_dice: 0.583  loss_bbox: 0.06806  loss_giou: 0.3312  loss_ce_dn: 0.2072  loss_mask_dn: 0.05892  loss_dice_dn: 0.5015  loss_bbox_dn: 0.05716  loss_giou_dn: 0.301  loss_ce_0: 1.438  loss_mask_0: 0.06665  loss_dice_0: 0.535  loss_bbox_0: 0.1103  loss_giou_0: 0.4638  loss_ce_dn_0: 0.7009  loss_mask_dn_0: 0.1907  loss_dice_dn_0: 2.847  loss_bbox_dn_0: 0.3434  loss_giou_dn_0: 0.8569  loss_ce_1: 1.483  loss_mask_1: 0.07063  loss_dice_1: 0.473  loss_bbox_1: 0.07086  loss_giou_1: 0.3669  loss_ce_dn_1: 0.286  loss_mask_dn_1: 0.06494  loss_dice_dn_1: 0.5442  loss_bbox_dn_1: 0.09707  loss_giou_dn_1: 0.3794  loss_ce_2: 1.34  loss_mask_2: 0.06591  loss_dice_2: 0.4388  loss_bbox_2: 0.07124  loss_giou_2: 0.3449  loss_ce_dn_2: 0.2375  loss_mask_dn_2: 0.06271  loss_dice_dn_2: 0.5233  loss_bbox_dn_2: 0.08004  loss_giou_dn_2: 0.356  loss_ce_3: 1.186  loss_mask_3: 0.06345  loss_dice_3: 0.4347  loss_bbox_3: 0.07988  loss_giou_3: 0.3473  loss_ce_dn_3: 0.2274  loss_mask_dn_3: 0.05975  loss_dice_dn_3: 0.5084  loss_bbox_dn_3: 0.06703  loss_giou_dn_3: 0.3395  loss_ce_4: 1.133  loss_mask_4: 0.06033  loss_dice_4: 0.504  loss_bbox_4: 0.06781  loss_giou_4: 0.3347  loss_ce_dn_4: 0.2018  loss_mask_dn_4: 0.0596  loss_dice_dn_4: 0.4809  loss_bbox_dn_4: 0.06658  loss_giou_dn_4: 0.3234  loss_ce_5: 1.099  loss_mask_5: 0.06741  loss_dice_5: 0.4275  loss_bbox_5: 0.07059  loss_giou_5: 0.3473  loss_ce_dn_5: 0.1986  loss_mask_dn_5: 0.05861  loss_dice_dn_5: 0.4951  loss_bbox_dn_5: 0.06092  loss_giou_dn_5: 0.3144  loss_ce_6: 1.013  loss_mask_6: 0.05873  loss_dice_6: 0.4352  loss_bbox_6: 0.07718  loss_giou_6: 0.3359  loss_ce_dn_6: 0.2044  loss_mask_dn_6: 0.05826  loss_dice_dn_6: 0.5125  loss_bbox_dn_6: 0.06036  loss_giou_dn_6: 0.3075  loss_ce_7: 1.014  loss_mask_7: 0.06471  loss_dice_7: 0.403  loss_bbox_7: 0.06903  loss_giou_7: 0.3296  loss_ce_dn_7: 0.2004  loss_mask_dn_7: 0.05867  loss_dice_dn_7: 0.4984  loss_bbox_dn_7: 0.05882  loss_giou_dn_7: 0.3004  loss_ce_8: 1.021  loss_mask_8: 0.0642  loss_dice_8: 0.3679  loss_bbox_8: 0.068  loss_giou_8: 0.334  loss_ce_dn_8: 0.2038  loss_mask_dn_8: 0.05825  loss_dice_dn_8: 0.5024  loss_bbox_dn_8: 0.05883  loss_giou_dn_8: 0.3061  loss_ce_interm: 1.378  loss_mask_interm: 0.07213  loss_dice_interm: 0.5343  loss_bbox_interm: 0.1137  loss_giou_interm: 0.3842  time: 1.8351  data_time: 0.0811  lr: 1e-06  max_mem: 6663M\n",
            "[05/20 19:08:04 d2.utils.events]:  eta: 0:16:34  iter: 5119  total_loss: 39.06  loss_ce: 0.954  loss_mask: 0.03322  loss_dice: 0.5254  loss_bbox: 0.05913  loss_giou: 0.3104  loss_ce_dn: 0.1578  loss_mask_dn: 0.02596  loss_dice_dn: 0.5653  loss_bbox_dn: 0.04114  loss_giou_dn: 0.2611  loss_ce_0: 1.135  loss_mask_0: 0.03202  loss_dice_0: 0.5745  loss_bbox_0: 0.07633  loss_giou_0: 0.3687  loss_ce_dn_0: 0.7175  loss_mask_dn_0: 0.1475  loss_dice_dn_0: 2.738  loss_bbox_dn_0: 0.2691  loss_giou_dn_0: 0.8467  loss_ce_1: 1.127  loss_mask_1: 0.02976  loss_dice_1: 0.564  loss_bbox_1: 0.06963  loss_giou_1: 0.3052  loss_ce_dn_1: 0.2618  loss_mask_dn_1: 0.02801  loss_dice_dn_1: 0.5915  loss_bbox_dn_1: 0.06654  loss_giou_dn_1: 0.3436  loss_ce_2: 1.218  loss_mask_2: 0.02862  loss_dice_2: 0.5992  loss_bbox_2: 0.0655  loss_giou_2: 0.2785  loss_ce_dn_2: 0.2131  loss_mask_dn_2: 0.02318  loss_dice_dn_2: 0.5619  loss_bbox_dn_2: 0.04855  loss_giou_dn_2: 0.291  loss_ce_3: 1.085  loss_mask_3: 0.03552  loss_dice_3: 0.4776  loss_bbox_3: 0.06216  loss_giou_3: 0.312  loss_ce_dn_3: 0.1963  loss_mask_dn_3: 0.02454  loss_dice_dn_3: 0.5802  loss_bbox_dn_3: 0.04472  loss_giou_dn_3: 0.2805  loss_ce_4: 0.9993  loss_mask_4: 0.03124  loss_dice_4: 0.4761  loss_bbox_4: 0.0615  loss_giou_4: 0.3065  loss_ce_dn_4: 0.1816  loss_mask_dn_4: 0.02424  loss_dice_dn_4: 0.5607  loss_bbox_dn_4: 0.04213  loss_giou_dn_4: 0.2708  loss_ce_5: 1.011  loss_mask_5: 0.0307  loss_dice_5: 0.6025  loss_bbox_5: 0.06201  loss_giou_5: 0.307  loss_ce_dn_5: 0.1737  loss_mask_dn_5: 0.02471  loss_dice_dn_5: 0.555  loss_bbox_dn_5: 0.04102  loss_giou_dn_5: 0.2647  loss_ce_6: 0.9962  loss_mask_6: 0.03543  loss_dice_6: 0.5004  loss_bbox_6: 0.05975  loss_giou_6: 0.2931  loss_ce_dn_6: 0.1698  loss_mask_dn_6: 0.02451  loss_dice_dn_6: 0.5344  loss_bbox_dn_6: 0.04101  loss_giou_dn_6: 0.2599  loss_ce_7: 0.9938  loss_mask_7: 0.02537  loss_dice_7: 0.5583  loss_bbox_7: 0.05928  loss_giou_7: 0.3025  loss_ce_dn_7: 0.1581  loss_mask_dn_7: 0.02589  loss_dice_dn_7: 0.5476  loss_bbox_dn_7: 0.04096  loss_giou_dn_7: 0.2551  loss_ce_8: 0.9482  loss_mask_8: 0.02758  loss_dice_8: 0.4943  loss_bbox_8: 0.05825  loss_giou_8: 0.3041  loss_ce_dn_8: 0.1585  loss_mask_dn_8: 0.02591  loss_dice_dn_8: 0.5729  loss_bbox_dn_8: 0.04119  loss_giou_dn_8: 0.2596  loss_ce_interm: 1.155  loss_mask_interm: 0.03577  loss_dice_interm: 0.6178  loss_bbox_interm: 0.08145  loss_giou_interm: 0.3848  time: 1.8344  data_time: 0.0754  lr: 1e-06  max_mem: 6663M\n",
            "[05/20 19:08:37 d2.utils.events]:  eta: 0:16:03  iter: 5139  total_loss: 45.5  loss_ce: 1.079  loss_mask: 0.02191  loss_dice: 0.8434  loss_bbox: 0.08795  loss_giou: 0.5192  loss_ce_dn: 0.1764  loss_mask_dn: 0.01873  loss_dice_dn: 0.7175  loss_bbox_dn: 0.02613  loss_giou_dn: 0.376  loss_ce_0: 1.459  loss_mask_0: 0.01997  loss_dice_0: 0.8349  loss_bbox_0: 0.06859  loss_giou_0: 0.5143  loss_ce_dn_0: 0.7627  loss_mask_dn_0: 0.06728  loss_dice_dn_0: 2.345  loss_bbox_dn_0: 0.1715  loss_giou_dn_0: 0.8548  loss_ce_1: 1.325  loss_mask_1: 0.02143  loss_dice_1: 0.6856  loss_bbox_1: 0.06551  loss_giou_1: 0.4622  loss_ce_dn_1: 0.2888  loss_mask_dn_1: 0.01864  loss_dice_dn_1: 0.717  loss_bbox_dn_1: 0.04052  loss_giou_dn_1: 0.4466  loss_ce_2: 1.236  loss_mask_2: 0.02313  loss_dice_2: 0.7559  loss_bbox_2: 0.07428  loss_giou_2: 0.4429  loss_ce_dn_2: 0.2427  loss_mask_dn_2: 0.01802  loss_dice_dn_2: 0.7359  loss_bbox_dn_2: 0.03002  loss_giou_dn_2: 0.4003  loss_ce_3: 1.12  loss_mask_3: 0.01966  loss_dice_3: 0.584  loss_bbox_3: 0.05934  loss_giou_3: 0.4165  loss_ce_dn_3: 0.2108  loss_mask_dn_3: 0.0184  loss_dice_dn_3: 0.7532  loss_bbox_dn_3: 0.02838  loss_giou_dn_3: 0.3891  loss_ce_4: 1.117  loss_mask_4: 0.01917  loss_dice_4: 0.819  loss_bbox_4: 0.0687  loss_giou_4: 0.4233  loss_ce_dn_4: 0.1935  loss_mask_dn_4: 0.0189  loss_dice_dn_4: 0.759  loss_bbox_dn_4: 0.02782  loss_giou_dn_4: 0.3892  loss_ce_5: 1.122  loss_mask_5: 0.01816  loss_dice_5: 0.672  loss_bbox_5: 0.07992  loss_giou_5: 0.4241  loss_ce_dn_5: 0.1894  loss_mask_dn_5: 0.01904  loss_dice_dn_5: 0.7392  loss_bbox_dn_5: 0.02711  loss_giou_dn_5: 0.3859  loss_ce_6: 1.24  loss_mask_6: 0.01661  loss_dice_6: 0.6072  loss_bbox_6: 0.07198  loss_giou_6: 0.4425  loss_ce_dn_6: 0.1879  loss_mask_dn_6: 0.01913  loss_dice_dn_6: 0.7024  loss_bbox_dn_6: 0.02743  loss_giou_dn_6: 0.3897  loss_ce_7: 1.241  loss_mask_7: 0.01952  loss_dice_7: 0.673  loss_bbox_7: 0.0695  loss_giou_7: 0.4792  loss_ce_dn_7: 0.1811  loss_mask_dn_7: 0.01862  loss_dice_dn_7: 0.7163  loss_bbox_dn_7: 0.02642  loss_giou_dn_7: 0.3849  loss_ce_8: 1.227  loss_mask_8: 0.01928  loss_dice_8: 0.5433  loss_bbox_8: 0.07519  loss_giou_8: 0.4776  loss_ce_dn_8: 0.1771  loss_mask_dn_8: 0.01809  loss_dice_dn_8: 0.7152  loss_bbox_dn_8: 0.0262  loss_giou_dn_8: 0.3791  loss_ce_interm: 1.454  loss_mask_interm: 0.02241  loss_dice_interm: 0.606  loss_bbox_interm: 0.07818  loss_giou_interm: 0.5533  time: 1.8337  data_time: 0.0964  lr: 1e-06  max_mem: 6663M\n",
            "[05/20 19:09:11 d2.utils.events]:  eta: 0:15:31  iter: 5159  total_loss: 44.2  loss_ce: 0.9275  loss_mask: 0.04244  loss_dice: 0.6061  loss_bbox: 0.07552  loss_giou: 0.2417  loss_ce_dn: 0.1474  loss_mask_dn: 0.04005  loss_dice_dn: 0.6564  loss_bbox_dn: 0.03974  loss_giou_dn: 0.2662  loss_ce_0: 1.22  loss_mask_0: 0.03584  loss_dice_0: 0.5407  loss_bbox_0: 0.0962  loss_giou_0: 0.2855  loss_ce_dn_0: 0.785  loss_mask_dn_0: 0.2596  loss_dice_dn_0: 2.312  loss_bbox_dn_0: 0.4031  loss_giou_dn_0: 0.8624  loss_ce_1: 1.244  loss_mask_1: 0.03368  loss_dice_1: 0.7034  loss_bbox_1: 0.08552  loss_giou_1: 0.2876  loss_ce_dn_1: 0.2778  loss_mask_dn_1: 0.03828  loss_dice_dn_1: 0.6872  loss_bbox_dn_1: 0.08347  loss_giou_dn_1: 0.3793  loss_ce_2: 1.277  loss_mask_2: 0.047  loss_dice_2: 0.6069  loss_bbox_2: 0.07354  loss_giou_2: 0.2748  loss_ce_dn_2: 0.2142  loss_mask_dn_2: 0.0363  loss_dice_dn_2: 0.6423  loss_bbox_dn_2: 0.05384  loss_giou_dn_2: 0.3136  loss_ce_3: 1.133  loss_mask_3: 0.04314  loss_dice_3: 0.6108  loss_bbox_3: 0.07825  loss_giou_3: 0.2616  loss_ce_dn_3: 0.1888  loss_mask_dn_3: 0.03891  loss_dice_dn_3: 0.6175  loss_bbox_dn_3: 0.04666  loss_giou_dn_3: 0.2896  loss_ce_4: 0.9852  loss_mask_4: 0.0433  loss_dice_4: 0.7219  loss_bbox_4: 0.07991  loss_giou_4: 0.2474  loss_ce_dn_4: 0.1891  loss_mask_dn_4: 0.0393  loss_dice_dn_4: 0.6447  loss_bbox_dn_4: 0.04514  loss_giou_dn_4: 0.2827  loss_ce_5: 0.993  loss_mask_5: 0.04214  loss_dice_5: 0.5288  loss_bbox_5: 0.07932  loss_giou_5: 0.2472  loss_ce_dn_5: 0.1749  loss_mask_dn_5: 0.04062  loss_dice_dn_5: 0.624  loss_bbox_dn_5: 0.04063  loss_giou_dn_5: 0.2877  loss_ce_6: 0.968  loss_mask_6: 0.04397  loss_dice_6: 0.6184  loss_bbox_6: 0.08445  loss_giou_6: 0.2507  loss_ce_dn_6: 0.1593  loss_mask_dn_6: 0.03875  loss_dice_dn_6: 0.6416  loss_bbox_dn_6: 0.04145  loss_giou_dn_6: 0.289  loss_ce_7: 0.9852  loss_mask_7: 0.03475  loss_dice_7: 0.6796  loss_bbox_7: 0.07535  loss_giou_7: 0.242  loss_ce_dn_7: 0.1472  loss_mask_dn_7: 0.0405  loss_dice_dn_7: 0.6028  loss_bbox_dn_7: 0.03937  loss_giou_dn_7: 0.2762  loss_ce_8: 0.9503  loss_mask_8: 0.04371  loss_dice_8: 0.6848  loss_bbox_8: 0.07815  loss_giou_8: 0.2367  loss_ce_dn_8: 0.1504  loss_mask_dn_8: 0.04066  loss_dice_dn_8: 0.646  loss_bbox_dn_8: 0.03891  loss_giou_dn_8: 0.2728  loss_ce_interm: 1.328  loss_mask_interm: 0.03795  loss_dice_interm: 0.6163  loss_bbox_interm: 0.1122  loss_giou_interm: 0.42  time: 1.8331  data_time: 0.0641  lr: 1e-06  max_mem: 6663M\n",
            "[05/20 19:09:45 d2.utils.events]:  eta: 0:14:59  iter: 5179  total_loss: 38.97  loss_ce: 0.9099  loss_mask: 0.03322  loss_dice: 0.3156  loss_bbox: 0.05536  loss_giou: 0.263  loss_ce_dn: 0.1969  loss_mask_dn: 0.0268  loss_dice_dn: 0.425  loss_bbox_dn: 0.0336  loss_giou_dn: 0.2268  loss_ce_0: 1.16  loss_mask_0: 0.03307  loss_dice_0: 0.3859  loss_bbox_0: 0.04573  loss_giou_0: 0.3434  loss_ce_dn_0: 0.7605  loss_mask_dn_0: 0.2417  loss_dice_dn_0: 2.617  loss_bbox_dn_0: 0.3178  loss_giou_dn_0: 0.8616  loss_ce_1: 1.145  loss_mask_1: 0.03818  loss_dice_1: 0.3269  loss_bbox_1: 0.04732  loss_giou_1: 0.2863  loss_ce_dn_1: 0.2788  loss_mask_dn_1: 0.02785  loss_dice_dn_1: 0.421  loss_bbox_dn_1: 0.08454  loss_giou_dn_1: 0.3396  loss_ce_2: 1.098  loss_mask_2: 0.03297  loss_dice_2: 0.3514  loss_bbox_2: 0.05051  loss_giou_2: 0.2676  loss_ce_dn_2: 0.2519  loss_mask_dn_2: 0.0281  loss_dice_dn_2: 0.4655  loss_bbox_dn_2: 0.06454  loss_giou_dn_2: 0.2866  loss_ce_3: 1.048  loss_mask_3: 0.03001  loss_dice_3: 0.354  loss_bbox_3: 0.04797  loss_giou_3: 0.2706  loss_ce_dn_3: 0.2326  loss_mask_dn_3: 0.02832  loss_dice_dn_3: 0.4365  loss_bbox_dn_3: 0.05888  loss_giou_dn_3: 0.2541  loss_ce_4: 0.9533  loss_mask_4: 0.03066  loss_dice_4: 0.335  loss_bbox_4: 0.05862  loss_giou_4: 0.2638  loss_ce_dn_4: 0.2251  loss_mask_dn_4: 0.02746  loss_dice_dn_4: 0.4486  loss_bbox_dn_4: 0.04301  loss_giou_dn_4: 0.2411  loss_ce_5: 0.9384  loss_mask_5: 0.03183  loss_dice_5: 0.3618  loss_bbox_5: 0.05684  loss_giou_5: 0.2589  loss_ce_dn_5: 0.2095  loss_mask_dn_5: 0.02827  loss_dice_dn_5: 0.4391  loss_bbox_dn_5: 0.04489  loss_giou_dn_5: 0.2326  loss_ce_6: 1.022  loss_mask_6: 0.03006  loss_dice_6: 0.3735  loss_bbox_6: 0.05629  loss_giou_6: 0.2253  loss_ce_dn_6: 0.2061  loss_mask_dn_6: 0.02803  loss_dice_dn_6: 0.4295  loss_bbox_dn_6: 0.03973  loss_giou_dn_6: 0.231  loss_ce_7: 0.9084  loss_mask_7: 0.02943  loss_dice_7: 0.3402  loss_bbox_7: 0.05477  loss_giou_7: 0.2688  loss_ce_dn_7: 0.1967  loss_mask_dn_7: 0.02739  loss_dice_dn_7: 0.4431  loss_bbox_dn_7: 0.03624  loss_giou_dn_7: 0.2299  loss_ce_8: 0.9144  loss_mask_8: 0.03109  loss_dice_8: 0.3349  loss_bbox_8: 0.05501  loss_giou_8: 0.2628  loss_ce_dn_8: 0.1942  loss_mask_dn_8: 0.02705  loss_dice_dn_8: 0.4262  loss_bbox_dn_8: 0.03479  loss_giou_dn_8: 0.2297  loss_ce_interm: 1.154  loss_mask_interm: 0.03284  loss_dice_interm: 0.3715  loss_bbox_interm: 0.09515  loss_giou_interm: 0.413  time: 1.8326  data_time: 0.0689  lr: 1e-06  max_mem: 6663M\n",
            "[05/20 19:10:19 d2.utils.events]:  eta: 0:14:27  iter: 5199  total_loss: 45.81  loss_ce: 1.004  loss_mask: 0.03731  loss_dice: 0.8336  loss_bbox: 0.07398  loss_giou: 0.4427  loss_ce_dn: 0.1779  loss_mask_dn: 0.0353  loss_dice_dn: 0.7186  loss_bbox_dn: 0.04207  loss_giou_dn: 0.3231  loss_ce_0: 1.264  loss_mask_0: 0.03698  loss_dice_0: 0.7626  loss_bbox_0: 0.0657  loss_giou_0: 0.516  loss_ce_dn_0: 0.7339  loss_mask_dn_0: 0.1304  loss_dice_dn_0: 2.605  loss_bbox_dn_0: 0.2041  loss_giou_dn_0: 0.8589  loss_ce_1: 1.273  loss_mask_1: 0.04287  loss_dice_1: 0.6312  loss_bbox_1: 0.05876  loss_giou_1: 0.4489  loss_ce_dn_1: 0.2559  loss_mask_dn_1: 0.03607  loss_dice_dn_1: 0.7543  loss_bbox_dn_1: 0.05863  loss_giou_dn_1: 0.3964  loss_ce_2: 1.197  loss_mask_2: 0.03615  loss_dice_2: 0.7097  loss_bbox_2: 0.05994  loss_giou_2: 0.4472  loss_ce_dn_2: 0.2158  loss_mask_dn_2: 0.03432  loss_dice_dn_2: 0.7219  loss_bbox_dn_2: 0.05181  loss_giou_dn_2: 0.3663  loss_ce_3: 1.058  loss_mask_3: 0.0357  loss_dice_3: 0.8787  loss_bbox_3: 0.05938  loss_giou_3: 0.466  loss_ce_dn_3: 0.1863  loss_mask_dn_3: 0.03508  loss_dice_dn_3: 0.6825  loss_bbox_dn_3: 0.04971  loss_giou_dn_3: 0.3407  loss_ce_4: 1.089  loss_mask_4: 0.03515  loss_dice_4: 0.7522  loss_bbox_4: 0.05785  loss_giou_4: 0.4373  loss_ce_dn_4: 0.1812  loss_mask_dn_4: 0.03557  loss_dice_dn_4: 0.6496  loss_bbox_dn_4: 0.0438  loss_giou_dn_4: 0.3204  loss_ce_5: 1.07  loss_mask_5: 0.03491  loss_dice_5: 0.7977  loss_bbox_5: 0.05606  loss_giou_5: 0.4428  loss_ce_dn_5: 0.1749  loss_mask_dn_5: 0.03517  loss_dice_dn_5: 0.6349  loss_bbox_dn_5: 0.04295  loss_giou_dn_5: 0.3233  loss_ce_6: 1.041  loss_mask_6: 0.03677  loss_dice_6: 0.8372  loss_bbox_6: 0.05624  loss_giou_6: 0.4786  loss_ce_dn_6: 0.1804  loss_mask_dn_6: 0.03488  loss_dice_dn_6: 0.688  loss_bbox_dn_6: 0.04447  loss_giou_dn_6: 0.327  loss_ce_7: 1.014  loss_mask_7: 0.03956  loss_dice_7: 0.8601  loss_bbox_7: 0.05703  loss_giou_7: 0.4422  loss_ce_dn_7: 0.1801  loss_mask_dn_7: 0.03557  loss_dice_dn_7: 0.5931  loss_bbox_dn_7: 0.04311  loss_giou_dn_7: 0.3241  loss_ce_8: 1.005  loss_mask_8: 0.03788  loss_dice_8: 0.73  loss_bbox_8: 0.05744  loss_giou_8: 0.4409  loss_ce_dn_8: 0.1816  loss_mask_dn_8: 0.03572  loss_dice_dn_8: 0.6787  loss_bbox_dn_8: 0.04341  loss_giou_dn_8: 0.3234  loss_ce_interm: 1.261  loss_mask_interm: 0.03177  loss_dice_interm: 0.6982  loss_bbox_interm: 0.08647  loss_giou_interm: 0.5468  time: 1.8320  data_time: 0.0897  lr: 1e-06  max_mem: 6663M\n",
            "[05/20 19:10:53 d2.utils.events]:  eta: 0:13:56  iter: 5219  total_loss: 45.07  loss_ce: 1.116  loss_mask: 0.02593  loss_dice: 0.6416  loss_bbox: 0.04777  loss_giou: 0.4361  loss_ce_dn: 0.2244  loss_mask_dn: 0.02494  loss_dice_dn: 0.5884  loss_bbox_dn: 0.0344  loss_giou_dn: 0.3372  loss_ce_0: 1.217  loss_mask_0: 0.03418  loss_dice_0: 0.5476  loss_bbox_0: 0.05791  loss_giou_0: 0.4466  loss_ce_dn_0: 0.7673  loss_mask_dn_0: 0.1124  loss_dice_dn_0: 2.444  loss_bbox_dn_0: 0.2186  loss_giou_dn_0: 0.8542  loss_ce_1: 1.231  loss_mask_1: 0.03972  loss_dice_1: 0.803  loss_bbox_1: 0.04991  loss_giou_1: 0.4925  loss_ce_dn_1: 0.2713  loss_mask_dn_1: 0.02478  loss_dice_dn_1: 0.6126  loss_bbox_dn_1: 0.05433  loss_giou_dn_1: 0.4396  loss_ce_2: 1.104  loss_mask_2: 0.03346  loss_dice_2: 0.7272  loss_bbox_2: 0.04309  loss_giou_2: 0.4623  loss_ce_dn_2: 0.2368  loss_mask_dn_2: 0.02463  loss_dice_dn_2: 0.5814  loss_bbox_dn_2: 0.0446  loss_giou_dn_2: 0.3618  loss_ce_3: 1.199  loss_mask_3: 0.03163  loss_dice_3: 0.6995  loss_bbox_3: 0.05248  loss_giou_3: 0.4703  loss_ce_dn_3: 0.2238  loss_mask_dn_3: 0.02194  loss_dice_dn_3: 0.5223  loss_bbox_dn_3: 0.03685  loss_giou_dn_3: 0.3262  loss_ce_4: 1.113  loss_mask_4: 0.03348  loss_dice_4: 0.6913  loss_bbox_4: 0.0467  loss_giou_4: 0.4595  loss_ce_dn_4: 0.2076  loss_mask_dn_4: 0.02342  loss_dice_dn_4: 0.5716  loss_bbox_dn_4: 0.03501  loss_giou_dn_4: 0.3265  loss_ce_5: 1.088  loss_mask_5: 0.02398  loss_dice_5: 0.5158  loss_bbox_5: 0.05185  loss_giou_5: 0.466  loss_ce_dn_5: 0.2094  loss_mask_dn_5: 0.02461  loss_dice_dn_5: 0.6198  loss_bbox_dn_5: 0.03432  loss_giou_dn_5: 0.3276  loss_ce_6: 1.158  loss_mask_6: 0.03121  loss_dice_6: 0.7037  loss_bbox_6: 0.04593  loss_giou_6: 0.4543  loss_ce_dn_6: 0.2349  loss_mask_dn_6: 0.02379  loss_dice_dn_6: 0.5862  loss_bbox_dn_6: 0.03451  loss_giou_dn_6: 0.3302  loss_ce_7: 1.117  loss_mask_7: 0.03  loss_dice_7: 0.7031  loss_bbox_7: 0.04991  loss_giou_7: 0.4526  loss_ce_dn_7: 0.2258  loss_mask_dn_7: 0.02455  loss_dice_dn_7: 0.5701  loss_bbox_dn_7: 0.0344  loss_giou_dn_7: 0.3346  loss_ce_8: 1.111  loss_mask_8: 0.03711  loss_dice_8: 0.6354  loss_bbox_8: 0.04575  loss_giou_8: 0.4537  loss_ce_dn_8: 0.2264  loss_mask_dn_8: 0.02499  loss_dice_dn_8: 0.5964  loss_bbox_dn_8: 0.03405  loss_giou_dn_8: 0.338  loss_ce_interm: 1.248  loss_mask_interm: 0.02986  loss_dice_interm: 0.6084  loss_bbox_interm: 0.0723  loss_giou_interm: 0.5813  time: 1.8315  data_time: 0.1139  lr: 1e-06  max_mem: 6663M\n",
            "[05/20 19:11:26 d2.utils.events]:  eta: 0:13:23  iter: 5239  total_loss: 38.96  loss_ce: 1.002  loss_mask: 0.04034  loss_dice: 0.4284  loss_bbox: 0.0713  loss_giou: 0.2933  loss_ce_dn: 0.2071  loss_mask_dn: 0.04146  loss_dice_dn: 0.5196  loss_bbox_dn: 0.05496  loss_giou_dn: 0.2654  loss_ce_0: 1.306  loss_mask_0: 0.04211  loss_dice_0: 0.6278  loss_bbox_0: 0.1095  loss_giou_0: 0.4712  loss_ce_dn_0: 0.7112  loss_mask_dn_0: 0.2641  loss_dice_dn_0: 2.817  loss_bbox_dn_0: 0.273  loss_giou_dn_0: 0.8524  loss_ce_1: 1.259  loss_mask_1: 0.04178  loss_dice_1: 0.517  loss_bbox_1: 0.1223  loss_giou_1: 0.3685  loss_ce_dn_1: 0.2841  loss_mask_dn_1: 0.04549  loss_dice_dn_1: 0.5235  loss_bbox_dn_1: 0.09965  loss_giou_dn_1: 0.375  loss_ce_2: 1.158  loss_mask_2: 0.03711  loss_dice_2: 0.4618  loss_bbox_2: 0.05285  loss_giou_2: 0.3263  loss_ce_dn_2: 0.2492  loss_mask_dn_2: 0.03934  loss_dice_dn_2: 0.4793  loss_bbox_dn_2: 0.07519  loss_giou_dn_2: 0.2866  loss_ce_3: 1.063  loss_mask_3: 0.03943  loss_dice_3: 0.4751  loss_bbox_3: 0.06627  loss_giou_3: 0.2873  loss_ce_dn_3: 0.2268  loss_mask_dn_3: 0.04115  loss_dice_dn_3: 0.5199  loss_bbox_dn_3: 0.06741  loss_giou_dn_3: 0.273  loss_ce_4: 1.032  loss_mask_4: 0.03883  loss_dice_4: 0.4627  loss_bbox_4: 0.06888  loss_giou_4: 0.2767  loss_ce_dn_4: 0.2025  loss_mask_dn_4: 0.04278  loss_dice_dn_4: 0.4828  loss_bbox_dn_4: 0.06319  loss_giou_dn_4: 0.2694  loss_ce_5: 1.029  loss_mask_5: 0.0398  loss_dice_5: 0.4062  loss_bbox_5: 0.07092  loss_giou_5: 0.2728  loss_ce_dn_5: 0.1971  loss_mask_dn_5: 0.0424  loss_dice_dn_5: 0.462  loss_bbox_dn_5: 0.06226  loss_giou_dn_5: 0.2766  loss_ce_6: 0.9738  loss_mask_6: 0.03907  loss_dice_6: 0.45  loss_bbox_6: 0.07301  loss_giou_6: 0.3125  loss_ce_dn_6: 0.1997  loss_mask_dn_6: 0.04046  loss_dice_dn_6: 0.5218  loss_bbox_dn_6: 0.05497  loss_giou_dn_6: 0.2755  loss_ce_7: 0.9924  loss_mask_7: 0.04233  loss_dice_7: 0.4479  loss_bbox_7: 0.072  loss_giou_7: 0.2931  loss_ce_dn_7: 0.2014  loss_mask_dn_7: 0.04167  loss_dice_dn_7: 0.5151  loss_bbox_dn_7: 0.05397  loss_giou_dn_7: 0.2633  loss_ce_8: 0.9895  loss_mask_8: 0.04279  loss_dice_8: 0.5062  loss_bbox_8: 0.08017  loss_giou_8: 0.2892  loss_ce_dn_8: 0.2093  loss_mask_dn_8: 0.04107  loss_dice_dn_8: 0.4876  loss_bbox_dn_8: 0.05445  loss_giou_dn_8: 0.2623  loss_ce_interm: 1.293  loss_mask_interm: 0.0428  loss_dice_interm: 0.5186  loss_bbox_interm: 0.09468  loss_giou_interm: 0.4451  time: 1.8309  data_time: 0.0526  lr: 1e-06  max_mem: 6663M\n",
            "[05/20 19:12:00 d2.utils.events]:  eta: 0:12:51  iter: 5259  total_loss: 40.81  loss_ce: 0.8709  loss_mask: 0.04501  loss_dice: 0.5017  loss_bbox: 0.04304  loss_giou: 0.2487  loss_ce_dn: 0.1346  loss_mask_dn: 0.04836  loss_dice_dn: 0.5704  loss_bbox_dn: 0.03914  loss_giou_dn: 0.2547  loss_ce_0: 1.215  loss_mask_0: 0.0514  loss_dice_0: 0.723  loss_bbox_0: 0.06605  loss_giou_0: 0.3956  loss_ce_dn_0: 0.8045  loss_mask_dn_0: 0.2568  loss_dice_dn_0: 2.464  loss_bbox_dn_0: 0.3694  loss_giou_dn_0: 0.8498  loss_ce_1: 1.209  loss_mask_1: 0.04517  loss_dice_1: 0.5086  loss_bbox_1: 0.06852  loss_giou_1: 0.3441  loss_ce_dn_1: 0.2874  loss_mask_dn_1: 0.06059  loss_dice_dn_1: 0.6299  loss_bbox_dn_1: 0.09868  loss_giou_dn_1: 0.3624  loss_ce_2: 1.179  loss_mask_2: 0.04858  loss_dice_2: 0.3595  loss_bbox_2: 0.05371  loss_giou_2: 0.3232  loss_ce_dn_2: 0.2621  loss_mask_dn_2: 0.04682  loss_dice_dn_2: 0.5395  loss_bbox_dn_2: 0.06637  loss_giou_dn_2: 0.3027  loss_ce_3: 1.066  loss_mask_3: 0.04599  loss_dice_3: 0.4055  loss_bbox_3: 0.05713  loss_giou_3: 0.3102  loss_ce_dn_3: 0.2174  loss_mask_dn_3: 0.04823  loss_dice_dn_3: 0.5453  loss_bbox_dn_3: 0.05199  loss_giou_dn_3: 0.2879  loss_ce_4: 1.025  loss_mask_4: 0.04848  loss_dice_4: 0.5101  loss_bbox_4: 0.0501  loss_giou_4: 0.315  loss_ce_dn_4: 0.1846  loss_mask_dn_4: 0.0464  loss_dice_dn_4: 0.5337  loss_bbox_dn_4: 0.04639  loss_giou_dn_4: 0.2824  loss_ce_5: 0.9229  loss_mask_5: 0.04473  loss_dice_5: 0.476  loss_bbox_5: 0.04906  loss_giou_5: 0.2986  loss_ce_dn_5: 0.1571  loss_mask_dn_5: 0.04746  loss_dice_dn_5: 0.5639  loss_bbox_dn_5: 0.04352  loss_giou_dn_5: 0.266  loss_ce_6: 0.9593  loss_mask_6: 0.04856  loss_dice_6: 0.4059  loss_bbox_6: 0.04858  loss_giou_6: 0.2891  loss_ce_dn_6: 0.1363  loss_mask_dn_6: 0.04696  loss_dice_dn_6: 0.5539  loss_bbox_dn_6: 0.04311  loss_giou_dn_6: 0.2742  loss_ce_7: 0.9618  loss_mask_7: 0.04593  loss_dice_7: 0.4997  loss_bbox_7: 0.04507  loss_giou_7: 0.2842  loss_ce_dn_7: 0.1383  loss_mask_dn_7: 0.0477  loss_dice_dn_7: 0.5737  loss_bbox_dn_7: 0.04094  loss_giou_dn_7: 0.2623  loss_ce_8: 0.8912  loss_mask_8: 0.05113  loss_dice_8: 0.4498  loss_bbox_8: 0.0487  loss_giou_8: 0.2614  loss_ce_dn_8: 0.1362  loss_mask_dn_8: 0.04801  loss_dice_dn_8: 0.5643  loss_bbox_dn_8: 0.04011  loss_giou_dn_8: 0.2551  loss_ce_interm: 1.211  loss_mask_interm: 0.0504  loss_dice_interm: 0.5642  loss_bbox_interm: 0.09426  loss_giou_interm: 0.3832  time: 1.8303  data_time: 0.0955  lr: 1e-06  max_mem: 6663M\n",
            "[05/20 19:12:35 d2.utils.events]:  eta: 0:12:18  iter: 5279  total_loss: 40.21  loss_ce: 0.8851  loss_mask: 0.07798  loss_dice: 0.4592  loss_bbox: 0.06435  loss_giou: 0.3143  loss_ce_dn: 0.2077  loss_mask_dn: 0.06314  loss_dice_dn: 0.5263  loss_bbox_dn: 0.04886  loss_giou_dn: 0.2209  loss_ce_0: 1.193  loss_mask_0: 0.0702  loss_dice_0: 0.6793  loss_bbox_0: 0.06385  loss_giou_0: 0.4134  loss_ce_dn_0: 0.7264  loss_mask_dn_0: 0.2702  loss_dice_dn_0: 2.377  loss_bbox_dn_0: 0.3696  loss_giou_dn_0: 0.8484  loss_ce_1: 1.185  loss_mask_1: 0.06713  loss_dice_1: 0.5994  loss_bbox_1: 0.06254  loss_giou_1: 0.3153  loss_ce_dn_1: 0.261  loss_mask_dn_1: 0.08449  loss_dice_dn_1: 0.568  loss_bbox_dn_1: 0.1088  loss_giou_dn_1: 0.3241  loss_ce_2: 1.196  loss_mask_2: 0.06482  loss_dice_2: 0.683  loss_bbox_2: 0.06369  loss_giou_2: 0.2866  loss_ce_dn_2: 0.2521  loss_mask_dn_2: 0.07455  loss_dice_dn_2: 0.5157  loss_bbox_dn_2: 0.083  loss_giou_dn_2: 0.2598  loss_ce_3: 1.19  loss_mask_3: 0.07102  loss_dice_3: 0.5452  loss_bbox_3: 0.05974  loss_giou_3: 0.3055  loss_ce_dn_3: 0.2205  loss_mask_dn_3: 0.06339  loss_dice_dn_3: 0.5093  loss_bbox_dn_3: 0.06447  loss_giou_dn_3: 0.2362  loss_ce_4: 1.043  loss_mask_4: 0.08626  loss_dice_4: 0.5014  loss_bbox_4: 0.05812  loss_giou_4: 0.2606  loss_ce_dn_4: 0.222  loss_mask_dn_4: 0.06376  loss_dice_dn_4: 0.5419  loss_bbox_dn_4: 0.05574  loss_giou_dn_4: 0.2396  loss_ce_5: 0.9515  loss_mask_5: 0.07604  loss_dice_5: 0.4753  loss_bbox_5: 0.06873  loss_giou_5: 0.2557  loss_ce_dn_5: 0.2162  loss_mask_dn_5: 0.06718  loss_dice_dn_5: 0.5225  loss_bbox_dn_5: 0.04745  loss_giou_dn_5: 0.2316  loss_ce_6: 0.9108  loss_mask_6: 0.07761  loss_dice_6: 0.5135  loss_bbox_6: 0.05777  loss_giou_6: 0.2815  loss_ce_dn_6: 0.2086  loss_mask_dn_6: 0.0654  loss_dice_dn_6: 0.5389  loss_bbox_dn_6: 0.0495  loss_giou_dn_6: 0.2276  loss_ce_7: 0.9393  loss_mask_7: 0.07366  loss_dice_7: 0.4336  loss_bbox_7: 0.06307  loss_giou_7: 0.2913  loss_ce_dn_7: 0.2154  loss_mask_dn_7: 0.06477  loss_dice_dn_7: 0.5327  loss_bbox_dn_7: 0.05127  loss_giou_dn_7: 0.2247  loss_ce_8: 0.9639  loss_mask_8: 0.07702  loss_dice_8: 0.5025  loss_bbox_8: 0.05874  loss_giou_8: 0.2692  loss_ce_dn_8: 0.2028  loss_mask_dn_8: 0.06368  loss_dice_dn_8: 0.5247  loss_bbox_dn_8: 0.05022  loss_giou_dn_8: 0.2209  loss_ce_interm: 1.216  loss_mask_interm: 0.07945  loss_dice_interm: 0.6135  loss_bbox_interm: 0.1122  loss_giou_interm: 0.3919  time: 1.8297  data_time: 0.0500  lr: 1e-06  max_mem: 6663M\n",
            "[05/20 19:13:09 d2.utils.events]:  eta: 0:11:46  iter: 5299  total_loss: 48.71  loss_ce: 0.8666  loss_mask: 0.02436  loss_dice: 0.5495  loss_bbox: 0.04179  loss_giou: 0.4193  loss_ce_dn: 0.2058  loss_mask_dn: 0.0222  loss_dice_dn: 0.5683  loss_bbox_dn: 0.02748  loss_giou_dn: 0.2989  loss_ce_0: 1.111  loss_mask_0: 0.02449  loss_dice_0: 0.6156  loss_bbox_0: 0.05521  loss_giou_0: 0.5427  loss_ce_dn_0: 0.6917  loss_mask_dn_0: 0.1057  loss_dice_dn_0: 2.28  loss_bbox_dn_0: 0.2024  loss_giou_dn_0: 0.8519  loss_ce_1: 1.127  loss_mask_1: 0.0259  loss_dice_1: 0.5863  loss_bbox_1: 0.04928  loss_giou_1: 0.4593  loss_ce_dn_1: 0.2675  loss_mask_dn_1: 0.02344  loss_dice_dn_1: 0.603  loss_bbox_dn_1: 0.04467  loss_giou_dn_1: 0.3826  loss_ce_2: 0.9678  loss_mask_2: 0.02342  loss_dice_2: 0.6737  loss_bbox_2: 0.04223  loss_giou_2: 0.5111  loss_ce_dn_2: 0.2483  loss_mask_dn_2: 0.02212  loss_dice_dn_2: 0.6253  loss_bbox_dn_2: 0.03172  loss_giou_dn_2: 0.3289  loss_ce_3: 0.941  loss_mask_3: 0.02251  loss_dice_3: 0.9426  loss_bbox_3: 0.04374  loss_giou_3: 0.4625  loss_ce_dn_3: 0.2531  loss_mask_dn_3: 0.02347  loss_dice_dn_3: 0.5925  loss_bbox_dn_3: 0.02802  loss_giou_dn_3: 0.314  loss_ce_4: 0.8721  loss_mask_4: 0.0249  loss_dice_4: 0.7927  loss_bbox_4: 0.04595  loss_giou_4: 0.4344  loss_ce_dn_4: 0.2496  loss_mask_dn_4: 0.02231  loss_dice_dn_4: 0.6104  loss_bbox_dn_4: 0.0289  loss_giou_dn_4: 0.3139  loss_ce_5: 0.887  loss_mask_5: 0.02706  loss_dice_5: 0.5454  loss_bbox_5: 0.05109  loss_giou_5: 0.4494  loss_ce_dn_5: 0.2383  loss_mask_dn_5: 0.0225  loss_dice_dn_5: 0.5911  loss_bbox_dn_5: 0.02787  loss_giou_dn_5: 0.3133  loss_ce_6: 0.8305  loss_mask_6: 0.02102  loss_dice_6: 0.6597  loss_bbox_6: 0.04635  loss_giou_6: 0.4568  loss_ce_dn_6: 0.218  loss_mask_dn_6: 0.02222  loss_dice_dn_6: 0.6154  loss_bbox_dn_6: 0.02752  loss_giou_dn_6: 0.3101  loss_ce_7: 0.8595  loss_mask_7: 0.02114  loss_dice_7: 0.5621  loss_bbox_7: 0.04825  loss_giou_7: 0.4467  loss_ce_dn_7: 0.2091  loss_mask_dn_7: 0.02261  loss_dice_dn_7: 0.5833  loss_bbox_dn_7: 0.02748  loss_giou_dn_7: 0.304  loss_ce_8: 0.8691  loss_mask_8: 0.02207  loss_dice_8: 0.5022  loss_bbox_8: 0.04678  loss_giou_8: 0.451  loss_ce_dn_8: 0.2068  loss_mask_dn_8: 0.02208  loss_dice_dn_8: 0.5439  loss_bbox_dn_8: 0.02748  loss_giou_dn_8: 0.3027  loss_ce_interm: 1.159  loss_mask_interm: 0.02289  loss_dice_interm: 0.5158  loss_bbox_interm: 0.06768  loss_giou_interm: 0.5305  time: 1.8292  data_time: 0.1098  lr: 1e-06  max_mem: 6663M\n",
            "[05/20 19:13:42 d2.utils.events]:  eta: 0:11:14  iter: 5319  total_loss: 36.36  loss_ce: 0.792  loss_mask: 0.03199  loss_dice: 0.526  loss_bbox: 0.06904  loss_giou: 0.2922  loss_ce_dn: 0.1674  loss_mask_dn: 0.02921  loss_dice_dn: 0.5543  loss_bbox_dn: 0.03675  loss_giou_dn: 0.2591  loss_ce_0: 1.281  loss_mask_0: 0.02518  loss_dice_0: 0.4475  loss_bbox_0: 0.06666  loss_giou_0: 0.4148  loss_ce_dn_0: 0.6823  loss_mask_dn_0: 0.1225  loss_dice_dn_0: 2.394  loss_bbox_dn_0: 0.2047  loss_giou_dn_0: 0.8532  loss_ce_1: 1.182  loss_mask_1: 0.0362  loss_dice_1: 0.6132  loss_bbox_1: 0.06065  loss_giou_1: 0.3206  loss_ce_dn_1: 0.24  loss_mask_dn_1: 0.02496  loss_dice_dn_1: 0.6004  loss_bbox_dn_1: 0.05663  loss_giou_dn_1: 0.323  loss_ce_2: 1.041  loss_mask_2: 0.03132  loss_dice_2: 0.5132  loss_bbox_2: 0.06781  loss_giou_2: 0.3317  loss_ce_dn_2: 0.2123  loss_mask_dn_2: 0.02633  loss_dice_dn_2: 0.5609  loss_bbox_dn_2: 0.04624  loss_giou_dn_2: 0.2908  loss_ce_3: 0.9372  loss_mask_3: 0.03161  loss_dice_3: 0.4829  loss_bbox_3: 0.06092  loss_giou_3: 0.29  loss_ce_dn_3: 0.2008  loss_mask_dn_3: 0.02988  loss_dice_dn_3: 0.572  loss_bbox_dn_3: 0.03852  loss_giou_dn_3: 0.2793  loss_ce_4: 0.8913  loss_mask_4: 0.03368  loss_dice_4: 0.5471  loss_bbox_4: 0.05961  loss_giou_4: 0.3  loss_ce_dn_4: 0.1837  loss_mask_dn_4: 0.02976  loss_dice_dn_4: 0.5514  loss_bbox_dn_4: 0.03731  loss_giou_dn_4: 0.2723  loss_ce_5: 0.8182  loss_mask_5: 0.0289  loss_dice_5: 0.5493  loss_bbox_5: 0.06223  loss_giou_5: 0.2955  loss_ce_dn_5: 0.1695  loss_mask_dn_5: 0.02863  loss_dice_dn_5: 0.5369  loss_bbox_dn_5: 0.03644  loss_giou_dn_5: 0.2559  loss_ce_6: 0.8415  loss_mask_6: 0.03255  loss_dice_6: 0.4889  loss_bbox_6: 0.05562  loss_giou_6: 0.2893  loss_ce_dn_6: 0.1621  loss_mask_dn_6: 0.02866  loss_dice_dn_6: 0.5346  loss_bbox_dn_6: 0.03601  loss_giou_dn_6: 0.2527  loss_ce_7: 0.8211  loss_mask_7: 0.02786  loss_dice_7: 0.5547  loss_bbox_7: 0.06881  loss_giou_7: 0.2938  loss_ce_dn_7: 0.1706  loss_mask_dn_7: 0.02883  loss_dice_dn_7: 0.5413  loss_bbox_dn_7: 0.03639  loss_giou_dn_7: 0.263  loss_ce_8: 0.794  loss_mask_8: 0.03492  loss_dice_8: 0.6317  loss_bbox_8: 0.06922  loss_giou_8: 0.3018  loss_ce_dn_8: 0.1697  loss_mask_dn_8: 0.02956  loss_dice_dn_8: 0.5338  loss_bbox_dn_8: 0.03655  loss_giou_dn_8: 0.2663  loss_ce_interm: 1.185  loss_mask_interm: 0.0293  loss_dice_interm: 0.5219  loss_bbox_interm: 0.06923  loss_giou_interm: 0.3675  time: 1.8286  data_time: 0.0812  lr: 1e-06  max_mem: 6663M\n",
            "[05/20 19:14:16 d2.utils.events]:  eta: 0:10:42  iter: 5339  total_loss: 40.56  loss_ce: 0.8983  loss_mask: 0.02912  loss_dice: 0.6415  loss_bbox: 0.06006  loss_giou: 0.4576  loss_ce_dn: 0.1608  loss_mask_dn: 0.02407  loss_dice_dn: 0.6563  loss_bbox_dn: 0.03127  loss_giou_dn: 0.2983  loss_ce_0: 1.243  loss_mask_0: 0.02477  loss_dice_0: 0.404  loss_bbox_0: 0.07093  loss_giou_0: 0.4181  loss_ce_dn_0: 0.7352  loss_mask_dn_0: 0.1509  loss_dice_dn_0: 2.879  loss_bbox_dn_0: 0.2226  loss_giou_dn_0: 0.8566  loss_ce_1: 1.129  loss_mask_1: 0.02717  loss_dice_1: 0.5703  loss_bbox_1: 0.06115  loss_giou_1: 0.4228  loss_ce_dn_1: 0.2916  loss_mask_dn_1: 0.02226  loss_dice_dn_1: 0.6308  loss_bbox_dn_1: 0.05335  loss_giou_dn_1: 0.4019  loss_ce_2: 1.116  loss_mask_2: 0.02782  loss_dice_2: 0.6181  loss_bbox_2: 0.05712  loss_giou_2: 0.4614  loss_ce_dn_2: 0.2284  loss_mask_dn_2: 0.02236  loss_dice_dn_2: 0.6445  loss_bbox_dn_2: 0.03897  loss_giou_dn_2: 0.3487  loss_ce_3: 0.9393  loss_mask_3: 0.0253  loss_dice_3: 0.5591  loss_bbox_3: 0.05775  loss_giou_3: 0.4481  loss_ce_dn_3: 0.1945  loss_mask_dn_3: 0.02364  loss_dice_dn_3: 0.6281  loss_bbox_dn_3: 0.03397  loss_giou_dn_3: 0.3178  loss_ce_4: 1.009  loss_mask_4: 0.02789  loss_dice_4: 0.4447  loss_bbox_4: 0.0595  loss_giou_4: 0.4288  loss_ce_dn_4: 0.1772  loss_mask_dn_4: 0.02409  loss_dice_dn_4: 0.605  loss_bbox_dn_4: 0.03303  loss_giou_dn_4: 0.3082  loss_ce_5: 0.9398  loss_mask_5: 0.02522  loss_dice_5: 0.5521  loss_bbox_5: 0.0632  loss_giou_5: 0.4464  loss_ce_dn_5: 0.1725  loss_mask_dn_5: 0.0233  loss_dice_dn_5: 0.6523  loss_bbox_dn_5: 0.03271  loss_giou_dn_5: 0.2962  loss_ce_6: 0.9918  loss_mask_6: 0.02324  loss_dice_6: 0.4819  loss_bbox_6: 0.06098  loss_giou_6: 0.4149  loss_ce_dn_6: 0.1644  loss_mask_dn_6: 0.02267  loss_dice_dn_6: 0.6246  loss_bbox_dn_6: 0.03182  loss_giou_dn_6: 0.2957  loss_ce_7: 0.8949  loss_mask_7: 0.02511  loss_dice_7: 0.6411  loss_bbox_7: 0.06319  loss_giou_7: 0.4324  loss_ce_dn_7: 0.1592  loss_mask_dn_7: 0.02372  loss_dice_dn_7: 0.6538  loss_bbox_dn_7: 0.03197  loss_giou_dn_7: 0.2949  loss_ce_8: 0.9885  loss_mask_8: 0.02516  loss_dice_8: 0.5924  loss_bbox_8: 0.05752  loss_giou_8: 0.4124  loss_ce_dn_8: 0.1592  loss_mask_dn_8: 0.0238  loss_dice_dn_8: 0.6019  loss_bbox_dn_8: 0.03184  loss_giou_dn_8: 0.2938  loss_ce_interm: 1.22  loss_mask_interm: 0.02429  loss_dice_interm: 0.5453  loss_bbox_interm: 0.1102  loss_giou_interm: 0.516  time: 1.8280  data_time: 0.0818  lr: 1e-06  max_mem: 6663M\n",
            "[05/20 19:14:50 d2.utils.events]:  eta: 0:10:11  iter: 5359  total_loss: 44.71  loss_ce: 0.9543  loss_mask: 0.04837  loss_dice: 0.5806  loss_bbox: 0.06193  loss_giou: 0.2996  loss_ce_dn: 0.1612  loss_mask_dn: 0.04466  loss_dice_dn: 0.6672  loss_bbox_dn: 0.04975  loss_giou_dn: 0.2801  loss_ce_0: 1.403  loss_mask_0: 0.05433  loss_dice_0: 0.8188  loss_bbox_0: 0.09124  loss_giou_0: 0.4705  loss_ce_dn_0: 0.6907  loss_mask_dn_0: 0.1349  loss_dice_dn_0: 2.624  loss_bbox_dn_0: 0.3185  loss_giou_dn_0: 0.8514  loss_ce_1: 1.34  loss_mask_1: 0.05239  loss_dice_1: 0.6882  loss_bbox_1: 0.08902  loss_giou_1: 0.3326  loss_ce_dn_1: 0.2588  loss_mask_dn_1: 0.04601  loss_dice_dn_1: 0.6826  loss_bbox_dn_1: 0.07486  loss_giou_dn_1: 0.391  loss_ce_2: 1.148  loss_mask_2: 0.05162  loss_dice_2: 0.7119  loss_bbox_2: 0.07099  loss_giou_2: 0.3522  loss_ce_dn_2: 0.2278  loss_mask_dn_2: 0.04305  loss_dice_dn_2: 0.6443  loss_bbox_dn_2: 0.05945  loss_giou_dn_2: 0.3446  loss_ce_3: 1.102  loss_mask_3: 0.05184  loss_dice_3: 0.5328  loss_bbox_3: 0.06548  loss_giou_3: 0.3207  loss_ce_dn_3: 0.2001  loss_mask_dn_3: 0.0463  loss_dice_dn_3: 0.6412  loss_bbox_dn_3: 0.05307  loss_giou_dn_3: 0.3133  loss_ce_4: 1.047  loss_mask_4: 0.04737  loss_dice_4: 0.5884  loss_bbox_4: 0.06817  loss_giou_4: 0.3105  loss_ce_dn_4: 0.179  loss_mask_dn_4: 0.04471  loss_dice_dn_4: 0.6148  loss_bbox_dn_4: 0.05103  loss_giou_dn_4: 0.2998  loss_ce_5: 1.054  loss_mask_5: 0.04666  loss_dice_5: 0.6722  loss_bbox_5: 0.06074  loss_giou_5: 0.3164  loss_ce_dn_5: 0.1681  loss_mask_dn_5: 0.04413  loss_dice_dn_5: 0.6396  loss_bbox_dn_5: 0.05298  loss_giou_dn_5: 0.2965  loss_ce_6: 0.9869  loss_mask_6: 0.05293  loss_dice_6: 0.7102  loss_bbox_6: 0.06537  loss_giou_6: 0.3086  loss_ce_dn_6: 0.1654  loss_mask_dn_6: 0.04197  loss_dice_dn_6: 0.6168  loss_bbox_dn_6: 0.0528  loss_giou_dn_6: 0.2925  loss_ce_7: 0.9348  loss_mask_7: 0.05606  loss_dice_7: 0.6547  loss_bbox_7: 0.06267  loss_giou_7: 0.3011  loss_ce_dn_7: 0.1627  loss_mask_dn_7: 0.04231  loss_dice_dn_7: 0.6314  loss_bbox_dn_7: 0.05097  loss_giou_dn_7: 0.2849  loss_ce_8: 0.9702  loss_mask_8: 0.04842  loss_dice_8: 0.6646  loss_bbox_8: 0.06254  loss_giou_8: 0.3022  loss_ce_dn_8: 0.1603  loss_mask_dn_8: 0.04483  loss_dice_dn_8: 0.6606  loss_bbox_dn_8: 0.05126  loss_giou_dn_8: 0.2839  loss_ce_interm: 1.233  loss_mask_interm: 0.06708  loss_dice_interm: 0.7261  loss_bbox_interm: 0.09716  loss_giou_interm: 0.4006  time: 1.8275  data_time: 0.0826  lr: 1e-06  max_mem: 6663M\n",
            "[05/20 19:15:23 d2.utils.events]:  eta: 0:09:39  iter: 5379  total_loss: 44.07  loss_ce: 1.059  loss_mask: 0.06368  loss_dice: 0.691  loss_bbox: 0.05538  loss_giou: 0.3561  loss_ce_dn: 0.1863  loss_mask_dn: 0.05413  loss_dice_dn: 0.5907  loss_bbox_dn: 0.04945  loss_giou_dn: 0.2931  loss_ce_0: 1.33  loss_mask_0: 0.0538  loss_dice_0: 0.6697  loss_bbox_0: 0.07459  loss_giou_0: 0.392  loss_ce_dn_0: 0.7378  loss_mask_dn_0: 0.1938  loss_dice_dn_0: 2.741  loss_bbox_dn_0: 0.2768  loss_giou_dn_0: 0.8595  loss_ce_1: 1.307  loss_mask_1: 0.06042  loss_dice_1: 0.6587  loss_bbox_1: 0.06398  loss_giou_1: 0.3656  loss_ce_dn_1: 0.3026  loss_mask_dn_1: 0.05289  loss_dice_dn_1: 0.645  loss_bbox_dn_1: 0.07558  loss_giou_dn_1: 0.3804  loss_ce_2: 1.252  loss_mask_2: 0.05989  loss_dice_2: 0.7045  loss_bbox_2: 0.08247  loss_giou_2: 0.3574  loss_ce_dn_2: 0.2328  loss_mask_dn_2: 0.04748  loss_dice_dn_2: 0.5885  loss_bbox_dn_2: 0.06796  loss_giou_dn_2: 0.3328  loss_ce_3: 1.108  loss_mask_3: 0.06729  loss_dice_3: 0.5457  loss_bbox_3: 0.08378  loss_giou_3: 0.3772  loss_ce_dn_3: 0.228  loss_mask_dn_3: 0.04813  loss_dice_dn_3: 0.5947  loss_bbox_dn_3: 0.05613  loss_giou_dn_3: 0.3115  loss_ce_4: 1.144  loss_mask_4: 0.05272  loss_dice_4: 0.5265  loss_bbox_4: 0.06816  loss_giou_4: 0.38  loss_ce_dn_4: 0.2105  loss_mask_dn_4: 0.0465  loss_dice_dn_4: 0.6218  loss_bbox_dn_4: 0.04816  loss_giou_dn_4: 0.3062  loss_ce_5: 1.058  loss_mask_5: 0.06788  loss_dice_5: 0.565  loss_bbox_5: 0.06831  loss_giou_5: 0.3339  loss_ce_dn_5: 0.1953  loss_mask_dn_5: 0.04921  loss_dice_dn_5: 0.6177  loss_bbox_dn_5: 0.05095  loss_giou_dn_5: 0.3013  loss_ce_6: 0.9808  loss_mask_6: 0.07271  loss_dice_6: 0.5584  loss_bbox_6: 0.06435  loss_giou_6: 0.3743  loss_ce_dn_6: 0.1879  loss_mask_dn_6: 0.04869  loss_dice_dn_6: 0.6095  loss_bbox_dn_6: 0.04982  loss_giou_dn_6: 0.3029  loss_ce_7: 1.096  loss_mask_7: 0.07126  loss_dice_7: 0.5622  loss_bbox_7: 0.0554  loss_giou_7: 0.3048  loss_ce_dn_7: 0.1864  loss_mask_dn_7: 0.05108  loss_dice_dn_7: 0.6146  loss_bbox_dn_7: 0.04977  loss_giou_dn_7: 0.299  loss_ce_8: 1.078  loss_mask_8: 0.0609  loss_dice_8: 0.6884  loss_bbox_8: 0.0545  loss_giou_8: 0.3113  loss_ce_dn_8: 0.185  loss_mask_dn_8: 0.05116  loss_dice_dn_8: 0.6229  loss_bbox_dn_8: 0.04836  loss_giou_dn_8: 0.297  loss_ce_interm: 1.252  loss_mask_interm: 0.06315  loss_dice_interm: 0.6851  loss_bbox_interm: 0.117  loss_giou_interm: 0.4765  time: 1.8269  data_time: 0.0652  lr: 1e-06  max_mem: 6663M\n",
            "[05/20 19:15:58 d2.utils.events]:  eta: 0:09:08  iter: 5399  total_loss: 29.88  loss_ce: 0.7381  loss_mask: 0.0424  loss_dice: 0.3734  loss_bbox: 0.0381  loss_giou: 0.1536  loss_ce_dn: 0.1465  loss_mask_dn: 0.0354  loss_dice_dn: 0.4188  loss_bbox_dn: 0.04516  loss_giou_dn: 0.1688  loss_ce_0: 0.9246  loss_mask_0: 0.04458  loss_dice_0: 0.3377  loss_bbox_0: 0.04643  loss_giou_0: 0.2517  loss_ce_dn_0: 0.6769  loss_mask_dn_0: 0.2712  loss_dice_dn_0: 2.417  loss_bbox_dn_0: 0.4638  loss_giou_dn_0: 0.8496  loss_ce_1: 0.939  loss_mask_1: 0.04378  loss_dice_1: 0.4137  loss_bbox_1: 0.03893  loss_giou_1: 0.1895  loss_ce_dn_1: 0.2257  loss_mask_dn_1: 0.0432  loss_dice_dn_1: 0.4222  loss_bbox_dn_1: 0.08015  loss_giou_dn_1: 0.2629  loss_ce_2: 0.9485  loss_mask_2: 0.04256  loss_dice_2: 0.4026  loss_bbox_2: 0.04121  loss_giou_2: 0.1756  loss_ce_dn_2: 0.2008  loss_mask_dn_2: 0.03659  loss_dice_dn_2: 0.4481  loss_bbox_dn_2: 0.05735  loss_giou_dn_2: 0.2082  loss_ce_3: 0.7869  loss_mask_3: 0.04635  loss_dice_3: 0.4604  loss_bbox_3: 0.04501  loss_giou_3: 0.1426  loss_ce_dn_3: 0.1753  loss_mask_dn_3: 0.0372  loss_dice_dn_3: 0.4553  loss_bbox_dn_3: 0.04971  loss_giou_dn_3: 0.1771  loss_ce_4: 0.712  loss_mask_4: 0.04306  loss_dice_4: 0.3821  loss_bbox_4: 0.04116  loss_giou_4: 0.1493  loss_ce_dn_4: 0.1745  loss_mask_dn_4: 0.03462  loss_dice_dn_4: 0.4216  loss_bbox_dn_4: 0.04765  loss_giou_dn_4: 0.1656  loss_ce_5: 0.7277  loss_mask_5: 0.04715  loss_dice_5: 0.4023  loss_bbox_5: 0.04617  loss_giou_5: 0.142  loss_ce_dn_5: 0.1594  loss_mask_dn_5: 0.03497  loss_dice_dn_5: 0.4029  loss_bbox_dn_5: 0.04611  loss_giou_dn_5: 0.1659  loss_ce_6: 0.7443  loss_mask_6: 0.03812  loss_dice_6: 0.442  loss_bbox_6: 0.04199  loss_giou_6: 0.16  loss_ce_dn_6: 0.1555  loss_mask_dn_6: 0.03472  loss_dice_dn_6: 0.4083  loss_bbox_dn_6: 0.04614  loss_giou_dn_6: 0.1694  loss_ce_7: 0.7451  loss_mask_7: 0.04057  loss_dice_7: 0.3968  loss_bbox_7: 0.03858  loss_giou_7: 0.1487  loss_ce_dn_7: 0.1571  loss_mask_dn_7: 0.03533  loss_dice_dn_7: 0.4201  loss_bbox_dn_7: 0.04599  loss_giou_dn_7: 0.1673  loss_ce_8: 0.7375  loss_mask_8: 0.0421  loss_dice_8: 0.4257  loss_bbox_8: 0.03879  loss_giou_8: 0.1483  loss_ce_dn_8: 0.1466  loss_mask_dn_8: 0.03521  loss_dice_dn_8: 0.41  loss_bbox_dn_8: 0.04493  loss_giou_dn_8: 0.1682  loss_ce_interm: 0.915  loss_mask_interm: 0.04238  loss_dice_interm: 0.3836  loss_bbox_interm: 0.07272  loss_giou_interm: 0.2567  time: 1.8265  data_time: 0.0799  lr: 1e-06  max_mem: 6663M\n",
            "[05/20 19:16:32 d2.utils.events]:  eta: 0:08:36  iter: 5419  total_loss: 37.4  loss_ce: 0.7896  loss_mask: 0.04683  loss_dice: 0.3888  loss_bbox: 0.0926  loss_giou: 0.2438  loss_ce_dn: 0.1738  loss_mask_dn: 0.04453  loss_dice_dn: 0.4395  loss_bbox_dn: 0.04741  loss_giou_dn: 0.2211  loss_ce_0: 1.192  loss_mask_0: 0.04671  loss_dice_0: 0.4515  loss_bbox_0: 0.1005  loss_giou_0: 0.3352  loss_ce_dn_0: 0.7323  loss_mask_dn_0: 0.2786  loss_dice_dn_0: 2.438  loss_bbox_dn_0: 0.3994  loss_giou_dn_0: 0.8588  loss_ce_1: 1.072  loss_mask_1: 0.03927  loss_dice_1: 0.4869  loss_bbox_1: 0.08903  loss_giou_1: 0.3239  loss_ce_dn_1: 0.2637  loss_mask_dn_1: 0.05027  loss_dice_dn_1: 0.4528  loss_bbox_dn_1: 0.08842  loss_giou_dn_1: 0.3281  loss_ce_2: 1.067  loss_mask_2: 0.03409  loss_dice_2: 0.4528  loss_bbox_2: 0.09013  loss_giou_2: 0.2749  loss_ce_dn_2: 0.2301  loss_mask_dn_2: 0.04623  loss_dice_dn_2: 0.4498  loss_bbox_dn_2: 0.06286  loss_giou_dn_2: 0.2564  loss_ce_3: 0.9309  loss_mask_3: 0.05027  loss_dice_3: 0.5538  loss_bbox_3: 0.0833  loss_giou_3: 0.2528  loss_ce_dn_3: 0.1953  loss_mask_dn_3: 0.04993  loss_dice_dn_3: 0.4293  loss_bbox_dn_3: 0.05375  loss_giou_dn_3: 0.2312  loss_ce_4: 0.9264  loss_mask_4: 0.04695  loss_dice_4: 0.482  loss_bbox_4: 0.0852  loss_giou_4: 0.2544  loss_ce_dn_4: 0.187  loss_mask_dn_4: 0.04551  loss_dice_dn_4: 0.4288  loss_bbox_dn_4: 0.05357  loss_giou_dn_4: 0.2237  loss_ce_5: 0.9083  loss_mask_5: 0.04271  loss_dice_5: 0.4424  loss_bbox_5: 0.08804  loss_giou_5: 0.2506  loss_ce_dn_5: 0.1882  loss_mask_dn_5: 0.04375  loss_dice_dn_5: 0.4044  loss_bbox_dn_5: 0.05066  loss_giou_dn_5: 0.227  loss_ce_6: 0.8361  loss_mask_6: 0.04193  loss_dice_6: 0.4279  loss_bbox_6: 0.08739  loss_giou_6: 0.2449  loss_ce_dn_6: 0.1845  loss_mask_dn_6: 0.04234  loss_dice_dn_6: 0.4111  loss_bbox_dn_6: 0.04921  loss_giou_dn_6: 0.2206  loss_ce_7: 0.8128  loss_mask_7: 0.04292  loss_dice_7: 0.4991  loss_bbox_7: 0.09065  loss_giou_7: 0.2424  loss_ce_dn_7: 0.1771  loss_mask_dn_7: 0.04315  loss_dice_dn_7: 0.4134  loss_bbox_dn_7: 0.04807  loss_giou_dn_7: 0.2205  loss_ce_8: 0.7955  loss_mask_8: 0.04919  loss_dice_8: 0.4322  loss_bbox_8: 0.09352  loss_giou_8: 0.2406  loss_ce_dn_8: 0.1701  loss_mask_dn_8: 0.04487  loss_dice_dn_8: 0.4185  loss_bbox_dn_8: 0.04851  loss_giou_dn_8: 0.2255  loss_ce_interm: 1.211  loss_mask_interm: 0.04578  loss_dice_interm: 0.5263  loss_bbox_interm: 0.1127  loss_giou_interm: 0.3869  time: 1.8261  data_time: 0.0853  lr: 1e-06  max_mem: 6663M\n",
            "[05/20 19:17:05 d2.utils.events]:  eta: 0:08:04  iter: 5439  total_loss: 40.41  loss_ce: 1.084  loss_mask: 0.01841  loss_dice: 0.5016  loss_bbox: 0.03716  loss_giou: 0.4162  loss_ce_dn: 0.1394  loss_mask_dn: 0.01927  loss_dice_dn: 0.5579  loss_bbox_dn: 0.02649  loss_giou_dn: 0.296  loss_ce_0: 1.24  loss_mask_0: 0.02416  loss_dice_0: 0.5207  loss_bbox_0: 0.05024  loss_giou_0: 0.5465  loss_ce_dn_0: 0.8064  loss_mask_dn_0: 0.0777  loss_dice_dn_0: 2.264  loss_bbox_dn_0: 0.2038  loss_giou_dn_0: 0.854  loss_ce_1: 1.284  loss_mask_1: 0.03052  loss_dice_1: 0.6059  loss_bbox_1: 0.04741  loss_giou_1: 0.4158  loss_ce_dn_1: 0.257  loss_mask_dn_1: 0.02212  loss_dice_dn_1: 0.5881  loss_bbox_dn_1: 0.05141  loss_giou_dn_1: 0.3668  loss_ce_2: 1.167  loss_mask_2: 0.02327  loss_dice_2: 0.5336  loss_bbox_2: 0.04165  loss_giou_2: 0.4156  loss_ce_dn_2: 0.2198  loss_mask_dn_2: 0.02064  loss_dice_dn_2: 0.5153  loss_bbox_dn_2: 0.03772  loss_giou_dn_2: 0.3271  loss_ce_3: 1.177  loss_mask_3: 0.02371  loss_dice_3: 0.6007  loss_bbox_3: 0.03823  loss_giou_3: 0.3893  loss_ce_dn_3: 0.1894  loss_mask_dn_3: 0.02163  loss_dice_dn_3: 0.5413  loss_bbox_dn_3: 0.02937  loss_giou_dn_3: 0.2977  loss_ce_4: 1.08  loss_mask_4: 0.02296  loss_dice_4: 0.5454  loss_bbox_4: 0.04025  loss_giou_4: 0.3877  loss_ce_dn_4: 0.1653  loss_mask_dn_4: 0.02057  loss_dice_dn_4: 0.5605  loss_bbox_dn_4: 0.02851  loss_giou_dn_4: 0.3003  loss_ce_5: 1.082  loss_mask_5: 0.01965  loss_dice_5: 0.6071  loss_bbox_5: 0.03791  loss_giou_5: 0.4607  loss_ce_dn_5: 0.1495  loss_mask_dn_5: 0.01925  loss_dice_dn_5: 0.5737  loss_bbox_dn_5: 0.02743  loss_giou_dn_5: 0.2897  loss_ce_6: 1.071  loss_mask_6: 0.02063  loss_dice_6: 0.5385  loss_bbox_6: 0.03879  loss_giou_6: 0.4169  loss_ce_dn_6: 0.135  loss_mask_dn_6: 0.01995  loss_dice_dn_6: 0.565  loss_bbox_dn_6: 0.027  loss_giou_dn_6: 0.2851  loss_ce_7: 1.084  loss_mask_7: 0.017  loss_dice_7: 0.4817  loss_bbox_7: 0.03488  loss_giou_7: 0.3599  loss_ce_dn_7: 0.1341  loss_mask_dn_7: 0.02014  loss_dice_dn_7: 0.5453  loss_bbox_dn_7: 0.02672  loss_giou_dn_7: 0.2872  loss_ce_8: 1.129  loss_mask_8: 0.01913  loss_dice_8: 0.5909  loss_bbox_8: 0.03545  loss_giou_8: 0.3543  loss_ce_dn_8: 0.138  loss_mask_dn_8: 0.02041  loss_dice_dn_8: 0.5747  loss_bbox_dn_8: 0.02711  loss_giou_dn_8: 0.2965  loss_ce_interm: 1.37  loss_mask_interm: 0.02873  loss_dice_interm: 0.497  loss_bbox_interm: 0.07448  loss_giou_interm: 0.4679  time: 1.8253  data_time: 0.0622  lr: 1e-06  max_mem: 6663M\n",
            "[05/20 19:17:38 d2.utils.events]:  eta: 0:07:32  iter: 5459  total_loss: 45.64  loss_ce: 1.179  loss_mask: 0.02779  loss_dice: 0.7196  loss_bbox: 0.0723  loss_giou: 0.4369  loss_ce_dn: 0.2028  loss_mask_dn: 0.02383  loss_dice_dn: 0.6712  loss_bbox_dn: 0.03658  loss_giou_dn: 0.3473  loss_ce_0: 1.366  loss_mask_0: 0.03398  loss_dice_0: 0.7653  loss_bbox_0: 0.1086  loss_giou_0: 0.6064  loss_ce_dn_0: 0.7078  loss_mask_dn_0: 0.1703  loss_dice_dn_0: 3.33  loss_bbox_dn_0: 0.2345  loss_giou_dn_0: 0.8598  loss_ce_1: 1.44  loss_mask_1: 0.02889  loss_dice_1: 0.6446  loss_bbox_1: 0.09235  loss_giou_1: 0.5128  loss_ce_dn_1: 0.2699  loss_mask_dn_1: 0.02356  loss_dice_dn_1: 0.7041  loss_bbox_dn_1: 0.05506  loss_giou_dn_1: 0.4088  loss_ce_2: 1.383  loss_mask_2: 0.02916  loss_dice_2: 0.793  loss_bbox_2: 0.07401  loss_giou_2: 0.5002  loss_ce_dn_2: 0.2794  loss_mask_dn_2: 0.02271  loss_dice_dn_2: 0.7021  loss_bbox_dn_2: 0.04407  loss_giou_dn_2: 0.3697  loss_ce_3: 1.372  loss_mask_3: 0.02849  loss_dice_3: 0.6794  loss_bbox_3: 0.0809  loss_giou_3: 0.4195  loss_ce_dn_3: 0.2461  loss_mask_dn_3: 0.02397  loss_dice_dn_3: 0.7156  loss_bbox_dn_3: 0.03731  loss_giou_dn_3: 0.3407  loss_ce_4: 1.349  loss_mask_4: 0.02859  loss_dice_4: 0.7745  loss_bbox_4: 0.08147  loss_giou_4: 0.4328  loss_ce_dn_4: 0.2453  loss_mask_dn_4: 0.02316  loss_dice_dn_4: 0.7105  loss_bbox_dn_4: 0.03759  loss_giou_dn_4: 0.3493  loss_ce_5: 1.279  loss_mask_5: 0.02274  loss_dice_5: 0.6849  loss_bbox_5: 0.09217  loss_giou_5: 0.4254  loss_ce_dn_5: 0.2324  loss_mask_dn_5: 0.02306  loss_dice_dn_5: 0.7088  loss_bbox_dn_5: 0.03496  loss_giou_dn_5: 0.3401  loss_ce_6: 1.183  loss_mask_6: 0.02372  loss_dice_6: 0.8509  loss_bbox_6: 0.08451  loss_giou_6: 0.4739  loss_ce_dn_6: 0.2137  loss_mask_dn_6: 0.02397  loss_dice_dn_6: 0.6904  loss_bbox_dn_6: 0.03455  loss_giou_dn_6: 0.3432  loss_ce_7: 1.181  loss_mask_7: 0.03062  loss_dice_7: 0.7679  loss_bbox_7: 0.07888  loss_giou_7: 0.4524  loss_ce_dn_7: 0.2099  loss_mask_dn_7: 0.02394  loss_dice_dn_7: 0.6986  loss_bbox_dn_7: 0.03488  loss_giou_dn_7: 0.3478  loss_ce_8: 1.182  loss_mask_8: 0.02331  loss_dice_8: 0.7539  loss_bbox_8: 0.07719  loss_giou_8: 0.4435  loss_ce_dn_8: 0.2019  loss_mask_dn_8: 0.02343  loss_dice_dn_8: 0.6633  loss_bbox_dn_8: 0.03621  loss_giou_dn_8: 0.3484  loss_ce_interm: 1.404  loss_mask_interm: 0.02888  loss_dice_interm: 0.8038  loss_bbox_interm: 0.08995  loss_giou_interm: 0.6944  time: 1.8248  data_time: 0.1034  lr: 1e-06  max_mem: 6663M\n",
            "[05/20 19:18:12 d2.utils.events]:  eta: 0:07:00  iter: 5479  total_loss: 46.8  loss_ce: 1.062  loss_mask: 0.05791  loss_dice: 0.7926  loss_bbox: 0.07039  loss_giou: 0.3641  loss_ce_dn: 0.2246  loss_mask_dn: 0.05629  loss_dice_dn: 0.6604  loss_bbox_dn: 0.04916  loss_giou_dn: 0.31  loss_ce_0: 1.3  loss_mask_0: 0.06932  loss_dice_0: 0.7818  loss_bbox_0: 0.1019  loss_giou_0: 0.5261  loss_ce_dn_0: 0.6926  loss_mask_dn_0: 0.3999  loss_dice_dn_0: 2.348  loss_bbox_dn_0: 0.3608  loss_giou_dn_0: 0.8589  loss_ce_1: 1.23  loss_mask_1: 0.06173  loss_dice_1: 0.6232  loss_bbox_1: 0.0804  loss_giou_1: 0.3347  loss_ce_dn_1: 0.2892  loss_mask_dn_1: 0.05125  loss_dice_dn_1: 0.7212  loss_bbox_dn_1: 0.09936  loss_giou_dn_1: 0.3863  loss_ce_2: 1.216  loss_mask_2: 0.06949  loss_dice_2: 0.7124  loss_bbox_2: 0.09699  loss_giou_2: 0.4144  loss_ce_dn_2: 0.2266  loss_mask_dn_2: 0.05487  loss_dice_dn_2: 0.7423  loss_bbox_dn_2: 0.07666  loss_giou_dn_2: 0.3507  loss_ce_3: 1.233  loss_mask_3: 0.05248  loss_dice_3: 0.6048  loss_bbox_3: 0.1009  loss_giou_3: 0.4307  loss_ce_dn_3: 0.2262  loss_mask_dn_3: 0.05656  loss_dice_dn_3: 0.7247  loss_bbox_dn_3: 0.05557  loss_giou_dn_3: 0.3261  loss_ce_4: 1.096  loss_mask_4: 0.0654  loss_dice_4: 0.5953  loss_bbox_4: 0.0779  loss_giou_4: 0.396  loss_ce_dn_4: 0.2309  loss_mask_dn_4: 0.0527  loss_dice_dn_4: 0.6855  loss_bbox_dn_4: 0.0586  loss_giou_dn_4: 0.3127  loss_ce_5: 1.075  loss_mask_5: 0.05207  loss_dice_5: 0.7087  loss_bbox_5: 0.07783  loss_giou_5: 0.3735  loss_ce_dn_5: 0.219  loss_mask_dn_5: 0.05008  loss_dice_dn_5: 0.6573  loss_bbox_dn_5: 0.06083  loss_giou_dn_5: 0.3139  loss_ce_6: 1.067  loss_mask_6: 0.05374  loss_dice_6: 0.708  loss_bbox_6: 0.07346  loss_giou_6: 0.369  loss_ce_dn_6: 0.222  loss_mask_dn_6: 0.04986  loss_dice_dn_6: 0.6578  loss_bbox_dn_6: 0.05587  loss_giou_dn_6: 0.3168  loss_ce_7: 1.094  loss_mask_7: 0.05452  loss_dice_7: 0.7059  loss_bbox_7: 0.07052  loss_giou_7: 0.3606  loss_ce_dn_7: 0.2295  loss_mask_dn_7: 0.05266  loss_dice_dn_7: 0.6531  loss_bbox_dn_7: 0.04871  loss_giou_dn_7: 0.314  loss_ce_8: 1.067  loss_mask_8: 0.05688  loss_dice_8: 0.6478  loss_bbox_8: 0.07113  loss_giou_8: 0.3641  loss_ce_dn_8: 0.229  loss_mask_dn_8: 0.05511  loss_dice_dn_8: 0.6841  loss_bbox_dn_8: 0.04907  loss_giou_dn_8: 0.3118  loss_ce_interm: 1.319  loss_mask_interm: 0.05819  loss_dice_interm: 0.5848  loss_bbox_interm: 0.1244  loss_giou_interm: 0.4956  time: 1.8243  data_time: 0.0928  lr: 1e-06  max_mem: 6663M\n",
            "[05/20 19:18:47 d2.data.datasets.coco]: Loaded 150 images in COCO format from /content/TACO-expl/data/annotations_off_0_resval.json\n",
            "[05/20 19:18:47 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "[05/20 19:18:47 d2.data.common]: Serializing 150 elements to byte tensors and concatenating them all ...\n",
            "[05/20 19:18:47 d2.data.common]: Serialized dataset takes 0.21 MiB\n",
            "WARNING [05/20 19:18:47 d2.evaluation.coco_evaluation]: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
            "[05/20 19:18:47 d2.evaluation.evaluator]: Start inference on 150 batches\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1066, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1066, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1066, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1066])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 19:18:55 d2.evaluation.evaluator]: Inference done 11/150. Dataloading: 0.0018 s/iter. Inference: 0.2788 s/iter. Eval: 0.4399 s/iter. Total: 0.7204 s/iter. ETA=0:01:40\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 608])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 608])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 608])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1200])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 750])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 19:19:00 d2.evaluation.evaluator]: Inference done 17/150. Dataloading: 0.0035 s/iter. Inference: 0.2937 s/iter. Eval: 0.4981 s/iter. Total: 0.7955 s/iter. ETA=0:01:45\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 750])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 19:19:05 d2.evaluation.evaluator]: Inference done 23/150. Dataloading: 0.0033 s/iter. Inference: 0.3017 s/iter. Eval: 0.5144 s/iter. Total: 0.8199 s/iter. ETA=0:01:44\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([750, 1333])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 750])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([750, 1333])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 750])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 19:19:11 d2.evaluation.evaluator]: Inference done 30/150. Dataloading: 0.0031 s/iter. Inference: 0.3028 s/iter. Eval: 0.5094 s/iter. Total: 0.8157 s/iter. ETA=0:01:37\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 19:19:16 d2.evaluation.evaluator]: Inference done 36/150. Dataloading: 0.0038 s/iter. Inference: 0.3024 s/iter. Eval: 0.5128 s/iter. Total: 0.8195 s/iter. ETA=0:01:33\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 750])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 19:19:21 d2.evaluation.evaluator]: Inference done 42/150. Dataloading: 0.0039 s/iter. Inference: 0.3064 s/iter. Eval: 0.5229 s/iter. Total: 0.8336 s/iter. ETA=0:01:30\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 19:19:27 d2.evaluation.evaluator]: Inference done 49/150. Dataloading: 0.0039 s/iter. Inference: 0.3020 s/iter. Eval: 0.5110 s/iter. Total: 0.8173 s/iter. ETA=0:01:22\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 19:19:32 d2.evaluation.evaluator]: Inference done 56/150. Dataloading: 0.0042 s/iter. Inference: 0.3004 s/iter. Eval: 0.5108 s/iter. Total: 0.8157 s/iter. ETA=0:01:16\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 19:19:38 d2.evaluation.evaluator]: Inference done 62/150. Dataloading: 0.0050 s/iter. Inference: 0.3027 s/iter. Eval: 0.5194 s/iter. Total: 0.8276 s/iter. ETA=0:01:12\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 19:19:43 d2.evaluation.evaluator]: Inference done 69/150. Dataloading: 0.0049 s/iter. Inference: 0.2999 s/iter. Eval: 0.5116 s/iter. Total: 0.8169 s/iter. ETA=0:01:06\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 19:19:48 d2.evaluation.evaluator]: Inference done 76/150. Dataloading: 0.0046 s/iter. Inference: 0.2978 s/iter. Eval: 0.5076 s/iter. Total: 0.8105 s/iter. ETA=0:00:59\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([852, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 19:19:54 d2.evaluation.evaluator]: Inference done 82/150. Dataloading: 0.0049 s/iter. Inference: 0.2996 s/iter. Eval: 0.5148 s/iter. Total: 0.8198 s/iter. ETA=0:00:55\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 19:19:59 d2.evaluation.evaluator]: Inference done 89/150. Dataloading: 0.0048 s/iter. Inference: 0.2976 s/iter. Eval: 0.5095 s/iter. Total: 0.8125 s/iter. ETA=0:00:49\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 19:20:04 d2.evaluation.evaluator]: Inference done 96/150. Dataloading: 0.0047 s/iter. Inference: 0.2959 s/iter. Eval: 0.5053 s/iter. Total: 0.8064 s/iter. ETA=0:00:43\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 19:20:10 d2.evaluation.evaluator]: Inference done 102/150. Dataloading: 0.0049 s/iter. Inference: 0.2978 s/iter. Eval: 0.5124 s/iter. Total: 0.8156 s/iter. ETA=0:00:39\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 19:20:15 d2.evaluation.evaluator]: Inference done 109/150. Dataloading: 0.0050 s/iter. Inference: 0.2973 s/iter. Eval: 0.5099 s/iter. Total: 0.8127 s/iter. ETA=0:00:33\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 19:20:20 d2.evaluation.evaluator]: Inference done 116/150. Dataloading: 0.0048 s/iter. Inference: 0.2958 s/iter. Eval: 0.5066 s/iter. Total: 0.8077 s/iter. ETA=0:00:27\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 19:20:26 d2.evaluation.evaluator]: Inference done 122/150. Dataloading: 0.0050 s/iter. Inference: 0.2966 s/iter. Eval: 0.5109 s/iter. Total: 0.8130 s/iter. ETA=0:00:22\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 19:20:31 d2.evaluation.evaluator]: Inference done 129/150. Dataloading: 0.0049 s/iter. Inference: 0.2960 s/iter. Eval: 0.5099 s/iter. Total: 0.8114 s/iter. ETA=0:00:17\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 750])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 19:20:36 d2.evaluation.evaluator]: Inference done 136/150. Dataloading: 0.0048 s/iter. Inference: 0.2949 s/iter. Eval: 0.5072 s/iter. Total: 0.8074 s/iter. ETA=0:00:11\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 750])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 750])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 19:20:42 d2.evaluation.evaluator]: Inference done 142/150. Dataloading: 0.0048 s/iter. Inference: 0.2957 s/iter. Eval: 0.5121 s/iter. Total: 0.8131 s/iter. ETA=0:00:06\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 608])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 608])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 608])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 19:20:48 d2.evaluation.evaluator]: Inference done 149/150. Dataloading: 0.0048 s/iter. Inference: 0.2954 s/iter. Eval: 0.5111 s/iter. Total: 0.8118 s/iter. ETA=0:00:00\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 608])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 19:20:48 d2.evaluation.evaluator]: Total inference time: 0:01:57.657257 (0.811429 s / iter per device, on 1 devices)\n",
            "[05/20 19:20:48 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:42 (0.295244 s / iter per device, on 1 devices)\n",
            "[05/20 19:20:48 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...\n",
            "[05/20 19:20:48 d2.evaluation.coco_evaluation]: Saving results to /content/output/chkpt/inference/coco_instances_results.json\n",
            "[05/20 19:20:49 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.03s)\n",
            "creating index...\n",
            "index created!\n",
            "[05/20 19:20:49 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*\n",
            "[05/20 19:20:49 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.16 seconds.\n",
            "[05/20 19:20:49 d2.evaluation.fast_eval_api]: Accumulating evaluation results...\n",
            "[05/20 19:20:49 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.07 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.247\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.418\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.246\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.061\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.256\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.425\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.323\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.440\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.449\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.112\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.489\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.794\n",
            "[05/20 19:20:49 d2.evaluation.coco_evaluation]: Evaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
            "| 24.668 | 41.807 | 24.648 | 6.063 | 25.633 | 42.510 |\n",
            "[05/20 19:20:49 d2.evaluation.coco_evaluation]: Per-category bbox AP: \n",
            "| category   | AP     | category              | AP     | category   | AP     |\n",
            "|:-----------|:-------|:----------------------|:-------|:-----------|:-------|\n",
            "| Bottle     | 53.507 | Bottle cap            | 12.732 | Can        | 43.902 |\n",
            "| Cigarette  | 2.504  | Cup                   | 30.693 | Lid        | 34.477 |\n",
            "| Other      | 20.389 | Plastic bag & wrapper | 22.270 | Pop tab    | 10.678 |\n",
            "| Straw      | 15.524 |                       |        |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.16s)\n",
            "creating index...\n",
            "index created!\n",
            "[05/20 19:20:49 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*\n",
            "[05/20 19:20:50 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.26 seconds.\n",
            "[05/20 19:20:50 d2.evaluation.fast_eval_api]: Accumulating evaluation results...\n",
            "[05/20 19:20:50 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.07 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.394\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.512\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.404\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.221\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.483\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.530\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.458\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.650\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.666\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.422\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.748\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.835\n",
            "[05/20 19:20:50 d2.evaluation.coco_evaluation]: Evaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 39.434 | 51.236 | 40.429 | 22.052 | 48.336 | 53.044 |\n",
            "[05/20 19:20:50 d2.evaluation.coco_evaluation]: Per-category segm AP: \n",
            "| category   | AP     | category              | AP     | category   | AP     |\n",
            "|:-----------|:-------|:----------------------|:-------|:-----------|:-------|\n",
            "| Bottle     | 74.176 | Bottle cap            | 40.640 | Can        | 56.536 |\n",
            "| Cigarette  | 20.801 | Cup                   | 42.877 | Lid        | 45.639 |\n",
            "| Other      | 30.600 | Plastic bag & wrapper | 36.334 | Pop tab    | 27.097 |\n",
            "| Straw      | 19.638 |                       |        |            |        |\n",
            "[05/20 19:20:50 d2.engine.defaults]: Evaluation results for TACO_val in csv format:\n",
            "[05/20 19:20:50 d2.evaluation.testing]: copypaste: Task: bbox\n",
            "[05/20 19:20:50 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl\n",
            "[05/20 19:20:50 d2.evaluation.testing]: copypaste: 24.6675,41.8075,24.6479,6.0634,25.6327,42.5102\n",
            "[05/20 19:20:50 d2.evaluation.testing]: copypaste: Task: segm\n",
            "[05/20 19:20:50 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl\n",
            "[05/20 19:20:50 d2.evaluation.testing]: copypaste: 39.4339,51.2356,40.4293,22.0519,48.3362,53.0436\n",
            "[05/20 19:20:50 d2.utils.events]:  eta: 0:06:27  iter: 5499  total_loss: 35.54  loss_ce: 0.7801  loss_mask: 0.03953  loss_dice: 0.558  loss_bbox: 0.06128  loss_giou: 0.2311  loss_ce_dn: 0.1355  loss_mask_dn: 0.04042  loss_dice_dn: 0.3635  loss_bbox_dn: 0.04064  loss_giou_dn: 0.2455  loss_ce_0: 0.9941  loss_mask_0: 0.04234  loss_dice_0: 0.5336  loss_bbox_0: 0.05263  loss_giou_0: 0.2883  loss_ce_dn_0: 0.6693  loss_mask_dn_0: 0.1936  loss_dice_dn_0: 2.171  loss_bbox_dn_0: 0.3249  loss_giou_dn_0: 0.8575  loss_ce_1: 1.042  loss_mask_1: 0.04211  loss_dice_1: 0.5212  loss_bbox_1: 0.06607  loss_giou_1: 0.2201  loss_ce_dn_1: 0.2259  loss_mask_dn_1: 0.04153  loss_dice_dn_1: 0.4726  loss_bbox_dn_1: 0.0821  loss_giou_dn_1: 0.3402  loss_ce_2: 1.021  loss_mask_2: 0.04503  loss_dice_2: 0.5689  loss_bbox_2: 0.07404  loss_giou_2: 0.2738  loss_ce_dn_2: 0.1778  loss_mask_dn_2: 0.03893  loss_dice_dn_2: 0.4042  loss_bbox_dn_2: 0.05544  loss_giou_dn_2: 0.2792  loss_ce_3: 0.7989  loss_mask_3: 0.04359  loss_dice_3: 0.5075  loss_bbox_3: 0.07109  loss_giou_3: 0.239  loss_ce_dn_3: 0.1556  loss_mask_dn_3: 0.04148  loss_dice_dn_3: 0.3696  loss_bbox_dn_3: 0.05361  loss_giou_dn_3: 0.2581  loss_ce_4: 0.7613  loss_mask_4: 0.04742  loss_dice_4: 0.6014  loss_bbox_4: 0.07682  loss_giou_4: 0.2938  loss_ce_dn_4: 0.1509  loss_mask_dn_4: 0.04221  loss_dice_dn_4: 0.3767  loss_bbox_dn_4: 0.04588  loss_giou_dn_4: 0.2472  loss_ce_5: 0.7625  loss_mask_5: 0.04421  loss_dice_5: 0.4996  loss_bbox_5: 0.06071  loss_giou_5: 0.236  loss_ce_dn_5: 0.1437  loss_mask_dn_5: 0.04225  loss_dice_dn_5: 0.3786  loss_bbox_dn_5: 0.04255  loss_giou_dn_5: 0.2486  loss_ce_6: 0.7989  loss_mask_6: 0.04461  loss_dice_6: 0.5457  loss_bbox_6: 0.06009  loss_giou_6: 0.2312  loss_ce_dn_6: 0.1417  loss_mask_dn_6: 0.03729  loss_dice_dn_6: 0.3621  loss_bbox_dn_6: 0.03928  loss_giou_dn_6: 0.247  loss_ce_7: 0.7826  loss_mask_7: 0.04015  loss_dice_7: 0.5659  loss_bbox_7: 0.05849  loss_giou_7: 0.2706  loss_ce_dn_7: 0.1367  loss_mask_dn_7: 0.03977  loss_dice_dn_7: 0.3757  loss_bbox_dn_7: 0.0407  loss_giou_dn_7: 0.2475  loss_ce_8: 0.7821  loss_mask_8: 0.04218  loss_dice_8: 0.5076  loss_bbox_8: 0.06513  loss_giou_8: 0.2639  loss_ce_dn_8: 0.1373  loss_mask_dn_8: 0.0399  loss_dice_dn_8: 0.3926  loss_bbox_dn_8: 0.04111  loss_giou_dn_8: 0.2457  loss_ce_interm: 0.9075  loss_mask_interm: 0.04224  loss_dice_interm: 0.4749  loss_bbox_interm: 0.1209  loss_giou_interm: 0.3793  time: 1.8240  data_time: 0.0741  lr: 1e-06  max_mem: 6663M\n",
            "[05/20 19:21:23 d2.utils.events]:  eta: 0:05:55  iter: 5519  total_loss: 50.96  loss_ce: 1.076  loss_mask: 0.04943  loss_dice: 0.8279  loss_bbox: 0.09308  loss_giou: 0.5672  loss_ce_dn: 0.1776  loss_mask_dn: 0.03773  loss_dice_dn: 0.7898  loss_bbox_dn: 0.0494  loss_giou_dn: 0.3803  loss_ce_0: 1.434  loss_mask_0: 0.04999  loss_dice_0: 1.035  loss_bbox_0: 0.07296  loss_giou_0: 0.6901  loss_ce_dn_0: 0.7288  loss_mask_dn_0: 0.1134  loss_dice_dn_0: 2.912  loss_bbox_dn_0: 0.205  loss_giou_dn_0: 0.8508  loss_ce_1: 1.277  loss_mask_1: 0.05598  loss_dice_1: 0.9234  loss_bbox_1: 0.06769  loss_giou_1: 0.5951  loss_ce_dn_1: 0.2634  loss_mask_dn_1: 0.04006  loss_dice_dn_1: 0.9087  loss_bbox_dn_1: 0.07234  loss_giou_dn_1: 0.4747  loss_ce_2: 1.216  loss_mask_2: 0.03894  loss_dice_2: 1.146  loss_bbox_2: 0.07913  loss_giou_2: 0.6024  loss_ce_dn_2: 0.254  loss_mask_dn_2: 0.03436  loss_dice_dn_2: 0.8637  loss_bbox_dn_2: 0.06241  loss_giou_dn_2: 0.4305  loss_ce_3: 1.269  loss_mask_3: 0.04465  loss_dice_3: 0.9706  loss_bbox_3: 0.07568  loss_giou_3: 0.5092  loss_ce_dn_3: 0.2119  loss_mask_dn_3: 0.03586  loss_dice_dn_3: 0.8331  loss_bbox_dn_3: 0.05575  loss_giou_dn_3: 0.3935  loss_ce_4: 1.253  loss_mask_4: 0.04431  loss_dice_4: 0.9355  loss_bbox_4: 0.06843  loss_giou_4: 0.5228  loss_ce_dn_4: 0.2029  loss_mask_dn_4: 0.03464  loss_dice_dn_4: 0.8161  loss_bbox_dn_4: 0.05605  loss_giou_dn_4: 0.3894  loss_ce_5: 1.069  loss_mask_5: 0.03959  loss_dice_5: 0.959  loss_bbox_5: 0.07234  loss_giou_5: 0.5219  loss_ce_dn_5: 0.1981  loss_mask_dn_5: 0.03445  loss_dice_dn_5: 0.8167  loss_bbox_dn_5: 0.05198  loss_giou_dn_5: 0.3752  loss_ce_6: 1.219  loss_mask_6: 0.03763  loss_dice_6: 0.9536  loss_bbox_6: 0.06692  loss_giou_6: 0.5264  loss_ce_dn_6: 0.1895  loss_mask_dn_6: 0.03179  loss_dice_dn_6: 0.753  loss_bbox_dn_6: 0.05119  loss_giou_dn_6: 0.3803  loss_ce_7: 1.091  loss_mask_7: 0.0415  loss_dice_7: 0.9477  loss_bbox_7: 0.07004  loss_giou_7: 0.5319  loss_ce_dn_7: 0.1799  loss_mask_dn_7: 0.03455  loss_dice_dn_7: 0.7874  loss_bbox_dn_7: 0.05126  loss_giou_dn_7: 0.3814  loss_ce_8: 1.084  loss_mask_8: 0.04419  loss_dice_8: 0.8126  loss_bbox_8: 0.08275  loss_giou_8: 0.5593  loss_ce_dn_8: 0.1806  loss_mask_dn_8: 0.03757  loss_dice_dn_8: 0.77  loss_bbox_dn_8: 0.0514  loss_giou_dn_8: 0.3821  loss_ce_interm: 1.37  loss_mask_interm: 0.05593  loss_dice_interm: 0.9413  loss_bbox_interm: 0.1126  loss_giou_interm: 0.6882  time: 1.8233  data_time: 0.0454  lr: 1e-06  max_mem: 6663M\n",
            "[05/20 19:21:56 d2.utils.events]:  eta: 0:05:24  iter: 5539  total_loss: 32.89  loss_ce: 0.7737  loss_mask: 0.02376  loss_dice: 0.4342  loss_bbox: 0.03979  loss_giou: 0.2351  loss_ce_dn: 0.1539  loss_mask_dn: 0.02288  loss_dice_dn: 0.5268  loss_bbox_dn: 0.03514  loss_giou_dn: 0.2117  loss_ce_0: 0.948  loss_mask_0: 0.03018  loss_dice_0: 0.4919  loss_bbox_0: 0.04792  loss_giou_0: 0.3332  loss_ce_dn_0: 0.7298  loss_mask_dn_0: 0.1635  loss_dice_dn_0: 2.297  loss_bbox_dn_0: 0.218  loss_giou_dn_0: 0.858  loss_ce_1: 0.9608  loss_mask_1: 0.02986  loss_dice_1: 0.6447  loss_bbox_1: 0.04266  loss_giou_1: 0.2391  loss_ce_dn_1: 0.2481  loss_mask_dn_1: 0.02292  loss_dice_dn_1: 0.5471  loss_bbox_dn_1: 0.0489  loss_giou_dn_1: 0.3095  loss_ce_2: 0.8496  loss_mask_2: 0.03083  loss_dice_2: 0.4405  loss_bbox_2: 0.0405  loss_giou_2: 0.2586  loss_ce_dn_2: 0.1974  loss_mask_dn_2: 0.02128  loss_dice_dn_2: 0.5389  loss_bbox_dn_2: 0.04069  loss_giou_dn_2: 0.2664  loss_ce_3: 0.809  loss_mask_3: 0.02387  loss_dice_3: 0.559  loss_bbox_3: 0.04038  loss_giou_3: 0.2515  loss_ce_dn_3: 0.1876  loss_mask_dn_3: 0.02307  loss_dice_dn_3: 0.5034  loss_bbox_dn_3: 0.03767  loss_giou_dn_3: 0.227  loss_ce_4: 0.7853  loss_mask_4: 0.02562  loss_dice_4: 0.3476  loss_bbox_4: 0.0398  loss_giou_4: 0.241  loss_ce_dn_4: 0.172  loss_mask_dn_4: 0.02316  loss_dice_dn_4: 0.5202  loss_bbox_dn_4: 0.03717  loss_giou_dn_4: 0.2177  loss_ce_5: 0.8177  loss_mask_5: 0.03056  loss_dice_5: 0.5472  loss_bbox_5: 0.03939  loss_giou_5: 0.2422  loss_ce_dn_5: 0.1641  loss_mask_dn_5: 0.02202  loss_dice_dn_5: 0.5321  loss_bbox_dn_5: 0.03453  loss_giou_dn_5: 0.2177  loss_ce_6: 0.7434  loss_mask_6: 0.02669  loss_dice_6: 0.4839  loss_bbox_6: 0.04004  loss_giou_6: 0.2414  loss_ce_dn_6: 0.1472  loss_mask_dn_6: 0.0225  loss_dice_dn_6: 0.5359  loss_bbox_dn_6: 0.03679  loss_giou_dn_6: 0.2212  loss_ce_7: 0.7652  loss_mask_7: 0.02607  loss_dice_7: 0.5487  loss_bbox_7: 0.04078  loss_giou_7: 0.2364  loss_ce_dn_7: 0.1509  loss_mask_dn_7: 0.02256  loss_dice_dn_7: 0.5189  loss_bbox_dn_7: 0.03544  loss_giou_dn_7: 0.2085  loss_ce_8: 0.7802  loss_mask_8: 0.02946  loss_dice_8: 0.4992  loss_bbox_8: 0.03939  loss_giou_8: 0.2359  loss_ce_dn_8: 0.1489  loss_mask_dn_8: 0.02278  loss_dice_dn_8: 0.5454  loss_bbox_dn_8: 0.03549  loss_giou_dn_8: 0.2124  loss_ce_interm: 0.9448  loss_mask_interm: 0.03736  loss_dice_interm: 0.5717  loss_bbox_interm: 0.08244  loss_giou_interm: 0.3252  time: 1.8227  data_time: 0.0611  lr: 1e-06  max_mem: 6663M\n",
            "[05/20 19:22:30 d2.utils.events]:  eta: 0:04:53  iter: 5559  total_loss: 39.87  loss_ce: 0.8573  loss_mask: 0.02633  loss_dice: 0.4675  loss_bbox: 0.09174  loss_giou: 0.3678  loss_ce_dn: 0.2  loss_mask_dn: 0.02689  loss_dice_dn: 0.5028  loss_bbox_dn: 0.04474  loss_giou_dn: 0.2805  loss_ce_0: 1.07  loss_mask_0: 0.0448  loss_dice_0: 0.6127  loss_bbox_0: 0.1297  loss_giou_0: 0.4487  loss_ce_dn_0: 0.6762  loss_mask_dn_0: 0.1259  loss_dice_dn_0: 2.52  loss_bbox_dn_0: 0.2424  loss_giou_dn_0: 0.85  loss_ce_1: 1.048  loss_mask_1: 0.04235  loss_dice_1: 0.455  loss_bbox_1: 0.08971  loss_giou_1: 0.367  loss_ce_dn_1: 0.2304  loss_mask_dn_1: 0.02634  loss_dice_dn_1: 0.535  loss_bbox_dn_1: 0.06537  loss_giou_dn_1: 0.3493  loss_ce_2: 0.9713  loss_mask_2: 0.04223  loss_dice_2: 0.4693  loss_bbox_2: 0.09426  loss_giou_2: 0.382  loss_ce_dn_2: 0.1991  loss_mask_dn_2: 0.02593  loss_dice_dn_2: 0.5222  loss_bbox_dn_2: 0.05369  loss_giou_dn_2: 0.3017  loss_ce_3: 0.9151  loss_mask_3: 0.03459  loss_dice_3: 0.4635  loss_bbox_3: 0.09937  loss_giou_3: 0.3758  loss_ce_dn_3: 0.1984  loss_mask_dn_3: 0.02729  loss_dice_dn_3: 0.5472  loss_bbox_dn_3: 0.04883  loss_giou_dn_3: 0.2956  loss_ce_4: 0.8822  loss_mask_4: 0.03021  loss_dice_4: 0.565  loss_bbox_4: 0.09561  loss_giou_4: 0.3696  loss_ce_dn_4: 0.1958  loss_mask_dn_4: 0.02715  loss_dice_dn_4: 0.5127  loss_bbox_dn_4: 0.04594  loss_giou_dn_4: 0.2942  loss_ce_5: 0.884  loss_mask_5: 0.02915  loss_dice_5: 0.4504  loss_bbox_5: 0.09603  loss_giou_5: 0.3707  loss_ce_dn_5: 0.2027  loss_mask_dn_5: 0.02665  loss_dice_dn_5: 0.5576  loss_bbox_dn_5: 0.04534  loss_giou_dn_5: 0.2891  loss_ce_6: 0.8592  loss_mask_6: 0.03529  loss_dice_6: 0.5623  loss_bbox_6: 0.09609  loss_giou_6: 0.3588  loss_ce_dn_6: 0.2044  loss_mask_dn_6: 0.02667  loss_dice_dn_6: 0.5694  loss_bbox_dn_6: 0.04562  loss_giou_dn_6: 0.2795  loss_ce_7: 0.8217  loss_mask_7: 0.03062  loss_dice_7: 0.4913  loss_bbox_7: 0.09253  loss_giou_7: 0.3685  loss_ce_dn_7: 0.203  loss_mask_dn_7: 0.02647  loss_dice_dn_7: 0.5297  loss_bbox_dn_7: 0.04505  loss_giou_dn_7: 0.2788  loss_ce_8: 0.844  loss_mask_8: 0.03198  loss_dice_8: 0.4974  loss_bbox_8: 0.0916  loss_giou_8: 0.3678  loss_ce_dn_8: 0.2076  loss_mask_dn_8: 0.02701  loss_dice_dn_8: 0.5392  loss_bbox_dn_8: 0.04552  loss_giou_dn_8: 0.2793  loss_ce_interm: 1.189  loss_mask_interm: 0.03465  loss_dice_interm: 0.5138  loss_bbox_interm: 0.1038  loss_giou_interm: 0.4178  time: 1.8222  data_time: 0.0729  lr: 1e-06  max_mem: 6663M\n",
            "[05/20 19:23:03 d2.utils.events]:  eta: 0:04:22  iter: 5579  total_loss: 36.76  loss_ce: 0.8888  loss_mask: 0.04508  loss_dice: 0.4202  loss_bbox: 0.04554  loss_giou: 0.2668  loss_ce_dn: 0.1863  loss_mask_dn: 0.04551  loss_dice_dn: 0.4839  loss_bbox_dn: 0.03934  loss_giou_dn: 0.2503  loss_ce_0: 1.109  loss_mask_0: 0.0469  loss_dice_0: 0.4024  loss_bbox_0: 0.06191  loss_giou_0: 0.3622  loss_ce_dn_0: 0.6538  loss_mask_dn_0: 0.176  loss_dice_dn_0: 2.145  loss_bbox_dn_0: 0.4495  loss_giou_dn_0: 0.8563  loss_ce_1: 1.116  loss_mask_1: 0.0512  loss_dice_1: 0.4505  loss_bbox_1: 0.06335  loss_giou_1: 0.3144  loss_ce_dn_1: 0.2556  loss_mask_dn_1: 0.04901  loss_dice_dn_1: 0.562  loss_bbox_dn_1: 0.08167  loss_giou_dn_1: 0.3224  loss_ce_2: 1.033  loss_mask_2: 0.04851  loss_dice_2: 0.4004  loss_bbox_2: 0.04988  loss_giou_2: 0.2955  loss_ce_dn_2: 0.2241  loss_mask_dn_2: 0.04862  loss_dice_dn_2: 0.5347  loss_bbox_dn_2: 0.05467  loss_giou_dn_2: 0.284  loss_ce_3: 0.8481  loss_mask_3: 0.03863  loss_dice_3: 0.4228  loss_bbox_3: 0.05083  loss_giou_3: 0.2934  loss_ce_dn_3: 0.2112  loss_mask_dn_3: 0.04681  loss_dice_dn_3: 0.5099  loss_bbox_dn_3: 0.04187  loss_giou_dn_3: 0.2639  loss_ce_4: 0.89  loss_mask_4: 0.04663  loss_dice_4: 0.4353  loss_bbox_4: 0.0511  loss_giou_4: 0.2578  loss_ce_dn_4: 0.1988  loss_mask_dn_4: 0.04975  loss_dice_dn_4: 0.5101  loss_bbox_dn_4: 0.03853  loss_giou_dn_4: 0.2571  loss_ce_5: 0.8951  loss_mask_5: 0.0387  loss_dice_5: 0.446  loss_bbox_5: 0.04772  loss_giou_5: 0.2666  loss_ce_dn_5: 0.2042  loss_mask_dn_5: 0.04706  loss_dice_dn_5: 0.4878  loss_bbox_dn_5: 0.04185  loss_giou_dn_5: 0.2565  loss_ce_6: 0.8809  loss_mask_6: 0.04439  loss_dice_6: 0.4264  loss_bbox_6: 0.04584  loss_giou_6: 0.2647  loss_ce_dn_6: 0.197  loss_mask_dn_6: 0.04841  loss_dice_dn_6: 0.4962  loss_bbox_dn_6: 0.04051  loss_giou_dn_6: 0.2531  loss_ce_7: 0.8696  loss_mask_7: 0.04161  loss_dice_7: 0.3623  loss_bbox_7: 0.04586  loss_giou_7: 0.2567  loss_ce_dn_7: 0.1882  loss_mask_dn_7: 0.04678  loss_dice_dn_7: 0.5069  loss_bbox_dn_7: 0.0393  loss_giou_dn_7: 0.2551  loss_ce_8: 0.8772  loss_mask_8: 0.0454  loss_dice_8: 0.43  loss_bbox_8: 0.04569  loss_giou_8: 0.2586  loss_ce_dn_8: 0.1888  loss_mask_dn_8: 0.04592  loss_dice_dn_8: 0.4751  loss_bbox_dn_8: 0.04001  loss_giou_dn_8: 0.2526  loss_ce_interm: 1.109  loss_mask_interm: 0.05023  loss_dice_interm: 0.441  loss_bbox_interm: 0.09946  loss_giou_interm: 0.3713  time: 1.8216  data_time: 0.0560  lr: 1e-06  max_mem: 6663M\n",
            "[05/20 19:23:38 d2.utils.events]:  eta: 0:03:51  iter: 5599  total_loss: 36.44  loss_ce: 0.9374  loss_mask: 0.0283  loss_dice: 0.472  loss_bbox: 0.05115  loss_giou: 0.297  loss_ce_dn: 0.1936  loss_mask_dn: 0.03492  loss_dice_dn: 0.4056  loss_bbox_dn: 0.03941  loss_giou_dn: 0.2729  loss_ce_0: 1.335  loss_mask_0: 0.02817  loss_dice_0: 0.4305  loss_bbox_0: 0.06536  loss_giou_0: 0.4024  loss_ce_dn_0: 0.6909  loss_mask_dn_0: 0.1334  loss_dice_dn_0: 2.037  loss_bbox_dn_0: 0.275  loss_giou_dn_0: 0.858  loss_ce_1: 1.217  loss_mask_1: 0.03506  loss_dice_1: 0.5831  loss_bbox_1: 0.05945  loss_giou_1: 0.3371  loss_ce_dn_1: 0.2891  loss_mask_dn_1: 0.03601  loss_dice_dn_1: 0.4807  loss_bbox_dn_1: 0.06598  loss_giou_dn_1: 0.3627  loss_ce_2: 1.109  loss_mask_2: 0.03543  loss_dice_2: 0.4417  loss_bbox_2: 0.05877  loss_giou_2: 0.2854  loss_ce_dn_2: 0.2444  loss_mask_dn_2: 0.03389  loss_dice_dn_2: 0.4417  loss_bbox_dn_2: 0.0523  loss_giou_dn_2: 0.3063  loss_ce_3: 1.055  loss_mask_3: 0.0288  loss_dice_3: 0.3901  loss_bbox_3: 0.05691  loss_giou_3: 0.2956  loss_ce_dn_3: 0.2017  loss_mask_dn_3: 0.03205  loss_dice_dn_3: 0.4383  loss_bbox_dn_3: 0.03988  loss_giou_dn_3: 0.2774  loss_ce_4: 0.9841  loss_mask_4: 0.02986  loss_dice_4: 0.3257  loss_bbox_4: 0.05488  loss_giou_4: 0.3229  loss_ce_dn_4: 0.1965  loss_mask_dn_4: 0.02967  loss_dice_dn_4: 0.4166  loss_bbox_dn_4: 0.0429  loss_giou_dn_4: 0.2812  loss_ce_5: 0.8429  loss_mask_5: 0.02626  loss_dice_5: 0.3972  loss_bbox_5: 0.06369  loss_giou_5: 0.3168  loss_ce_dn_5: 0.1919  loss_mask_dn_5: 0.03272  loss_dice_dn_5: 0.4014  loss_bbox_dn_5: 0.04047  loss_giou_dn_5: 0.2686  loss_ce_6: 0.8815  loss_mask_6: 0.02782  loss_dice_6: 0.3905  loss_bbox_6: 0.05095  loss_giou_6: 0.304  loss_ce_dn_6: 0.1895  loss_mask_dn_6: 0.03221  loss_dice_dn_6: 0.4083  loss_bbox_dn_6: 0.03925  loss_giou_dn_6: 0.2692  loss_ce_7: 0.899  loss_mask_7: 0.02766  loss_dice_7: 0.3815  loss_bbox_7: 0.04963  loss_giou_7: 0.2752  loss_ce_dn_7: 0.1898  loss_mask_dn_7: 0.0356  loss_dice_dn_7: 0.3976  loss_bbox_dn_7: 0.04004  loss_giou_dn_7: 0.2707  loss_ce_8: 0.8958  loss_mask_8: 0.03274  loss_dice_8: 0.3657  loss_bbox_8: 0.05621  loss_giou_8: 0.3001  loss_ce_dn_8: 0.1918  loss_mask_dn_8: 0.03615  loss_dice_dn_8: 0.4032  loss_bbox_dn_8: 0.03973  loss_giou_dn_8: 0.2751  loss_ce_interm: 1.323  loss_mask_interm: 0.03482  loss_dice_interm: 0.4689  loss_bbox_interm: 0.08004  loss_giou_interm: 0.4173  time: 1.8214  data_time: 0.1346  lr: 1e-06  max_mem: 6663M\n",
            "[05/20 19:24:13 d2.utils.events]:  eta: 0:03:19  iter: 5619  total_loss: 43.62  loss_ce: 0.9151  loss_mask: 0.03166  loss_dice: 0.4823  loss_bbox: 0.111  loss_giou: 0.4431  loss_ce_dn: 0.1573  loss_mask_dn: 0.03448  loss_dice_dn: 0.5148  loss_bbox_dn: 0.0317  loss_giou_dn: 0.3216  loss_ce_0: 1.161  loss_mask_0: 0.02806  loss_dice_0: 0.5588  loss_bbox_0: 0.08536  loss_giou_0: 0.59  loss_ce_dn_0: 0.7167  loss_mask_dn_0: 0.1532  loss_dice_dn_0: 1.711  loss_bbox_dn_0: 0.2512  loss_giou_dn_0: 0.8574  loss_ce_1: 1.147  loss_mask_1: 0.02704  loss_dice_1: 0.499  loss_bbox_1: 0.103  loss_giou_1: 0.5117  loss_ce_dn_1: 0.2423  loss_mask_dn_1: 0.03362  loss_dice_dn_1: 0.5754  loss_bbox_dn_1: 0.0648  loss_giou_dn_1: 0.385  loss_ce_2: 1.158  loss_mask_2: 0.0296  loss_dice_2: 0.5287  loss_bbox_2: 0.07437  loss_giou_2: 0.493  loss_ce_dn_2: 0.2096  loss_mask_dn_2: 0.03243  loss_dice_dn_2: 0.5218  loss_bbox_dn_2: 0.04348  loss_giou_dn_2: 0.3576  loss_ce_3: 0.9096  loss_mask_3: 0.02705  loss_dice_3: 0.5053  loss_bbox_3: 0.08141  loss_giou_3: 0.454  loss_ce_dn_3: 0.196  loss_mask_dn_3: 0.03291  loss_dice_dn_3: 0.5324  loss_bbox_dn_3: 0.03923  loss_giou_dn_3: 0.3356  loss_ce_4: 1.04  loss_mask_4: 0.03014  loss_dice_4: 0.477  loss_bbox_4: 0.08827  loss_giou_4: 0.4872  loss_ce_dn_4: 0.1793  loss_mask_dn_4: 0.03287  loss_dice_dn_4: 0.5376  loss_bbox_dn_4: 0.03423  loss_giou_dn_4: 0.3286  loss_ce_5: 0.8506  loss_mask_5: 0.02891  loss_dice_5: 0.3925  loss_bbox_5: 0.08516  loss_giou_5: 0.4119  loss_ce_dn_5: 0.1691  loss_mask_dn_5: 0.03289  loss_dice_dn_5: 0.5301  loss_bbox_dn_5: 0.03079  loss_giou_dn_5: 0.3278  loss_ce_6: 0.9398  loss_mask_6: 0.03036  loss_dice_6: 0.4588  loss_bbox_6: 0.09392  loss_giou_6: 0.445  loss_ce_dn_6: 0.1694  loss_mask_dn_6: 0.03493  loss_dice_dn_6: 0.499  loss_bbox_dn_6: 0.03124  loss_giou_dn_6: 0.3301  loss_ce_7: 0.8468  loss_mask_7: 0.02931  loss_dice_7: 0.316  loss_bbox_7: 0.09997  loss_giou_7: 0.4693  loss_ce_dn_7: 0.1603  loss_mask_dn_7: 0.03377  loss_dice_dn_7: 0.5202  loss_bbox_dn_7: 0.02971  loss_giou_dn_7: 0.3278  loss_ce_8: 1.042  loss_mask_8: 0.03405  loss_dice_8: 0.357  loss_bbox_8: 0.09645  loss_giou_8: 0.4549  loss_ce_dn_8: 0.1555  loss_mask_dn_8: 0.03466  loss_dice_dn_8: 0.5137  loss_bbox_dn_8: 0.03051  loss_giou_dn_8: 0.3242  loss_ce_interm: 1.275  loss_mask_interm: 0.03267  loss_dice_interm: 0.4928  loss_bbox_interm: 0.0697  loss_giou_interm: 0.448  time: 1.8211  data_time: 0.1435  lr: 1e-06  max_mem: 6663M\n",
            "[05/20 19:24:47 d2.utils.events]:  eta: 0:02:48  iter: 5639  total_loss: 50.06  loss_ce: 1.099  loss_mask: 0.0328  loss_dice: 0.9404  loss_bbox: 0.06213  loss_giou: 0.5427  loss_ce_dn: 0.2282  loss_mask_dn: 0.02687  loss_dice_dn: 0.7729  loss_bbox_dn: 0.03414  loss_giou_dn: 0.3989  loss_ce_0: 1.453  loss_mask_0: 0.03932  loss_dice_0: 0.8608  loss_bbox_0: 0.05481  loss_giou_0: 0.4107  loss_ce_dn_0: 0.7654  loss_mask_dn_0: 0.1509  loss_dice_dn_0: 2.619  loss_bbox_dn_0: 0.2002  loss_giou_dn_0: 0.8602  loss_ce_1: 1.455  loss_mask_1: 0.022  loss_dice_1: 0.5779  loss_bbox_1: 0.06691  loss_giou_1: 0.501  loss_ce_dn_1: 0.2924  loss_mask_dn_1: 0.03288  loss_dice_dn_1: 0.8734  loss_bbox_dn_1: 0.06219  loss_giou_dn_1: 0.4349  loss_ce_2: 1.29  loss_mask_2: 0.02826  loss_dice_2: 0.8454  loss_bbox_2: 0.07259  loss_giou_2: 0.4703  loss_ce_dn_2: 0.2565  loss_mask_dn_2: 0.02969  loss_dice_dn_2: 0.818  loss_bbox_dn_2: 0.05266  loss_giou_dn_2: 0.4034  loss_ce_3: 1.2  loss_mask_3: 0.03045  loss_dice_3: 0.8183  loss_bbox_3: 0.06194  loss_giou_3: 0.4954  loss_ce_dn_3: 0.243  loss_mask_dn_3: 0.02371  loss_dice_dn_3: 0.7385  loss_bbox_dn_3: 0.04298  loss_giou_dn_3: 0.3901  loss_ce_4: 1.236  loss_mask_4: 0.02701  loss_dice_4: 0.6827  loss_bbox_4: 0.06932  loss_giou_4: 0.544  loss_ce_dn_4: 0.2392  loss_mask_dn_4: 0.02572  loss_dice_dn_4: 0.7651  loss_bbox_dn_4: 0.04035  loss_giou_dn_4: 0.3968  loss_ce_5: 1.209  loss_mask_5: 0.02916  loss_dice_5: 0.5575  loss_bbox_5: 0.0615  loss_giou_5: 0.5435  loss_ce_dn_5: 0.2275  loss_mask_dn_5: 0.02465  loss_dice_dn_5: 0.7341  loss_bbox_dn_5: 0.0332  loss_giou_dn_5: 0.394  loss_ce_6: 1.172  loss_mask_6: 0.03316  loss_dice_6: 0.906  loss_bbox_6: 0.0679  loss_giou_6: 0.5527  loss_ce_dn_6: 0.2223  loss_mask_dn_6: 0.02626  loss_dice_dn_6: 0.7328  loss_bbox_dn_6: 0.03432  loss_giou_dn_6: 0.3953  loss_ce_7: 1.256  loss_mask_7: 0.02742  loss_dice_7: 0.692  loss_bbox_7: 0.06396  loss_giou_7: 0.5457  loss_ce_dn_7: 0.2259  loss_mask_dn_7: 0.02552  loss_dice_dn_7: 0.7525  loss_bbox_dn_7: 0.03467  loss_giou_dn_7: 0.4002  loss_ce_8: 1.25  loss_mask_8: 0.02571  loss_dice_8: 0.6537  loss_bbox_8: 0.05485  loss_giou_8: 0.5608  loss_ce_dn_8: 0.2242  loss_mask_dn_8: 0.02697  loss_dice_dn_8: 0.7557  loss_bbox_dn_8: 0.0343  loss_giou_dn_8: 0.4011  loss_ce_interm: 1.37  loss_mask_interm: 0.02815  loss_dice_interm: 0.8231  loss_bbox_interm: 0.1015  loss_giou_interm: 0.6227  time: 1.8207  data_time: 0.1168  lr: 1e-06  max_mem: 6663M\n",
            "[05/20 19:25:21 d2.utils.events]:  eta: 0:02:17  iter: 5659  total_loss: 36.09  loss_ce: 0.9158  loss_mask: 0.05226  loss_dice: 0.5912  loss_bbox: 0.04807  loss_giou: 0.2515  loss_ce_dn: 0.1573  loss_mask_dn: 0.05501  loss_dice_dn: 0.53  loss_bbox_dn: 0.0462  loss_giou_dn: 0.2178  loss_ce_0: 1.039  loss_mask_0: 0.05617  loss_dice_0: 0.4587  loss_bbox_0: 0.05316  loss_giou_0: 0.3127  loss_ce_dn_0: 0.6707  loss_mask_dn_0: 0.2587  loss_dice_dn_0: 1.877  loss_bbox_dn_0: 0.3413  loss_giou_dn_0: 0.8545  loss_ce_1: 0.8951  loss_mask_1: 0.05734  loss_dice_1: 0.5369  loss_bbox_1: 0.04908  loss_giou_1: 0.3162  loss_ce_dn_1: 0.2268  loss_mask_dn_1: 0.06545  loss_dice_dn_1: 0.5736  loss_bbox_dn_1: 0.08191  loss_giou_dn_1: 0.3039  loss_ce_2: 0.9814  loss_mask_2: 0.06163  loss_dice_2: 0.5213  loss_bbox_2: 0.04924  loss_giou_2: 0.2685  loss_ce_dn_2: 0.1886  loss_mask_dn_2: 0.06068  loss_dice_dn_2: 0.5587  loss_bbox_dn_2: 0.06512  loss_giou_dn_2: 0.2568  loss_ce_3: 0.9153  loss_mask_3: 0.06055  loss_dice_3: 0.4442  loss_bbox_3: 0.04939  loss_giou_3: 0.2581  loss_ce_dn_3: 0.1777  loss_mask_dn_3: 0.05858  loss_dice_dn_3: 0.5223  loss_bbox_dn_3: 0.05365  loss_giou_dn_3: 0.2335  loss_ce_4: 0.9444  loss_mask_4: 0.05029  loss_dice_4: 0.5581  loss_bbox_4: 0.04961  loss_giou_4: 0.2491  loss_ce_dn_4: 0.1636  loss_mask_dn_4: 0.05673  loss_dice_dn_4: 0.5399  loss_bbox_dn_4: 0.05008  loss_giou_dn_4: 0.2293  loss_ce_5: 0.9579  loss_mask_5: 0.05731  loss_dice_5: 0.533  loss_bbox_5: 0.04677  loss_giou_5: 0.2355  loss_ce_dn_5: 0.1699  loss_mask_dn_5: 0.05547  loss_dice_dn_5: 0.5285  loss_bbox_dn_5: 0.04518  loss_giou_dn_5: 0.2252  loss_ce_6: 0.9955  loss_mask_6: 0.05653  loss_dice_6: 0.5531  loss_bbox_6: 0.047  loss_giou_6: 0.239  loss_ce_dn_6: 0.1657  loss_mask_dn_6: 0.05682  loss_dice_dn_6: 0.5179  loss_bbox_dn_6: 0.04555  loss_giou_dn_6: 0.2231  loss_ce_7: 0.9793  loss_mask_7: 0.05511  loss_dice_7: 0.5525  loss_bbox_7: 0.04719  loss_giou_7: 0.2444  loss_ce_dn_7: 0.1593  loss_mask_dn_7: 0.0569  loss_dice_dn_7: 0.5235  loss_bbox_dn_7: 0.04705  loss_giou_dn_7: 0.2217  loss_ce_8: 0.9136  loss_mask_8: 0.05851  loss_dice_8: 0.5366  loss_bbox_8: 0.04756  loss_giou_8: 0.2544  loss_ce_dn_8: 0.1583  loss_mask_dn_8: 0.05697  loss_dice_dn_8: 0.5285  loss_bbox_dn_8: 0.04677  loss_giou_dn_8: 0.2186  loss_ce_interm: 1.029  loss_mask_interm: 0.05782  loss_dice_interm: 0.4755  loss_bbox_interm: 0.09159  loss_giou_interm: 0.325  time: 1.8201  data_time: 0.0694  lr: 1e-06  max_mem: 6663M\n",
            "[05/20 19:25:54 d2.utils.events]:  eta: 0:01:46  iter: 5679  total_loss: 41.11  loss_ce: 0.9979  loss_mask: 0.02571  loss_dice: 0.5561  loss_bbox: 0.09129  loss_giou: 0.3047  loss_ce_dn: 0.1845  loss_mask_dn: 0.02634  loss_dice_dn: 0.5371  loss_bbox_dn: 0.03103  loss_giou_dn: 0.2615  loss_ce_0: 1.201  loss_mask_0: 0.02527  loss_dice_0: 0.5643  loss_bbox_0: 0.08675  loss_giou_0: 0.463  loss_ce_dn_0: 0.8157  loss_mask_dn_0: 0.0979  loss_dice_dn_0: 2.521  loss_bbox_dn_0: 0.3202  loss_giou_dn_0: 0.8607  loss_ce_1: 1.161  loss_mask_1: 0.02668  loss_dice_1: 0.5497  loss_bbox_1: 0.08841  loss_giou_1: 0.362  loss_ce_dn_1: 0.2489  loss_mask_dn_1: 0.02902  loss_dice_dn_1: 0.5232  loss_bbox_dn_1: 0.06266  loss_giou_dn_1: 0.3717  loss_ce_2: 1.014  loss_mask_2: 0.02788  loss_dice_2: 0.4728  loss_bbox_2: 0.1056  loss_giou_2: 0.3989  loss_ce_dn_2: 0.2254  loss_mask_dn_2: 0.02716  loss_dice_dn_2: 0.538  loss_bbox_dn_2: 0.0464  loss_giou_dn_2: 0.3021  loss_ce_3: 0.9746  loss_mask_3: 0.02546  loss_dice_3: 0.5836  loss_bbox_3: 0.1029  loss_giou_3: 0.3314  loss_ce_dn_3: 0.2087  loss_mask_dn_3: 0.02731  loss_dice_dn_3: 0.5312  loss_bbox_dn_3: 0.03643  loss_giou_dn_3: 0.2735  loss_ce_4: 0.8916  loss_mask_4: 0.02926  loss_dice_4: 0.5228  loss_bbox_4: 0.1023  loss_giou_4: 0.322  loss_ce_dn_4: 0.1893  loss_mask_dn_4: 0.02734  loss_dice_dn_4: 0.5185  loss_bbox_dn_4: 0.03582  loss_giou_dn_4: 0.2696  loss_ce_5: 0.936  loss_mask_5: 0.03572  loss_dice_5: 0.4763  loss_bbox_5: 0.09959  loss_giou_5: 0.3165  loss_ce_dn_5: 0.1734  loss_mask_dn_5: 0.02858  loss_dice_dn_5: 0.5307  loss_bbox_dn_5: 0.03118  loss_giou_dn_5: 0.2606  loss_ce_6: 0.9774  loss_mask_6: 0.03229  loss_dice_6: 0.4895  loss_bbox_6: 0.0952  loss_giou_6: 0.3134  loss_ce_dn_6: 0.1751  loss_mask_dn_6: 0.02815  loss_dice_dn_6: 0.5103  loss_bbox_dn_6: 0.0307  loss_giou_dn_6: 0.2707  loss_ce_7: 1.021  loss_mask_7: 0.02674  loss_dice_7: 0.5848  loss_bbox_7: 0.09165  loss_giou_7: 0.3084  loss_ce_dn_7: 0.1841  loss_mask_dn_7: 0.02741  loss_dice_dn_7: 0.4999  loss_bbox_dn_7: 0.03161  loss_giou_dn_7: 0.265  loss_ce_8: 1.016  loss_mask_8: 0.02801  loss_dice_8: 0.6335  loss_bbox_8: 0.09611  loss_giou_8: 0.307  loss_ce_dn_8: 0.1833  loss_mask_dn_8: 0.02692  loss_dice_dn_8: 0.5099  loss_bbox_dn_8: 0.03067  loss_giou_dn_8: 0.2634  loss_ce_interm: 1.246  loss_mask_interm: 0.0331  loss_dice_interm: 0.5517  loss_bbox_interm: 0.08553  loss_giou_interm: 0.4489  time: 1.8196  data_time: 0.0894  lr: 1e-06  max_mem: 6663M\n",
            "[05/20 19:26:26 d2.utils.events]:  eta: 0:01:14  iter: 5699  total_loss: 37.08  loss_ce: 0.9747  loss_mask: 0.03548  loss_dice: 0.3269  loss_bbox: 0.0585  loss_giou: 0.2828  loss_ce_dn: 0.2168  loss_mask_dn: 0.03442  loss_dice_dn: 0.4375  loss_bbox_dn: 0.04936  loss_giou_dn: 0.2597  loss_ce_0: 1.171  loss_mask_0: 0.04175  loss_dice_0: 0.5195  loss_bbox_0: 0.07537  loss_giou_0: 0.4517  loss_ce_dn_0: 0.811  loss_mask_dn_0: 0.1445  loss_dice_dn_0: 2.448  loss_bbox_dn_0: 0.2648  loss_giou_dn_0: 0.8597  loss_ce_1: 1.217  loss_mask_1: 0.03582  loss_dice_1: 0.4372  loss_bbox_1: 0.06899  loss_giou_1: 0.3384  loss_ce_dn_1: 0.2961  loss_mask_dn_1: 0.03631  loss_dice_dn_1: 0.4242  loss_bbox_dn_1: 0.08256  loss_giou_dn_1: 0.3511  loss_ce_2: 1.177  loss_mask_2: 0.03573  loss_dice_2: 0.4469  loss_bbox_2: 0.05849  loss_giou_2: 0.3154  loss_ce_dn_2: 0.2496  loss_mask_dn_2: 0.03591  loss_dice_dn_2: 0.4659  loss_bbox_dn_2: 0.0612  loss_giou_dn_2: 0.3067  loss_ce_3: 1.034  loss_mask_3: 0.03529  loss_dice_3: 0.4332  loss_bbox_3: 0.06148  loss_giou_3: 0.2942  loss_ce_dn_3: 0.2403  loss_mask_dn_3: 0.03588  loss_dice_dn_3: 0.4355  loss_bbox_dn_3: 0.052  loss_giou_dn_3: 0.2836  loss_ce_4: 0.9619  loss_mask_4: 0.03793  loss_dice_4: 0.4364  loss_bbox_4: 0.05832  loss_giou_4: 0.2775  loss_ce_dn_4: 0.2313  loss_mask_dn_4: 0.03339  loss_dice_dn_4: 0.4484  loss_bbox_dn_4: 0.05276  loss_giou_dn_4: 0.27  loss_ce_5: 0.9863  loss_mask_5: 0.03325  loss_dice_5: 0.4319  loss_bbox_5: 0.05979  loss_giou_5: 0.2735  loss_ce_dn_5: 0.2209  loss_mask_dn_5: 0.03412  loss_dice_dn_5: 0.4478  loss_bbox_dn_5: 0.05036  loss_giou_dn_5: 0.2609  loss_ce_6: 0.9708  loss_mask_6: 0.03561  loss_dice_6: 0.374  loss_bbox_6: 0.0586  loss_giou_6: 0.2838  loss_ce_dn_6: 0.2146  loss_mask_dn_6: 0.03297  loss_dice_dn_6: 0.4167  loss_bbox_dn_6: 0.04894  loss_giou_dn_6: 0.257  loss_ce_7: 0.9264  loss_mask_7: 0.03329  loss_dice_7: 0.3942  loss_bbox_7: 0.05761  loss_giou_7: 0.2867  loss_ce_dn_7: 0.2141  loss_mask_dn_7: 0.03427  loss_dice_dn_7: 0.4247  loss_bbox_dn_7: 0.04752  loss_giou_dn_7: 0.2612  loss_ce_8: 0.9637  loss_mask_8: 0.03255  loss_dice_8: 0.3964  loss_bbox_8: 0.05858  loss_giou_8: 0.2829  loss_ce_dn_8: 0.2201  loss_mask_dn_8: 0.03444  loss_dice_dn_8: 0.4284  loss_bbox_dn_8: 0.04814  loss_giou_dn_8: 0.2592  loss_ce_interm: 1.155  loss_mask_interm: 0.03977  loss_dice_interm: 0.4865  loss_bbox_interm: 0.08288  loss_giou_interm: 0.3907  time: 1.8189  data_time: 0.0448  lr: 1e-06  max_mem: 6663M\n",
            "[05/20 19:27:00 d2.utils.events]:  eta: 0:00:43  iter: 5719  total_loss: 49.01  loss_ce: 0.9693  loss_mask: 0.03297  loss_dice: 0.813  loss_bbox: 0.06398  loss_giou: 0.4469  loss_ce_dn: 0.2062  loss_mask_dn: 0.02201  loss_dice_dn: 0.7615  loss_bbox_dn: 0.03055  loss_giou_dn: 0.3389  loss_ce_0: 1.318  loss_mask_0: 0.04249  loss_dice_0: 0.9887  loss_bbox_0: 0.07765  loss_giou_0: 0.5551  loss_ce_dn_0: 0.734  loss_mask_dn_0: 0.1149  loss_dice_dn_0: 2.505  loss_bbox_dn_0: 0.2111  loss_giou_dn_0: 0.8537  loss_ce_1: 1.306  loss_mask_1: 0.03832  loss_dice_1: 0.9358  loss_bbox_1: 0.07948  loss_giou_1: 0.4882  loss_ce_dn_1: 0.2856  loss_mask_dn_1: 0.02359  loss_dice_dn_1: 0.646  loss_bbox_dn_1: 0.04886  loss_giou_dn_1: 0.3953  loss_ce_2: 1.145  loss_mask_2: 0.04138  loss_dice_2: 0.6061  loss_bbox_2: 0.08837  loss_giou_2: 0.5261  loss_ce_dn_2: 0.2663  loss_mask_dn_2: 0.02254  loss_dice_dn_2: 0.7514  loss_bbox_dn_2: 0.03847  loss_giou_dn_2: 0.3575  loss_ce_3: 1.145  loss_mask_3: 0.02865  loss_dice_3: 0.7832  loss_bbox_3: 0.06596  loss_giou_3: 0.4262  loss_ce_dn_3: 0.2429  loss_mask_dn_3: 0.0224  loss_dice_dn_3: 0.7193  loss_bbox_dn_3: 0.03401  loss_giou_dn_3: 0.3476  loss_ce_4: 0.9941  loss_mask_4: 0.03206  loss_dice_4: 0.8079  loss_bbox_4: 0.06329  loss_giou_4: 0.4073  loss_ce_dn_4: 0.2185  loss_mask_dn_4: 0.02363  loss_dice_dn_4: 0.7819  loss_bbox_dn_4: 0.03384  loss_giou_dn_4: 0.3501  loss_ce_5: 1.01  loss_mask_5: 0.03229  loss_dice_5: 0.641  loss_bbox_5: 0.05771  loss_giou_5: 0.4042  loss_ce_dn_5: 0.2209  loss_mask_dn_5: 0.02212  loss_dice_dn_5: 0.7261  loss_bbox_dn_5: 0.02948  loss_giou_dn_5: 0.3544  loss_ce_6: 0.987  loss_mask_6: 0.03676  loss_dice_6: 0.7065  loss_bbox_6: 0.06435  loss_giou_6: 0.3964  loss_ce_dn_6: 0.2056  loss_mask_dn_6: 0.02093  loss_dice_dn_6: 0.7727  loss_bbox_dn_6: 0.03007  loss_giou_dn_6: 0.3525  loss_ce_7: 1.014  loss_mask_7: 0.0328  loss_dice_7: 0.6442  loss_bbox_7: 0.06731  loss_giou_7: 0.4202  loss_ce_dn_7: 0.1994  loss_mask_dn_7: 0.02231  loss_dice_dn_7: 0.7229  loss_bbox_dn_7: 0.03033  loss_giou_dn_7: 0.3386  loss_ce_8: 0.9767  loss_mask_8: 0.033  loss_dice_8: 0.7454  loss_bbox_8: 0.05289  loss_giou_8: 0.3758  loss_ce_dn_8: 0.2  loss_mask_dn_8: 0.02246  loss_dice_dn_8: 0.7566  loss_bbox_dn_8: 0.03077  loss_giou_dn_8: 0.3379  loss_ce_interm: 1.282  loss_mask_interm: 0.04656  loss_dice_interm: 1.003  loss_bbox_interm: 0.0943  loss_giou_interm: 0.5534  time: 1.8184  data_time: 0.0929  lr: 1e-06  max_mem: 6663M\n",
            "[05/20 19:27:34 d2.utils.events]:  eta: 0:00:12  iter: 5739  total_loss: 33.53  loss_ce: 0.8581  loss_mask: 0.04859  loss_dice: 0.3475  loss_bbox: 0.05683  loss_giou: 0.2604  loss_ce_dn: 0.2074  loss_mask_dn: 0.03587  loss_dice_dn: 0.3433  loss_bbox_dn: 0.04746  loss_giou_dn: 0.2471  loss_ce_0: 1.117  loss_mask_0: 0.04959  loss_dice_0: 0.5209  loss_bbox_0: 0.05566  loss_giou_0: 0.2901  loss_ce_dn_0: 0.6443  loss_mask_dn_0: 0.251  loss_dice_dn_0: 2.298  loss_bbox_dn_0: 0.3391  loss_giou_dn_0: 0.8597  loss_ce_1: 1.248  loss_mask_1: 0.05272  loss_dice_1: 0.2946  loss_bbox_1: 0.05501  loss_giou_1: 0.2393  loss_ce_dn_1: 0.3047  loss_mask_dn_1: 0.03786  loss_dice_dn_1: 0.3353  loss_bbox_dn_1: 0.08389  loss_giou_dn_1: 0.3243  loss_ce_2: 0.9907  loss_mask_2: 0.03963  loss_dice_2: 0.3374  loss_bbox_2: 0.05728  loss_giou_2: 0.2724  loss_ce_dn_2: 0.2734  loss_mask_dn_2: 0.03303  loss_dice_dn_2: 0.3348  loss_bbox_dn_2: 0.06202  loss_giou_dn_2: 0.2629  loss_ce_3: 0.9071  loss_mask_3: 0.04879  loss_dice_3: 0.3264  loss_bbox_3: 0.05889  loss_giou_3: 0.2776  loss_ce_dn_3: 0.2343  loss_mask_dn_3: 0.03535  loss_dice_dn_3: 0.3426  loss_bbox_dn_3: 0.04969  loss_giou_dn_3: 0.2509  loss_ce_4: 0.8585  loss_mask_4: 0.04786  loss_dice_4: 0.3669  loss_bbox_4: 0.05706  loss_giou_4: 0.2791  loss_ce_dn_4: 0.2213  loss_mask_dn_4: 0.03418  loss_dice_dn_4: 0.3322  loss_bbox_dn_4: 0.04891  loss_giou_dn_4: 0.2413  loss_ce_5: 0.8821  loss_mask_5: 0.04584  loss_dice_5: 0.3696  loss_bbox_5: 0.05699  loss_giou_5: 0.2344  loss_ce_dn_5: 0.216  loss_mask_dn_5: 0.03569  loss_dice_dn_5: 0.3325  loss_bbox_dn_5: 0.04527  loss_giou_dn_5: 0.2421  loss_ce_6: 0.8554  loss_mask_6: 0.04501  loss_dice_6: 0.3311  loss_bbox_6: 0.05777  loss_giou_6: 0.2374  loss_ce_dn_6: 0.2142  loss_mask_dn_6: 0.03325  loss_dice_dn_6: 0.3353  loss_bbox_dn_6: 0.04499  loss_giou_dn_6: 0.2458  loss_ce_7: 0.8524  loss_mask_7: 0.04329  loss_dice_7: 0.3131  loss_bbox_7: 0.05716  loss_giou_7: 0.236  loss_ce_dn_7: 0.2076  loss_mask_dn_7: 0.03474  loss_dice_dn_7: 0.3405  loss_bbox_dn_7: 0.04214  loss_giou_dn_7: 0.2429  loss_ce_8: 0.8575  loss_mask_8: 0.05248  loss_dice_8: 0.3035  loss_bbox_8: 0.05563  loss_giou_8: 0.2385  loss_ce_dn_8: 0.2139  loss_mask_dn_8: 0.03679  loss_dice_dn_8: 0.332  loss_bbox_dn_8: 0.04709  loss_giou_dn_8: 0.2472  loss_ce_interm: 1.093  loss_mask_interm: 0.04979  loss_dice_interm: 0.4367  loss_bbox_interm: 0.124  loss_giou_interm: 0.3648  time: 1.8180  data_time: 0.0805  lr: 1e-06  max_mem: 6663M\n",
            "[05/20 19:27:51 d2.utils.events]:  eta: 0:00:00  iter: 5747  total_loss: 38.89  loss_ce: 1.008  loss_mask: 0.03223  loss_dice: 0.4349  loss_bbox: 0.06124  loss_giou: 0.3111  loss_ce_dn: 0.211  loss_mask_dn: 0.03104  loss_dice_dn: 0.5489  loss_bbox_dn: 0.04297  loss_giou_dn: 0.2727  loss_ce_0: 1.182  loss_mask_0: 0.03999  loss_dice_0: 0.616  loss_bbox_0: 0.06856  loss_giou_0: 0.3673  loss_ce_dn_0: 0.6996  loss_mask_dn_0: 0.1811  loss_dice_dn_0: 2.789  loss_bbox_dn_0: 0.2422  loss_giou_dn_0: 0.8577  loss_ce_1: 1.352  loss_mask_1: 0.03864  loss_dice_1: 0.4407  loss_bbox_1: 0.07243  loss_giou_1: 0.3557  loss_ce_dn_1: 0.2712  loss_mask_dn_1: 0.02927  loss_dice_dn_1: 0.4816  loss_bbox_dn_1: 0.06294  loss_giou_dn_1: 0.348  loss_ce_2: 1.045  loss_mask_2: 0.02966  loss_dice_2: 0.3719  loss_bbox_2: 0.06424  loss_giou_2: 0.3454  loss_ce_dn_2: 0.2452  loss_mask_dn_2: 0.02928  loss_dice_dn_2: 0.4957  loss_bbox_dn_2: 0.05582  loss_giou_dn_2: 0.3096  loss_ce_3: 0.9688  loss_mask_3: 0.03193  loss_dice_3: 0.4069  loss_bbox_3: 0.07825  loss_giou_3: 0.3663  loss_ce_dn_3: 0.2368  loss_mask_dn_3: 0.02992  loss_dice_dn_3: 0.4782  loss_bbox_dn_3: 0.04455  loss_giou_dn_3: 0.2872  loss_ce_4: 1.02  loss_mask_4: 0.0346  loss_dice_4: 0.4363  loss_bbox_4: 0.07527  loss_giou_4: 0.3389  loss_ce_dn_4: 0.2172  loss_mask_dn_4: 0.0276  loss_dice_dn_4: 0.4811  loss_bbox_dn_4: 0.04445  loss_giou_dn_4: 0.2766  loss_ce_5: 0.9909  loss_mask_5: 0.03946  loss_dice_5: 0.3852  loss_bbox_5: 0.06707  loss_giou_5: 0.2873  loss_ce_dn_5: 0.2165  loss_mask_dn_5: 0.02995  loss_dice_dn_5: 0.4711  loss_bbox_dn_5: 0.04527  loss_giou_dn_5: 0.2818  loss_ce_6: 0.9453  loss_mask_6: 0.03791  loss_dice_6: 0.3539  loss_bbox_6: 0.06541  loss_giou_6: 0.2806  loss_ce_dn_6: 0.2142  loss_mask_dn_6: 0.02805  loss_dice_dn_6: 0.4448  loss_bbox_dn_6: 0.04457  loss_giou_dn_6: 0.2799  loss_ce_7: 0.9925  loss_mask_7: 0.03767  loss_dice_7: 0.3298  loss_bbox_7: 0.06385  loss_giou_7: 0.2734  loss_ce_dn_7: 0.2142  loss_mask_dn_7: 0.0308  loss_dice_dn_7: 0.4868  loss_bbox_dn_7: 0.04214  loss_giou_dn_7: 0.273  loss_ce_8: 0.9933  loss_mask_8: 0.03772  loss_dice_8: 0.4205  loss_bbox_8: 0.06088  loss_giou_8: 0.2804  loss_ce_dn_8: 0.2167  loss_mask_dn_8: 0.03183  loss_dice_dn_8: 0.4917  loss_bbox_dn_8: 0.04299  loss_giou_dn_8: 0.2747  loss_ce_interm: 1.266  loss_mask_interm: 0.04147  loss_dice_interm: 0.5557  loss_bbox_interm: 0.09296  loss_giou_interm: 0.3641  time: 1.8177  data_time: 0.0559  lr: 1e-06  max_mem: 6663M\n",
            "[05/20 19:27:52 d2.engine.hooks]: Overall training speed: 5746 iterations in 2:54:04 (1.8177 s / it)\n",
            "[05/20 19:27:52 d2.engine.hooks]: Total training time: 3:18:23 (0:24:18 on hooks)\n",
            "[05/20 19:27:52 d2.data.datasets.coco]: Loaded 150 images in COCO format from /content/TACO-expl/data/annotations_off_0_resval.json\n",
            "[05/20 19:27:52 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "[05/20 19:27:52 d2.data.common]: Serializing 150 elements to byte tensors and concatenating them all ...\n",
            "[05/20 19:27:52 d2.data.common]: Serialized dataset takes 0.21 MiB\n",
            "WARNING [05/20 19:27:52 d2.evaluation.coco_evaluation]: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
            "[05/20 19:27:52 d2.evaluation.evaluator]: Start inference on 150 batches\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1066, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1066, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1066, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1066])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 19:28:01 d2.evaluation.evaluator]: Inference done 11/150. Dataloading: 0.0018 s/iter. Inference: 0.2812 s/iter. Eval: 0.4677 s/iter. Total: 0.7508 s/iter. ETA=0:01:44\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 608])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 608])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 608])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1200])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 750])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 19:28:07 d2.evaluation.evaluator]: Inference done 18/150. Dataloading: 0.0023 s/iter. Inference: 0.2851 s/iter. Eval: 0.4950 s/iter. Total: 0.7826 s/iter. ETA=0:01:43\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 750])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 19:28:12 d2.evaluation.evaluator]: Inference done 23/150. Dataloading: 0.0031 s/iter. Inference: 0.2992 s/iter. Eval: 0.5425 s/iter. Total: 0.8453 s/iter. ETA=0:01:47\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([750, 1333])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 750])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([750, 1333])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 750])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 19:28:17 d2.evaluation.evaluator]: Inference done 30/150. Dataloading: 0.0030 s/iter. Inference: 0.3010 s/iter. Eval: 0.5344 s/iter. Total: 0.8389 s/iter. ETA=0:01:40\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 750])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 19:28:23 d2.evaluation.evaluator]: Inference done 37/150. Dataloading: 0.0032 s/iter. Inference: 0.2990 s/iter. Eval: 0.5296 s/iter. Total: 0.8322 s/iter. ETA=0:01:34\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 19:28:29 d2.evaluation.evaluator]: Inference done 43/150. Dataloading: 0.0046 s/iter. Inference: 0.3037 s/iter. Eval: 0.5462 s/iter. Total: 0.8550 s/iter. ETA=0:01:31\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 19:28:34 d2.evaluation.evaluator]: Inference done 50/150. Dataloading: 0.0043 s/iter. Inference: 0.3019 s/iter. Eval: 0.5355 s/iter. Total: 0.8423 s/iter. ETA=0:01:24\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 19:28:40 d2.evaluation.evaluator]: Inference done 57/150. Dataloading: 0.0041 s/iter. Inference: 0.2983 s/iter. Eval: 0.5298 s/iter. Total: 0.8326 s/iter. ETA=0:01:17\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 19:28:46 d2.evaluation.evaluator]: Inference done 63/150. Dataloading: 0.0040 s/iter. Inference: 0.3012 s/iter. Eval: 0.5412 s/iter. Total: 0.8470 s/iter. ETA=0:01:13\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 19:28:51 d2.evaluation.evaluator]: Inference done 70/150. Dataloading: 0.0039 s/iter. Inference: 0.2995 s/iter. Eval: 0.5361 s/iter. Total: 0.8400 s/iter. ETA=0:01:07\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([852, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 19:28:56 d2.evaluation.evaluator]: Inference done 77/150. Dataloading: 0.0037 s/iter. Inference: 0.2965 s/iter. Eval: 0.5283 s/iter. Total: 0.8290 s/iter. ETA=0:01:00\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 19:29:02 d2.evaluation.evaluator]: Inference done 83/150. Dataloading: 0.0038 s/iter. Inference: 0.2977 s/iter. Eval: 0.5360 s/iter. Total: 0.8381 s/iter. ETA=0:00:56\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 19:29:08 d2.evaluation.evaluator]: Inference done 90/150. Dataloading: 0.0037 s/iter. Inference: 0.2971 s/iter. Eval: 0.5339 s/iter. Total: 0.8352 s/iter. ETA=0:00:50\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 19:29:13 d2.evaluation.evaluator]: Inference done 97/150. Dataloading: 0.0037 s/iter. Inference: 0.2954 s/iter. Eval: 0.5295 s/iter. Total: 0.8291 s/iter. ETA=0:00:43\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 19:29:18 d2.evaluation.evaluator]: Inference done 103/150. Dataloading: 0.0039 s/iter. Inference: 0.2969 s/iter. Eval: 0.5351 s/iter. Total: 0.8364 s/iter. ETA=0:00:39\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 19:29:24 d2.evaluation.evaluator]: Inference done 110/150. Dataloading: 0.0039 s/iter. Inference: 0.2963 s/iter. Eval: 0.5343 s/iter. Total: 0.8350 s/iter. ETA=0:00:33\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 19:29:29 d2.evaluation.evaluator]: Inference done 117/150. Dataloading: 0.0038 s/iter. Inference: 0.2947 s/iter. Eval: 0.5300 s/iter. Total: 0.8289 s/iter. ETA=0:00:27\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 19:29:35 d2.evaluation.evaluator]: Inference done 123/150. Dataloading: 0.0041 s/iter. Inference: 0.2950 s/iter. Eval: 0.5336 s/iter. Total: 0.8332 s/iter. ETA=0:00:22\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 19:29:41 d2.evaluation.evaluator]: Inference done 130/150. Dataloading: 0.0042 s/iter. Inference: 0.2945 s/iter. Eval: 0.5330 s/iter. Total: 0.8322 s/iter. ETA=0:00:16\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 750])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 750])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 19:29:46 d2.evaluation.evaluator]: Inference done 137/150. Dataloading: 0.0042 s/iter. Inference: 0.2939 s/iter. Eval: 0.5308 s/iter. Total: 0.8294 s/iter. ETA=0:00:10\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 750])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 19:29:52 d2.evaluation.evaluator]: Inference done 143/150. Dataloading: 0.0041 s/iter. Inference: 0.2950 s/iter. Eval: 0.5348 s/iter. Total: 0.8344 s/iter. ETA=0:00:05\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([800, 1067])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1067, 800])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 608])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 608])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 608])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "________THE IMAGE SIZE IS:________\n",
            "torch.Size([1333, 608])\n",
            "__________________________________\n",
            "torch.Size([300, 10])\n",
            "__________________________________\n",
            "torch.Size([300, 4])\n",
            "__________________________________\n",
            "[05/20 19:29:57 d2.evaluation.evaluator]: Inference done 150/150. Dataloading: 0.0041 s/iter. Inference: 0.2950 s/iter. Eval: 0.5335 s/iter. Total: 0.8331 s/iter. ETA=0:00:00\n",
            "[05/20 19:29:57 d2.evaluation.evaluator]: Total inference time: 0:02:00.865656 (0.833556 s / iter per device, on 1 devices)\n",
            "[05/20 19:29:57 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:42 (0.295019 s / iter per device, on 1 devices)\n",
            "[05/20 19:29:58 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...\n",
            "[05/20 19:29:58 d2.evaluation.coco_evaluation]: Saving results to /content/output/chkpt/inference/coco_instances_results.json\n",
            "[05/20 19:29:58 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "[05/20 19:29:58 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*\n",
            "[05/20 19:29:58 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.17 seconds.\n",
            "[05/20 19:29:58 d2.evaluation.fast_eval_api]: Accumulating evaluation results...\n",
            "[05/20 19:29:58 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.07 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.246\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.418\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.248\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.058\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.248\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.430\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.332\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.438\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.447\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.105\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.489\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.796\n",
            "[05/20 19:29:58 d2.evaluation.coco_evaluation]: Evaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
            "| 24.598 | 41.764 | 24.810 | 5.847 | 24.764 | 42.986 |\n",
            "[05/20 19:29:58 d2.evaluation.coco_evaluation]: Per-category bbox AP: \n",
            "| category   | AP     | category              | AP     | category   | AP     |\n",
            "|:-----------|:-------|:----------------------|:-------|:-----------|:-------|\n",
            "| Bottle     | 53.563 | Bottle cap            | 13.224 | Can        | 44.099 |\n",
            "| Cigarette  | 2.654  | Cup                   | 30.789 | Lid        | 34.744 |\n",
            "| Other      | 20.530 | Plastic bag & wrapper | 22.084 | Pop tab    | 8.939  |\n",
            "| Straw      | 15.355 |                       |        |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.17s)\n",
            "creating index...\n",
            "index created!\n",
            "[05/20 19:29:59 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*\n",
            "[05/20 19:29:59 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.25 seconds.\n",
            "[05/20 19:29:59 d2.evaluation.fast_eval_api]: Accumulating evaluation results...\n",
            "[05/20 19:29:59 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.07 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.394\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.512\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.401\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.247\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.468\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.534\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.468\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.647\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.665\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.416\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.750\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.835\n",
            "[05/20 19:29:59 d2.evaluation.coco_evaluation]: Evaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 39.390 | 51.157 | 40.099 | 24.702 | 46.771 | 53.445 |\n",
            "[05/20 19:29:59 d2.evaluation.coco_evaluation]: Per-category segm AP: \n",
            "| category   | AP     | category              | AP     | category   | AP     |\n",
            "|:-----------|:-------|:----------------------|:-------|:-----------|:-------|\n",
            "| Bottle     | 74.198 | Bottle cap            | 40.677 | Can        | 57.067 |\n",
            "| Cigarette  | 20.393 | Cup                   | 42.946 | Lid        | 46.221 |\n",
            "| Other      | 30.715 | Plastic bag & wrapper | 35.372 | Pop tab    | 26.907 |\n",
            "| Straw      | 19.400 |                       |        |            |        |\n",
            "[05/20 19:29:59 d2.engine.defaults]: Evaluation results for TACO_val in csv format:\n",
            "[05/20 19:29:59 d2.evaluation.testing]: copypaste: Task: bbox\n",
            "[05/20 19:29:59 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl\n",
            "[05/20 19:29:59 d2.evaluation.testing]: copypaste: 24.5980,41.7637,24.8105,5.8468,24.7635,42.9855\n",
            "[05/20 19:29:59 d2.evaluation.testing]: copypaste: Task: segm\n",
            "[05/20 19:29:59 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl\n",
            "[05/20 19:29:59 d2.evaluation.testing]: copypaste: 39.3896,51.1568,40.0989,24.7023,46.7714,53.4449\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir(\"/content/output/chkpt/\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k52BU8K6lr0d",
        "outputId": "ad2ceed6-e3c5-4595-9a84-1b34cd0ded62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['model_0001915.pth',\n",
              " 'model_0003831.pth',\n",
              " 'model_final.pth',\n",
              " 'events.out.tfevents.1715969610.7688afa66bed.3673.0',\n",
              " 'model_0002873.pth',\n",
              " 'model_0001436.pth',\n",
              " 'model_0005268.pth',\n",
              " 'model_0003352.pth',\n",
              " 'model_0002394.pth',\n",
              " 'metrics.json',\n",
              " 'inference',\n",
              " 'model_0000957.pth',\n",
              " 'model_0004789.pth',\n",
              " 'model_0000478.pth',\n",
              " 'events.out.tfevents.1715971997.7688afa66bed.12409.0',\n",
              " 'model_0005747.pth',\n",
              " 'last_checkpoint',\n",
              " 'model_0004310.pth']"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"/content/output/chkpt/model_final.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "U40BT_ZWl9aQ",
        "outputId": "97596cf7-6445-4e61-a672-90db3b122bbb"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_db4336fc-106c-4b63-8401-e7887ec1030d\", \"model_final.pth\", 514930329)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"/content/output/chkpt/model_0005747.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "QRFnoHynmEO0",
        "outputId": "7c686e67-3693-4d72-8a8e-f35db3e556c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_57268a68-6ef3-4a51-9ca7-d105986a2fa9\", \"model_0005747.pth\", 338740336)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"/content/output/chkpt/model_0005268.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "YBVOhOcMmNOv",
        "outputId": "71572da3-e2f0-46ff-fac4-2a56783275d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c4852b3c-f25e-42ad-b692-ce03ae6ddd74\", \"model_0005268.pth\", 338740336)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"/content/output/chkpt/last_checkpoint\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "hqpMaY0FpYwC",
        "outputId": "b6162f2b-d4a8-4997-d12f-cc0c3ddbc3e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_e867470e-a403-432e-a649-c9dd7abc9574\", \"last_checkpoint\", 15)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run this if you want to check how many trainable parameters we have"
      ],
      "metadata": {
        "id": "0JVZhhKDFYpo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from detectron2.modeling import build_model\n",
        "model = build_model(train_cfg_loaded)\n",
        "num_trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(num_trainable_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZljjMBcCFLtJ",
        "outputId": "52e790a5-9e9c-448d-9ecd-242ec3da4291"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "criterion.weight_dict  {'loss_ce': 4.0, 'loss_mask': 5.0, 'loss_dice': 5.0, 'loss_bbox': 5.0, 'loss_giou': 2.0, 'loss_ce_interm': 4.0, 'loss_mask_interm': 5.0, 'loss_dice_interm': 5.0, 'loss_bbox_interm': 5.0, 'loss_giou_interm': 2.0, 'loss_ce_dn': 4.0, 'loss_mask_dn': 5.0, 'loss_dice_dn': 5.0, 'loss_bbox_dn': 5.0, 'loss_giou_dn': 2.0, 'loss_ce_interm_dn': 4.0, 'loss_mask_interm_dn': 5.0, 'loss_dice_interm_dn': 5.0, 'loss_bbox_interm_dn': 5.0, 'loss_giou_interm_dn': 2.0, 'loss_ce_0': 4.0, 'loss_mask_0': 5.0, 'loss_dice_0': 5.0, 'loss_bbox_0': 5.0, 'loss_giou_0': 2.0, 'loss_ce_interm_0': 4.0, 'loss_mask_interm_0': 5.0, 'loss_dice_interm_0': 5.0, 'loss_bbox_interm_0': 5.0, 'loss_giou_interm_0': 2.0, 'loss_ce_dn_0': 4.0, 'loss_mask_dn_0': 5.0, 'loss_dice_dn_0': 5.0, 'loss_bbox_dn_0': 5.0, 'loss_giou_dn_0': 2.0, 'loss_ce_interm_dn_0': 4.0, 'loss_mask_interm_dn_0': 5.0, 'loss_dice_interm_dn_0': 5.0, 'loss_bbox_interm_dn_0': 5.0, 'loss_giou_interm_dn_0': 2.0, 'loss_ce_1': 4.0, 'loss_mask_1': 5.0, 'loss_dice_1': 5.0, 'loss_bbox_1': 5.0, 'loss_giou_1': 2.0, 'loss_ce_interm_1': 4.0, 'loss_mask_interm_1': 5.0, 'loss_dice_interm_1': 5.0, 'loss_bbox_interm_1': 5.0, 'loss_giou_interm_1': 2.0, 'loss_ce_dn_1': 4.0, 'loss_mask_dn_1': 5.0, 'loss_dice_dn_1': 5.0, 'loss_bbox_dn_1': 5.0, 'loss_giou_dn_1': 2.0, 'loss_ce_interm_dn_1': 4.0, 'loss_mask_interm_dn_1': 5.0, 'loss_dice_interm_dn_1': 5.0, 'loss_bbox_interm_dn_1': 5.0, 'loss_giou_interm_dn_1': 2.0, 'loss_ce_2': 4.0, 'loss_mask_2': 5.0, 'loss_dice_2': 5.0, 'loss_bbox_2': 5.0, 'loss_giou_2': 2.0, 'loss_ce_interm_2': 4.0, 'loss_mask_interm_2': 5.0, 'loss_dice_interm_2': 5.0, 'loss_bbox_interm_2': 5.0, 'loss_giou_interm_2': 2.0, 'loss_ce_dn_2': 4.0, 'loss_mask_dn_2': 5.0, 'loss_dice_dn_2': 5.0, 'loss_bbox_dn_2': 5.0, 'loss_giou_dn_2': 2.0, 'loss_ce_interm_dn_2': 4.0, 'loss_mask_interm_dn_2': 5.0, 'loss_dice_interm_dn_2': 5.0, 'loss_bbox_interm_dn_2': 5.0, 'loss_giou_interm_dn_2': 2.0, 'loss_ce_3': 4.0, 'loss_mask_3': 5.0, 'loss_dice_3': 5.0, 'loss_bbox_3': 5.0, 'loss_giou_3': 2.0, 'loss_ce_interm_3': 4.0, 'loss_mask_interm_3': 5.0, 'loss_dice_interm_3': 5.0, 'loss_bbox_interm_3': 5.0, 'loss_giou_interm_3': 2.0, 'loss_ce_dn_3': 4.0, 'loss_mask_dn_3': 5.0, 'loss_dice_dn_3': 5.0, 'loss_bbox_dn_3': 5.0, 'loss_giou_dn_3': 2.0, 'loss_ce_interm_dn_3': 4.0, 'loss_mask_interm_dn_3': 5.0, 'loss_dice_interm_dn_3': 5.0, 'loss_bbox_interm_dn_3': 5.0, 'loss_giou_interm_dn_3': 2.0, 'loss_ce_4': 4.0, 'loss_mask_4': 5.0, 'loss_dice_4': 5.0, 'loss_bbox_4': 5.0, 'loss_giou_4': 2.0, 'loss_ce_interm_4': 4.0, 'loss_mask_interm_4': 5.0, 'loss_dice_interm_4': 5.0, 'loss_bbox_interm_4': 5.0, 'loss_giou_interm_4': 2.0, 'loss_ce_dn_4': 4.0, 'loss_mask_dn_4': 5.0, 'loss_dice_dn_4': 5.0, 'loss_bbox_dn_4': 5.0, 'loss_giou_dn_4': 2.0, 'loss_ce_interm_dn_4': 4.0, 'loss_mask_interm_dn_4': 5.0, 'loss_dice_interm_dn_4': 5.0, 'loss_bbox_interm_dn_4': 5.0, 'loss_giou_interm_dn_4': 2.0, 'loss_ce_5': 4.0, 'loss_mask_5': 5.0, 'loss_dice_5': 5.0, 'loss_bbox_5': 5.0, 'loss_giou_5': 2.0, 'loss_ce_interm_5': 4.0, 'loss_mask_interm_5': 5.0, 'loss_dice_interm_5': 5.0, 'loss_bbox_interm_5': 5.0, 'loss_giou_interm_5': 2.0, 'loss_ce_dn_5': 4.0, 'loss_mask_dn_5': 5.0, 'loss_dice_dn_5': 5.0, 'loss_bbox_dn_5': 5.0, 'loss_giou_dn_5': 2.0, 'loss_ce_interm_dn_5': 4.0, 'loss_mask_interm_dn_5': 5.0, 'loss_dice_interm_dn_5': 5.0, 'loss_bbox_interm_dn_5': 5.0, 'loss_giou_interm_dn_5': 2.0, 'loss_ce_6': 4.0, 'loss_mask_6': 5.0, 'loss_dice_6': 5.0, 'loss_bbox_6': 5.0, 'loss_giou_6': 2.0, 'loss_ce_interm_6': 4.0, 'loss_mask_interm_6': 5.0, 'loss_dice_interm_6': 5.0, 'loss_bbox_interm_6': 5.0, 'loss_giou_interm_6': 2.0, 'loss_ce_dn_6': 4.0, 'loss_mask_dn_6': 5.0, 'loss_dice_dn_6': 5.0, 'loss_bbox_dn_6': 5.0, 'loss_giou_dn_6': 2.0, 'loss_ce_interm_dn_6': 4.0, 'loss_mask_interm_dn_6': 5.0, 'loss_dice_interm_dn_6': 5.0, 'loss_bbox_interm_dn_6': 5.0, 'loss_giou_interm_dn_6': 2.0, 'loss_ce_7': 4.0, 'loss_mask_7': 5.0, 'loss_dice_7': 5.0, 'loss_bbox_7': 5.0, 'loss_giou_7': 2.0, 'loss_ce_interm_7': 4.0, 'loss_mask_interm_7': 5.0, 'loss_dice_interm_7': 5.0, 'loss_bbox_interm_7': 5.0, 'loss_giou_interm_7': 2.0, 'loss_ce_dn_7': 4.0, 'loss_mask_dn_7': 5.0, 'loss_dice_dn_7': 5.0, 'loss_bbox_dn_7': 5.0, 'loss_giou_dn_7': 2.0, 'loss_ce_interm_dn_7': 4.0, 'loss_mask_interm_dn_7': 5.0, 'loss_dice_interm_dn_7': 5.0, 'loss_bbox_interm_dn_7': 5.0, 'loss_giou_interm_dn_7': 2.0, 'loss_ce_8': 4.0, 'loss_mask_8': 5.0, 'loss_dice_8': 5.0, 'loss_bbox_8': 5.0, 'loss_giou_8': 2.0, 'loss_ce_interm_8': 4.0, 'loss_mask_interm_8': 5.0, 'loss_dice_interm_8': 5.0, 'loss_bbox_interm_8': 5.0, 'loss_giou_interm_8': 2.0, 'loss_ce_dn_8': 4.0, 'loss_mask_dn_8': 5.0, 'loss_dice_dn_8': 5.0, 'loss_bbox_dn_8': 5.0, 'loss_giou_dn_8': 2.0, 'loss_ce_interm_dn_8': 4.0, 'loss_mask_interm_dn_8': 5.0, 'loss_dice_interm_dn_8': 5.0, 'loss_bbox_interm_dn_8': 5.0, 'loss_giou_interm_dn_8': 2.0}\n",
            "20361524\n"
          ]
        }
      ]
    }
  ]
}
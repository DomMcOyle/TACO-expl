{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7pzTIxbXnL6S"
      },
      "outputs": [],
      "source": [
        "!nvcc --version\n",
        "!nvidia-smi\n",
        "import torch\n",
        "torch.__version__"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install 'git+https://github.com/facebookresearch/detectron2.git@5aeb252b194b93dc2879b4ac34bc51a31b5aee13'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "WGL4szW1o_UM",
        "outputId": "8049b151-a17d-475b-f12c-94e30d61c9d2"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/facebookresearch/detectron2.git@5aeb252b194b93dc2879b4ac34bc51a31b5aee13\n",
            "  Cloning https://github.com/facebookresearch/detectron2.git (to revision 5aeb252b194b93dc2879b4ac34bc51a31b5aee13) to /tmp/pip-req-build-obre19yr\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/detectron2.git /tmp/pip-req-build-obre19yr\n",
            "  Running command git rev-parse -q --verify 'sha^5aeb252b194b93dc2879b4ac34bc51a31b5aee13'\n",
            "  Running command git fetch -q https://github.com/facebookresearch/detectron2.git 5aeb252b194b93dc2879b4ac34bc51a31b5aee13\n",
            "  Running command git checkout -q 5aeb252b194b93dc2879b4ac34bc51a31b5aee13\n",
            "  Resolved https://github.com/facebookresearch/detectron2.git to commit 5aeb252b194b93dc2879b4ac34bc51a31b5aee13\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: Pillow>=7.1 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (9.4.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (3.7.1)\n",
            "Requirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (2.0.7)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (2.4.0)\n",
            "Collecting yacs>=0.1.8 (from detectron2==0.6)\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (0.9.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (2.2.1)\n",
            "Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (4.66.4)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (2.15.2)\n",
            "Collecting fvcore<0.1.6,>=0.1.5 (from detectron2==0.6)\n",
            "  Downloading fvcore-0.1.5.post20221221.tar.gz (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting iopath<0.1.10,>=0.1.7 (from detectron2==0.6)\n",
            "  Downloading iopath-0.1.9-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (0.18.3)\n",
            "Requirement already satisfied: pydot in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (1.4.2)\n",
            "Collecting omegaconf>=2.1 (from detectron2==0.6)\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting hydra-core>=1.1 (from detectron2==0.6)\n",
            "  Downloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting black==22.3.0 (from detectron2==0.6)\n",
            "  Downloading black-22.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting timm (from detectron2==0.6)\n",
            "  Downloading timm-1.0.3-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m37.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fairscale (from detectron2==0.6)\n",
            "  Downloading fairscale-0.4.13.tar.gz (266 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m266.3/266.3 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (24.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from black==22.3.0->detectron2==0.6) (8.1.7)\n",
            "Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.10/dist-packages (from black==22.3.0->detectron2==0.6) (4.2.1)\n",
            "Collecting pathspec>=0.9.0 (from black==22.3.0->detectron2==0.6)\n",
            "  Downloading pathspec-0.12.1-py3-none-any.whl (31 kB)\n",
            "Collecting mypy-extensions>=0.4.3 (from black==22.3.0->detectron2==0.6)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from black==22.3.0->detectron2==0.6) (2.0.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (1.25.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (6.0.1)\n",
            "Collecting antlr4-python3-runtime==4.9.* (from hydra-core>=1.1->detectron2==0.6)\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting portalocker (from iopath<0.1.10,>=0.1.7->detectron2==0.6)\n",
            "  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (2.8.2)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from fairscale->detectron2==0.6) (2.2.1+cu121)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (1.63.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (3.6)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (2.31.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (67.7.2)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (3.0.3)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm->detectron2==0.6) (0.17.1+cu121)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (from timm->detectron2==0.6) (0.20.3)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm->detectron2==0.6) (0.4.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard->detectron2==0.6) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (2024.2.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->fairscale->detectron2==0.6) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->fairscale->detectron2==0.6) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->fairscale->detectron2==0.6) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->fairscale->detectron2==0.6) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->fairscale->detectron2==0.6) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->fairscale->detectron2==0.6) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.8.0->fairscale->detectron2==0.6)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.8.0->fairscale->detectron2==0.6)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.8.0->fairscale->detectron2==0.6)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.8.0->fairscale->detectron2==0.6)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.8.0->fairscale->detectron2==0.6)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.8.0->fairscale->detectron2==0.6)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.8.0->fairscale->detectron2==0.6)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.8.0->fairscale->detectron2==0.6)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.8.0->fairscale->detectron2==0.6)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch>=1.8.0->fairscale->detectron2==0.6)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.8.0->fairscale->detectron2==0.6)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->fairscale->detectron2==0.6) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.0->fairscale->detectron2==0.6)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard->detectron2==0.6) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard->detectron2==0.6) (3.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->fairscale->detectron2==0.6) (1.3.0)\n",
            "Building wheels for collected packages: detectron2, fvcore, antlr4-python3-runtime, fairscale\n",
            "  Building wheel for detectron2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for detectron2: filename=detectron2-0.6-cp310-cp310-linux_x86_64.whl size=5792609 sha256=05611ad4d77ae089f3bb79c2c32ceb2c3f8b29515733478308aad72906709204\n",
            "  Stored in directory: /root/.cache/pip/wheels/93/68/da/76b0102912a9ea75cda929a4556a3eb0e5377b1d1ce0a79940\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fvcore: filename=fvcore-0.1.5.post20221221-py3-none-any.whl size=61400 sha256=6a07458d6cef860ea8ac7e3fa0475f087cdac1bdb949238e32899085512ba54c\n",
            "  Stored in directory: /root/.cache/pip/wheels/01/c0/af/77c1cf53a1be9e42a52b48e5af2169d40ec2e89f7362489dd0\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=44681babb56cfc579c233be96e81cd2d1add1e191b59062b50aad86e3a77e73f\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n",
            "  Building wheel for fairscale (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fairscale: filename=fairscale-0.4.13-py3-none-any.whl size=332108 sha256=dba1c1a23ba22d963bd19da88129d9c6710c9776f4527f35c4441f3745e46061\n",
            "  Stored in directory: /root/.cache/pip/wheels/78/a4/c0/fb0a7ef03cff161611c3fa40c6cf898f76e58ec421b88e8cb3\n",
            "Successfully built detectron2 fvcore antlr4-python3-runtime fairscale\n",
            "Installing collected packages: antlr4-python3-runtime, yacs, portalocker, pathspec, omegaconf, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, mypy-extensions, nvidia-cusparse-cu12, nvidia-cudnn-cu12, iopath, hydra-core, black, nvidia-cusolver-cu12, fvcore, fairscale, timm, detectron2\n",
            "Successfully installed antlr4-python3-runtime-4.9.3 black-22.3.0 detectron2-0.6 fairscale-0.4.13 fvcore-0.1.5.post20221221 hydra-core-1.3.2 iopath-0.1.9 mypy-extensions-1.0.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 omegaconf-2.3.0 pathspec-0.12.1 portalocker-2.8.2 timm-1.0.3 yacs-0.1.8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pydevd_plugins"
                ]
              },
              "id": "59f50091941845f6ba2ec3da5d3689d6"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/\n",
        "!git clone https://github.com/DomMcOyle/TACO-expl.git\n",
        "%cd /content/TACO-expl\n",
        "!git checkout maskdino\n",
        "!git pull origin maskdino"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eNqUmCxBPkgp",
        "outputId": "e82a336a-7095-4188-9b43-f3e2acf986ea"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "fatal: destination path 'TACO-expl' already exists and is not an empty directory.\n",
            "/content/TACO-expl\n",
            "Already on 'maskdino'\n",
            "Your branch is up to date with 'origin/maskdino'.\n",
            "From https://github.com/DomMcOyle/TACO-expl\n",
            " * branch            maskdino   -> FETCH_HEAD\n",
            "Already up to date.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/TACO-expl/MaskDINO\n",
        "!pip install -r requirements.txt\n",
        "%cd /content/TACO-expl/MaskDINO/maskdino/modeling/pixel_decoder/ops\n",
        "!sh make.sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X9P0HDTGnRDI",
        "outputId": "4211d3f2-f377-406b-8003-09abab14eecc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/TACO-expl/MaskDINO\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (3.0.10)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (1.11.4)\n",
            "Requirement already satisfied: shapely in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (2.0.4)\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (1.0.3)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (3.9.0)\n",
            "Collecting submitit (from -r requirements.txt (line 6))\n",
            "  Downloading submitit-1.5.1-py3-none-any.whl (74 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.7/74.7 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (0.19.3)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (4.8.0.76)\n",
            "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy->-r requirements.txt (line 2)) (1.25.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from timm->-r requirements.txt (line 4)) (2.2.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm->-r requirements.txt (line 4)) (0.17.1+cu121)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm->-r requirements.txt (line 4)) (6.0.1)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (from timm->-r requirements.txt (line 4)) (0.20.3)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm->-r requirements.txt (line 4)) (0.4.3)\n",
            "Requirement already satisfied: cloudpickle>=1.2.1 in /usr/local/lib/python3.10/dist-packages (from submitit->-r requirements.txt (line 6)) (2.2.1)\n",
            "Requirement already satisfied: typing_extensions>=3.7.4.2 in /usr/local/lib/python3.10/dist-packages (from submitit->-r requirements.txt (line 6)) (4.11.0)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image->-r requirements.txt (line 7)) (3.3)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->-r requirements.txt (line 7)) (9.4.0)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->-r requirements.txt (line 7)) (2.31.6)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->-r requirements.txt (line 7)) (2024.5.10)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->-r requirements.txt (line 7)) (1.6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->-r requirements.txt (line 7)) (24.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm->-r requirements.txt (line 4)) (3.14.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm->-r requirements.txt (line 4)) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm->-r requirements.txt (line 4)) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm->-r requirements.txt (line 4)) (4.66.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->timm->-r requirements.txt (line 4)) (1.12)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->timm->-r requirements.txt (line 4)) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->timm->-r requirements.txt (line 4)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->timm->-r requirements.txt (line 4)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->timm->-r requirements.txt (line 4)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->timm->-r requirements.txt (line 4)) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->timm->-r requirements.txt (line 4)) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->timm->-r requirements.txt (line 4)) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->timm->-r requirements.txt (line 4)) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->timm->-r requirements.txt (line 4)) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->timm->-r requirements.txt (line 4)) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch->timm->-r requirements.txt (line 4)) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->timm->-r requirements.txt (line 4)) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->timm->-r requirements.txt (line 4)) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->timm->-r requirements.txt (line 4)) (12.4.127)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->timm->-r requirements.txt (line 4)) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm->-r requirements.txt (line 4)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm->-r requirements.txt (line 4)) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm->-r requirements.txt (line 4)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm->-r requirements.txt (line 4)) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->timm->-r requirements.txt (line 4)) (1.3.0)\n",
            "Installing collected packages: submitit\n",
            "Successfully installed submitit-1.5.1\n",
            "/content/TACO-expl/MaskDINO/maskdino/modeling/pixel_decoder/ops\n",
            "No CUDA runtime is found, using CUDA_HOME='/usr/local/cuda'\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/TACO-expl/MaskDINO/maskdino/modeling/pixel_decoder/ops/setup.py\", line 76, in <module>\n",
            "    ext_modules=get_extensions(),\n",
            "  File \"/content/TACO-expl/MaskDINO/maskdino/modeling/pixel_decoder/ops/setup.py\", line 54, in get_extensions\n",
            "    raise NotImplementedError('No CUDA runtime is found. Please set FORCE_CUDA=1 or test it by running torch.cuda.is_available().')\n",
            "NotImplementedError: No CUDA runtime is found. Please set FORCE_CUDA=1 or test it by running torch.cuda.is_available().\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/MyDrive/\", force_remount = True)"
      ],
      "metadata": {
        "id": "yKG8tycQnkyb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3fe7824-3078-4f01-a50f-1fe9696d46a3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/MyDrive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os, json, cv2, random"
      ],
      "metadata": {
        "id": "tGO4a4xoP6ZE"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ijdCQoDbP9Oh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/\n",
        "# Some basic setup:\n",
        "# Setup detectron2 logger\n",
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "\n",
        "# import some common libraries\n",
        "import numpy as np\n",
        "import os, json, cv2, random\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# import some common detectron2 utilities\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog, DatasetCatalog"
      ],
      "metadata": {
        "id": "LfdhgozHnZpe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "178ffcf9-22ec-4dd2-f03b-6375fa7c9e69"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/TACO-expl/\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "import os.path\n",
        "import json\n",
        "import argparse\n",
        "import numpy as np\n",
        "import random\n",
        "import datetime as dt\n",
        "import copy\n",
        "import torch.nn as nn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from pathlib import Path\n",
        "\n",
        "import torch\n",
        "import math\n",
        "import torch.utils.data\n",
        "from torch.utils.data import DataLoader\n",
        "from pycocotools import mask as coco_mask"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oEpIySaFnprv",
        "outputId": "5d9042b3-9277-43f9-d38f-022a7b0cb3c7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/TACO-expl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DEFAULT_RANDOM_SEED = 42\n",
        "# basic random seed\n",
        "def seedBasic(seed=DEFAULT_RANDOM_SEED):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "# torch random seed\n",
        "def seedTorch(seed=DEFAULT_RANDOM_SEED):\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "# combine\n",
        "def seedEverything(seed=DEFAULT_RANDOM_SEED):\n",
        "    seedBasic(seed)\n",
        "    seedTorch(seed)\n",
        "\n",
        "seedEverything()"
      ],
      "metadata": {
        "id": "gHfxVrm3nrzg"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keep_categories = [\"Bottle\", \"Bottle cap\", \"Can\", \"Cigarette\", \"Cup\",\n",
        "                   \"Lid\", \"Plastic bag & wrapper\", \"Pop tab\", \"Straw\"]\n",
        "\n",
        "def create_map(original, keep_supercategories):\n",
        "  class_map = {}\n",
        "  for cat in original:\n",
        "    if cat[\"supercategory\"] in keep_supercategories:\n",
        "      class_map[cat[\"name\"]] = cat[\"supercategory\"]\n",
        "    else:\n",
        "      class_map[cat[\"name\"]] = \"Other\"\n",
        "  return class_map\n",
        "\n",
        "def replace_dataset_classes(dataset, class_map):\n",
        "      \"\"\" Replaces classes of dataset based on a dictionary\"\"\"\n",
        "      class_new_names = list(set(class_map.values()))\n",
        "      class_new_names.sort()\n",
        "      class_originals = copy.deepcopy(dataset['categories'])\n",
        "      dataset['categories'] = []\n",
        "      class_ids_map = {}  # map from old id to new id\n",
        "\n",
        "      # Assign background id 0\n",
        "      has_background = False\n",
        "      if 'Background' in class_new_names:\n",
        "          if class_new_names.index('Background') != 0:\n",
        "              class_new_names.remove('Background')\n",
        "              class_new_names.insert(0, 'Background')\n",
        "          has_background = True\n",
        "\n",
        "      # Replace categories\n",
        "      for id_new, class_new_name in enumerate(class_new_names):\n",
        "          # Make sure id:0 is reserved for background\n",
        "          id_rectified = id_new\n",
        "          if not has_background:\n",
        "              id_rectified += 1\n",
        "\n",
        "          category = {\n",
        "              'supercategory': '',\n",
        "              'id': id_rectified,  # Background has id=0\n",
        "              'name': class_new_name,\n",
        "          }\n",
        "          dataset['categories'].append(category)\n",
        "          # Map class names\n",
        "          for class_original in class_originals:\n",
        "              if class_map[class_original['name']] == class_new_name:\n",
        "                  class_ids_map[class_original['id']] = id_rectified\n",
        "\n",
        "      # Update annotations category id tag\n",
        "      for ann in dataset['annotations']:\n",
        "          ann['category_id'] = class_ids_map[ann['category_id']]"
      ],
      "metadata": {
        "id": "ZCws_VTInwr5"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/TACO-expl/data/annotations.json\", \"r\") as f: #\"/content/TACO/data/annotations.json\"\n",
        "    dataset = json.loads(f.read())\n",
        "\n",
        "class_map = create_map(dataset[\"categories\"], keep_categories)\n",
        "replace_dataset_classes(dataset, class_map)\n",
        "dataset[\"categories\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9QJNgK7anxnv",
        "outputId": "edfb4594-f060-412d-f6bc-26e77a3e5ecc"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'supercategory': '', 'id': 1, 'name': 'Bottle'},\n",
              " {'supercategory': '', 'id': 2, 'name': 'Bottle cap'},\n",
              " {'supercategory': '', 'id': 3, 'name': 'Can'},\n",
              " {'supercategory': '', 'id': 4, 'name': 'Cigarette'},\n",
              " {'supercategory': '', 'id': 5, 'name': 'Cup'},\n",
              " {'supercategory': '', 'id': 6, 'name': 'Lid'},\n",
              " {'supercategory': '', 'id': 7, 'name': 'Other'},\n",
              " {'supercategory': '', 'id': 8, 'name': 'Plastic bag & wrapper'},\n",
              " {'supercategory': '', 'id': 9, 'name': 'Pop tab'},\n",
              " {'supercategory': '', 'id': 10, 'name': 'Straw'}]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classes = [elem[\"name\"] for elem in dataset[\"categories\"]]\n",
        "print(classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mz77Fd0Any8W",
        "outputId": "17ef875b-5dbe-4f6c-8048-e5ef228bb887"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Bottle', 'Bottle cap', 'Can', 'Cigarette', 'Cup', 'Lid', 'Other', 'Plastic bag & wrapper', 'Pop tab', 'Straw']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from detectron2.data.datasets import register_coco_instances\n",
        "from detectron2.data import MetadataCatalog\n",
        "\n",
        "help(register_coco_instances)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3-UgdxXOsei",
        "outputId": "a682aaa5-976c-424a-d517-d0e12911266b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on function register_coco_instances in module detectron2.data.datasets.coco:\n",
            "\n",
            "register_coco_instances(name, metadata, json_file, image_root)\n",
            "    Register a dataset in COCO's json annotation format for\n",
            "    instance detection, instance segmentation and keypoint detection.\n",
            "    (i.e., Type 1 and 2 in http://cocodataset.org/#format-data.\n",
            "    `instances*.json` and `person_keypoints*.json` in the dataset).\n",
            "    \n",
            "    This is an example of how to register a new dataset.\n",
            "    You can do something similar to this function, to register new datasets.\n",
            "    \n",
            "    Args:\n",
            "        name (str): the name that identifies a dataset, e.g. \"coco_2014_train\".\n",
            "        metadata (dict): extra metadata associated with this dataset.  You can\n",
            "            leave it as an empty dict.\n",
            "        json_file (str): path to the json instance annotation file.\n",
            "        image_root (str or path-like): directory which contains all the images.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_annotation_file = '/content/TACO-expl/data/annotations_off_0_train.json'\n",
        "val_annotation_file = '/content/TACO-expl/data/annotations_off_0_val.json'\n",
        "test_annotation_file = '/content/TACO-expl/data/annotations_off_0_test.json'\n",
        "\n",
        "\n",
        "img_dir = '/content/MyDrive/MyDrive/official/'\n",
        "\n",
        "register_coco_instances(\"TACO_train\", {}, train_annotation_file, img_dir)\n",
        "MetadataCatalog.get(\"TACO_train\").set(thing_classes = classes)\n",
        "dataset_dicts_train = DatasetCatalog.get(\"TACO_train\")\n",
        "\n",
        "register_coco_instances(\"TACO_val\", {}, val_annotation_file, img_dir)\n",
        "MetadataCatalog.get(\"TACO_val\").set(thing_classes = classes)\n",
        "dataset_dicts_val = DatasetCatalog.get(\"TACO_val\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LmR4YkANn3eG",
        "outputId": "7724b634-7fed-44a8-87de-89b645bb8aa8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05/17 18:42:18 d2.data.datasets.coco]: Loaded 1200 images in COCO format from /content/TACO-expl/data/annotations_off_0_train.json\n",
            "[05/17 18:42:19 d2.data.datasets.coco]: Loaded 150 images in COCO format from /content/TACO-expl/data/annotations_off_0_val.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "with open(val_annotation_file, \"r\") as f:\n",
        "  val_annotations = json.load(f)\n",
        "\n",
        "print(val_annotations['annotations'][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dTmEjMI4RWrM",
        "outputId": "0738167e-995b-4d2e-c560-ff47aa0d6e74"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'id': 47, 'image_id': 15, 'category_id': 1, 'segmentation': [[249.0, 1458.0, 236.0, 1360.0, 222.0, 1247.0, 150.0, 784.0, 150.0, 747.0, 157.0, 712.0, 172.0, 675.0, 184.0, 656.0, 205.0, 632.0, 238.0, 603.0, 263.0, 589.0, 299.0, 575.0, 312.0, 570.0, 322.0, 568.0, 324.0, 567.0, 323.0, 538.0, 319.0, 497.0, 314.0, 432.0, 307.0, 362.0, 307.0, 354.0, 313.0, 346.0, 317.0, 343.0, 328.0, 338.0, 345.0, 333.0, 355.0, 330.0, 363.0, 328.0, 371.0, 334.0, 386.0, 332.0, 404.0, 330.0, 421.0, 330.0, 450.0, 332.0, 476.0, 335.0, 486.0, 338.0, 489.0, 337.0, 493.0, 335.0, 501.0, 337.0, 509.0, 341.0, 518.0, 346.0, 527.0, 351.0, 531.0, 359.0, 531.0, 369.0, 532.0, 400.0, 533.0, 429.0, 538.0, 526.0, 541.0, 566.0, 545.0, 568.0, 582.0, 580.0, 626.0, 604.0, 655.0, 627.0, 688.0, 667.0, 707.0, 704.0, 717.0, 753.0, 718.0, 806.0, 712.0, 952.0, 706.0, 1090.0, 698.0, 1222.0, 693.0, 1386.0, 688.0, 1433.0, 685.0, 1454.0, 671.0, 1493.0, 644.0, 1539.0, 603.0, 1582.0, 552.0, 1614.0, 498.0, 1630.0, 445.0, 1632.0, 381.0, 1617.0, 329.0, 1589.0, 285.0, 1544.0, 265.0, 1505.0, 256.0, 1482.0, 249.0, 1458.0]], 'area': 550185.5, 'bbox': [150.0, 328.0, 568.0, 1304.0], 'iscrowd': 0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "with open(test_annotation_file, \"r\") as f:\n",
        "  test_annotations = json.load(f)"
      ],
      "metadata": {
        "id": "nEKVFRHyK-SZ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "first_img = val_annotations[\"images\"][0]\n",
        "first_ann = val_annotations[\"annotations\"][0]\n",
        "\n",
        "print(first_img)\n",
        "print(first_ann)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ixS2PmNZRf_0",
        "outputId": "9558a89a-4460-4109-e1f3-8412441e794e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'id': 899, 'width': 3264, 'height': 2448, 'file_name': 'batch_4/000023.JPG', 'license': None, 'flickr_url': 'https://farm66.staticflickr.com/65535/47803892332_5218b74150_o.png', 'coco_url': None, 'date_captured': None, 'flickr_640_url': 'https://farm66.staticflickr.com/65535/47803892332_f552fb65c7_z.jpg'}\n",
            "{'id': 47, 'image_id': 15, 'category_id': 1, 'segmentation': [[249.0, 1458.0, 236.0, 1360.0, 222.0, 1247.0, 150.0, 784.0, 150.0, 747.0, 157.0, 712.0, 172.0, 675.0, 184.0, 656.0, 205.0, 632.0, 238.0, 603.0, 263.0, 589.0, 299.0, 575.0, 312.0, 570.0, 322.0, 568.0, 324.0, 567.0, 323.0, 538.0, 319.0, 497.0, 314.0, 432.0, 307.0, 362.0, 307.0, 354.0, 313.0, 346.0, 317.0, 343.0, 328.0, 338.0, 345.0, 333.0, 355.0, 330.0, 363.0, 328.0, 371.0, 334.0, 386.0, 332.0, 404.0, 330.0, 421.0, 330.0, 450.0, 332.0, 476.0, 335.0, 486.0, 338.0, 489.0, 337.0, 493.0, 335.0, 501.0, 337.0, 509.0, 341.0, 518.0, 346.0, 527.0, 351.0, 531.0, 359.0, 531.0, 369.0, 532.0, 400.0, 533.0, 429.0, 538.0, 526.0, 541.0, 566.0, 545.0, 568.0, 582.0, 580.0, 626.0, 604.0, 655.0, 627.0, 688.0, 667.0, 707.0, 704.0, 717.0, 753.0, 718.0, 806.0, 712.0, 952.0, 706.0, 1090.0, 698.0, 1222.0, 693.0, 1386.0, 688.0, 1433.0, 685.0, 1454.0, 671.0, 1493.0, 644.0, 1539.0, 603.0, 1582.0, 552.0, 1614.0, 498.0, 1630.0, 445.0, 1632.0, 381.0, 1617.0, 329.0, 1589.0, 285.0, 1544.0, 265.0, 1505.0, 256.0, 1482.0, 249.0, 1458.0]], 'area': 550185.5, 'bbox': [150.0, 328.0, 568.0, 1304.0], 'iscrowd': 0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /content/resized_validation/"
      ],
      "metadata": {
        "id": "8miIwfAhWjKd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import numpy as np\n",
        "import itertools\n",
        "\n",
        "def visualize_mask(mask):\n",
        "    plt.figure(figsize=(8, 8))\n",
        "    plt.imshow(mask)\n",
        "    #plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "def flatten(aList):\n",
        "  t = []\n",
        "  for i in aList:\n",
        "    if not isinstance(i, list):\n",
        "      t.append(i)\n",
        "    else:\n",
        "      t.extend(flatten(i))\n",
        "  return t\n",
        "\n",
        "def mask_to_polygon(mask):\n",
        "    # Find contours\n",
        "    contours, _ = cv2.findContours(mask.astype(np.uint8), cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    polygons = []\n",
        "    for contour in contours:\n",
        "        # Convert polygon to list of coordinates\n",
        "        polygon = contour.squeeze().astype(float).tolist()\n",
        "        polygons.append(polygon)\n",
        "    #polygons = flatten(polygons)\n",
        "    return polygons\n",
        "\n",
        "def visualize_polygons(polygons):\n",
        "    plt.figure(figsize=(8, 8))\n",
        "    for polygon in polygons:\n",
        "        polygon = np.array(polygon)\n",
        "        plt.plot(polygon[:, 0], polygon[:, 1], color='red', linewidth=2)\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "\"\"\"\n",
        "def group_coords_poly(ungrouped_poly):\n",
        "  to_return = []\n",
        "  for inner_list in ungrouped_poly:\n",
        "    to_append = [[inner_list[i], inner_list[i+1]] for i in range(0, len(inner_list), 2)]\n",
        "    to_return.append(to_append)\n",
        "  return to_return\n",
        "\"\"\"\n",
        "def group_coords_poly(ungrouped_poly):\n",
        "  ung_poly = ungrouped_poly.copy()\n",
        "  ung_poly = flatten(ung_poly)\n",
        "  to_return = [[[ung_poly[i], ung_poly[i+1]] for i in range(0, len(ung_poly), 2)]]\n",
        "  return to_return\n",
        "\n",
        "def ungroup_coords_poly(grouped_poly):\n",
        "  #to_return = [[elem for pair_inner_list in inner_list for elem in pair_inner_list] for inner_list in grouped_poly]\n",
        "  to_return = [flatten(grouped_poly)]\n",
        "  return to_return\n",
        "\n",
        "#some_ann = [[2152.0, 1374.0, 2206.0, 1375.0, 2239.0, 1366.0], [2262.0, 1358.0, 2275.0, 1342.0, 2270.0, 1323.0, 2259.0, 1312.0, 2249.0, 1308.0, 2251.0, 1291.0, 2236.0, 1270.0, 2218.0, 1259.0, 2191.0, 1254.0, 2149.0, 1256.0, 2125.0, 1259.0, 2109.0, 1272.0, 2098.0, 1285.0, 2093.0, 1294.0, 2090.0, 1307.0, 2080.0, 1314.0, 2069.0, 1324.0, 2073.0, 1347.0, 2095.0, 1363.0, 2122.0, 1370.0, 2152.0, 1374.0]]\n",
        "#to_print = group_coords_poly(some_ann)\n",
        "#print(to_print)\n",
        "#print(ungroup_coords_poly(to_print))"
      ],
      "metadata": {
        "id": "X4xIrBlcDqcU"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /content/res_val"
      ],
      "metadata": {
        "id": "lOauoO5DEBns"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from itertools import groupby\n",
        "\n",
        "def binary_mask_to_rle(binary_mask):\n",
        "    rle = {'counts': [], 'size': list(binary_mask.shape)}\n",
        "    counts = rle.get('counts')\n",
        "    for i, (value, elements) in enumerate(groupby(binary_mask.ravel(order='F'))):\n",
        "        if i == 0 and value == 1:\n",
        "            counts.append(0)\n",
        "        counts.append(len(list(elements)))\n",
        "    return rle"
      ],
      "metadata": {
        "id": "bNnUYm237aMV"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from detectron2.data.transforms.augmentation_impl import ResizeShortestEdge\n",
        "from detectron2.data.transforms import ResizeTransform\n",
        "from PIL import Image\n",
        "from pycocotools import mask as coco_mask\n",
        "from skimage import measure\n",
        "\n",
        "def check_rotation_and_alpha(image):\n",
        "        img_shape = np.shape(image)\n",
        "        rot = False\n",
        "        # load metadata\n",
        "        exif = image.getexif()\n",
        "        if exif:\n",
        "            exif = dict(exif.items())\n",
        "            # Rotate portrait images if necessary (274 is the orientation tag code)\n",
        "            if 274 in exif:\n",
        "                if exif[274] == 3:\n",
        "                    rot = True\n",
        "                    image = image.rotate(180, expand=True)\n",
        "                if exif[274] == 6:\n",
        "                    rot = True\n",
        "                    image = image.rotate(270, expand=True)\n",
        "                if exif[274] == 8:\n",
        "                    rot = True\n",
        "                    image = image.rotate(90, expand=True)\n",
        "\n",
        "        # If has an alpha channel, remove it for consistency\n",
        "        if img_shape[-1] == 4:\n",
        "            image = image[..., :3]\n",
        "        return image, rot\n",
        "\n"
      ],
      "metadata": {
        "id": "trBmn-8NSECn"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def resize_split(ann_json_string, new_json_path, new_img_folder ):\n",
        "  resized_json = {}\n",
        "  resized_json['info'] = ann_json_string['info']\n",
        "  resized_json['scene_annotations'] = ann_json_string['scene_annotations']\n",
        "  resized_json['licenses'] = ann_json_string['licenses']\n",
        "  resized_json['categories'] = ann_json_string['categories']\n",
        "  resized_json['scene_categories'] = ann_json_string['scene_categories']\n",
        "  resize_obj_func = ResizeShortestEdge(800,\n",
        "                                  1333,\n",
        "                                  sample_style = \"choice\")\n",
        "  if not os.path.exists(os.path.join(\"/content/\", new_img_folder)):\n",
        "    os.mkdir(os.path.join(\"/content/\", new_img_folder))\n",
        "  res_imgs_json_path = new_json_path#'/content/TACO-expl/data/annotations_off_0_resval.json'\n",
        "\n",
        "  res_imgs_list = []\n",
        "  res_annotation_list = []\n",
        "  for img_meta in ann_json_string[\"images\"]:\n",
        "\n",
        "    res_img_dict = img_meta.copy()\n",
        "    id = img_meta[\"id\"]\n",
        "    height = img_meta[\"height\"]\n",
        "    width = img_meta[\"width\"]\n",
        "    print(height, width)\n",
        "    img_path = img_meta[\"file_name\"]\n",
        "    sub_dir = img_path.split(\"/\")[0]\n",
        "    folder = os.path.join(\"/content/\", new_img_folder, sub_dir)\n",
        "    if not os.path.exists(folder):\n",
        "      os.mkdir(folder)\n",
        "\n",
        "    new_h, new_w = ResizeShortestEdge.get_output_shape(height, width, 800, 1333)\n",
        "    res_img_dict.update({\"height\": new_h, \"width\": new_w })\n",
        "    res_imgs_list.append(res_img_dict)\n",
        "\n",
        "    trans_func = ResizeTransform(height, width, new_h, new_w, Image.BILINEAR)\n",
        "\n",
        "    img = Image.open(os.path.join(\"/content/MyDrive/MyDrive/official\", img_path))\n",
        "    img = check_rotation_and_alpha(img)\n",
        "    img = np.array(img)\n",
        "    print(img.shape)\n",
        "    res_img = trans_func.apply_image(img)\n",
        "    res_pil = Image.fromarray(res_img.astype(np.uint8))\n",
        "    res_pil.save(os.path.join(folder, img_path.split(\"/\")[1]))\n",
        "\n",
        "    for annotation in ann_json_string[\"annotations\"]:\n",
        "      if annotation[\"image_id\"] == id:\n",
        "        res_segm_dict = annotation.copy()\n",
        "        rles = coco_mask.frPyObjects(annotation[\"segmentation\"], height, width)\n",
        "        rle = coco_mask.merge(rles)\n",
        "        mask = coco_mask.decode(rle)\n",
        "\n",
        "        res_mask = trans_func.apply_segmentation(mask)\n",
        "        res_mask = np.asfortranarray(np.squeeze(res_mask))\n",
        "        uncomp = binary_mask_to_rle(res_mask)\n",
        "\n",
        "\n",
        "        encoded_ground_truth = coco_mask.encode(res_mask)\n",
        "        ground_truth_area = float(coco_mask.area(encoded_ground_truth))\n",
        "        ground_truth_bounding_box = coco_mask.toBbox(encoded_ground_truth).tolist()\n",
        "\n",
        "        res_segm_dict.update({\"segmentation\": uncomp,\n",
        "                            \"area\": ground_truth_area,\n",
        "                            \"bbox\": ground_truth_bounding_box})\n",
        "        res_annotation_list.append(res_segm_dict)\n",
        "\n",
        "  resized_json[\"images\"] = res_imgs_list\n",
        "  resized_json[\"annotations\"] = res_annotation_list\n",
        "  with open(res_imgs_json_path, \"w\") as f:\n",
        "    json.dump(resized_json, f)\n",
        "  return resized_json\n"
      ],
      "metadata": {
        "id": "uEqMML0RLCxb"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/rot_train.zip /content/rot_train/"
      ],
      "metadata": {
        "id": "TdxacmgpJYAE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "from matplotlib.pyplot import imshow\n",
        "from PIL import Image\n",
        "%matplotlib inline\n",
        "train_annotation_file = '/content/TACO-expl/data/annotations_off_0_train.json'\n",
        "\n",
        "with open(train_annotation_file, \"r\") as f:\n",
        "  train_annotations = json.load(f)\n",
        "\n",
        "if not os.path.exists(\"/content/rot_train\"):\n",
        "  os.mkdir(\"/content/rot_train\")\n",
        "\n",
        "for img_info in train_annotations[\"images\"]:\n",
        "  sub_dir = img_info[\"file_name\"].split(\"/\")[0]\n",
        "  folder = os.path.join(\"/content/rot_train\", sub_dir)\n",
        "  #if not os.path.exists(folder):\n",
        "  #    os.mkdir(folder)\n",
        "  img = Image.open(os.path.join(\"/content/MyDrive/MyDrive/official\", img_info[\"file_name\"]))\n",
        "  big, rot = check_rotation_and_alpha(img)\n",
        "  if rot:\n",
        "    print(img_info[\"file_name\"])\n",
        "    save1 = img\n",
        "    save2 = big\n",
        "    break\n",
        "\n",
        "  #img.save(os.path.join(\"/content/rot_train/\", img_info[\"file_name\"]))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iz4XUiWpQPUQ",
        "outputId": "330f5d22-ceb0-4df6-e14a-5b3099820f8b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batch_14/000037.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "jso = resize_split(val_annotations, \"/content/TACO-expl/data/annotations_off_0_resval.json\", \"res_val\" )\n"
      ],
      "metadata": {
        "id": "IBiJJ3eEMts-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e65c5188-cd71-4de4-c339-34957a56c9de"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2448 3264\n",
            "3264 2448\n",
            "4032 3024\n",
            "4160 3120\n",
            "3264 2448\n",
            "2448 3264\n",
            "3264 2448\n",
            "4160 3120\n",
            "3264 2448\n",
            "3264 2448\n",
            "3264 2448\n",
            "2049 1537\n",
            "3264 2448\n",
            "4128 3096\n",
            "3264 2448\n",
            "4000 1824\n",
            "4128 2322\n",
            "3264 2448\n",
            "4160 3120\n",
            "4032 3024\n",
            "4160 3120\n",
            "3968 2976\n",
            "3264 2448\n",
            "4160 3120\n",
            "2448 3264\n",
            "4032 3024\n",
            "3120 4160\n",
            "2448 3264\n",
            "2448 3264\n",
            "4032 3024\n",
            "3264 2448\n",
            "2448 3264\n",
            "3264 2448\n",
            "5312 2988\n",
            "2448 3264\n",
            "2448 3264\n",
            "2448 3264\n",
            "2448 3264\n",
            "3264 2448\n",
            "3120 4160\n",
            "4032 3024\n",
            "1600 1200\n",
            "2448 3264\n",
            "4160 3120\n",
            "3264 2448\n",
            "3264 2448\n",
            "3264 2448\n",
            "4000 1824\n",
            "4000 1824\n",
            "4000 1824\n",
            "3120 4160\n",
            "3264 2448\n",
            "2448 3264\n",
            "3264 2448\n",
            "3264 2448\n",
            "2448 3264\n",
            "3264 2448\n",
            "3264 2448\n",
            "4160 3120\n",
            "2049 1537\n",
            "3264 2448\n",
            "4032 3024\n",
            "2448 3264\n",
            "2340 4160\n",
            "3264 2448\n",
            "2448 3264\n",
            "1968 2624\n",
            "1600 1200\n",
            "3264 2448\n",
            "4032 2268\n",
            "4208 2368\n",
            "2448 3264\n",
            "3264 2448\n",
            "3264 2448\n",
            "3264 2448\n",
            "2448 3264\n",
            "4160 3120\n",
            "2049 1537\n",
            "2048 1536\n",
            "3264 2448\n",
            "3264 2448\n",
            "1536 2048\n",
            "3264 2448\n",
            "3264 2448\n",
            "4160 3120\n",
            "3264 2448\n",
            "5312 2988\n",
            "3264 2448\n",
            "3264 2448\n",
            "3264 2448\n",
            "3264 2448\n",
            "4032 3024\n",
            "3120 4160\n",
            "2607 2448\n",
            "4160 3120\n",
            "3264 2448\n",
            "4032 3024\n",
            "3264 2448\n",
            "4032 3024\n",
            "3120 4160\n",
            "1537 2049\n",
            "3264 2448\n",
            "4000 1824\n",
            "3264 2448\n",
            "3264 2448\n",
            "2760 3680\n",
            "3264 2448\n",
            "3264 2448\n",
            "2448 3264\n",
            "4000 6000\n",
            "4608 3456\n",
            "1968 2624\n",
            "3264 2448\n",
            "4032 2268\n",
            "3264 2448\n",
            "4000 1824\n",
            "3264 2448\n",
            "4032 3024\n",
            "2448 3264\n",
            "3264 2448\n",
            "3024 4032\n",
            "1536 2048\n",
            "4000 1824\n",
            "2448 3264\n",
            "3264 2448\n",
            "3120 4160\n",
            "4160 3120\n",
            "2340 4160\n",
            "3264 2448\n",
            "3264 2448\n",
            "2448 3264\n",
            "3264 2448\n",
            "4160 3120\n",
            "3264 2448\n",
            "3264 2448\n",
            "4032 3024\n",
            "3264 2448\n",
            "2448 3264\n",
            "2448 3264\n",
            "3120 4160\n",
            "2448 3264\n",
            "4032 3024\n",
            "4032 2268\n",
            "2448 3264\n",
            "3264 2448\n",
            "3264 2448\n",
            "3264 2448\n",
            "3264 2448\n",
            "5312 2988\n",
            "2448 3264\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "jso = resize_split(test_annotations, \"/content/TACO-expl/data/annotations_off_0_restest.json\", \"res_test\" )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u42NsLlNi2v2",
        "outputId": "bb172b2a-7cdc-447c-ccde-0460b013af3e"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4160 3120\n",
            "4032 3024\n",
            "2448 3264\n",
            "4032 3024\n",
            "1968 2624\n",
            "2049 1537\n",
            "3264 2448\n",
            "2448 3264\n",
            "3264 2448\n",
            "4618 3463\n",
            "2448 3264\n",
            "4160 3120\n",
            "3264 2448\n",
            "5312 2988\n",
            "4000 1824\n",
            "3264 2448\n",
            "2448 3264\n",
            "4000 6000\n",
            "5312 2988\n",
            "4000 1824\n",
            "3120 4160\n",
            "4128 2322\n",
            "2048 1536\n",
            "2448 3264\n",
            "3120 4160\n",
            "3264 2448\n",
            "2448 3264\n",
            "3264 2448\n",
            "4000 1824\n",
            "3264 2448\n",
            "4032 3024\n",
            "4000 1824\n",
            "3264 2448\n",
            "2448 3264\n",
            "5312 2988\n",
            "2448 3264\n",
            "2448 3264\n",
            "1968 2624\n",
            "4208 2368\n",
            "4160 3120\n",
            "3264 2448\n",
            "4032 3024\n",
            "4000 1824\n",
            "4032 3024\n",
            "4032 3024\n",
            "3264 2448\n",
            "2448 3264\n",
            "4032 2268\n",
            "3264 2448\n",
            "4160 3120\n",
            "3024 4032\n",
            "4032 3024\n",
            "3264 2448\n",
            "3264 2448\n",
            "2448 3264\n",
            "2368 4208\n",
            "4000 1824\n",
            "4032 3024\n",
            "3264 2448\n",
            "4160 3120\n",
            "3264 2448\n",
            "2448 3264\n",
            "3264 2448\n",
            "2448 3264\n",
            "3264 2448\n",
            "3264 2448\n",
            "2448 3264\n",
            "4208 2368\n",
            "3264 2448\n",
            "3264 2448\n",
            "2049 1537\n",
            "2448 3264\n",
            "3264 2448\n",
            "3264 2448\n",
            "4160 3120\n",
            "3264 2448\n",
            "4618 3463\n",
            "3264 2448\n",
            "5312 2988\n",
            "3264 2448\n",
            "2448 3264\n",
            "4160 3120\n",
            "3264 2448\n",
            "1824 4000\n",
            "2448 3264\n",
            "4000 1824\n",
            "1824 4000\n",
            "3264 2448\n",
            "2448 3264\n",
            "3264 2448\n",
            "2448 3264\n",
            "3264 2448\n",
            "3264 2448\n",
            "4000 1824\n",
            "4160 3120\n",
            "1824 4000\n",
            "4000 6000\n",
            "2448 3264\n",
            "3264 2448\n",
            "3264 2448\n",
            "3264 2448\n",
            "4000 1824\n",
            "4032 3024\n",
            "2049 1537\n",
            "3264 2448\n",
            "3120 4160\n",
            "2448 3264\n",
            "4160 3120\n",
            "4032 3024\n",
            "4160 3120\n",
            "2448 3264\n",
            "4032 3024\n",
            "4032 3024\n",
            "4000 6000\n",
            "4032 3024\n",
            "3264 2448\n",
            "2448 3264\n",
            "1824 4000\n",
            "5312 2988\n",
            "1824 4000\n",
            "3264 2448\n",
            "3120 4160\n",
            "3264 2448\n",
            "3264 2448\n",
            "4032 3024\n",
            "2048 1536\n",
            "2448 3264\n",
            "2448 3264\n",
            "1824 4000\n",
            "3264 2448\n",
            "3968 2976\n",
            "3264 2448\n",
            "3264 2448\n",
            "1824 4000\n",
            "3264 2448\n",
            "3264 2448\n",
            "3264 2448\n",
            "1968 2624\n",
            "4160 3120\n",
            "2368 4208\n",
            "4160 3120\n",
            "3264 2448\n",
            "2048 1536\n",
            "2448 3264\n",
            "3264 2448\n",
            "3264 2448\n",
            "2597 2442\n",
            "3264 2448\n",
            "2448 3264\n",
            "3264 2448\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fUA77h8f4lEN",
        "outputId": "7bc2855a-37ad-40b7-c545-cd5fd2e37423"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " data\t       LICENSE\t\t\t  sample_imgs\n",
            " demo.ipynb   'log official finetuning'  'Training notebook.ipynb'\n",
            " detector      MaskDINO\t\t\t 'Training Notebook.ipynb'\n",
            " download.py   README.md\t\t  Training_notebook_maskdino_2.ipynb\n",
            " HDDETR        requirements.txt\t\t  Training_notebook_maskdino.ipynb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "jso['images'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yOBePsrG4Zab",
        "outputId": "6ff43402-201b-4b19-97df-ba8b8ec352c9"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'id': 899,\n",
              " 'width': 1067,\n",
              " 'height': 800,\n",
              " 'file_name': 'batch_4/000023.JPG',\n",
              " 'license': None,\n",
              " 'flickr_url': 'https://farm66.staticflickr.com/65535/47803892332_5218b74150_o.png',\n",
              " 'coco_url': None,\n",
              " 'date_captured': None,\n",
              " 'flickr_640_url': 'https://farm66.staticflickr.com/65535/47803892332_f552fb65c7_z.jpg'}"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "jso['annotations'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fNCjOLJ1kDOf",
        "outputId": "7f6e2e7b-fb72-4120-a8db-e9a0c510e400"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'id': 2802,\n",
              " 'image_id': 899,\n",
              " 'category_id': 2,\n",
              " 'segmentation': {'counts': [541232,\n",
              "   2,\n",
              "   798,\n",
              "   7,\n",
              "   792,\n",
              "   10,\n",
              "   789,\n",
              "   12,\n",
              "   787,\n",
              "   13,\n",
              "   786,\n",
              "   15,\n",
              "   785,\n",
              "   15,\n",
              "   783,\n",
              "   18,\n",
              "   779,\n",
              "   22,\n",
              "   776,\n",
              "   24,\n",
              "   774,\n",
              "   27,\n",
              "   772,\n",
              "   28,\n",
              "   771,\n",
              "   29,\n",
              "   770,\n",
              "   31,\n",
              "   768,\n",
              "   32,\n",
              "   767,\n",
              "   33,\n",
              "   766,\n",
              "   34,\n",
              "   765,\n",
              "   36,\n",
              "   763,\n",
              "   37,\n",
              "   763,\n",
              "   37,\n",
              "   763,\n",
              "   37,\n",
              "   763,\n",
              "   37,\n",
              "   763,\n",
              "   37,\n",
              "   763,\n",
              "   37,\n",
              "   763,\n",
              "   38,\n",
              "   761,\n",
              "   39,\n",
              "   761,\n",
              "   39,\n",
              "   761,\n",
              "   39,\n",
              "   761,\n",
              "   39,\n",
              "   761,\n",
              "   39,\n",
              "   761,\n",
              "   39,\n",
              "   761,\n",
              "   39,\n",
              "   761,\n",
              "   39,\n",
              "   761,\n",
              "   39,\n",
              "   761,\n",
              "   39,\n",
              "   761,\n",
              "   39,\n",
              "   761,\n",
              "   39,\n",
              "   761,\n",
              "   39,\n",
              "   761,\n",
              "   39,\n",
              "   761,\n",
              "   39,\n",
              "   761,\n",
              "   39,\n",
              "   761,\n",
              "   39,\n",
              "   761,\n",
              "   39,\n",
              "   761,\n",
              "   39,\n",
              "   761,\n",
              "   39,\n",
              "   762,\n",
              "   38,\n",
              "   762,\n",
              "   38,\n",
              "   762,\n",
              "   38,\n",
              "   762,\n",
              "   37,\n",
              "   764,\n",
              "   36,\n",
              "   764,\n",
              "   36,\n",
              "   765,\n",
              "   35,\n",
              "   765,\n",
              "   34,\n",
              "   767,\n",
              "   33,\n",
              "   768,\n",
              "   32,\n",
              "   769,\n",
              "   30,\n",
              "   771,\n",
              "   29,\n",
              "   772,\n",
              "   28,\n",
              "   774,\n",
              "   25,\n",
              "   776,\n",
              "   5,\n",
              "   1,\n",
              "   18,\n",
              "   783,\n",
              "   17,\n",
              "   783,\n",
              "   16,\n",
              "   785,\n",
              "   15,\n",
              "   786,\n",
              "   13,\n",
              "   788,\n",
              "   11,\n",
              "   790,\n",
              "   9,\n",
              "   793,\n",
              "   6,\n",
              "   798,\n",
              "   1,\n",
              "   258761],\n",
              "  'size': [800, 1067]},\n",
              " 'area': 2008.0,\n",
              " 'bbox': [676.0, 410.0, 68.0, 39.0],\n",
              " 'iscrowd': 0}"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/TACO-expl/data/annotations_off_0_restest.json\", \"w\") as f:\n",
        "    json.dump(jso, f)"
      ],
      "metadata": {
        "id": "zuMcpg4ve-ky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_LaOf6bZkR11",
        "outputId": "e7a3b51e-707a-482c-b22a-cae8216e95a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "build  functions  modules\t\t\t\t  setup.py  test.py\n",
            "dist   make.sh\t  MultiScaleDeformableAttention.egg-info  src\n"
          ]
        }
      ]
    }
  ]
}
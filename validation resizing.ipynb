{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ML4CV project work\n",
        "\n",
        "Summary: Improving and explaining instance segmentation on a litter detection dataset\n",
        "\n",
        "Members:\n",
        "- Dell'Olio Domenico\n",
        "- Delvecchio Giovanni Pio\n",
        "- Disabato Raffaele\n",
        "\n",
        "The project was developed in order to improve instance segmentation results on the [TACO Dataset](http://tacodataset.org/).\n",
        "\n",
        "We decided to implement and test various architectures, among the highest scoring on COCO instance segmentation datasets, in order to compare their performances.\n",
        "We also tested some explainability methods on these models to try and explain model predictions."
      ],
      "metadata": {
        "id": "K6woye2It_t7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## This notebook contains:\n",
        "- Validation and Test set resizing, dataset rotation"
      ],
      "metadata": {
        "id": "fnn0i2y9uEPx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Validation and Test set resizing, dataset rotation\n",
        "As mentioned in the Training notebook for the MaskDINO architecture, we encountered some problems in allowing images in the test and validation set to be resized during evaluation.\n",
        "We found the idea of applying the preprocessing, including image rotation, on the stored images to be a faster solution. This required to modify the annotations accordingly, thus we exploited some functions from the Detectron 2 framework."
      ],
      "metadata": {
        "id": "6AEtau6vxLFq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#install detectron2\n",
        "!pip install 'git+https://github.com/facebookresearch/detectron2.git@5aeb252b194b93dc2879b4ac34bc51a31b5aee13'"
      ],
      "metadata": {
        "id": "WGL4szW1o_UM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pull and copy repository\n",
        "%cd /content/\n",
        "!git clone https://github.com/DomMcOyle/TACO-expl.git\n",
        "%cd /content/TACO-expl\n",
        "!git checkout maskdino\n",
        "!git pull origin maskdino"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eNqUmCxBPkgp",
        "outputId": "e82a336a-7095-4188-9b43-f3e2acf986ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "fatal: destination path 'TACO-expl' already exists and is not an empty directory.\n",
            "/content/TACO-expl\n",
            "Already on 'maskdino'\n",
            "Your branch is up to date with 'origin/maskdino'.\n",
            "From https://github.com/DomMcOyle/TACO-expl\n",
            " * branch            maskdino   -> FETCH_HEAD\n",
            "Already up to date.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# install repository requirements and detectron2\n",
        "%cd /content/TACO-expl/MaskDINO\n",
        "!pip install -r requirements.txt\n",
        "%cd /content/TACO-expl/MaskDINO/maskdino/modeling/pixel_decoder/ops\n",
        "!sh make.sh"
      ],
      "metadata": {
        "id": "X9P0HDTGnRDI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import drive\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/MyDrive/\", force_remount = True)"
      ],
      "metadata": {
        "id": "yKG8tycQnkyb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3fe7824-3078-4f01-a50f-1fe9696d46a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/MyDrive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import some common libraries\n",
        "import os, cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import os.path\n",
        "import json\n",
        "import argparse\n",
        "import numpy as np\n",
        "import random\n",
        "import datetime as dt\n",
        "import copy\n",
        "from pathlib import Path\n",
        "from itertools import groupby\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "from skimage import measure\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch.utils.data\n",
        "from torch.utils.data import DataLoader\n",
        "from pycocotools import mask as coco_mask\n",
        "\n",
        "%cd /content/\n",
        "# Some basic setup:\n",
        "# Setup detectron2 logger\n",
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "\n",
        "# import some common detectron2 utilities\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
        "from detectron2.data.transforms.augmentation_impl import ResizeShortestEdge\n",
        "from detectron2.data.transforms import ResizeTransform\n",
        "\n",
        "%cd /content/TACO-expl/\n",
        "\n"
      ],
      "metadata": {
        "id": "LfdhgozHnZpe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "178ffcf9-22ec-4dd2-f03b-6375fa7c9e69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# setting seeds\n",
        "DEFAULT_RANDOM_SEED = 42\n",
        "# basic random seed\n",
        "def seedBasic(seed=DEFAULT_RANDOM_SEED):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "# torch random seed\n",
        "def seedTorch(seed=DEFAULT_RANDOM_SEED):\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "# combine\n",
        "def seedEverything(seed=DEFAULT_RANDOM_SEED):\n",
        "    seedBasic(seed)\n",
        "    seedTorch(seed)\n",
        "\n",
        "seedEverything()"
      ],
      "metadata": {
        "id": "gHfxVrm3nrzg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we list the annotations JSON file to load to apply the edits."
      ],
      "metadata": {
        "id": "A43mTimS1UJ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_annotation_file = '/content/TACO-expl/data/annotations_off_0_train.json'\n",
        "val_annotation_file = '/content/TACO-expl/data/annotations_off_0_val.json'\n",
        "test_annotation_file = '/content/TACO-expl/data/annotations_off_0_test.json'\n",
        "\n",
        "\n",
        "img_dir = '/content/MyDrive/MyDrive/official/'"
      ],
      "metadata": {
        "id": "LmR4YkANn3eG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(val_annotation_file, \"r\") as f:\n",
        "  val_annotations = json.load(f)"
      ],
      "metadata": {
        "id": "dTmEjMI4RWrM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(test_annotation_file, \"r\") as f:\n",
        "  test_annotations = json.load(f)"
      ],
      "metadata": {
        "id": "nEKVFRHyK-SZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we declare the functions to rotate the images and eventually remove the alpha channels, as done in the original TACO repository, and the function to convert a binary mask to uncompressed Run-Lenght-Encoding.\n",
        "\n",
        "The latter function is re-adapted from the following Stack Overflow [question](https://stackoverflow.com/questions/49494337/encode-numpy-array-using-uncompressed-rle-for-coco-dataset). This function is required as the segmentations, within the COCO format, may be described in different ways, mainly as polygons (this is the case of the official TACO dataset) and as uncompressed RLE. Since the masks are loaded from polygons and rendered as bitmaps in the moment of resizing, we were required to convert the bitmaps back to a \"COCO-compatible\" format.\n",
        "\n",
        " We ruled out the polygon representation as it would require a pretty convoluted operation which would also introduce some quantization error and, since the pycocotools repository only handles and converts in the internal compressed RLE format, we had to resort to an external function.\n"
      ],
      "metadata": {
        "id": "L7_k7L173Cca"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def binary_mask_to_rle(binary_mask):\n",
        "    \"\"\"\n",
        "    Function converting a bitmap mask to Run-Lenght Encoding format.\n",
        "    :param binary_mask: numpy array containing the binary map\n",
        "    \"\"\"\n",
        "    rle = {'counts': [], 'size': list(binary_mask.shape)}\n",
        "    counts = rle.get('counts')\n",
        "    for i, (value, elements) in enumerate(groupby(binary_mask.ravel(order='F'))):\n",
        "        if i == 0 and value == 1:\n",
        "            counts.append(0)\n",
        "        counts.append(len(list(elements)))\n",
        "    return rle\n",
        "\n",
        "\n",
        "def check_rotation_and_alpha(image):\n",
        "    \"\"\"\n",
        "    Function checking the Exif rotation code and rotating the image accordingly.\n",
        "    It also removes the alpha channel.\n",
        "    :param image: PIL image to be rotated\n",
        "    \"\"\"\n",
        "    img_shape = np.shape(image)\n",
        "    rot = False\n",
        "    # load metadata\n",
        "    exif = image.getexif()\n",
        "    if exif:\n",
        "        exif = dict(exif.items())\n",
        "        # Rotate portrait images if necessary (274 is the orientation tag code)\n",
        "        if 274 in exif:\n",
        "            if exif[274] == 3:\n",
        "                image = image.rotate(180, expand=True)\n",
        "            if exif[274] == 6:\n",
        "                image = image.rotate(270, expand=True)\n",
        "            if exif[274] == 8:\n",
        "                image = image.rotate(90, expand=True)\n",
        "    # If has an alpha channel, remove it for consistency\n",
        "    if img_shape[-1] == 4:\n",
        "        image = image[..., :3]\n",
        "    return image\n",
        "\n"
      ],
      "metadata": {
        "id": "trBmn-8NSECn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then, with the following function we perform image rotation and resizing, modifying their annotation together."
      ],
      "metadata": {
        "id": "KgWa3k-H6KWu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def resize_split(ann_json_string, new_json_path, new_img_folder):\n",
        "  \"\"\"\n",
        "  Function resizing and rotating a given split.\n",
        "  :param ann_json_string: Annotation read from a json file\n",
        "  :param new_json_path: path where to save the new annotation file\n",
        "  :param new_image_folder: path where the edited images must be saved\n",
        "  \"\"\"\n",
        "  # copying information from the previous annotation file\n",
        "  resized_json = {}\n",
        "  resized_json['info'] = ann_json_string['info']\n",
        "  resized_json['scene_annotations'] = ann_json_string['scene_annotations']\n",
        "  resized_json['licenses'] = ann_json_string['licenses']\n",
        "  resized_json['categories'] = ann_json_string['categories']\n",
        "  resized_json['scene_categories'] = ann_json_string['scene_categories']\n",
        "  # creating the object for getting image resizing dimensions\n",
        "  resize_obj_func = ResizeShortestEdge(800,\n",
        "                                  1333,\n",
        "                                  sample_style = \"choice\")\n",
        "  # creates the image folder if necessary\n",
        "  if not os.path.exists(os.path.join(\"/content/\", new_img_folder)):\n",
        "    os.mkdir(os.path.join(\"/content/\", new_img_folder))\n",
        "  res_imgs_json_path = new_json_path\n",
        "\n",
        "  res_imgs_list = []\n",
        "  res_annotation_list = []\n",
        "  # for each metadata on the images\n",
        "  for img_meta in ann_json_string[\"images\"]:\n",
        "    # the information is copied\n",
        "    res_img_dict = img_meta.copy()\n",
        "    id = img_meta[\"id\"]\n",
        "    height = img_meta[\"height\"]\n",
        "    width = img_meta[\"width\"]\n",
        "    img_path = img_meta[\"file_name\"]\n",
        "    sub_dir = img_path.split(\"/\")[0]\n",
        "    # creates subdir if necessary\n",
        "    folder = os.path.join(\"/content/\", new_img_folder, sub_dir)\n",
        "    if not os.path.exists(folder):\n",
        "      os.mkdir(folder)\n",
        "\n",
        "    # resizes image\n",
        "    new_h, new_w = ResizeShortestEdge.get_output_shape(height, width, 800, 1333)\n",
        "    res_img_dict.update({\"height\": new_h, \"width\": new_w })\n",
        "    res_imgs_list.append(res_img_dict)\n",
        "\n",
        "    trans_func = ResizeTransform(height, width, new_h, new_w, Image.BILINEAR)\n",
        "\n",
        "    img = Image.open(os.path.join(\"/content/MyDrive/MyDrive/official\", img_path))\n",
        "    img = check_rotation_and_alpha(img)\n",
        "    img = np.array(img)\n",
        "    res_img = trans_func.apply_image(img)\n",
        "    res_pil = Image.fromarray(res_img.astype(np.uint8))\n",
        "    res_pil.save(os.path.join(folder, img_path.split(\"/\")[1]))\n",
        "\n",
        "    for annotation in ann_json_string[\"annotations\"]:\n",
        "      # updates any annotation\n",
        "      if annotation[\"image_id\"] == id:\n",
        "        res_segm_dict = annotation.copy()\n",
        "        # decodes segmentation\n",
        "        rles = coco_mask.frPyObjects(annotation[\"segmentation\"], height, width)\n",
        "        rle = coco_mask.merge(rles)\n",
        "        mask = coco_mask.decode(rle)\n",
        "        # transforms mask and encodes it\n",
        "        res_mask = trans_func.apply_segmentation(mask)\n",
        "        res_mask = np.asfortranarray(np.squeeze(res_mask))\n",
        "        uncomp = binary_mask_to_rle(res_mask)\n",
        "\n",
        "        encoded_ground_truth = coco_mask.encode(res_mask)\n",
        "        # resizes area and boxes\n",
        "        ground_truth_area = float(coco_mask.area(encoded_ground_truth))\n",
        "        ground_truth_bounding_box = coco_mask.toBbox(encoded_ground_truth).tolist()\n",
        "\n",
        "        res_segm_dict.update({\"segmentation\": uncomp,\n",
        "                            \"area\": ground_truth_area,\n",
        "                            \"bbox\": ground_truth_bounding_box})\n",
        "        res_annotation_list.append(res_segm_dict)\n",
        "\n",
        "  resized_json[\"images\"] = res_imgs_list\n",
        "  resized_json[\"annotations\"] = res_annotation_list\n",
        "  with open(res_imgs_json_path, \"w\") as f:\n",
        "    json.dump(resized_json, f)\n",
        "  return resized_json\n"
      ],
      "metadata": {
        "id": "uEqMML0RLCxb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "jso = resize_split(val_annotations, \"/content/TACO-expl/data/annotations_off_0_resval.json\", \"res_val\" )\n"
      ],
      "metadata": {
        "id": "IBiJJ3eEMts-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "jso = resize_split(test_annotations, \"/content/TACO-expl/data/annotations_off_0_restest.json\", \"res_test\" )\n"
      ],
      "metadata": {
        "id": "u42NsLlNi2v2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally we leave the small script to apply only rotation on training images, as augmentation and pre-processing is automatically dealt with by the MaskDINO framework."
      ],
      "metadata": {
        "id": "Kgl4iiX18WC7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_annotation_file = '/content/TACO-expl/data/annotations_off_0_train.json'\n",
        "\n",
        "with open(train_annotation_file, \"r\") as f:\n",
        "  train_annotations = json.load(f)\n",
        "\n",
        "if not os.path.exists(\"/content/rot_train\"):\n",
        "  os.mkdir(\"/content/rot_train\")\n",
        "\n",
        "for img_info in train_annotations[\"images\"]:\n",
        "  sub_dir = img_info[\"file_name\"].split(\"/\")[0]\n",
        "  folder = os.path.join(\"/content/rot_train\", sub_dir)\n",
        "  if not os.path.exists(folder):\n",
        "      os.mkdir(folder)\n",
        "  img = Image.open(os.path.join(\"/content/MyDrive/MyDrive/official\", img_info[\"file_name\"]))\n",
        "  img = check_rotation_and_alpha(img)\n",
        "\n",
        "\n",
        "  img.save(os.path.join(\"/content/rot_train/\", img_info[\"file_name\"]))\n",
        "\n"
      ],
      "metadata": {
        "id": "Iz4XUiWpQPUQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}